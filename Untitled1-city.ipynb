{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c69b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_GPU = True\n",
    "# Импорт нужных библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from neighbors import Neighborhoods\n",
    "\n",
    "from indices import MainDataset\n",
    "from dnn_utils import preprocess_floor\n",
    "from metric import metrics_stat, deviation_metric\n",
    "\n",
    "def reset_tensorflow_session():\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(41)\n",
    "    np.random.seed(41)\n",
    "\n",
    "\n",
    "THRESHOLD = 0.15\n",
    "NEGATIVE_WEIGHT = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad81492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Категориальные данные\n",
    "CATEGORICAL_FEATURES_COLUMNS = ['region', 'city', 'realty_type', 'floor', 'osm_city_nearest_name', 'street']\n",
    "# Численные данные\n",
    "NUM_FEATURES_COLUMNS = ['lat', 'lng', 'osm_amenity_points_in_0.001',\n",
    "                        'osm_amenity_points_in_0.005', 'osm_amenity_points_in_0.0075',\n",
    "                        'osm_amenity_points_in_0.01', 'osm_building_points_in_0.001',\n",
    "                        'osm_building_points_in_0.005', 'osm_building_points_in_0.0075',\n",
    "                        'osm_building_points_in_0.01', 'osm_catering_points_in_0.001',\n",
    "                        'osm_catering_points_in_0.005', 'osm_catering_points_in_0.0075',\n",
    "                        'osm_catering_points_in_0.01', 'osm_city_closest_dist',\n",
    "                        'osm_city_nearest_population',\n",
    "                        'osm_crossing_closest_dist', 'osm_crossing_points_in_0.001',\n",
    "                        'osm_crossing_points_in_0.005', 'osm_crossing_points_in_0.0075',\n",
    "                        'osm_crossing_points_in_0.01', 'osm_culture_points_in_0.001',\n",
    "                        'osm_culture_points_in_0.005', 'osm_culture_points_in_0.0075',\n",
    "                        'osm_culture_points_in_0.01', 'osm_finance_points_in_0.001',\n",
    "                        'osm_finance_points_in_0.005', 'osm_finance_points_in_0.0075',\n",
    "                        'osm_finance_points_in_0.01', 'osm_healthcare_points_in_0.005',\n",
    "                        'osm_healthcare_points_in_0.0075', 'osm_healthcare_points_in_0.01',\n",
    "                        'osm_historic_points_in_0.005', 'osm_historic_points_in_0.0075',\n",
    "                        'osm_historic_points_in_0.01', 'osm_hotels_points_in_0.005',\n",
    "                        'osm_hotels_points_in_0.0075', 'osm_hotels_points_in_0.01',\n",
    "                        'osm_leisure_points_in_0.005', 'osm_leisure_points_in_0.0075',\n",
    "                        'osm_leisure_points_in_0.01', 'osm_offices_points_in_0.001',\n",
    "                        'osm_offices_points_in_0.005', 'osm_offices_points_in_0.0075',\n",
    "                        'osm_offices_points_in_0.01', 'osm_shops_points_in_0.001',\n",
    "                        'osm_shops_points_in_0.005', 'osm_shops_points_in_0.0075',\n",
    "                        'osm_shops_points_in_0.01', 'osm_subway_closest_dist',\n",
    "                        'osm_train_stop_closest_dist', 'osm_train_stop_points_in_0.005',\n",
    "                        'osm_train_stop_points_in_0.0075', 'osm_train_stop_points_in_0.01',\n",
    "                        'osm_transport_stop_closest_dist', 'osm_transport_stop_points_in_0.005',\n",
    "                        'osm_transport_stop_points_in_0.0075',\n",
    "                        'osm_transport_stop_points_in_0.01',\n",
    "                        'reform_count_of_houses_1000', 'reform_count_of_houses_500',\n",
    "                        'reform_house_population_1000', 'reform_house_population_500',\n",
    "                        'reform_mean_floor_count_1000', 'reform_mean_floor_count_500',\n",
    "                        'reform_mean_year_building_1000', 'reform_mean_year_building_500', 'total_square',\n",
    "                        \"neighbor_dist\", \"neighbor_total_price\", \"neighbor_square_price\", \"neighbor10_dist\",\n",
    "                        \"has_basement\", \"floor_count\"\n",
    "\n",
    "                        ]\n",
    "# Таргет\n",
    "TARGET_COLUMNS = ['per_square_meter_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f38513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "train = train[train.price_type == 1].reset_index(drop=True)\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "dataset = pd.concat([train, test]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5746945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_index = MainDataset(\"dataset/train.csv\")\n",
    "test_dataset_index = MainDataset(\"dataset/test.csv\", need_index=False)\n",
    "neighborhoods = Neighborhoods(train_dataset_index.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b04a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"neighbor_dist\"] = -999\n",
    "dataset[\"neighbor_total_price\"] = -999\n",
    "dataset[\"neighbor_square_price\"] = -999\n",
    "dataset[\"neighbor10_dist\"] = -999\n",
    "\n",
    "for d in [test_dataset_index, train_dataset_index]:\n",
    "    for i, o in enumerate(d.all_objects):\n",
    "        if o.row[\"price_type\"] != 1:\n",
    "            continue\n",
    "        neighbor = neighborhoods.get_haversine_closest(o, 12)\n",
    "        neighbor1 = neighborhoods.get_haversine_closest(o, 2)\n",
    "        n = neighbor[0]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor_dist\"] = n[1]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor_total_price\"] = n[0].row[\"per_square_meter_price\"] * \\\n",
    "                                                                            n[0].row[\"total_square\"]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor_square_price\"] = n[0].row[\"per_square_meter_price\"]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor10_dist\"] = neighbor[10][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43d686ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset=preprocess_floor.preprocess(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe00571",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b44d9345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>floor</th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>osm_amenity_points_in_0.001</th>\n",
       "      <th>osm_amenity_points_in_0.005</th>\n",
       "      <th>osm_amenity_points_in_0.0075</th>\n",
       "      <th>osm_amenity_points_in_0.01</th>\n",
       "      <th>osm_building_points_in_0.001</th>\n",
       "      <th>...</th>\n",
       "      <th>date</th>\n",
       "      <th>realty_type</th>\n",
       "      <th>price_type</th>\n",
       "      <th>is_train</th>\n",
       "      <th>neighbor_dist</th>\n",
       "      <th>neighbor_total_price</th>\n",
       "      <th>neighbor_square_price</th>\n",
       "      <th>neighbor10_dist</th>\n",
       "      <th>has_basement</th>\n",
       "      <th>floor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Красноярск</td>\n",
       "      <td>-999</td>\n",
       "      <td>COL_62</td>\n",
       "      <td>56.063615</td>\n",
       "      <td>92.958428</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334024</td>\n",
       "      <td>995000.0</td>\n",
       "      <td>41458.333333</td>\n",
       "      <td>0.451369</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Саратов</td>\n",
       "      <td>-999</td>\n",
       "      <td>COL_71</td>\n",
       "      <td>51.534581</td>\n",
       "      <td>46.020549</td>\n",
       "      <td>13</td>\n",
       "      <td>198</td>\n",
       "      <td>345</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086136</td>\n",
       "      <td>2985000.0</td>\n",
       "      <td>33166.666667</td>\n",
       "      <td>0.190652</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Красноярск</td>\n",
       "      <td>-999</td>\n",
       "      <td>COL_140</td>\n",
       "      <td>56.026884</td>\n",
       "      <td>92.818323</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027117</td>\n",
       "      <td>18308000.0</td>\n",
       "      <td>61026.666667</td>\n",
       "      <td>0.291762</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Иркутск</td>\n",
       "      <td>-999</td>\n",
       "      <td>COL_202</td>\n",
       "      <td>52.275528</td>\n",
       "      <td>104.251444</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220089</td>\n",
       "      <td>5870000.0</td>\n",
       "      <td>58700.000000</td>\n",
       "      <td>0.435699</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Белгород</td>\n",
       "      <td>-999</td>\n",
       "      <td>COL_207</td>\n",
       "      <td>50.576545</td>\n",
       "      <td>36.584197</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>73</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046677</td>\n",
       "      <td>4179000.0</td>\n",
       "      <td>59700.000000</td>\n",
       "      <td>0.147191</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         city floor       id        lat         lng  \\\n",
       "0  Красноярск  -999   COL_62  56.063615   92.958428   \n",
       "1     Саратов  -999   COL_71  51.534581   46.020549   \n",
       "2  Красноярск  -999  COL_140  56.026884   92.818323   \n",
       "3     Иркутск  -999  COL_202  52.275528  104.251444   \n",
       "4    Белгород  -999  COL_207  50.576545   36.584197   \n",
       "\n",
       "   osm_amenity_points_in_0.001  osm_amenity_points_in_0.005  \\\n",
       "0                            0                            7   \n",
       "1                           13                          198   \n",
       "2                            3                           15   \n",
       "3                            0                           10   \n",
       "4                            4                           48   \n",
       "\n",
       "   osm_amenity_points_in_0.0075  osm_amenity_points_in_0.01  \\\n",
       "0                            14                          26   \n",
       "1                           345                         462   \n",
       "2                            23                          33   \n",
       "3                            26                          40   \n",
       "4                            73                          92   \n",
       "\n",
       "   osm_building_points_in_0.001  ...        date  realty_type  price_type  \\\n",
       "0                             0  ...  2020-01-05          110           1   \n",
       "1                             0  ...  2020-01-05           10           1   \n",
       "2                             0  ...  2020-01-05           10           1   \n",
       "3                             0  ...  2020-01-05           10           1   \n",
       "4                             0  ...  2020-01-05           10           1   \n",
       "\n",
       "   is_train  neighbor_dist  neighbor_total_price  neighbor_square_price  \\\n",
       "0         1       0.334024              995000.0           41458.333333   \n",
       "1         1       0.086136             2985000.0           33166.666667   \n",
       "2         1       0.027117            18308000.0           61026.666667   \n",
       "3         1       0.220089             5870000.0           58700.000000   \n",
       "4         1       0.046677             4179000.0           59700.000000   \n",
       "\n",
       "   neighbor10_dist has_basement  floor_count  \n",
       "0         0.451369         -999         -999  \n",
       "1         0.190652         -999         -999  \n",
       "2         0.291762         -999         -999  \n",
       "3         0.435699         -999         -999  \n",
       "4         0.147191         -999         -999  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2d395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        dict_encoding = {key: val for val, key in enumerate(df[column].unique())}\n",
    "        df[column] = df[column].map(dict_encoding)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96dd82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Квантильное преобразование данных\n",
    "def get_quantile_transform(_df, columns_for_quantilization, random_state=41, n_quantiles=100,\n",
    "                           output_distribution='normal'):\n",
    "    df = _df.copy()\n",
    "    for col in columns_for_quantilization:\n",
    "        qt = QuantileTransformer(random_state=random_state, n_quantiles=n_quantiles,\n",
    "                                 output_distribution=output_distribution)\n",
    "        df[col] = qt.fit_transform(df[[col]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f02ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# МинМакс преобразование данных\n",
    "def get_minmax_transform(_df, columns_for_quantilization, min_value=-1, max_value=1):\n",
    "    df = _df.copy()\n",
    "    for col in columns_for_quantilization:\n",
    "        scaler = MinMaxScaler(feature_range=(min_value, max_value))\n",
    "        df[col] = scaler.fit_transform(df[[col]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a25aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hotencoding для категориальных фичей\n",
    "data = encode_categorical_features(dataset, CATEGORICAL_FEATURES_COLUMNS)\n",
    "# Нормализация численных данных\n",
    "data = get_quantile_transform(data, NUM_FEATURES_COLUMNS)\n",
    "data = get_minmax_transform(data, NUM_FEATURES_COLUMNS)\n",
    "# Заполняем NaN значения\n",
    "data = data.fillna(data.mean())\n",
    "train = data[data.is_train == 1].reset_index(drop=True)\n",
    "test = data[data.is_train == 0].reset_index(drop=True)\n",
    "train = train.drop(columns=['is_train'])\n",
    "test = test.drop(columns=['is_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dda13b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>floor</th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>osm_amenity_points_in_0.001</th>\n",
       "      <th>osm_amenity_points_in_0.005</th>\n",
       "      <th>osm_amenity_points_in_0.0075</th>\n",
       "      <th>osm_amenity_points_in_0.01</th>\n",
       "      <th>osm_building_points_in_0.001</th>\n",
       "      <th>...</th>\n",
       "      <th>date</th>\n",
       "      <th>realty_type</th>\n",
       "      <th>price_type</th>\n",
       "      <th>is_train</th>\n",
       "      <th>neighbor_dist</th>\n",
       "      <th>neighbor_total_price</th>\n",
       "      <th>neighbor_square_price</th>\n",
       "      <th>neighbor10_dist</th>\n",
       "      <th>has_basement</th>\n",
       "      <th>floor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COL_62</td>\n",
       "      <td>0.060226</td>\n",
       "      <td>0.223088</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.234768</td>\n",
       "      <td>-0.256798</td>\n",
       "      <td>-0.245381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.295130</td>\n",
       "      <td>-0.335815</td>\n",
       "      <td>-0.100252</td>\n",
       "      <td>0.117420</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>COL_71</td>\n",
       "      <td>-0.284322</td>\n",
       "      <td>-0.042332</td>\n",
       "      <td>0.298058</td>\n",
       "      <td>0.285412</td>\n",
       "      <td>0.284259</td>\n",
       "      <td>0.272468</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.125504</td>\n",
       "      <td>-0.153689</td>\n",
       "      <td>-0.153689</td>\n",
       "      <td>-0.153382</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COL_140</td>\n",
       "      <td>0.033880</td>\n",
       "      <td>0.146323</td>\n",
       "      <td>0.067077</td>\n",
       "      <td>-0.131259</td>\n",
       "      <td>-0.182216</td>\n",
       "      <td>-0.206562</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.370964</td>\n",
       "      <td>0.158787</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>-0.012065</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>COL_202</td>\n",
       "      <td>-0.206973</td>\n",
       "      <td>0.271530</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.194000</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.178437</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175130</td>\n",
       "      <td>-0.023753</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.108638</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>COL_207</td>\n",
       "      <td>-0.335843</td>\n",
       "      <td>-0.118494</td>\n",
       "      <td>0.110487</td>\n",
       "      <td>0.077531</td>\n",
       "      <td>0.017066</td>\n",
       "      <td>-0.039228</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.260458</td>\n",
       "      <td>-0.092197</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>-0.236639</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   city  floor       id       lat       lng  osm_amenity_points_in_0.001  \\\n",
       "0     0      0   COL_62  0.060226  0.223088                    -1.000000   \n",
       "1     1      0   COL_71 -0.284322 -0.042332                     0.298058   \n",
       "2     0      0  COL_140  0.033880  0.146323                     0.067077   \n",
       "3     2      0  COL_202 -0.206973  0.271530                    -1.000000   \n",
       "4     3      0  COL_207 -0.335843 -0.118494                     0.110487   \n",
       "\n",
       "   osm_amenity_points_in_0.005  osm_amenity_points_in_0.0075  \\\n",
       "0                    -0.234768                     -0.256798   \n",
       "1                     0.285412                      0.284259   \n",
       "2                    -0.131259                     -0.182216   \n",
       "3                    -0.194000                     -0.167492   \n",
       "4                     0.077531                      0.017066   \n",
       "\n",
       "   osm_amenity_points_in_0.01  osm_building_points_in_0.001  ...        date  \\\n",
       "0                   -0.245381                          -1.0  ...  2020-01-05   \n",
       "1                    0.272468                          -1.0  ...  2020-01-05   \n",
       "2                   -0.206562                          -1.0  ...  2020-01-05   \n",
       "3                   -0.178437                          -1.0  ...  2020-01-05   \n",
       "4                   -0.039228                          -1.0  ...  2020-01-05   \n",
       "\n",
       "   realty_type  price_type  is_train  neighbor_dist  neighbor_total_price  \\\n",
       "0            0           1         1       0.295130             -0.335815   \n",
       "1            1           1         1      -0.125504             -0.153689   \n",
       "2            1           1         1      -0.370964              0.158787   \n",
       "3            1           1         1       0.175130             -0.023753   \n",
       "4            1           1         1      -0.260458             -0.092197   \n",
       "\n",
       "   neighbor_square_price  neighbor10_dist  has_basement  floor_count  \n",
       "0              -0.100252         0.117420          -1.0         -1.0  \n",
       "1              -0.153689        -0.153382          -1.0         -1.0  \n",
       "2               0.014434        -0.012065          -1.0         -1.0  \n",
       "3               0.001876         0.108638          -1.0         -1.0  \n",
       "4               0.007306        -0.236639          -1.0         -1.0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ab5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standart_split(data, n_splits=5, seed=41):\n",
    "    kf = KFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
    "    split_list = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        split_list += [(train_index, test_index)]\n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58abc8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(arr_features, arr_target, arr_region, arr_city, arr_realty, batch_size):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            {\n",
    "                \"model_features_input\": arr_features,\n",
    "                \"model_region_input\": arr_region,\n",
    "                \"model_city_input\": arr_city,\n",
    "                \"model_realty_input\": arr_realty,\n",
    "            },\n",
    "            {\n",
    "                \"model_output\": arr_target,\n",
    "            },\n",
    "        )\n",
    "    ).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a920212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_order(columns):\n",
    "    columns_order = sorted([x for x in columns if not x in (CATEGORICAL_FEATURES_COLUMNS + TARGET_COLUMNS)])\n",
    "    return columns_order + CATEGORICAL_FEATURES_COLUMNS + TARGET_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5297a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Коллбэк, для отслеживания целевой метрики\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, val_dataset, val_targets):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.val_targets = val_targets\n",
    "        self.val_dataset = val_dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        predicts = self.model.predict(self.val_dataset)[:, 0]\n",
    "        targets = self.val_targets[:, 0]\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Текущий реальный скор(валидационная часть): {np.round(deviation_metric(targets, predicts), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d10647aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Dropout(x):\n",
    "    return keras.layers.Dropout(x)\n",
    "\n",
    "\n",
    "def Flatten():\n",
    "    return keras.layers.Flatten()\n",
    "\n",
    "\n",
    "def Concatenate():\n",
    "    return keras.layers.Concatenate()\n",
    "\n",
    "\n",
    "# Функция обучения модели\n",
    "def fit(model, epochs, train_dataset, val_dataset, val_targets, verbose=1):\n",
    "    if IS_GPU:\n",
    "        print(f\"Начинаю обучение модели (GPU) количество эпох = {epochs}\")\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            # Коллбэк для остановки, если модель перестала обучаться\n",
    "            early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=2.5e-6,\n",
    "                                                                       patience=100, restore_best_weights=True,\n",
    "                                                                       mode='min')\n",
    "            # Коллбэк для уменьшения скорости обучения\n",
    "            lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-9,\n",
    "                                                               mode='min')\n",
    "            # Кастомный коллбэк для отображения скора по целевой метрике\n",
    "            metric_callback = CustomCallback(val_dataset, val_targets)\n",
    "            history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, verbose=verbose,\n",
    "                                shuffle=True, callbacks=[early_stopping_callback, lr_callback, metric_callback],\n",
    "                                workers=-1)\n",
    "            return history\n",
    "    else:\n",
    "        print(f\"Начинаю обучение модели (СPU) количество эпох = {epochs}\")\n",
    "        # Коллбэк для остановки, если модель перестала обучаться\n",
    "        early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=2.5e-6, patience=100,\n",
    "                                                                   restore_best_weights=True, mode='min')\n",
    "        # Коллбэк для уменьшения скорости обучения\n",
    "        lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-9,\n",
    "                                                           mode='min')\n",
    "        # Кастомный коллбэк для отображения скора по целевой метрике\n",
    "        metric_callback = CustomCallback(val_dataset, val_targets)\n",
    "        history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, verbose=verbose, shuffle=True,\n",
    "                            callbacks=[early_stopping_callback, lr_callback, metric_callback], workers=-1)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76d3c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Реализация кастомной функции потерь для обучения\n",
    "def tf_custom_loss(y_true, y_pred):\n",
    "    threshold = 0.6\n",
    "    error = tf.abs(y_true - y_pred) / y_true\n",
    "    is_small_error = error <= threshold\n",
    "    small_error_loss = tf.square(error / 0.15 - 1)\n",
    "    big_error_loss = 9.0 * tf.ones_like(small_error_loss) + tf.abs(error)\n",
    "    # big_error_loss = (3.0 * tf.ones_like(small_error_loss) + tf.abs(error)) ** 2\n",
    "    return tf.where(is_small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d27cdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Компиляция текущей модели\n",
    "def compile_model(train_dataset, val_dataset, num_features, max_realty, max_region, max_city, lr=5e-4):\n",
    "    reset_tensorflow_session()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    model_input_layer = tf.keras.Input(shape=(num_features), name=\"model_features_input\")\n",
    "    model_input_realty = tf.keras.Input(shape=(1), name=\"model_realty_input\")\n",
    "    model_input_region = tf.keras.Input(shape=(1), name=\"model_region_input\")\n",
    "    model_input_city = tf.keras.Input(shape=(1), name=\"model_city_input\")\n",
    "\n",
    "    model_embedding_layer_realty = keras.layers.Embedding(max_realty + 1, 4, input_length=1, dtype=tf.float64)(\n",
    "        model_input_realty)\n",
    "    model_embedding_layer_region = keras.layers.Embedding(max_region + 1, 32, input_length=1, dtype=tf.float64)(\n",
    "        model_input_region)\n",
    "    model_embedding_layer_city = keras.layers.Embedding(max_city + 1, 32, input_length=1, dtype=tf.float64)(\n",
    "        model_input_city)\n",
    "\n",
    "    concatenated_input_layer = Concatenate()(\n",
    "        [Flatten()(model_embedding_layer_realty), Flatten()(model_embedding_layer_region),\n",
    "         Flatten()(model_embedding_layer_city), Flatten()(model_input_layer)])\n",
    "\n",
    "    layer_0 = keras.layers.Dense(128, activation=\"relu\")(concatenated_input_layer)\n",
    "    layer_1 = keras.layers.Dense(64, activation=\"relu\")(layer_0)\n",
    "    layer_2 = keras.layers.Dense(32, activation=\"relu\")(layer_1)\n",
    "    model_output_layer = keras.layers.Dense(1, activation=\"relu\", name=\"model_output\")(layer_2)\n",
    "\n",
    "    cur_model = keras.Model(\n",
    "        inputs=[\n",
    "            model_input_layer,\n",
    "            model_input_realty,\n",
    "            model_input_region,\n",
    "            model_input_city,\n",
    "        ],\n",
    "        outputs=[\n",
    "            model_output_layer,\n",
    "        ])\n",
    "\n",
    "    print(f\"Модель: input_shape = {cur_model.input_shape} output_shape = {cur_model.output_shape}\")\n",
    "#     cur_model.compile(loss=tf_custom_loss, optimizer=optimizer)  # , run_eagerly=True)\n",
    "    cur_model.compile(loss=tf_custom_loss, optimizer=optimizer)  # , run_eagerly=True)\n",
    "\n",
    "    #\n",
    "    return cur_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "276f6c0d-40c1-4955-8931-3f450c5841ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фолд: 0\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.7972 - val_loss: 1.9045\n",
      "Текущий реальный скор(валидационная часть): 1.8038\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 1.9671 - val_loss: 1.6726\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.6482 - val_loss: 1.5932\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.5028 - val_loss: 1.5527\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.4238 - val_loss: 1.4986\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.3524 - val_loss: 1.5051\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 936us/step - loss: 1.2952 - val_loss: 1.4710\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.2432 - val_loss: 1.4790\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.1885 - val_loss: 1.4588\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.1398 - val_loss: 1.4654\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 1.1031 - val_loss: 1.4639\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.0595 - val_loss: 1.4551\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.0211 - val_loss: 1.4626\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.9884 - val_loss: 1.4613\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.9605 - val_loss: 1.4670\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.9541 - val_loss: 1.4707\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.9310 - val_loss: 1.4831\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.9653 - val_loss: 1.5816\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.9376 - val_loss: 1.5393\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.9103 - val_loss: 1.5429\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.9108 - val_loss: 1.6050\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.8793 - val_loss: 1.6522\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.9114 - val_loss: 1.4555\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.8311 - val_loss: 1.5161\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.7896 - val_loss: 1.5141\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.7633 - val_loss: 1.5339\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.7346 - val_loss: 1.5659\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.7149 - val_loss: 1.6036\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6984 - val_loss: 1.6220\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.6847 - val_loss: 1.6352\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.6705 - val_loss: 1.6172\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.6745 - val_loss: 1.6354\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.7028 - val_loss: 1.5201\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.6738 - val_loss: 1.4803\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.6423 - val_loss: 1.4623\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.6226 - val_loss: 1.4501\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.6097 - val_loss: 1.4413\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5993 - val_loss: 1.4354\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5900 - val_loss: 1.4323\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5820 - val_loss: 1.4299\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5719 - val_loss: 1.4234\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5645 - val_loss: 1.4203\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5672 - val_loss: 1.4204\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5575 - val_loss: 1.4152\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5515 - val_loss: 1.4174\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5460 - val_loss: 1.4176\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5408 - val_loss: 1.4183\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5360 - val_loss: 1.4136\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5312 - val_loss: 1.4193\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.5271 - val_loss: 1.4217\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5228 - val_loss: 1.4173\n",
      "Текущий реальный скор(валидационная часть): 1.3158\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5185 - val_loss: 1.4174\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5146 - val_loss: 1.4164\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5116 - val_loss: 1.4313\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5174 - val_loss: 1.4162\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5061 - val_loss: 1.4073\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.5016 - val_loss: 1.4075\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4969 - val_loss: 1.4120\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4933 - val_loss: 1.4126\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4893 - val_loss: 1.4119\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4863 - val_loss: 1.4174\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4822 - val_loss: 1.4197\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4811 - val_loss: 1.4183\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4756 - val_loss: 1.4186\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4709 - val_loss: 1.4164\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4673 - val_loss: 1.4164\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4659 - val_loss: 1.4101\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4633 - val_loss: 1.4145\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4610 - val_loss: 1.4140\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4591 - val_loss: 1.4159\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4573 - val_loss: 1.4160\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4558 - val_loss: 1.4184\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4541 - val_loss: 1.4153\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4527 - val_loss: 1.4129\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4514 - val_loss: 1.4114\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4499 - val_loss: 1.4087\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4652 - val_loss: 1.3833\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4743 - val_loss: 1.3884\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4743 - val_loss: 1.3859\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4735 - val_loss: 1.3895\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4715 - val_loss: 1.3886\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4688 - val_loss: 1.3896\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4660 - val_loss: 1.3919\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.4634 - val_loss: 1.3946\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4611 - val_loss: 1.3973\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4587 - val_loss: 1.3994\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4567 - val_loss: 1.4006\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4609 - val_loss: 1.4351\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4558 - val_loss: 1.4357\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4537 - val_loss: 1.4360\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4519 - val_loss: 1.4361\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4504 - val_loss: 1.4368\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4489 - val_loss: 1.4370\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.4477 - val_loss: 1.4375\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4464 - val_loss: 1.4378\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4453 - val_loss: 1.4377\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4443 - val_loss: 1.4385\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4437 - val_loss: 1.4360\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4420 - val_loss: 1.4371\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4413 - val_loss: 1.4377\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4407 - val_loss: 1.4380\n",
      "Текущий реальный скор(валидационная часть): 1.3442\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4402 - val_loss: 1.4387\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4397 - val_loss: 1.4388\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4392 - val_loss: 1.4393\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 767us/step - loss: 0.4387 - val_loss: 1.4396\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 770us/step - loss: 0.4382 - val_loss: 1.4396\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4378 - val_loss: 1.4402\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4363 - val_loss: 1.4402\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4358 - val_loss: 1.4409\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4354 - val_loss: 1.4415\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4351 - val_loss: 1.4418\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4349 - val_loss: 1.4421\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4346 - val_loss: 1.4423\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4343 - val_loss: 1.4427\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.4341 - val_loss: 1.4428\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4338 - val_loss: 1.4431\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4336 - val_loss: 1.4433\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4327 - val_loss: 1.4465\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4323 - val_loss: 1.4469\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4321 - val_loss: 1.4471\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4320 - val_loss: 1.4472\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4319 - val_loss: 1.4473\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4318 - val_loss: 1.4475\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4316 - val_loss: 1.4475\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4315 - val_loss: 1.4477\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4314 - val_loss: 1.4477\n",
      "Epoch 127/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4313 - val_loss: 1.4480\n",
      "Epoch 128/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4307 - val_loss: 1.4497\n",
      "Epoch 129/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4305 - val_loss: 1.4503\n",
      "Epoch 130/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4304 - val_loss: 1.4504\n",
      "Epoch 131/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4303 - val_loss: 1.4505\n",
      "Epoch 132/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4303 - val_loss: 1.4506\n",
      "Epoch 133/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4302 - val_loss: 1.4506\n",
      "Epoch 134/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.4302 - val_loss: 1.4508\n",
      "Epoch 135/1000\n",
      "134/134 [==============================] - 0s 770us/step - loss: 0.4301 - val_loss: 1.4508\n",
      "Epoch 136/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4301 - val_loss: 1.4509\n",
      "Epoch 137/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4300 - val_loss: 1.4509\n",
      "Epoch 138/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4296 - val_loss: 1.4515\n",
      "Epoch 139/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4296 - val_loss: 1.4518\n",
      "Epoch 140/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4295 - val_loss: 1.4520\n",
      "Epoch 141/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4295 - val_loss: 1.4521\n",
      "Epoch 142/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4295 - val_loss: 1.4522\n",
      "Epoch 143/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4294 - val_loss: 1.4522\n",
      "Epoch 144/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4294 - val_loss: 1.4523\n",
      "Epoch 145/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4294 - val_loss: 1.4523\n",
      "Epoch 146/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4294 - val_loss: 1.4523\n",
      "Epoch 147/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4293 - val_loss: 1.4524\n",
      "Epoch 148/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4291 - val_loss: 1.4525\n",
      "Epoch 149/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4291 - val_loss: 1.4527\n",
      "Epoch 150/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4291 - val_loss: 1.4528\n",
      "Epoch 151/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4291 - val_loss: 1.4528\n",
      "Текущий реальный скор(валидационная часть): 1.361\n",
      "Epoch 152/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4290 - val_loss: 1.4529\n",
      "Epoch 153/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4290 - val_loss: 1.4529\n",
      "Epoch 154/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4290 - val_loss: 1.4529\n",
      "Epoch 155/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4290 - val_loss: 1.4530\n",
      "Epoch 156/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4290 - val_loss: 1.4530\n",
      "Epoch 157/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.4290 - val_loss: 1.4530\n",
      "Epoch 158/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4289 - val_loss: 1.4531\n",
      "Epoch 159/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4289 - val_loss: 1.4531\n",
      "Epoch 160/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4289 - val_loss: 1.4532\n",
      "Epoch 161/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4288 - val_loss: 1.4532\n",
      "Epoch 162/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4288 - val_loss: 1.4532\n",
      "Epoch 163/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4288 - val_loss: 1.4532\n",
      "Epoch 164/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4288 - val_loss: 1.4533\n",
      "Epoch 165/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4288 - val_loss: 1.4533\n",
      "Epoch 166/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4288 - val_loss: 1.4533\n",
      "Epoch 167/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4288 - val_loss: 1.4533\n",
      "Epoch 168/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4287 - val_loss: 1.4533\n",
      "Epoch 169/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4287 - val_loss: 1.4533\n",
      "Epoch 170/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4287 - val_loss: 1.4534\n",
      "Epoch 171/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4287 - val_loss: 1.4534\n",
      "Epoch 172/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4287 - val_loss: 1.4534\n",
      "Epoch 173/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4287 - val_loss: 1.4534\n",
      "Epoch 174/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4287 - val_loss: 1.4534\n",
      "Epoch 175/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4287 - val_loss: 1.4534\n",
      "Epoch 176/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4287 - val_loss: 1.4534\n",
      "Epoch 177/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4287 - val_loss: 1.4534\n",
      "Скор для фолда(0) : 1.2747 средний скор на префиксе = 1.2747 это заняло = 20 сек.\n",
      "Фолд: 1\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8053 - val_loss: 2.2990\n",
      "Текущий реальный скор(валидационная часть): 2.2171\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.9430 - val_loss: 1.8632\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.6337 - val_loss: 1.7118\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.4909 - val_loss: 1.6361\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.4023 - val_loss: 1.6031\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.3334 - val_loss: 1.5846\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.2825 - val_loss: 1.5794\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.2251 - val_loss: 1.5688\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.1756 - val_loss: 1.5780\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.1293 - val_loss: 1.6112\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.0847 - val_loss: 1.5903\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 1.0535 - val_loss: 1.5667\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.0456 - val_loss: 1.6146\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.0229 - val_loss: 1.6855\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.0048 - val_loss: 1.7043\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.9739 - val_loss: 1.6490\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.9659 - val_loss: 1.5962\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.9405 - val_loss: 1.6070\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.9598 - val_loss: 1.5967\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.9582 - val_loss: 1.5239\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.9302 - val_loss: 1.6662\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.9008 - val_loss: 1.7899\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.9182 - val_loss: 1.7391\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.9666 - val_loss: 1.5880\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.9731 - val_loss: 1.5451\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.0031 - val_loss: 1.7373\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.9374 - val_loss: 1.8502\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.8564 - val_loss: 1.9361\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.8195 - val_loss: 1.9379\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.7893 - val_loss: 1.9146\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7891 - val_loss: 1.5947\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6961 - val_loss: 1.6035\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.6525 - val_loss: 1.6100\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6216 - val_loss: 1.6045\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.6046 - val_loss: 1.6296\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5852 - val_loss: 1.6416\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5691 - val_loss: 1.6411\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5568 - val_loss: 1.6491\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5494 - val_loss: 1.6576\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5327 - val_loss: 1.6772\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5407 - val_loss: 1.6487\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5266 - val_loss: 1.6583\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5149 - val_loss: 1.6670\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5046 - val_loss: 1.6742\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4970 - val_loss: 1.6818\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4899 - val_loss: 1.6843\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4838 - val_loss: 1.6868\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4781 - val_loss: 1.6851\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4728 - val_loss: 1.6855\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4682 - val_loss: 1.6859\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4732 - val_loss: 1.6726\n",
      "Текущий реальный скор(валидационная часть): 1.5688\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4696 - val_loss: 1.6653\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4663 - val_loss: 1.6525\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4631 - val_loss: 1.6483\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4601 - val_loss: 1.6439\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4574 - val_loss: 1.6414\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4549 - val_loss: 1.6392\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4524 - val_loss: 1.6365\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4498 - val_loss: 1.6341\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4477 - val_loss: 1.6330\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4592 - val_loss: 1.5966\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4583 - val_loss: 1.5975\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4544 - val_loss: 1.5974\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4511 - val_loss: 1.5970\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4484 - val_loss: 1.5973\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4459 - val_loss: 1.5976\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4437 - val_loss: 1.5986\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4417 - val_loss: 1.5986\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4398 - val_loss: 1.5998\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4378 - val_loss: 1.6011\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4421 - val_loss: 1.6294\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4393 - val_loss: 1.6290\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4378 - val_loss: 1.6289\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4365 - val_loss: 1.6282\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4353 - val_loss: 1.6284\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4342 - val_loss: 1.6281\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4331 - val_loss: 1.6278\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4322 - val_loss: 1.6278\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4312 - val_loss: 1.6279\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4302 - val_loss: 1.6271\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4316 - val_loss: 1.6342\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4301 - val_loss: 1.6341\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4295 - val_loss: 1.6336\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4290 - val_loss: 1.6335\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4284 - val_loss: 1.6331\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4279 - val_loss: 1.6329\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4274 - val_loss: 1.6327\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4269 - val_loss: 1.6322\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4265 - val_loss: 1.6323\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4260 - val_loss: 1.6320\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4264 - val_loss: 1.6407\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4253 - val_loss: 1.6411\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4250 - val_loss: 1.6411\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4247 - val_loss: 1.6408\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4244 - val_loss: 1.6407\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4242 - val_loss: 1.6404\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4239 - val_loss: 1.6402\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4236 - val_loss: 1.6401\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 778us/step - loss: 0.4234 - val_loss: 1.6399\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4232 - val_loss: 1.6398\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4227 - val_loss: 1.6460\n",
      "Текущий реальный скор(валидационная часть): 1.553\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4220 - val_loss: 1.6468\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4218 - val_loss: 1.6470\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4216 - val_loss: 1.6469\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4215 - val_loss: 1.6468\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4214 - val_loss: 1.6467\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4213 - val_loss: 1.6466\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4212 - val_loss: 1.6465\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4211 - val_loss: 1.6464\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4209 - val_loss: 1.6463\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4203 - val_loss: 1.6483\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4201 - val_loss: 1.6491\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4200 - val_loss: 1.6493\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4199 - val_loss: 1.6493\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4199 - val_loss: 1.6493\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4198 - val_loss: 1.6493\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.4198 - val_loss: 1.6492\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4197 - val_loss: 1.6492\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4197 - val_loss: 1.6492\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4196 - val_loss: 1.6491\n",
      "Скор для фолда(1) : 1.4665 средний скор на префиксе = 1.3706 это заняло = 13 сек.\n",
      "Фолд: 2\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8177 - val_loss: 2.1699\n",
      "Текущий реальный скор(валидационная часть): 2.1166\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 1.9571 - val_loss: 1.8036\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.6582 - val_loss: 1.6027\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.5120 - val_loss: 1.5027\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.4244 - val_loss: 1.5128\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 1.3528 - val_loss: 1.4771\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.2935 - val_loss: 1.4353\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.2340 - val_loss: 1.4289\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.1872 - val_loss: 1.4005\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.1519 - val_loss: 1.3815\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.1126 - val_loss: 1.3611\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 1.0738 - val_loss: 1.3361\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.0406 - val_loss: 1.3460\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 1.0142 - val_loss: 1.3418\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.9908 - val_loss: 1.3605\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.9790 - val_loss: 1.4142\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.9743 - val_loss: 1.4234\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.9623 - val_loss: 1.4194\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.9429 - val_loss: 1.3945\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.9069 - val_loss: 1.3561\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.8526 - val_loss: 1.3832\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.8209 - val_loss: 1.3740\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.8435 - val_loss: 1.3413\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.8040 - val_loss: 1.3543\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.7781 - val_loss: 1.4061\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.7588 - val_loss: 1.4470\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7450 - val_loss: 1.5003\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.7454 - val_loss: 1.5371\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.7369 - val_loss: 1.5525\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.7424 - val_loss: 1.5316\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7494 - val_loss: 1.4648\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.7297 - val_loss: 1.3941\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.6855 - val_loss: 1.2895\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.6428 - val_loss: 1.3040\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6217 - val_loss: 1.3106\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.6067 - val_loss: 1.3131\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5956 - val_loss: 1.3143\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5859 - val_loss: 1.3195\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5758 - val_loss: 1.3200\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5672 - val_loss: 1.3216\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5597 - val_loss: 1.3225\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5531 - val_loss: 1.3228\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5465 - val_loss: 1.3256\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5624 - val_loss: 1.2919\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5655 - val_loss: 1.3060\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5560 - val_loss: 1.3058\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5511 - val_loss: 1.3036\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5465 - val_loss: 1.3022\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5419 - val_loss: 1.3026\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5377 - val_loss: 1.3023\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5339 - val_loss: 1.3020\n",
      "Текущий реальный скор(валидационная часть): 1.2009\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5303 - val_loss: 1.3019\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5267 - val_loss: 1.3005\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5383 - val_loss: 1.3273\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5294 - val_loss: 1.3302\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5238 - val_loss: 1.3314\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5199 - val_loss: 1.3330\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5163 - val_loss: 1.3348\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5132 - val_loss: 1.3354\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5104 - val_loss: 1.3362\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5077 - val_loss: 1.3365\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5053 - val_loss: 1.3374\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5030 - val_loss: 1.3378\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5026 - val_loss: 1.3380\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4999 - val_loss: 1.3368\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4982 - val_loss: 1.3360\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4966 - val_loss: 1.3358\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4952 - val_loss: 1.3359\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4939 - val_loss: 1.3387\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4927 - val_loss: 1.3385\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4915 - val_loss: 1.3383\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4904 - val_loss: 1.3381\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4893 - val_loss: 1.3378\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4891 - val_loss: 1.3285\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4887 - val_loss: 1.3289\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4880 - val_loss: 1.3291\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4874 - val_loss: 1.3294\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4867 - val_loss: 1.3296\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4861 - val_loss: 1.3299\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4856 - val_loss: 1.3300\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4850 - val_loss: 1.3301\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4845 - val_loss: 1.3301\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4839 - val_loss: 1.3303\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4843 - val_loss: 1.3356\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4834 - val_loss: 1.3358\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4830 - val_loss: 1.3359\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4827 - val_loss: 1.3360\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4823 - val_loss: 1.3360\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4821 - val_loss: 1.3362\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4817 - val_loss: 1.3364\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4814 - val_loss: 1.3364\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4812 - val_loss: 1.3365\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4809 - val_loss: 1.3366\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4805 - val_loss: 1.3425\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4796 - val_loss: 1.3434\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4794 - val_loss: 1.3436\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4792 - val_loss: 1.3436\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4791 - val_loss: 1.3437\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4789 - val_loss: 1.3438\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4788 - val_loss: 1.3438\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4787 - val_loss: 1.3439\n",
      "Текущий реальный скор(валидационная часть): 1.248\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 883us/step - loss: 0.4785 - val_loss: 1.3439\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4784 - val_loss: 1.3439\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4778 - val_loss: 1.3461\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4775 - val_loss: 1.3470\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4774 - val_loss: 1.3473\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4773 - val_loss: 1.3474\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4772 - val_loss: 1.3475\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4772 - val_loss: 1.3475\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4771 - val_loss: 1.3475\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4770 - val_loss: 1.3476\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4770 - val_loss: 1.3476\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4769 - val_loss: 1.3476\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4765 - val_loss: 1.3482\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4764 - val_loss: 1.3486\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4764 - val_loss: 1.3488\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4763 - val_loss: 1.3490\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4763 - val_loss: 1.3491\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4763 - val_loss: 1.3492\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4762 - val_loss: 1.3492\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4762 - val_loss: 1.3492\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4762 - val_loss: 1.3493\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4761 - val_loss: 1.3493\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4759 - val_loss: 1.3494\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4759 - val_loss: 1.3496\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4758 - val_loss: 1.3497\n",
      "Epoch 127/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4758 - val_loss: 1.3498\n",
      "Epoch 128/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4758 - val_loss: 1.3498\n",
      "Epoch 129/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4758 - val_loss: 1.3499\n",
      "Epoch 130/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4758 - val_loss: 1.3499\n",
      "Epoch 131/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4758 - val_loss: 1.3500\n",
      "Epoch 132/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4757 - val_loss: 1.3500\n",
      "Epoch 133/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4757 - val_loss: 1.3500\n",
      "Скор для фолда(2) : 1.1847 средний скор на префиксе = 1.3086 это заняло = 15 сек.\n",
      "Фолд: 3\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8065 - val_loss: 2.4962\n",
      "Текущий реальный скор(валидационная часть): 2.4204\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 1.9626 - val_loss: 1.8813\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.6590 - val_loss: 1.6556\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.5114 - val_loss: 1.5689\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 1.4165 - val_loss: 1.5869\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 1.3408 - val_loss: 1.6130\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.2850 - val_loss: 1.6325\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 1.2329 - val_loss: 1.6178\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 1.1868 - val_loss: 1.6319\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.1450 - val_loss: 1.6735\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 1.1150 - val_loss: 1.6804\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.0811 - val_loss: 1.6420\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 767us/step - loss: 1.0415 - val_loss: 1.6150\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 1.0099 - val_loss: 1.6464\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.9925 - val_loss: 1.6300\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.9507 - val_loss: 1.6231\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.9336 - val_loss: 1.6118\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.9188 - val_loss: 1.6086\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.8969 - val_loss: 1.6130\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.8801 - val_loss: 1.6210\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.8670 - val_loss: 1.6200\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.8473 - val_loss: 1.6296\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.8369 - val_loss: 1.6506\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.8297 - val_loss: 1.6885\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.8642 - val_loss: 1.6554\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.8292 - val_loss: 1.6402\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.7951 - val_loss: 1.6290\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.7720 - val_loss: 1.6277\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.7541 - val_loss: 1.6367\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7388 - val_loss: 1.6310\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.7247 - val_loss: 1.6391\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.7138 - val_loss: 1.6357\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.7031 - val_loss: 1.6414\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.6935 - val_loss: 1.6382\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.6925 - val_loss: 1.6202\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.6854 - val_loss: 1.6177\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.6794 - val_loss: 1.6173\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.6743 - val_loss: 1.6171\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.6694 - val_loss: 1.6158\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.6648 - val_loss: 1.6131\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.6603 - val_loss: 1.6117\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6559 - val_loss: 1.6114\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.6517 - val_loss: 1.6104\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6490 - val_loss: 1.6336\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.6644 - val_loss: 1.5852\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.6534 - val_loss: 1.5847\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.6482 - val_loss: 1.5831\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.6442 - val_loss: 1.5821\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.6406 - val_loss: 1.5836\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.6403 - val_loss: 1.5838\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.6350 - val_loss: 1.5849\n",
      "Текущий реальный скор(валидационная часть): 1.4993\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.6318 - val_loss: 1.5847\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.6289 - val_loss: 1.5846\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.6264 - val_loss: 1.5845\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.6247 - val_loss: 1.5890\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.6230 - val_loss: 1.5890\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.6212 - val_loss: 1.5889\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.6196 - val_loss: 1.5890\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.6181 - val_loss: 1.5890\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.6168 - val_loss: 1.5890\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.6154 - val_loss: 1.5891\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.6141 - val_loss: 1.5890\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.6128 - val_loss: 1.5888\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.6115 - val_loss: 1.5888\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.6083 - val_loss: 1.5863\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.6073 - val_loss: 1.5841\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.6048 - val_loss: 1.5867\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.6039 - val_loss: 1.5860\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.6033 - val_loss: 1.5860\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.6026 - val_loss: 1.5857\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.6020 - val_loss: 1.5859\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.6014 - val_loss: 1.5857\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.6008 - val_loss: 1.5858\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.6002 - val_loss: 1.5855\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.5983 - val_loss: 1.5875\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5979 - val_loss: 1.5875\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5976 - val_loss: 1.5903\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5973 - val_loss: 1.5902\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5970 - val_loss: 1.5903\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5967 - val_loss: 1.5902\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5964 - val_loss: 1.5902\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5961 - val_loss: 1.5902\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5958 - val_loss: 1.5902\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5955 - val_loss: 1.5902\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5944 - val_loss: 1.5912\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.5941 - val_loss: 1.5914\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5940 - val_loss: 1.5915\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5938 - val_loss: 1.5915\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5937 - val_loss: 1.5915\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5935 - val_loss: 1.5915\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5934 - val_loss: 1.5916\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5933 - val_loss: 1.5915\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5931 - val_loss: 1.5915\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5930 - val_loss: 1.5915\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5923 - val_loss: 1.5919\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.5922 - val_loss: 1.5921\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5921 - val_loss: 1.5921\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5921 - val_loss: 1.5922\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5920 - val_loss: 1.5922\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.5919 - val_loss: 1.5922\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5918 - val_loss: 1.5922\n",
      "Текущий реальный скор(валидационная часть): 1.507\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.5918 - val_loss: 1.5922\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5917 - val_loss: 1.5922\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5916 - val_loss: 1.5922\n",
      "Скор для фолда(3) : 1.4899 средний скор на префиксе = 1.354 это заняло = 11 сек.\n",
      "Фолд: 4\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8121 - val_loss: 2.4741\n",
      "Текущий реальный скор(валидационная часть): 2.4339\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 1.9421 - val_loss: 1.9108\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.6463 - val_loss: 1.8070\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.5134 - val_loss: 1.7501\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 1.4070 - val_loss: 1.7102\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 1.3315 - val_loss: 1.7160\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 1.2748 - val_loss: 1.7611\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.2252 - val_loss: 1.7405\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 1.1785 - val_loss: 1.7867\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 1.1399 - val_loss: 1.8739\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.1083 - val_loss: 1.8012\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 1.0681 - val_loss: 1.8407\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.0356 - val_loss: 1.8745\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.0264 - val_loss: 1.8428\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.0506 - val_loss: 1.6971\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.0767 - val_loss: 1.5930\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.0507 - val_loss: 1.6414\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 1.0177 - val_loss: 1.6530\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.9673 - val_loss: 1.6024\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.9180 - val_loss: 1.6459\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.8609 - val_loss: 1.6880\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.8285 - val_loss: 1.7125\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.7878 - val_loss: 1.7253\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.7583 - val_loss: 1.7453\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.7398 - val_loss: 1.7471\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.7151 - val_loss: 1.8099\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.8395 - val_loss: 2.0620\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.8709 - val_loss: 2.0089\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.8172 - val_loss: 1.8946\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.7588 - val_loss: 1.7608\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.6986 - val_loss: 1.7655\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.6667 - val_loss: 1.7601\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.6450 - val_loss: 1.7632\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.6254 - val_loss: 1.7800\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.6080 - val_loss: 1.7710\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5925 - val_loss: 1.7676\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.6088 - val_loss: 1.7710\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5820 - val_loss: 1.7797\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5656 - val_loss: 1.7869\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.5542 - val_loss: 1.7941\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.5452 - val_loss: 1.7981\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5371 - val_loss: 1.7975\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.5301 - val_loss: 1.7965\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5229 - val_loss: 1.7926\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5165 - val_loss: 1.7938\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 762us/step - loss: 0.5108 - val_loss: 1.7936\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.5267 - val_loss: 1.7317\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.5209 - val_loss: 1.7378\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5104 - val_loss: 1.7389\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.5030 - val_loss: 1.7396\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4971 - val_loss: 1.7406\n",
      "Текущий реальный скор(валидационная часть): 1.6269\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 774us/step - loss: 0.4923 - val_loss: 1.7476\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4877 - val_loss: 1.7445\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4835 - val_loss: 1.7494\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4798 - val_loss: 1.7466\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4759 - val_loss: 1.7520\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 765us/step - loss: 0.4732 - val_loss: 1.7329\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4695 - val_loss: 1.7341\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4672 - val_loss: 1.7363\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4651 - val_loss: 1.7371\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4632 - val_loss: 1.7393\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4616 - val_loss: 1.7398\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4600 - val_loss: 1.7415\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4584 - val_loss: 1.7442\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4569 - val_loss: 1.7462\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4554 - val_loss: 1.7470\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4566 - val_loss: 1.7491\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.4551 - val_loss: 1.7492\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4541 - val_loss: 1.7494\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4531 - val_loss: 1.7493\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4522 - val_loss: 1.7494\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4514 - val_loss: 1.7493\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.4506 - val_loss: 1.7496\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4498 - val_loss: 1.7498\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4490 - val_loss: 1.7496\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4482 - val_loss: 1.7474\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4500 - val_loss: 1.7404\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4498 - val_loss: 1.7408\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4493 - val_loss: 1.7420\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4488 - val_loss: 1.7425\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4484 - val_loss: 1.7431\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4479 - val_loss: 1.7434\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4475 - val_loss: 1.7440\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4471 - val_loss: 1.7442\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4467 - val_loss: 1.7448\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4463 - val_loss: 1.7452\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4486 - val_loss: 1.7553\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4477 - val_loss: 1.7562\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 763us/step - loss: 0.4473 - val_loss: 1.7570\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.4470 - val_loss: 1.7577\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4467 - val_loss: 1.7583\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4465 - val_loss: 1.7589\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4462 - val_loss: 1.7594\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4459 - val_loss: 1.7598\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.4457 - val_loss: 1.7603\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4454 - val_loss: 1.7607\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4458 - val_loss: 1.7736\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4446 - val_loss: 1.7744\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4444 - val_loss: 1.7747\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4442 - val_loss: 1.7748\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4441 - val_loss: 1.7750\n",
      "Текущий реальный скор(валидационная часть): 1.6662\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4440 - val_loss: 1.7751\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4438 - val_loss: 1.7753\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4437 - val_loss: 1.7753\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4436 - val_loss: 1.7755\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4434 - val_loss: 1.7756\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4430 - val_loss: 1.7777\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4427 - val_loss: 1.7785\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4425 - val_loss: 1.7788\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4424 - val_loss: 1.7789\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.4424 - val_loss: 1.7790\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4423 - val_loss: 1.7791\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4422 - val_loss: 1.7791\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4422 - val_loss: 1.7792\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 762us/step - loss: 0.4421 - val_loss: 1.7792\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4421 - val_loss: 1.7793\n",
      "Скор для фолда(4) : 1.4995 средний скор на префиксе = 1.3831 это заняло = 13 сек.\n",
      "Фолд: 5\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.7942 - val_loss: 2.6035\n",
      "Текущий реальный скор(валидационная часть): 2.4889\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.9359 - val_loss: 2.1462\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.6323 - val_loss: 2.0329\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 730us/step - loss: 1.4599 - val_loss: 1.9944\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 1.3871 - val_loss: 1.9271\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 1.3107 - val_loss: 1.9055\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 1.2453 - val_loss: 1.8958\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.1931 - val_loss: 1.9005\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.1491 - val_loss: 1.9706\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.1057 - val_loss: 1.9904\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.0615 - val_loss: 1.9993\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.0326 - val_loss: 1.9492\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.9938 - val_loss: 1.9731\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.9595 - val_loss: 1.9144\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.9395 - val_loss: 1.9574\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.9407 - val_loss: 2.0330\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.9400 - val_loss: 1.9372\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.9657 - val_loss: 1.9239\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.8814 - val_loss: 1.8926\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.8486 - val_loss: 1.8334\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.8241 - val_loss: 1.8249\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.8060 - val_loss: 1.8092\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.7997 - val_loss: 1.8663\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.7858 - val_loss: 1.8925\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.7727 - val_loss: 1.9306\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.7592 - val_loss: 1.9575\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.7469 - val_loss: 1.9866\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.7386 - val_loss: 2.0464\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7284 - val_loss: 2.1023\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.7266 - val_loss: 2.1284\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.7261 - val_loss: 2.1822\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.7274 - val_loss: 2.1812\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.7694 - val_loss: 1.8345\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.7267 - val_loss: 1.7632\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6818 - val_loss: 1.7532\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6559 - val_loss: 1.7472\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6403 - val_loss: 1.7443\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6219 - val_loss: 1.7379\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.6107 - val_loss: 1.7324\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5995 - val_loss: 1.7332\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5919 - val_loss: 1.7299\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5825 - val_loss: 1.7327\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5759 - val_loss: 1.7304\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.5677 - val_loss: 1.7323\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5619 - val_loss: 1.7332\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5539 - val_loss: 1.7304\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5477 - val_loss: 1.7316\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5417 - val_loss: 1.7302\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.5361 - val_loss: 1.7258\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5310 - val_loss: 1.7303\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.5259 - val_loss: 1.7248\n",
      "Текущий реальный скор(валидационная часть): 1.6398\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5210 - val_loss: 1.7247\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5165 - val_loss: 1.7220\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5116 - val_loss: 1.7181\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5065 - val_loss: 1.7129\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 870us/step - loss: 0.5019 - val_loss: 1.7118\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4974 - val_loss: 1.7063\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4930 - val_loss: 1.7076\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4888 - val_loss: 1.6994\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4856 - val_loss: 1.7004\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.4813 - val_loss: 1.6927\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.4781 - val_loss: 1.6931\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4732 - val_loss: 1.6932\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4688 - val_loss: 1.6908\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.4648 - val_loss: 1.6879\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4618 - val_loss: 1.6775\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4592 - val_loss: 1.6742\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4560 - val_loss: 1.6687\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4531 - val_loss: 1.6700\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4498 - val_loss: 1.6633\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4467 - val_loss: 1.6670\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.4435 - val_loss: 1.6598\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4406 - val_loss: 1.6504\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4391 - val_loss: 1.6462\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4357 - val_loss: 1.6446\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4313 - val_loss: 1.6367\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4283 - val_loss: 1.6367\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4265 - val_loss: 1.6368\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4235 - val_loss: 1.6441\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4203 - val_loss: 1.6331\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.4145 - val_loss: 1.6354\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4108 - val_loss: 1.6325\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4079 - val_loss: 1.6349\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4054 - val_loss: 1.6309\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.4030 - val_loss: 1.6302\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4006 - val_loss: 1.6288\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3994 - val_loss: 1.6290\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3981 - val_loss: 1.6253\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.3963 - val_loss: 1.6313\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3937 - val_loss: 1.6261\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3942 - val_loss: 1.6143\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3904 - val_loss: 1.6281\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.3883 - val_loss: 1.6172\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3882 - val_loss: 1.6246\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3950 - val_loss: 1.6547\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3936 - val_loss: 1.6478\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3995 - val_loss: 1.6441\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4027 - val_loss: 1.6467\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.4067 - val_loss: 1.6809\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4137 - val_loss: 1.7188\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4097 - val_loss: 1.6880\n",
      "Текущий реальный скор(валидационная часть): 1.6092\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4046 - val_loss: 1.6442\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3878 - val_loss: 1.6543\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.3822 - val_loss: 1.6585\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3789 - val_loss: 1.6622\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3757 - val_loss: 1.6604\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3732 - val_loss: 1.6609\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3711 - val_loss: 1.6597\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3692 - val_loss: 1.6603\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3675 - val_loss: 1.6598\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3658 - val_loss: 1.6593\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3977 - val_loss: 1.6557\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3982 - val_loss: 1.6543\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3959 - val_loss: 1.6620\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3927 - val_loss: 1.6668\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3895 - val_loss: 1.6718\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3864 - val_loss: 1.6762\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3834 - val_loss: 1.6801\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3808 - val_loss: 1.6840\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3777 - val_loss: 1.6845\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3745 - val_loss: 1.6882\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3819 - val_loss: 1.7258\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3794 - val_loss: 1.7238\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3762 - val_loss: 1.7221\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3737 - val_loss: 1.7208\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3716 - val_loss: 1.7197\n",
      "Epoch 127/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3697 - val_loss: 1.7185\n",
      "Epoch 128/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3680 - val_loss: 1.7180\n",
      "Epoch 129/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3664 - val_loss: 1.7170\n",
      "Epoch 130/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3649 - val_loss: 1.7164\n",
      "Epoch 131/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3636 - val_loss: 1.7157\n",
      "Epoch 132/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3663 - val_loss: 1.6877\n",
      "Epoch 133/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3622 - val_loss: 1.6876\n",
      "Epoch 134/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3612 - val_loss: 1.6879\n",
      "Epoch 135/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3603 - val_loss: 1.6886\n",
      "Epoch 136/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3595 - val_loss: 1.6891\n",
      "Epoch 137/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.3588 - val_loss: 1.6895\n",
      "Epoch 138/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3581 - val_loss: 1.6903\n",
      "Epoch 139/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3574 - val_loss: 1.6904\n",
      "Epoch 140/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3568 - val_loss: 1.6911\n",
      "Epoch 141/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3562 - val_loss: 1.6914\n",
      "Epoch 142/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3557 - val_loss: 1.6914\n",
      "Epoch 143/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3547 - val_loss: 1.6928\n",
      "Epoch 144/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3543 - val_loss: 1.6934\n",
      "Epoch 145/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3539 - val_loss: 1.6939\n",
      "Epoch 146/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3535 - val_loss: 1.6944\n",
      "Epoch 147/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3532 - val_loss: 1.6948\n",
      "Epoch 148/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3529 - val_loss: 1.6953\n",
      "Epoch 149/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3526 - val_loss: 1.6957\n",
      "Epoch 150/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3523 - val_loss: 1.6961\n",
      "Epoch 151/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3520 - val_loss: 1.6964\n",
      "Текущий реальный скор(валидационная часть): 1.6203\n",
      "Epoch 152/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3508 - val_loss: 1.7021\n",
      "Epoch 153/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3501 - val_loss: 1.7032\n",
      "Epoch 154/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.3499 - val_loss: 1.7037\n",
      "Epoch 155/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3497 - val_loss: 1.7040\n",
      "Epoch 156/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3495 - val_loss: 1.7042\n",
      "Epoch 157/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3494 - val_loss: 1.7044\n",
      "Epoch 158/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3492 - val_loss: 1.7046\n",
      "Epoch 159/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3491 - val_loss: 1.7048\n",
      "Epoch 160/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3489 - val_loss: 1.7050\n",
      "Epoch 161/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3488 - val_loss: 1.7051\n",
      "Epoch 162/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3478 - val_loss: 1.7076\n",
      "Epoch 163/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3476 - val_loss: 1.7085\n",
      "Epoch 164/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3475 - val_loss: 1.7089\n",
      "Epoch 165/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3474 - val_loss: 1.7091\n",
      "Epoch 166/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3473 - val_loss: 1.7093\n",
      "Epoch 167/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3473 - val_loss: 1.7094\n",
      "Epoch 168/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3472 - val_loss: 1.7095\n",
      "Epoch 169/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3471 - val_loss: 1.7096\n",
      "Epoch 170/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3471 - val_loss: 1.7097\n",
      "Epoch 171/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3470 - val_loss: 1.7098\n",
      "Epoch 172/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3464 - val_loss: 1.7105\n",
      "Epoch 173/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3463 - val_loss: 1.7109\n",
      "Epoch 174/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3463 - val_loss: 1.7112\n",
      "Epoch 175/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3462 - val_loss: 1.7114\n",
      "Epoch 176/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.3462 - val_loss: 1.7115\n",
      "Epoch 177/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3462 - val_loss: 1.7116\n",
      "Epoch 178/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3461 - val_loss: 1.7117\n",
      "Epoch 179/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3461 - val_loss: 1.7118\n",
      "Epoch 180/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3461 - val_loss: 1.7118\n",
      "Epoch 181/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3460 - val_loss: 1.7119\n",
      "Epoch 182/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3457 - val_loss: 1.7121\n",
      "Epoch 183/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3457 - val_loss: 1.7122\n",
      "Epoch 184/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3456 - val_loss: 1.7123\n",
      "Epoch 185/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3456 - val_loss: 1.7124\n",
      "Epoch 186/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3456 - val_loss: 1.7125\n",
      "Epoch 187/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.3456 - val_loss: 1.7126\n",
      "Epoch 188/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3456 - val_loss: 1.7127\n",
      "Epoch 189/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3455 - val_loss: 1.7127\n",
      "Epoch 190/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.3455 - val_loss: 1.7127\n",
      "Epoch 191/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3455 - val_loss: 1.7128\n",
      "Скор для фолда(5) : 1.5339 средний скор на префиксе = 1.4082 это заняло = 21 сек.\n",
      "Фолд: 6\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8004 - val_loss: 2.0567\n",
      "Текущий реальный скор(валидационная часть): 1.9814\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.9796 - val_loss: 1.5840\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.6699 - val_loss: 1.5002\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.5209 - val_loss: 1.4063\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 1.4205 - val_loss: 1.3368\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.3556 - val_loss: 1.3046\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 1.3036 - val_loss: 1.3189\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.2555 - val_loss: 1.3489\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.2065 - val_loss: 1.2674\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.1609 - val_loss: 1.2114\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.1272 - val_loss: 1.3357\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.0860 - val_loss: 1.1868\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.0554 - val_loss: 1.1631\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.0168 - val_loss: 1.2515\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.0109 - val_loss: 1.1479\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.9760 - val_loss: 1.1548\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.9597 - val_loss: 1.2127\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.9186 - val_loss: 1.3119\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.8902 - val_loss: 1.2434\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.8807 - val_loss: 1.2451\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.8710 - val_loss: 1.2447\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.8707 - val_loss: 1.2098\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.8794 - val_loss: 1.2315\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.8589 - val_loss: 1.1802\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.8463 - val_loss: 1.2268\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.8379 - val_loss: 1.3593\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.7854 - val_loss: 1.3851\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7530 - val_loss: 1.3671\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.7314 - val_loss: 1.3368\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.7145 - val_loss: 1.3262\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7064 - val_loss: 1.2980\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6938 - val_loss: 1.2835\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6823 - val_loss: 1.2611\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6737 - val_loss: 1.2304\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6478 - val_loss: 1.2277\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6280 - val_loss: 1.1946\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.5930 - val_loss: 1.2108\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.5701 - val_loss: 1.2138\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5557 - val_loss: 1.2196\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5449 - val_loss: 1.2218\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5357 - val_loss: 1.2258\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5268 - val_loss: 1.1953\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5274 - val_loss: 1.2356\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5154 - val_loss: 1.2373\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5086 - val_loss: 1.2433\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.5159 - val_loss: 1.2152\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5083 - val_loss: 1.2141\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5040 - val_loss: 1.2122\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.5003 - val_loss: 1.2111\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4968 - val_loss: 1.2117\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4934 - val_loss: 1.2127\n",
      "Текущий реальный скор(валидационная часть): 1.1205\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.4905 - val_loss: 1.2148\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4875 - val_loss: 1.2153\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4847 - val_loss: 1.2168\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4819 - val_loss: 1.2204\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4929 - val_loss: 1.1951\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.4903 - val_loss: 1.1987\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4868 - val_loss: 1.2035\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4835 - val_loss: 1.2040\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.4809 - val_loss: 1.2055\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4784 - val_loss: 1.2072\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4762 - val_loss: 1.2078\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4741 - val_loss: 1.2095\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4721 - val_loss: 1.2107\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4703 - val_loss: 1.2118\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4746 - val_loss: 1.2132\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4711 - val_loss: 1.2122\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4696 - val_loss: 1.2123\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.4682 - val_loss: 1.2127\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.4670 - val_loss: 1.2131\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.4659 - val_loss: 1.2128\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4648 - val_loss: 1.2130\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4638 - val_loss: 1.2133\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4628 - val_loss: 1.2140\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4617 - val_loss: 1.2143\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4654 - val_loss: 1.2104\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4653 - val_loss: 1.2099\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4646 - val_loss: 1.2096\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4640 - val_loss: 1.2095\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4634 - val_loss: 1.2093\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4627 - val_loss: 1.2093\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4622 - val_loss: 1.2096\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4616 - val_loss: 1.2099\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4610 - val_loss: 1.2099\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4605 - val_loss: 1.2101\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4639 - val_loss: 1.2158\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 940us/step - loss: 0.4623 - val_loss: 1.2162\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 764us/step - loss: 0.4619 - val_loss: 1.2164\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4615 - val_loss: 1.2166\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4611 - val_loss: 1.2167\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4606 - val_loss: 1.2167\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4603 - val_loss: 1.2168\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4599 - val_loss: 1.2168\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4596 - val_loss: 1.2168\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4593 - val_loss: 1.2168\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.4596 - val_loss: 1.2220\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4580 - val_loss: 1.2232\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4576 - val_loss: 1.2233\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4574 - val_loss: 1.2231\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4572 - val_loss: 1.2230\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4571 - val_loss: 1.2230\n",
      "Текущий реальный скор(валидационная часть): 1.1421\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4569 - val_loss: 1.2229\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4567 - val_loss: 1.2228\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.4566 - val_loss: 1.2227\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4564 - val_loss: 1.2226\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.4559 - val_loss: 1.2255\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4554 - val_loss: 1.2265\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4552 - val_loss: 1.2269\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4551 - val_loss: 1.2270\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4550 - val_loss: 1.2270\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4549 - val_loss: 1.2270\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4549 - val_loss: 1.2270\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4548 - val_loss: 1.2270\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4547 - val_loss: 1.2269\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4546 - val_loss: 1.2269\n",
      "Скор для фолда(6) : 1.0574 средний скор на префиксе = 1.3581 это заняло = 13 сек.\n",
      "Фолд: 7\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8216 - val_loss: 2.5493\n",
      "Текущий реальный скор(валидационная часть): 2.4635\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.9736 - val_loss: 1.8488\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.6644 - val_loss: 1.6952\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.5163 - val_loss: 1.6609\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.4305 - val_loss: 1.6246\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.3552 - val_loss: 1.5360\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.2912 - val_loss: 1.5235\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.2344 - val_loss: 1.5202\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.1798 - val_loss: 1.5292\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.1287 - val_loss: 1.5324\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.0892 - val_loss: 1.5272\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.0492 - val_loss: 1.5672\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 1.0133 - val_loss: 1.5790\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.9860 - val_loss: 1.5483\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.9708 - val_loss: 1.6450\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 825us/step - loss: 0.9596 - val_loss: 1.7117\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.9303 - val_loss: 1.8596\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.9184 - val_loss: 1.7414\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.9445 - val_loss: 1.5687\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.8705 - val_loss: 1.6165\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.8253 - val_loss: 1.6664\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.7991 - val_loss: 1.6879\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.7787 - val_loss: 1.6992\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.7618 - val_loss: 1.7379\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7467 - val_loss: 1.7714\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7307 - val_loss: 1.7934\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.7166 - val_loss: 1.8315\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.7021 - val_loss: 1.8537\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7534 - val_loss: 1.5060\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7120 - val_loss: 1.4992\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6848 - val_loss: 1.4989\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6646 - val_loss: 1.4933\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6461 - val_loss: 1.4962\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.6377 - val_loss: 1.4831\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6258 - val_loss: 1.4815\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6150 - val_loss: 1.4792\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6056 - val_loss: 1.4789\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5976 - val_loss: 1.4801\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5899 - val_loss: 1.4823\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5841 - val_loss: 1.4891\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5910 - val_loss: 1.4753\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5728 - val_loss: 1.4823\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5662 - val_loss: 1.4791\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5594 - val_loss: 1.4902\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5541 - val_loss: 1.4865\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5477 - val_loss: 1.4930\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5422 - val_loss: 1.4998\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5377 - val_loss: 1.5016\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5325 - val_loss: 1.5060\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5285 - val_loss: 1.5086\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5237 - val_loss: 1.5147\n",
      "Текущий реальный скор(валидационная часть): 1.4195\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5247 - val_loss: 1.5213\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5226 - val_loss: 1.5320\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5202 - val_loss: 1.5364\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5181 - val_loss: 1.5382\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5158 - val_loss: 1.5393\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5136 - val_loss: 1.5378\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5121 - val_loss: 1.5394\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5097 - val_loss: 1.5384\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5074 - val_loss: 1.5398\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5052 - val_loss: 1.5385\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5271 - val_loss: 1.4685\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5257 - val_loss: 1.4668\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5204 - val_loss: 1.4665\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5158 - val_loss: 1.4652\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5117 - val_loss: 1.4654\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5082 - val_loss: 1.4661\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5048 - val_loss: 1.4667\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5017 - val_loss: 1.4675\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4990 - val_loss: 1.4683\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4965 - val_loss: 1.4688\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4944 - val_loss: 1.4705\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4923 - val_loss: 1.4704\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4903 - val_loss: 1.4715\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4884 - val_loss: 1.4718\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4893 - val_loss: 1.5086\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4867 - val_loss: 1.5083\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4851 - val_loss: 1.5081\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4838 - val_loss: 1.5081\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4825 - val_loss: 1.5076\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4814 - val_loss: 1.5081\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4803 - val_loss: 1.5083\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4793 - val_loss: 1.5083\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4783 - val_loss: 1.5083\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4774 - val_loss: 1.5086\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4782 - val_loss: 1.5101\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4768 - val_loss: 1.5099\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4762 - val_loss: 1.5093\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4756 - val_loss: 1.5089\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4751 - val_loss: 1.5084\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4746 - val_loss: 1.5083\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4742 - val_loss: 1.5079\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4737 - val_loss: 1.5051\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4733 - val_loss: 1.5050\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4729 - val_loss: 1.5047\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4736 - val_loss: 1.5060\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4730 - val_loss: 1.5073\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4726 - val_loss: 1.5079\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4723 - val_loss: 1.5083\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4720 - val_loss: 1.5087\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4718 - val_loss: 1.5089\n",
      "Текущий реальный скор(валидационная часть): 1.4141\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4715 - val_loss: 1.5092\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4713 - val_loss: 1.5094\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4710 - val_loss: 1.5096\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4708 - val_loss: 1.5098\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 778us/step - loss: 0.4708 - val_loss: 1.5189\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 876us/step - loss: 0.4699 - val_loss: 1.5226\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 776us/step - loss: 0.4697 - val_loss: 1.5229\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 766us/step - loss: 0.4696 - val_loss: 1.5231\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 766us/step - loss: 0.4694 - val_loss: 1.5233\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 775us/step - loss: 0.4693 - val_loss: 1.5234\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 770us/step - loss: 0.4692 - val_loss: 1.5235\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 777us/step - loss: 0.4691 - val_loss: 1.5237\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 774us/step - loss: 0.4690 - val_loss: 1.5239\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 780us/step - loss: 0.4688 - val_loss: 1.5239\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 0s 772us/step - loss: 0.4685 - val_loss: 1.5302\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - 0s 768us/step - loss: 0.4681 - val_loss: 1.5312\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4680 - val_loss: 1.5316\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4679 - val_loss: 1.5317\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4678 - val_loss: 1.5319\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4678 - val_loss: 1.5320\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4677 - val_loss: 1.5320\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4676 - val_loss: 1.5321\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4676 - val_loss: 1.5321\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4675 - val_loss: 1.5322\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4672 - val_loss: 1.5333\n",
      "Epoch 127/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4671 - val_loss: 1.5339\n",
      "Epoch 128/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4670 - val_loss: 1.5343\n",
      "Epoch 129/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4670 - val_loss: 1.5345\n",
      "Epoch 130/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4670 - val_loss: 1.5346\n",
      "Epoch 131/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.4669 - val_loss: 1.5347\n",
      "Epoch 132/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4669 - val_loss: 1.5348\n",
      "Epoch 133/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4669 - val_loss: 1.5348\n",
      "Epoch 134/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4668 - val_loss: 1.5349\n",
      "Epoch 135/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4668 - val_loss: 1.5349\n",
      "Epoch 136/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4666 - val_loss: 1.5352\n",
      "Epoch 137/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4666 - val_loss: 1.5355\n",
      "Epoch 138/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4665 - val_loss: 1.5357\n",
      "Epoch 139/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4665 - val_loss: 1.5358\n",
      "Epoch 140/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4665 - val_loss: 1.5359\n",
      "Epoch 141/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4665 - val_loss: 1.5360\n",
      "Epoch 142/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4665 - val_loss: 1.5360\n",
      "Epoch 143/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4665 - val_loss: 1.5361\n",
      "Epoch 144/1000\n",
      "134/134 [==============================] - 0s 765us/step - loss: 0.4665 - val_loss: 1.5361\n",
      "Epoch 145/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4664 - val_loss: 1.5361\n",
      "Epoch 146/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4663 - val_loss: 1.5362\n",
      "Epoch 147/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4663 - val_loss: 1.5363\n",
      "Epoch 148/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4663 - val_loss: 1.5364\n",
      "Epoch 149/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4663 - val_loss: 1.5365\n",
      "Epoch 150/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4663 - val_loss: 1.5365\n",
      "Epoch 151/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4663 - val_loss: 1.5366\n",
      "Текущий реальный скор(валидационная часть): 1.4354\n",
      "Epoch 152/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4663 - val_loss: 1.5366\n",
      "Epoch 153/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4663 - val_loss: 1.5366\n",
      "Epoch 154/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4663 - val_loss: 1.5367\n",
      "Epoch 155/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4662 - val_loss: 1.5367\n",
      "Epoch 156/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4662 - val_loss: 1.5367\n",
      "Epoch 157/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4662 - val_loss: 1.5368\n",
      "Epoch 158/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4662 - val_loss: 1.5368\n",
      "Epoch 159/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4662 - val_loss: 1.5368\n",
      "Epoch 160/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4662 - val_loss: 1.5369\n",
      "Epoch 161/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4662 - val_loss: 1.5369\n",
      "Epoch 162/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4662 - val_loss: 1.5369\n",
      "Epoch 163/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4662 - val_loss: 1.5369\n",
      "Epoch 164/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4662 - val_loss: 1.5369\n",
      "Epoch 165/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4662 - val_loss: 1.5370\n",
      "Скор для фолда(7) : 1.3747 средний скор на префиксе = 1.3602 это заняло = 18 сек.\n",
      "Фолд: 8\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8251 - val_loss: 1.8822\n",
      "Текущий реальный скор(валидационная часть): 1.8267\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.9746 - val_loss: 1.4593\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.6767 - val_loss: 1.4257\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 1.5162 - val_loss: 1.3124\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.4206 - val_loss: 1.2572\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.3562 - val_loss: 1.2567\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.3010 - val_loss: 1.2395\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.2449 - val_loss: 1.2236\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.1961 - val_loss: 1.2685\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.1483 - val_loss: 1.2161\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.1040 - val_loss: 1.2097\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.0719 - val_loss: 1.2210\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.0446 - val_loss: 1.2466\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.0308 - val_loss: 1.3287\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.0318 - val_loss: 1.3847\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.0024 - val_loss: 1.2258\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.0034 - val_loss: 1.2048\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.9679 - val_loss: 1.2079\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.9581 - val_loss: 1.2758\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.9656 - val_loss: 1.2283\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.0004 - val_loss: 1.3319\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.9593 - val_loss: 1.3843\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.9093 - val_loss: 1.2657\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.8764 - val_loss: 1.1957\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.8279 - val_loss: 1.2004\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.7865 - val_loss: 1.1646\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7727 - val_loss: 1.2159\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.7586 - val_loss: 1.3141\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7461 - val_loss: 1.3108\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.7350 - val_loss: 1.3524\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.7160 - val_loss: 1.4873\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.7036 - val_loss: 1.4863\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.7326 - val_loss: 1.5322\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7622 - val_loss: 1.6803\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.8096 - val_loss: 1.5914\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.7871 - val_loss: 1.6881\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.7661 - val_loss: 1.2716\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6722 - val_loss: 1.2651\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6256 - val_loss: 1.2637\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5979 - val_loss: 1.2650\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5742 - val_loss: 1.2646\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5567 - val_loss: 1.2644\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5403 - val_loss: 1.2691\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5275 - val_loss: 1.2837\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5148 - val_loss: 1.2913\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5057 - val_loss: 1.3003\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5270 - val_loss: 1.3138\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5295 - val_loss: 1.3056\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5166 - val_loss: 1.3029\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5068 - val_loss: 1.2939\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4975 - val_loss: 1.2972\n",
      "Текущий реальный скор(валидационная часть): 1.1583\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4900 - val_loss: 1.2949\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4826 - val_loss: 1.2977\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4762 - val_loss: 1.2963\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4695 - val_loss: 1.2984\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4637 - val_loss: 1.3027\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4752 - val_loss: 1.3289\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4684 - val_loss: 1.3357\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4577 - val_loss: 1.3411\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4507 - val_loss: 1.3458\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4449 - val_loss: 1.3500\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4400 - val_loss: 1.3518\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4359 - val_loss: 1.3545\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4324 - val_loss: 1.3565\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4291 - val_loss: 1.3579\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4259 - val_loss: 1.3596\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4400 - val_loss: 1.3829\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4412 - val_loss: 1.3892\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4394 - val_loss: 1.3945\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4378 - val_loss: 1.3986\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4363 - val_loss: 1.4017\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4348 - val_loss: 1.4049\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4332 - val_loss: 1.4078\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4318 - val_loss: 1.4107\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4297 - val_loss: 1.4139\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4281 - val_loss: 1.4175\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4418 - val_loss: 1.4226\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4383 - val_loss: 1.4221\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4352 - val_loss: 1.4221\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4326 - val_loss: 1.4222\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4304 - val_loss: 1.4226\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4283 - val_loss: 1.4229\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4265 - val_loss: 1.4232\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4247 - val_loss: 1.4237\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4231 - val_loss: 1.4242\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4216 - val_loss: 1.4248\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4204 - val_loss: 1.4142\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4193 - val_loss: 1.4151\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4184 - val_loss: 1.4162\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4175 - val_loss: 1.4172\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4167 - val_loss: 1.4183\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4159 - val_loss: 1.4191\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4151 - val_loss: 1.4200\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4144 - val_loss: 1.4208\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4138 - val_loss: 1.4215\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4130 - val_loss: 1.4222\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4110 - val_loss: 1.4283\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4103 - val_loss: 1.4288\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4097 - val_loss: 1.4291\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4092 - val_loss: 1.4295\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4088 - val_loss: 1.4298\n",
      "Текущий реальный скор(валидационная часть): 1.3167\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4084 - val_loss: 1.4302\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4080 - val_loss: 1.4306\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4076 - val_loss: 1.4310\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4070 - val_loss: 1.4312\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4066 - val_loss: 1.4317\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4050 - val_loss: 1.4319\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4046 - val_loss: 1.4326\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4043 - val_loss: 1.4329\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4042 - val_loss: 1.4331\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4040 - val_loss: 1.4333\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4038 - val_loss: 1.4362\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4036 - val_loss: 1.4363\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4035 - val_loss: 1.4365\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4033 - val_loss: 1.4366\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4031 - val_loss: 1.4368\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4021 - val_loss: 1.4377\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4019 - val_loss: 1.4381\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4018 - val_loss: 1.4383\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - 0s 892us/step - loss: 0.4017 - val_loss: 1.4385\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.4017 - val_loss: 1.4386\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4016 - val_loss: 1.4387\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4015 - val_loss: 1.4388\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4014 - val_loss: 1.4389\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4013 - val_loss: 1.4390\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4013 - val_loss: 1.4390\n",
      "Скор для фолда(8) : 1.0501 средний скор на префиксе = 1.3257 это заняло = 14 сек.\n",
      "Фолд: 9\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8001 - val_loss: 2.1619\n",
      "Текущий реальный скор(валидационная часть): 2.0638\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.9386 - val_loss: 1.7584\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.6565 - val_loss: 1.7211\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.5075 - val_loss: 1.6581\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.4252 - val_loss: 1.6393\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.3501 - val_loss: 1.6286\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.2900 - val_loss: 1.6081\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.2512 - val_loss: 1.5782\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.2141 - val_loss: 1.5645\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.1701 - val_loss: 1.5530\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.1325 - val_loss: 1.5814\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.0798 - val_loss: 1.5548\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.0491 - val_loss: 1.4928\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.0108 - val_loss: 1.4675\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.9931 - val_loss: 1.5287\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.0104 - val_loss: 1.5789\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 1.0089 - val_loss: 1.6106\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.0383 - val_loss: 1.5705\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.0501 - val_loss: 1.5871\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.0000 - val_loss: 1.5469\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.9670 - val_loss: 1.5041\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.9134 - val_loss: 1.4712\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.8763 - val_loss: 1.4987\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.8660 - val_loss: 1.6210\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.8764 - val_loss: 1.6438\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.8101 - val_loss: 1.6093\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.7570 - val_loss: 1.5899\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.7277 - val_loss: 1.5649\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.7002 - val_loss: 1.5463\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.6783 - val_loss: 1.5337\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.6586 - val_loss: 1.6900\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.6831 - val_loss: 1.5166\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.6438 - val_loss: 1.5233\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6191 - val_loss: 1.5215\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.6139 - val_loss: 1.4739\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5997 - val_loss: 1.4818\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5872 - val_loss: 1.4869\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5780 - val_loss: 1.4887\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5677 - val_loss: 1.4938\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5599 - val_loss: 1.4968\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5529 - val_loss: 1.5025\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5464 - val_loss: 1.5042\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5405 - val_loss: 1.5082\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5347 - val_loss: 1.5094\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5476 - val_loss: 1.5090\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5457 - val_loss: 1.5067\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5427 - val_loss: 1.5005\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5405 - val_loss: 1.4994\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5375 - val_loss: 1.4973\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5345 - val_loss: 1.4954\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.5318 - val_loss: 1.4940\n",
      "Текущий реальный скор(валидационная часть): 1.4081\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5291 - val_loss: 1.4934\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5264 - val_loss: 1.4913\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5233 - val_loss: 1.4910\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5341 - val_loss: 1.4882\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5321 - val_loss: 1.4874\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5265 - val_loss: 1.4871\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5222 - val_loss: 1.4873\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5186 - val_loss: 1.4867\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5154 - val_loss: 1.4868\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5125 - val_loss: 1.4873\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5098 - val_loss: 1.4868\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5074 - val_loss: 1.4862\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5048 - val_loss: 1.4846\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5065 - val_loss: 1.4902\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5022 - val_loss: 1.4892\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5005 - val_loss: 1.4884\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4990 - val_loss: 1.4878\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4976 - val_loss: 1.4871\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4964 - val_loss: 1.4869\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4951 - val_loss: 1.4858\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4939 - val_loss: 1.4848\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4926 - val_loss: 1.4845\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4915 - val_loss: 1.4838\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4907 - val_loss: 1.4820\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4894 - val_loss: 1.4817\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4887 - val_loss: 1.4814\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4881 - val_loss: 1.4809\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4874 - val_loss: 1.4808\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 764us/step - loss: 0.4868 - val_loss: 1.4803\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.4863 - val_loss: 1.4800\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4857 - val_loss: 1.4796\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4851 - val_loss: 1.4792\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4846 - val_loss: 1.4789\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4839 - val_loss: 1.4821\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 776us/step - loss: 0.4830 - val_loss: 1.4819\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4826 - val_loss: 1.4818\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4823 - val_loss: 1.4818\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4820 - val_loss: 1.4817\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4817 - val_loss: 1.4816\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4815 - val_loss: 1.4814\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4812 - val_loss: 1.4814\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4809 - val_loss: 1.4811\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4807 - val_loss: 1.4812\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4800 - val_loss: 1.4846\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4793 - val_loss: 1.4850\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4791 - val_loss: 1.4849\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4789 - val_loss: 1.4849\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4788 - val_loss: 1.4849\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4787 - val_loss: 1.4849\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4785 - val_loss: 1.4848\n",
      "Текущий реальный скор(валидационная часть): 1.4087\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4784 - val_loss: 1.4848\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4783 - val_loss: 1.4847\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4781 - val_loss: 1.4847\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4775 - val_loss: 1.4861\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4773 - val_loss: 1.4866\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4772 - val_loss: 1.4868\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4771 - val_loss: 1.4869\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4770 - val_loss: 1.4869\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4770 - val_loss: 1.4869\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4769 - val_loss: 1.4868\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4768 - val_loss: 1.4868\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4768 - val_loss: 1.4868\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4767 - val_loss: 1.4868\n",
      "Скор для фолда(9) : 1.3658 средний скор на префиксе = 1.3297 это заняло = 13 сек.\n",
      "Фолд: 10\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.7934 - val_loss: 2.6615\n",
      "Текущий реальный скор(валидационная часть): 2.4533\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.9502 - val_loss: 1.9233\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.6335 - val_loss: 1.7214\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 730us/step - loss: 1.4972 - val_loss: 1.7652\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.4007 - val_loss: 1.7318\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.3199 - val_loss: 1.7850\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.2632 - val_loss: 1.7845\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.2150 - val_loss: 1.7612\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.1597 - val_loss: 1.7376\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.1243 - val_loss: 1.7514\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 1.0793 - val_loss: 1.7373\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 1.0702 - val_loss: 1.7443\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 726us/step - loss: 1.0513 - val_loss: 1.9170\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.0140 - val_loss: 1.7530\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.9947 - val_loss: 1.7314\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.9663 - val_loss: 1.7796\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.9478 - val_loss: 1.8254\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.9230 - val_loss: 1.8979\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.9044 - val_loss: 1.9188\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.8910 - val_loss: 1.9393\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.8775 - val_loss: 1.9828\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.8648 - val_loss: 2.0404\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.8568 - val_loss: 2.1067\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.8654 - val_loss: 1.8515\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.8361 - val_loss: 1.8413\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.8038 - val_loss: 1.8267\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.7831 - val_loss: 1.8284\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.7666 - val_loss: 1.8336\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.7532 - val_loss: 1.8372\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.7411 - val_loss: 1.8488\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7305 - val_loss: 1.8528\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.7205 - val_loss: 1.8554\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.7122 - val_loss: 1.8682\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.7188 - val_loss: 1.7430\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.7180 - val_loss: 1.7419\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.7128 - val_loss: 1.7414\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.7080 - val_loss: 1.7392\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7036 - val_loss: 1.7385\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.6984 - val_loss: 1.7392\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.6939 - val_loss: 1.7407\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6895 - val_loss: 1.7418\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6854 - val_loss: 1.7401\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.6812 - val_loss: 1.7430\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6925 - val_loss: 1.8094\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6819 - val_loss: 1.8158\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6755 - val_loss: 1.8197\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6706 - val_loss: 1.8235\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6662 - val_loss: 1.8264\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6621 - val_loss: 1.8290\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6583 - val_loss: 1.8297\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6549 - val_loss: 1.8332\n",
      "Текущий реальный скор(валидационная часть): 1.5884\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6517 - val_loss: 1.8341\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6486 - val_loss: 1.8345\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.6458 - val_loss: 1.8581\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6427 - val_loss: 1.8552\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6408 - val_loss: 1.8541\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6390 - val_loss: 1.8539\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6373 - val_loss: 1.8535\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6357 - val_loss: 1.8555\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6342 - val_loss: 1.8550\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.6327 - val_loss: 1.8549\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6313 - val_loss: 1.8545\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6299 - val_loss: 1.8518\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.6276 - val_loss: 1.8247\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6265 - val_loss: 1.8247\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6256 - val_loss: 1.8245\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6248 - val_loss: 1.8242\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6241 - val_loss: 1.8241\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6233 - val_loss: 1.8239\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6226 - val_loss: 1.8237\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6218 - val_loss: 1.8234\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6211 - val_loss: 1.8233\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6204 - val_loss: 1.8230\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6188 - val_loss: 1.8131\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6186 - val_loss: 1.8136\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.6182 - val_loss: 1.8138\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6178 - val_loss: 1.8140\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.6174 - val_loss: 1.8140\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6170 - val_loss: 1.8140\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6166 - val_loss: 1.8140\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6163 - val_loss: 1.8142\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6159 - val_loss: 1.8141\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.6156 - val_loss: 1.8141\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6143 - val_loss: 1.8203\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6140 - val_loss: 1.8208\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6138 - val_loss: 1.8209\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.6136 - val_loss: 1.8210\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6134 - val_loss: 1.8209\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6132 - val_loss: 1.8210\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.6129 - val_loss: 1.8209\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6127 - val_loss: 1.8209\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6126 - val_loss: 1.8209\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6124 - val_loss: 1.8209\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.6116 - val_loss: 1.8232\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6114 - val_loss: 1.8240\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6113 - val_loss: 1.8244\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6112 - val_loss: 1.8245\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6111 - val_loss: 1.8245\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.6110 - val_loss: 1.8245\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6109 - val_loss: 1.8245\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6108 - val_loss: 1.8246\n",
      "Текущий реальный скор(валидационная часть): 1.5872\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.6108 - val_loss: 1.8245\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.6107 - val_loss: 1.8246\n",
      "Скор для фолда(10) : 1.5274 средний скор на префиксе = 1.3477 это заняло = 11 сек.\n",
      "Фолд: 11\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8051 - val_loss: 2.6617\n",
      "Текущий реальный скор(валидационная часть): 2.6004\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 1.9340 - val_loss: 2.0353\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.6266 - val_loss: 1.8816\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.4909 - val_loss: 1.8730\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.3940 - val_loss: 1.9058\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.3159 - val_loss: 1.8921\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 1.2593 - val_loss: 1.8848\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.2044 - val_loss: 1.8923\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.1622 - val_loss: 1.8280\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 1.1206 - val_loss: 1.8677\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 1.0870 - val_loss: 1.8034\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 1.0396 - val_loss: 1.8118\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.0177 - val_loss: 1.8237\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 1.0305 - val_loss: 1.9421\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.9960 - val_loss: 1.8077\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.9382 - val_loss: 1.8032\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.9012 - val_loss: 1.8275\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.9247 - val_loss: 1.8325\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.9449 - val_loss: 1.8378\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.9399 - val_loss: 1.8283\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.9422 - val_loss: 1.7577\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.8899 - val_loss: 1.7698\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.8524 - val_loss: 1.7962\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.8255 - val_loss: 1.7402\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.8035 - val_loss: 1.7556\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.8146 - val_loss: 1.8052\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.8250 - val_loss: 1.8179\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.8436 - val_loss: 1.7891\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.8563 - val_loss: 2.1997\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.8815 - val_loss: 2.2166\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.8283 - val_loss: 2.1859\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.7998 - val_loss: 2.0958\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7827 - val_loss: 1.9799\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7566 - val_loss: 1.9719\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.6917 - val_loss: 1.7574\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.6342 - val_loss: 1.7497\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 914us/step - loss: 0.5873 - val_loss: 1.7468\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.5562 - val_loss: 1.7396\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5370 - val_loss: 1.7576\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5530 - val_loss: 1.7904\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5193 - val_loss: 1.7854\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5009 - val_loss: 1.7892\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4872 - val_loss: 1.7991\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4768 - val_loss: 1.8011\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4660 - val_loss: 1.8024\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4576 - val_loss: 1.8078\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4496 - val_loss: 1.8136\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4424 - val_loss: 1.8231\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4667 - val_loss: 1.9168\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4668 - val_loss: 2.0115\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4651 - val_loss: 2.0430\n",
      "Текущий реальный скор(валидационная часть): 1.9853\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4565 - val_loss: 2.0568\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4525 - val_loss: 2.0704\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4492 - val_loss: 2.0938\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4454 - val_loss: 2.0992\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4418 - val_loss: 2.1094\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4384 - val_loss: 2.1187\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4347 - val_loss: 2.1197\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4490 - val_loss: 1.9900\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4293 - val_loss: 1.9687\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4158 - val_loss: 1.9666\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4073 - val_loss: 1.9636\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4012 - val_loss: 1.9651\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3961 - val_loss: 1.9651\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3919 - val_loss: 1.9649\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3881 - val_loss: 1.9644\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3845 - val_loss: 1.9653\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.3814 - val_loss: 1.9646\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3790 - val_loss: 1.9346\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.3771 - val_loss: 1.9368\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3751 - val_loss: 1.9384\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.3734 - val_loss: 1.9394\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.3719 - val_loss: 1.9394\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3704 - val_loss: 1.9398\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3690 - val_loss: 1.9408\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.3677 - val_loss: 1.9410\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3665 - val_loss: 1.9423\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3653 - val_loss: 1.9429\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3667 - val_loss: 1.9076\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3656 - val_loss: 1.9061\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3647 - val_loss: 1.9059\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3639 - val_loss: 1.9054\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.3632 - val_loss: 1.9049\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3624 - val_loss: 1.9038\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3618 - val_loss: 1.9034\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3611 - val_loss: 1.9031\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3604 - val_loss: 1.8995\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3595 - val_loss: 1.9003\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3608 - val_loss: 1.8641\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3599 - val_loss: 1.8645\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3593 - val_loss: 1.8649\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.3589 - val_loss: 1.8654\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.3584 - val_loss: 1.8657\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3579 - val_loss: 1.8662\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3575 - val_loss: 1.8663\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3571 - val_loss: 1.8669\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3567 - val_loss: 1.8672\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3563 - val_loss: 1.8676\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.3575 - val_loss: 1.8812\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.3566 - val_loss: 1.8815\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3563 - val_loss: 1.8820\n",
      "Текущий реальный скор(валидационная часть): 1.8229\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3561 - val_loss: 1.8824\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3558 - val_loss: 1.8827\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3556 - val_loss: 1.8833\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3554 - val_loss: 1.8836\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3551 - val_loss: 1.8839\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3549 - val_loss: 1.8842\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3547 - val_loss: 1.8845\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3548 - val_loss: 1.9027\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3540 - val_loss: 1.9039\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3538 - val_loss: 1.9040\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3537 - val_loss: 1.9040\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3536 - val_loss: 1.9040\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3535 - val_loss: 1.9040\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3534 - val_loss: 1.9042\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3533 - val_loss: 1.9041\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3532 - val_loss: 1.9043\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.3531 - val_loss: 1.9043\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.3527 - val_loss: 1.9096\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3525 - val_loss: 1.9113\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3524 - val_loss: 1.9118\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3523 - val_loss: 1.9119\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3523 - val_loss: 1.9120\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3522 - val_loss: 1.9120\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3522 - val_loss: 1.9120\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3521 - val_loss: 1.9121\n",
      "Epoch 127/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3521 - val_loss: 1.9121\n",
      "Epoch 128/1000\n",
      "134/134 [==============================] - 0s 766us/step - loss: 0.3520 - val_loss: 1.9120\n",
      "Epoch 129/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.3517 - val_loss: 1.9136\n",
      "Epoch 130/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3517 - val_loss: 1.9144\n",
      "Epoch 131/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.3516 - val_loss: 1.9149\n",
      "Epoch 132/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.3516 - val_loss: 1.9151\n",
      "Epoch 133/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.3516 - val_loss: 1.9153\n",
      "Epoch 134/1000\n",
      "134/134 [==============================] - 0s 906us/step - loss: 0.3515 - val_loss: 1.9154\n",
      "Epoch 135/1000\n",
      "134/134 [==============================] - 0s 762us/step - loss: 0.3515 - val_loss: 1.9154\n",
      "Epoch 136/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3515 - val_loss: 1.9154\n",
      "Epoch 137/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.3515 - val_loss: 1.9155\n",
      "Epoch 138/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3514 - val_loss: 1.9155\n",
      "Скор для фолда(11) : 1.6457 средний скор на префиксе = 1.3725 это заняло = 15 сек.\n",
      "Фолд: 12\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8229 - val_loss: 2.2633\n",
      "Текущий реальный скор(валидационная часть): 2.1699\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 1.9607 - val_loss: 1.8146\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.6538 - val_loss: 1.6565\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.5113 - val_loss: 1.5923\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.4242 - val_loss: 1.6180\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.3478 - val_loss: 1.6047\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.2772 - val_loss: 1.6043\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.2253 - val_loss: 1.6084\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.1762 - val_loss: 1.6247\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.1328 - val_loss: 1.6038\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.0948 - val_loss: 1.6782\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.0639 - val_loss: 1.6952\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.0365 - val_loss: 1.6736\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.0147 - val_loss: 1.6516\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.9797 - val_loss: 1.6375\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.9381 - val_loss: 1.6404\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.9097 - val_loss: 1.6392\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.8861 - val_loss: 1.6468\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.8705 - val_loss: 1.6467\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.8484 - val_loss: 1.6555\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.8337 - val_loss: 1.6728\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.8210 - val_loss: 1.6937\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.8068 - val_loss: 1.7370\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.7965 - val_loss: 1.7710\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.8191 - val_loss: 1.8036\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.7854 - val_loss: 1.7802\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7588 - val_loss: 1.7564\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.7402 - val_loss: 1.7500\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.7253 - val_loss: 1.7501\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7132 - val_loss: 1.7499\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7024 - val_loss: 1.7514\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6921 - val_loss: 1.7503\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6831 - val_loss: 1.7507\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6741 - val_loss: 1.7502\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6908 - val_loss: 1.6579\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6903 - val_loss: 1.6507\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6843 - val_loss: 1.6465\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.6778 - val_loss: 1.6448\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.6721 - val_loss: 1.6396\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6655 - val_loss: 1.6380\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6600 - val_loss: 1.6376\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6539 - val_loss: 1.6385\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6488 - val_loss: 1.6386\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6437 - val_loss: 1.6396\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6480 - val_loss: 1.6325\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6364 - val_loss: 1.6355\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.6303 - val_loss: 1.6396\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6253 - val_loss: 1.6406\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6212 - val_loss: 1.6415\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6174 - val_loss: 1.6426\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6139 - val_loss: 1.6442\n",
      "Текущий реальный скор(валидационная часть): 1.5247\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6106 - val_loss: 1.6453\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6076 - val_loss: 1.6457\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6046 - val_loss: 1.6466\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6027 - val_loss: 1.6619\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.6005 - val_loss: 1.6623\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5986 - val_loss: 1.6627\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5969 - val_loss: 1.6652\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5952 - val_loss: 1.6654\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5928 - val_loss: 1.6556\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5931 - val_loss: 1.6645\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5914 - val_loss: 1.6650\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5899 - val_loss: 1.6648\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5886 - val_loss: 1.6651\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5861 - val_loss: 1.6582\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5852 - val_loss: 1.6579\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5844 - val_loss: 1.6580\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5838 - val_loss: 1.6580\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5831 - val_loss: 1.6580\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.5825 - val_loss: 1.6580\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5818 - val_loss: 1.6580\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.5812 - val_loss: 1.6583\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5806 - val_loss: 1.6587\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5800 - val_loss: 1.6614\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5782 - val_loss: 1.6573\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5779 - val_loss: 1.6575\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5775 - val_loss: 1.6574\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5772 - val_loss: 1.6573\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5769 - val_loss: 1.6572\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5765 - val_loss: 1.6573\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5762 - val_loss: 1.6574\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5759 - val_loss: 1.6575\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5755 - val_loss: 1.6575\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5752 - val_loss: 1.6576\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5736 - val_loss: 1.6602\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5716 - val_loss: 1.6601\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5714 - val_loss: 1.6599\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.5712 - val_loss: 1.6597\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5711 - val_loss: 1.6596\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5709 - val_loss: 1.6596\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5708 - val_loss: 1.6595\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5706 - val_loss: 1.6594\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5705 - val_loss: 1.6594\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.5704 - val_loss: 1.6594\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5697 - val_loss: 1.6601\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5696 - val_loss: 1.6604\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5695 - val_loss: 1.6605\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5694 - val_loss: 1.6605\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5693 - val_loss: 1.6605\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5692 - val_loss: 1.6605\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5692 - val_loss: 1.6605\n",
      "Текущий реальный скор(валидационная часть): 1.5423\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5691 - val_loss: 1.6605\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5690 - val_loss: 1.6605\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5689 - val_loss: 1.6605\n",
      "Скор для фолда(12) : 1.4712 средний скор на префиксе = 1.3801 это заняло = 11 сек.\n",
      "Фолд: 13\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.7659 - val_loss: 2.7145\n",
      "Текущий реальный скор(валидационная часть): 2.5996\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.9442 - val_loss: 2.1834\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.6366 - val_loss: 1.9817\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.4913 - val_loss: 1.8535\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.4091 - val_loss: 1.8284\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.3349 - val_loss: 1.8054\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.2802 - val_loss: 1.7851\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.2304 - val_loss: 1.7396\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.1892 - val_loss: 1.7655\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.1361 - val_loss: 1.7315\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.0964 - val_loss: 1.6555\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.0578 - val_loss: 1.7174\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.0203 - val_loss: 1.7554\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.9950 - val_loss: 1.7332\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.9603 - val_loss: 1.6800\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.9441 - val_loss: 1.6281\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.8955 - val_loss: 1.6621\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.8730 - val_loss: 1.6172\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.8650 - val_loss: 1.6409\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.8612 - val_loss: 1.7757\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.8598 - val_loss: 1.8963\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.8351 - val_loss: 1.8616\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.8426 - val_loss: 1.6099\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.8275 - val_loss: 1.5223\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.7770 - val_loss: 1.6688\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.7383 - val_loss: 1.6549\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.7061 - val_loss: 1.6595\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6893 - val_loss: 1.6974\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.7217 - val_loss: 1.5719\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.7275 - val_loss: 1.6126\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.7815 - val_loss: 1.6172\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.7565 - val_loss: 1.6381\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.7551 - val_loss: 1.7908\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.7354 - val_loss: 1.6852\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.7397 - val_loss: 1.8118\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6730 - val_loss: 1.8187\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.6224 - val_loss: 1.7952\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5944 - val_loss: 1.7447\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.5718 - val_loss: 1.7416\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5561 - val_loss: 1.7359\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5437 - val_loss: 1.7307\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5324 - val_loss: 1.7244\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5240 - val_loss: 1.7258\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5156 - val_loss: 1.7226\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5580 - val_loss: 1.6075\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5317 - val_loss: 1.6084\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5101 - val_loss: 1.6096\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4957 - val_loss: 1.6143\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4851 - val_loss: 1.6126\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4770 - val_loss: 1.6115\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4693 - val_loss: 1.6124\n",
      "Текущий реальный скор(валидационная часть): 1.5347\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4625 - val_loss: 1.6121\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4567 - val_loss: 1.6130\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4511 - val_loss: 1.6098\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4725 - val_loss: 1.6027\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4780 - val_loss: 1.6064\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4772 - val_loss: 1.6119\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4753 - val_loss: 1.6206\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4742 - val_loss: 1.6273\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4705 - val_loss: 1.6356\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 822us/step - loss: 0.4666 - val_loss: 1.6428\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4626 - val_loss: 1.6490\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4591 - val_loss: 1.6542\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4552 - val_loss: 1.6581\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4627 - val_loss: 1.6516\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4509 - val_loss: 1.6532\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.4447 - val_loss: 1.6549\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4399 - val_loss: 1.6568\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4361 - val_loss: 1.6577\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4326 - val_loss: 1.6588\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4298 - val_loss: 1.6598\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4271 - val_loss: 1.6611\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4245 - val_loss: 1.6621\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4222 - val_loss: 1.6629\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4241 - val_loss: 1.6646\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4206 - val_loss: 1.6649\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4192 - val_loss: 1.6650\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4180 - val_loss: 1.6657\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4168 - val_loss: 1.6659\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4156 - val_loss: 1.6665\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4146 - val_loss: 1.6670\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4135 - val_loss: 1.6672\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4125 - val_loss: 1.6701\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4116 - val_loss: 1.6706\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4143 - val_loss: 1.6700\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4131 - val_loss: 1.6699\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4124 - val_loss: 1.6673\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.4117 - val_loss: 1.6673\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4111 - val_loss: 1.6674\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4105 - val_loss: 1.6675\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4099 - val_loss: 1.6676\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4094 - val_loss: 1.6678\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4088 - val_loss: 1.6681\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4083 - val_loss: 1.6684\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4107 - val_loss: 1.6733\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4084 - val_loss: 1.6734\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4079 - val_loss: 1.6734\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4075 - val_loss: 1.6734\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4072 - val_loss: 1.6734\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4068 - val_loss: 1.6735\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4065 - val_loss: 1.6735\n",
      "Текущий реальный скор(валидационная часть): 1.5906\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4062 - val_loss: 1.6736\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4058 - val_loss: 1.6737\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4055 - val_loss: 1.6738\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4057 - val_loss: 1.6769\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4042 - val_loss: 1.6775\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4039 - val_loss: 1.6776\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4037 - val_loss: 1.6777\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4036 - val_loss: 1.6777\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4034 - val_loss: 1.6777\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4033 - val_loss: 1.6777\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4031 - val_loss: 1.6777\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4030 - val_loss: 1.6777\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4028 - val_loss: 1.6778\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.4023 - val_loss: 1.6790\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4019 - val_loss: 1.6795\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4018 - val_loss: 1.6797\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4017 - val_loss: 1.6798\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4016 - val_loss: 1.6799\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4015 - val_loss: 1.6799\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4014 - val_loss: 1.6799\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4014 - val_loss: 1.6799\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4013 - val_loss: 1.6800\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4012 - val_loss: 1.6800\n",
      "Скор для фолда(13) : 1.4449 средний скор на префиксе = 1.3848 это заняло = 14 сек.\n",
      "Фолд: 14\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8221 - val_loss: 2.0955\n",
      "Текущий реальный скор(валидационная часть): 2.0346\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.9495 - val_loss: 1.6262\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.6430 - val_loss: 1.5050\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.5040 - val_loss: 1.4765\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.4111 - val_loss: 1.4911\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.3440 - val_loss: 1.5217\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.2881 - val_loss: 1.5743\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.2407 - val_loss: 1.5930\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.1947 - val_loss: 1.5994\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.1534 - val_loss: 1.5563\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.1162 - val_loss: 1.5882\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.0812 - val_loss: 1.5762\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.0528 - val_loss: 1.5978\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.0512 - val_loss: 1.5601\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.0735 - val_loss: 1.4342\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.9697 - val_loss: 1.4697\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.9228 - val_loss: 1.4715\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.8964 - val_loss: 1.4705\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.8737 - val_loss: 1.4853\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.8577 - val_loss: 1.5022\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.8363 - val_loss: 1.5234\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.8164 - val_loss: 1.5510\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.7997 - val_loss: 1.5736\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.7824 - val_loss: 1.5941\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.7732 - val_loss: 1.6056\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.7933 - val_loss: 1.4860\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.7771 - val_loss: 1.4849\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.7458 - val_loss: 1.4882\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7240 - val_loss: 1.4899\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.7085 - val_loss: 1.4932\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6956 - val_loss: 1.4927\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6837 - val_loss: 1.4948\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6738 - val_loss: 1.4997\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6648 - val_loss: 1.5016\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6558 - val_loss: 1.5048\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6513 - val_loss: 1.5280\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6568 - val_loss: 1.5013\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6449 - val_loss: 1.5016\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6404 - val_loss: 1.4984\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6360 - val_loss: 1.4986\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6320 - val_loss: 1.4992\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6280 - val_loss: 1.4999\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6243 - val_loss: 1.4998\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.6208 - val_loss: 1.5011\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6172 - val_loss: 1.5016\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6262 - val_loss: 1.5033\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6239 - val_loss: 1.5000\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6203 - val_loss: 1.4984\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6171 - val_loss: 1.4971\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6141 - val_loss: 1.4960\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6114 - val_loss: 1.4958\n",
      "Текущий реальный скор(валидационная часть): 1.3989\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6087 - val_loss: 1.4959\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.6060 - val_loss: 1.4950\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6035 - val_loss: 1.4952\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6012 - val_loss: 1.4943\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6048 - val_loss: 1.4871\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6008 - val_loss: 1.4865\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5991 - val_loss: 1.4865\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5973 - val_loss: 1.4865\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5958 - val_loss: 1.4866\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.5943 - val_loss: 1.4865\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5930 - val_loss: 1.4867\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.5917 - val_loss: 1.4866\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5905 - val_loss: 1.4869\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5893 - val_loss: 1.4871\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5889 - val_loss: 1.4867\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5878 - val_loss: 1.4870\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5870 - val_loss: 1.4875\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5863 - val_loss: 1.4879\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5856 - val_loss: 1.4884\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5849 - val_loss: 1.4889\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5843 - val_loss: 1.4892\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5836 - val_loss: 1.4896\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5830 - val_loss: 1.4900\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5824 - val_loss: 1.4902\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5818 - val_loss: 1.4908\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.5812 - val_loss: 1.4909\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5808 - val_loss: 1.4909\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5804 - val_loss: 1.4909\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5800 - val_loss: 1.4909\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5797 - val_loss: 1.4910\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.5793 - val_loss: 1.4911\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5790 - val_loss: 1.4913\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5787 - val_loss: 1.4914\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5784 - val_loss: 1.4915\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5776 - val_loss: 1.4951\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5769 - val_loss: 1.4953\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5767 - val_loss: 1.4954\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5765 - val_loss: 1.4954\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5764 - val_loss: 1.4955\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5762 - val_loss: 1.4955\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5761 - val_loss: 1.4956\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5759 - val_loss: 1.4956\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5757 - val_loss: 1.4957\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5756 - val_loss: 1.4957\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5749 - val_loss: 1.4957\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.5746 - val_loss: 1.4957\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5745 - val_loss: 1.4958\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5744 - val_loss: 1.4959\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.5743 - val_loss: 1.4959\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5743 - val_loss: 1.4960\n",
      "Текущий реальный скор(валидационная часть): 1.4139\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.5742 - val_loss: 1.4960\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5741 - val_loss: 1.4960\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5740 - val_loss: 1.4961\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5740 - val_loss: 1.4961\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5735 - val_loss: 1.4961\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5735 - val_loss: 1.4961\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5734 - val_loss: 1.4961\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.5734 - val_loss: 1.4961\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.5733 - val_loss: 1.4962\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5733 - val_loss: 1.4962\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5732 - val_loss: 1.4962\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5732 - val_loss: 1.4962\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5732 - val_loss: 1.4963\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5731 - val_loss: 1.4963\n",
      "Скор для фолда(14) : 1.3567 средний скор на префиксе = 1.3829 это заняло = 13 сек.\n",
      "Фолд: 15\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8147 - val_loss: 1.9887\n",
      "Текущий реальный скор(валидационная часть): 1.9116\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.9548 - val_loss: 1.8230\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.6342 - val_loss: 1.6723\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.5016 - val_loss: 1.6262\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.4159 - val_loss: 1.6029\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.3428 - val_loss: 1.5944\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.2830 - val_loss: 1.5799\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 1.2255 - val_loss: 1.5783\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.1735 - val_loss: 1.5669\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.1296 - val_loss: 1.5601\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.0863 - val_loss: 1.5458\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.0730 - val_loss: 1.5177\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.0339 - val_loss: 1.4764\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.0068 - val_loss: 1.5405\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.9817 - val_loss: 1.5175\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.9498 - val_loss: 1.5856\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.9267 - val_loss: 1.6155\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.9521 - val_loss: 1.5929\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.9105 - val_loss: 1.5899\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.9025 - val_loss: 1.6203\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.9169 - val_loss: 1.6315\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.9068 - val_loss: 1.7731\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.8617 - val_loss: 1.7689\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.8648 - val_loss: 1.8568\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.8008 - val_loss: 1.8646\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.7584 - val_loss: 1.8557\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.7294 - val_loss: 1.8309\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6992 - val_loss: 1.8319\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6823 - val_loss: 1.8525\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6574 - val_loss: 1.8519\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.6416 - val_loss: 1.8521\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6280 - val_loss: 1.8565\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6138 - val_loss: 1.8583\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6334 - val_loss: 1.6763\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.6142 - val_loss: 1.6803\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5941 - val_loss: 1.6927\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.5825 - val_loss: 1.6274\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5866 - val_loss: 1.7223\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5655 - val_loss: 1.7326\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5547 - val_loss: 1.7436\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5479 - val_loss: 1.7535\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5410 - val_loss: 1.7567\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5346 - val_loss: 1.7568\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5573 - val_loss: 1.6213\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5608 - val_loss: 1.6074\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5577 - val_loss: 1.5966\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5549 - val_loss: 1.5844\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5512 - val_loss: 1.5776\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 766us/step - loss: 0.5472 - val_loss: 1.5730\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 889us/step - loss: 0.5424 - val_loss: 1.5662\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 765us/step - loss: 0.5385 - val_loss: 1.5623\n",
      "Текущий реальный скор(валидационная часть): 1.4667\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5346 - val_loss: 1.5602\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.5302 - val_loss: 1.5582\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 796us/step - loss: 0.5426 - val_loss: 1.5334\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.5309 - val_loss: 1.5372\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 768us/step - loss: 0.5247 - val_loss: 1.5391\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.5199 - val_loss: 1.5407\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5156 - val_loss: 1.5437\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.5119 - val_loss: 1.5438\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5086 - val_loss: 1.5434\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5054 - val_loss: 1.5429\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5026 - val_loss: 1.5423\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.5000 - val_loss: 1.5423\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4983 - val_loss: 1.5421\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4963 - val_loss: 1.5416\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4947 - val_loss: 1.5414\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4933 - val_loss: 1.5405\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4919 - val_loss: 1.5407\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4906 - val_loss: 1.5407\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4894 - val_loss: 1.5406\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4882 - val_loss: 1.5401\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4871 - val_loss: 1.5400\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4859 - val_loss: 1.5398\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4847 - val_loss: 1.5328\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4848 - val_loss: 1.5329\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4841 - val_loss: 1.5333\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4834 - val_loss: 1.5331\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4828 - val_loss: 1.5334\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4822 - val_loss: 1.5334\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4816 - val_loss: 1.5332\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4810 - val_loss: 1.5336\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4804 - val_loss: 1.5334\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4799 - val_loss: 1.5335\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4800 - val_loss: 1.5367\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4792 - val_loss: 1.5367\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4788 - val_loss: 1.5367\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 774us/step - loss: 0.4784 - val_loss: 1.5366\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4781 - val_loss: 1.5366\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4778 - val_loss: 1.5366\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.4774 - val_loss: 1.5365\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4771 - val_loss: 1.5366\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.4768 - val_loss: 1.5365\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.4765 - val_loss: 1.5365\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.4761 - val_loss: 1.5416\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4751 - val_loss: 1.5422\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.4749 - val_loss: 1.5421\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4747 - val_loss: 1.5419\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4745 - val_loss: 1.5418\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4744 - val_loss: 1.5416\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4742 - val_loss: 1.5415\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4741 - val_loss: 1.5413\n",
      "Текущий реальный скор(валидационная часть): 1.4483\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4739 - val_loss: 1.5412\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.4738 - val_loss: 1.5411\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.4732 - val_loss: 1.5433\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4729 - val_loss: 1.5441\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4727 - val_loss: 1.5443\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4726 - val_loss: 1.5444\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4725 - val_loss: 1.5444\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.4725 - val_loss: 1.5444\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4724 - val_loss: 1.5443\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.4723 - val_loss: 1.5442\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.4722 - val_loss: 1.5442\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.4722 - val_loss: 1.5442\n",
      "Скор для фолда(15) : 1.3953 средний скор на префиксе = 1.3837 это заняло = 12 сек.\n",
      "Фолд: 16\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8208 - val_loss: 2.4822\n",
      "Текущий реальный скор(валидационная часть): 2.3639\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.9508 - val_loss: 1.9880\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 1.6275 - val_loss: 1.8639\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.4776 - val_loss: 1.8014\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.4004 - val_loss: 1.7840\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.3326 - val_loss: 1.7216\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.2828 - val_loss: 1.6922\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.2288 - val_loss: 1.6529\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.1813 - val_loss: 1.6491\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.1370 - val_loss: 1.6161\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.1026 - val_loss: 1.6098\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.0684 - val_loss: 1.6002\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.0460 - val_loss: 1.5967\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.0036 - val_loss: 1.5971\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.9707 - val_loss: 1.5877\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.9476 - val_loss: 1.6006\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.9320 - val_loss: 1.5881\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.9244 - val_loss: 1.5966\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.9098 - val_loss: 1.6358\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.9475 - val_loss: 1.7366\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.9701 - val_loss: 1.6384\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.9496 - val_loss: 1.5764\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.9373 - val_loss: 1.7671\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.9322 - val_loss: 1.7325\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.8833 - val_loss: 1.5555\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.8565 - val_loss: 1.5886\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.8201 - val_loss: 1.5880\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.8067 - val_loss: 1.5592\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.8063 - val_loss: 1.5634\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.9151 - val_loss: 1.5486\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.9531 - val_loss: 1.6109\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.8738 - val_loss: 1.8168\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.7863 - val_loss: 1.7479\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.7381 - val_loss: 1.8515\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.7148 - val_loss: 1.9583\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.6892 - val_loss: 1.9559\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.6856 - val_loss: 1.9667\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6871 - val_loss: 1.9836\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.7365 - val_loss: 1.7584\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7815 - val_loss: 1.8408\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.7470 - val_loss: 1.5518\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6287 - val_loss: 1.5599\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5791 - val_loss: 1.5788\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.5520 - val_loss: 1.5805\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5275 - val_loss: 1.5793\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.5142 - val_loss: 1.5806\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.4980 - val_loss: 1.5729\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.4889 - val_loss: 1.5743\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.4763 - val_loss: 1.5654\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.4713 - val_loss: 1.5706\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4787 - val_loss: 1.5755\n",
      "Текущий реальный скор(валидационная часть): 1.4403\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4635 - val_loss: 1.5831\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.4528 - val_loss: 1.5797\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4453 - val_loss: 1.5747\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.4387 - val_loss: 1.5716\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.4331 - val_loss: 1.5700\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.4282 - val_loss: 1.5642\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.4235 - val_loss: 1.5614\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4192 - val_loss: 1.5603\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.4147 - val_loss: 1.5629\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.4319 - val_loss: 1.5650\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.4358 - val_loss: 1.5564\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.4295 - val_loss: 1.5484\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.4243 - val_loss: 1.5509\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.4203 - val_loss: 1.5499\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.4167 - val_loss: 1.5466\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.4134 - val_loss: 1.5429\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.4103 - val_loss: 1.5440\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.4074 - val_loss: 1.5430\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.4046 - val_loss: 1.5427\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.4022 - val_loss: 1.5426\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.3996 - val_loss: 1.5429\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3972 - val_loss: 1.5410\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3949 - val_loss: 1.5425\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.3927 - val_loss: 1.5413\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3905 - val_loss: 1.5414\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3881 - val_loss: 1.5414\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3859 - val_loss: 1.5417\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3840 - val_loss: 1.5410\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.3819 - val_loss: 1.5412\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3800 - val_loss: 1.5430\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3780 - val_loss: 1.5447\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3763 - val_loss: 1.5459\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3900 - val_loss: 1.5624\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3898 - val_loss: 1.5624\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3866 - val_loss: 1.5623\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3839 - val_loss: 1.5623\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3814 - val_loss: 1.5616\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3793 - val_loss: 1.5619\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3772 - val_loss: 1.5622\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3755 - val_loss: 1.5617\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3737 - val_loss: 1.5627\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 730us/step - loss: 0.3721 - val_loss: 1.5628\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3806 - val_loss: 1.5472\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.3754 - val_loss: 1.5492\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3732 - val_loss: 1.5514\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3714 - val_loss: 1.5536\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3699 - val_loss: 1.5554\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3685 - val_loss: 1.5573\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3672 - val_loss: 1.5591\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 729us/step - loss: 0.3660 - val_loss: 1.5602\n",
      "Текущий реальный скор(валидационная часть): 1.4399\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.3650 - val_loss: 1.5621\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3639 - val_loss: 1.5635\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3658 - val_loss: 1.5704\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.3658 - val_loss: 1.5711\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.3650 - val_loss: 1.5718\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.3642 - val_loss: 1.5724\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3635 - val_loss: 1.5729\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.3629 - val_loss: 1.5735\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3623 - val_loss: 1.5741\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3617 - val_loss: 1.5747\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3612 - val_loss: 1.5752\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3607 - val_loss: 1.5760\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3616 - val_loss: 1.5744\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.3604 - val_loss: 1.5747\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3600 - val_loss: 1.5750\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.3597 - val_loss: 1.5753\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3593 - val_loss: 1.5755\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3590 - val_loss: 1.5758\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3587 - val_loss: 1.5762\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.3584 - val_loss: 1.5763\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.3581 - val_loss: 1.5767\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3578 - val_loss: 1.5770\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3573 - val_loss: 1.5785\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.3565 - val_loss: 1.5788\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3563 - val_loss: 1.5789\n",
      "Epoch 127/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3562 - val_loss: 1.5789\n",
      "Epoch 128/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3560 - val_loss: 1.5790\n",
      "Epoch 129/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3559 - val_loss: 1.5791\n",
      "Epoch 130/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3557 - val_loss: 1.5792\n",
      "Epoch 131/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3556 - val_loss: 1.5793\n",
      "Epoch 132/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3555 - val_loss: 1.5794\n",
      "Epoch 133/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3553 - val_loss: 1.5796\n",
      "Epoch 134/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3546 - val_loss: 1.5802\n",
      "Epoch 135/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3544 - val_loss: 1.5805\n",
      "Epoch 136/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.3543 - val_loss: 1.5806\n",
      "Epoch 137/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3542 - val_loss: 1.5806\n",
      "Epoch 138/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3542 - val_loss: 1.5807\n",
      "Epoch 139/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3541 - val_loss: 1.5808\n",
      "Epoch 140/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3540 - val_loss: 1.5808\n",
      "Epoch 141/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.3540 - val_loss: 1.5809\n",
      "Epoch 142/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3539 - val_loss: 1.5809\n",
      "Epoch 143/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.3539 - val_loss: 1.5809\n",
      "Epoch 144/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3534 - val_loss: 1.5811\n",
      "Epoch 145/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.3533 - val_loss: 1.5812\n",
      "Epoch 146/1000\n",
      "134/134 [==============================] - 0s 730us/step - loss: 0.3533 - val_loss: 1.5813\n",
      "Epoch 147/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3533 - val_loss: 1.5813\n",
      "Epoch 148/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3532 - val_loss: 1.5813\n",
      "Epoch 149/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3532 - val_loss: 1.5814\n",
      "Epoch 150/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3532 - val_loss: 1.5814\n",
      "Epoch 151/1000\n",
      "134/134 [==============================] - 0s 730us/step - loss: 0.3531 - val_loss: 1.5814\n",
      "Текущий реальный скор(валидационная часть): 1.4542\n",
      "Epoch 152/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.3531 - val_loss: 1.5814\n",
      "Epoch 153/1000\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.3531 - val_loss: 1.5815\n",
      "Epoch 154/1000\n",
      "134/134 [==============================] - 0s 763us/step - loss: 0.3528 - val_loss: 1.5815\n",
      "Epoch 155/1000\n",
      "134/134 [==============================] - 0s 759us/step - loss: 0.3528 - val_loss: 1.5816\n",
      "Epoch 156/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3528 - val_loss: 1.5816\n",
      "Epoch 157/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.3528 - val_loss: 1.5816\n",
      "Epoch 158/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3527 - val_loss: 1.5816\n",
      "Epoch 159/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3527 - val_loss: 1.5816\n",
      "Epoch 160/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3527 - val_loss: 1.5817\n",
      "Epoch 161/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3527 - val_loss: 1.5817\n",
      "Epoch 162/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3527 - val_loss: 1.5817\n",
      "Epoch 163/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3527 - val_loss: 1.5817\n",
      "Epoch 164/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3525 - val_loss: 1.5817\n",
      "Epoch 165/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.3525 - val_loss: 1.5817\n",
      "Epoch 166/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3525 - val_loss: 1.5817\n",
      "Epoch 167/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3525 - val_loss: 1.5817\n",
      "Epoch 168/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3525 - val_loss: 1.5818\n",
      "Epoch 169/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3525 - val_loss: 1.5818\n",
      "Epoch 170/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.3525 - val_loss: 1.5818\n",
      "Epoch 171/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3525 - val_loss: 1.5818\n",
      "Epoch 172/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3525 - val_loss: 1.5818\n",
      "Epoch 173/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3525 - val_loss: 1.5818\n",
      "Скор для фолда(16) : 1.4187 средний скор на префиксе = 1.3857 это заняло = 19 сек.\n",
      "Фолд: 17\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.7890 - val_loss: 2.0542\n",
      "Текущий реальный скор(валидационная часть): 1.9529\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.9648 - val_loss: 1.6641\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 1.6548 - val_loss: 1.5479\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 1.4990 - val_loss: 1.4459\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.4137 - val_loss: 1.3859\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.3407 - val_loss: 1.3900\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.2854 - val_loss: 1.3667\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.2357 - val_loss: 1.3671\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.1794 - val_loss: 1.3527\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 1.1572 - val_loss: 1.3678\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 1.1262 - val_loss: 1.3788\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 1.0810 - val_loss: 1.3780\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 1.0525 - val_loss: 1.3698\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 1.0155 - val_loss: 1.3866\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.9957 - val_loss: 1.3981\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.9917 - val_loss: 1.3721\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 1.0123 - val_loss: 1.3562\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 1.0326 - val_loss: 1.4922\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 1.0375 - val_loss: 1.3944\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.9521 - val_loss: 1.4455\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.8776 - val_loss: 1.4407\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.8321 - val_loss: 1.4274\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.8008 - val_loss: 1.4323\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.7746 - val_loss: 1.4187\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.7495 - val_loss: 1.4139\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.7273 - val_loss: 1.4212\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.7105 - val_loss: 1.4222\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.6932 - val_loss: 1.4170\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.6775 - val_loss: 1.4040\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.6797 - val_loss: 1.4054\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 777us/step - loss: 0.6670 - val_loss: 1.4001\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.6456 - val_loss: 1.4036\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.6301 - val_loss: 1.4076\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.6185 - val_loss: 1.4135\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.6079 - val_loss: 1.4135\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5987 - val_loss: 1.4140\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5903 - val_loss: 1.4117\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5824 - val_loss: 1.4112\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5753 - val_loss: 1.4125\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5992 - val_loss: 1.4218\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5913 - val_loss: 1.4274\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5866 - val_loss: 1.4309\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5822 - val_loss: 1.4350\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5781 - val_loss: 1.4395\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5748 - val_loss: 1.4591\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5772 - val_loss: 1.4441\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5679 - val_loss: 1.4485\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5638 - val_loss: 1.4516\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5596 - val_loss: 1.4546\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5655 - val_loss: 1.4465\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5568 - val_loss: 1.4437\n",
      "Текущий реальный скор(валидационная часть): 1.3124\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5496 - val_loss: 1.4373\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5470 - val_loss: 1.4405\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5438 - val_loss: 1.4392\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5405 - val_loss: 1.4382\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5376 - val_loss: 1.4377\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5348 - val_loss: 1.4377\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5323 - val_loss: 1.4372\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5300 - val_loss: 1.4372\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5286 - val_loss: 1.4332\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5254 - val_loss: 1.4331\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5231 - val_loss: 1.4359\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5244 - val_loss: 1.4329\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5215 - val_loss: 1.4336\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5201 - val_loss: 1.4342\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5188 - val_loss: 1.4348\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 973us/step - loss: 0.5175 - val_loss: 1.4352\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 762us/step - loss: 0.5157 - val_loss: 1.4339\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5153 - val_loss: 1.4362\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5161 - val_loss: 1.4374\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5161 - val_loss: 1.4371\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5153 - val_loss: 1.4370\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5144 - val_loss: 1.4400\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5133 - val_loss: 1.4369\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5111 - val_loss: 1.4379\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5109 - val_loss: 1.4373\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5099 - val_loss: 1.4383\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5098 - val_loss: 1.4375\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5088 - val_loss: 1.4389\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5102 - val_loss: 1.4364\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5085 - val_loss: 1.4366\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5082 - val_loss: 1.4368\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5079 - val_loss: 1.4370\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.5076 - val_loss: 1.4372\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5072 - val_loss: 1.4374\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5069 - val_loss: 1.4376\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5066 - val_loss: 1.4378\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5063 - val_loss: 1.4379\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5060 - val_loss: 1.4381\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5058 - val_loss: 1.4368\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5047 - val_loss: 1.4368\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 757us/step - loss: 0.5044 - val_loss: 1.4369\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5042 - val_loss: 1.4370\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5041 - val_loss: 1.4371\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5039 - val_loss: 1.4373\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5038 - val_loss: 1.4374\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5036 - val_loss: 1.4375\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.5035 - val_loss: 1.4376\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 755us/step - loss: 0.5034 - val_loss: 1.4377\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5029 - val_loss: 1.4372\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5025 - val_loss: 1.4370\n",
      "Текущий реальный скор(валидационная часть): 1.3116\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 0.5023 - val_loss: 1.4369\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5022 - val_loss: 1.4370\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5021 - val_loss: 1.4370\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5020 - val_loss: 1.4371\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.5020 - val_loss: 1.4372\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 756us/step - loss: 0.5019 - val_loss: 1.4372\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5018 - val_loss: 1.4373\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5017 - val_loss: 1.4374\n",
      "Скор для фолда(17) : 1.2037 средний скор на префиксе = 1.3756 это заняло = 12 сек.\n",
      "Фолд: 18\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.8234 - val_loss: 2.3121\n",
      "Текущий реальный скор(валидационная часть): 2.2483\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.9476 - val_loss: 1.6141\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.6564 - val_loss: 1.4402\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.5089 - val_loss: 1.4182\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.4268 - val_loss: 1.4125\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.3567 - val_loss: 1.4004\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 1.2960 - val_loss: 1.3865\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.2382 - val_loss: 1.4229\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 1.1885 - val_loss: 1.4251\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 1.1465 - val_loss: 1.4597\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.1191 - val_loss: 1.4831\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 1.0928 - val_loss: 1.4746\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 1.0807 - val_loss: 1.4894\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.0242 - val_loss: 1.5380\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 1.0102 - val_loss: 1.5201\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 1.0155 - val_loss: 1.6036\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 1.0128 - val_loss: 1.4677\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.9607 - val_loss: 1.4985\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.8838 - val_loss: 1.5205\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.8401 - val_loss: 1.5217\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.8120 - val_loss: 1.5454\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.7883 - val_loss: 1.5495\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7674 - val_loss: 1.5557\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.7477 - val_loss: 1.5687\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.7311 - val_loss: 1.5696\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.7149 - val_loss: 1.5824\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.7019 - val_loss: 1.5979\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.7129 - val_loss: 1.5516\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6978 - val_loss: 1.5421\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6807 - val_loss: 1.5387\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6682 - val_loss: 1.5392\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6552 - val_loss: 1.5310\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.6446 - val_loss: 1.5357\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.6349 - val_loss: 1.5415\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6249 - val_loss: 1.5469\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.6189 - val_loss: 1.5503\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6075 - val_loss: 1.5637\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.6183 - val_loss: 1.5289\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6193 - val_loss: 1.5174\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.6175 - val_loss: 1.5109\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.6160 - val_loss: 1.5076\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6133 - val_loss: 1.5063\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.6107 - val_loss: 1.5062\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 788us/step - loss: 0.6076 - val_loss: 1.5046\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.6049 - val_loss: 1.5037\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6003 - val_loss: 1.5092\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5968 - val_loss: 1.5074\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6103 - val_loss: 1.4998\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6001 - val_loss: 1.5052\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5925 - val_loss: 1.5134\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5871 - val_loss: 1.5203\n",
      "Текущий реальный скор(валидационная часть): 1.4169\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5826 - val_loss: 1.5266\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5787 - val_loss: 1.5299\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5750 - val_loss: 1.5323\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5717 - val_loss: 1.5342\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5688 - val_loss: 1.5355\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5660 - val_loss: 1.5372\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5629 - val_loss: 1.5416\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5598 - val_loss: 1.5418\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5580 - val_loss: 1.5423\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5565 - val_loss: 1.5428\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5551 - val_loss: 1.5434\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5537 - val_loss: 1.5438\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5524 - val_loss: 1.5446\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5512 - val_loss: 1.5449\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5500 - val_loss: 1.5456\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.5488 - val_loss: 1.5459\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5487 - val_loss: 1.5450\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5484 - val_loss: 1.5452\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5476 - val_loss: 1.5453\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5470 - val_loss: 1.5455\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5463 - val_loss: 1.5456\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5456 - val_loss: 1.5459\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5451 - val_loss: 1.5460\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5444 - val_loss: 1.5461\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5439 - val_loss: 1.5462\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5433 - val_loss: 1.5464\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5441 - val_loss: 1.5475\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5431 - val_loss: 1.5477\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5426 - val_loss: 1.5479\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5422 - val_loss: 1.5481\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5419 - val_loss: 1.5483\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5415 - val_loss: 1.5484\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5412 - val_loss: 1.5485\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.5409 - val_loss: 1.5486\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5405 - val_loss: 1.5487\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5402 - val_loss: 1.5489\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.5401 - val_loss: 1.5505\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5389 - val_loss: 1.5508\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5386 - val_loss: 1.5509\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5384 - val_loss: 1.5510\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5382 - val_loss: 1.5510\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.5381 - val_loss: 1.5511\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5379 - val_loss: 1.5512\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5377 - val_loss: 1.5512\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.5376 - val_loss: 1.5512\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.5374 - val_loss: 1.5513\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5369 - val_loss: 1.5521\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5365 - val_loss: 1.5525\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.5363 - val_loss: 1.5526\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.5362 - val_loss: 1.5527\n",
      "Текущий реальный скор(валидационная часть): 1.4473\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5361 - val_loss: 1.5527\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5360 - val_loss: 1.5528\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5359 - val_loss: 1.5528\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.5358 - val_loss: 1.5528\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 745us/step - loss: 0.5358 - val_loss: 1.5528\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5357 - val_loss: 1.5528\n",
      "Скор для фолда(18) : 1.289 средний скор на префиксе = 1.3711 это заняло = 12 сек.\n",
      "Фолд: 19\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (GPU) количество эпох = 1000\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 1ms/step - loss: 3.7938 - val_loss: 2.4025\n",
      "Текущий реальный скор(валидационная часть): 2.2892\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.9117 - val_loss: 1.9665\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.6183 - val_loss: 1.7994\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.4788 - val_loss: 1.7201\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 1.3953 - val_loss: 1.6823\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.3287 - val_loss: 1.6245\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.2761 - val_loss: 1.6313\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.2271 - val_loss: 1.6249\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 1.1799 - val_loss: 1.5918\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 1.1550 - val_loss: 1.5625\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 1.1245 - val_loss: 1.6261\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.0953 - val_loss: 1.6782\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.0713 - val_loss: 1.6419\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 1.0490 - val_loss: 1.6368\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.0719 - val_loss: 1.6285\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.0924 - val_loss: 1.6247\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 0s 727us/step - loss: 1.0944 - val_loss: 1.6813\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 1.0349 - val_loss: 1.6047\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.9231 - val_loss: 1.5611\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.8600 - val_loss: 1.5677\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.8203 - val_loss: 1.5561\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.7857 - val_loss: 1.5911\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.7717 - val_loss: 1.5728\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.7540 - val_loss: 1.5463\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.7367 - val_loss: 1.5474\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.7206 - val_loss: 1.6017\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.7216 - val_loss: 1.5573\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.7473 - val_loss: 1.5414\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.7264 - val_loss: 1.5589\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.7125 - val_loss: 1.5504\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 0s 728us/step - loss: 0.7048 - val_loss: 1.5705\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.7419 - val_loss: 1.5178\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.7263 - val_loss: 1.5566\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 0s 730us/step - loss: 0.6844 - val_loss: 1.5094\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.7011 - val_loss: 1.5078\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.7066 - val_loss: 1.5456\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.6814 - val_loss: 1.5923\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.7005 - val_loss: 1.5159\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.6670 - val_loss: 1.4387\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6563 - val_loss: 1.6448\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.6946 - val_loss: 1.5631\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.8173 - val_loss: 1.5540\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.8869 - val_loss: 1.4119\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.7798 - val_loss: 1.5147\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.7011 - val_loss: 1.6345\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.6848 - val_loss: 1.6649\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.7170 - val_loss: 1.6595\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.7475 - val_loss: 1.5790\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.7770 - val_loss: 1.3686\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.7670 - val_loss: 1.3838\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.7127 - val_loss: 1.5018\n",
      "Текущий реальный скор(валидационная часть): 1.3814\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6779 - val_loss: 1.3717\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.6033 - val_loss: 1.4148\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.5634 - val_loss: 1.3379\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.5352 - val_loss: 1.3071\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 0s 727us/step - loss: 0.5100 - val_loss: 1.3632\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.4963 - val_loss: 1.3673\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.4881 - val_loss: 1.3981\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 0s 730us/step - loss: 0.4798 - val_loss: 1.4443\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.4910 - val_loss: 1.4685\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.4972 - val_loss: 1.5003\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.5223 - val_loss: 1.4204\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.6597 - val_loss: 1.4108\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.6723 - val_loss: 1.4645\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.6517 - val_loss: 1.5085\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.6148 - val_loss: 1.3892\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.5259 - val_loss: 1.4126\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.4672 - val_loss: 1.4414\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.4383 - val_loss: 1.4523\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.4183 - val_loss: 1.4579\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.4044 - val_loss: 1.4666\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.3927 - val_loss: 1.4696\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.3828 - val_loss: 1.4703\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3731 - val_loss: 1.4883\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.3694 - val_loss: 1.4807\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 0s 729us/step - loss: 0.3845 - val_loss: 1.4969\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.3851 - val_loss: 1.4837\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3820 - val_loss: 1.4676\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3783 - val_loss: 1.4537\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3732 - val_loss: 1.4391\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3679 - val_loss: 1.4302\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3620 - val_loss: 1.4235\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3554 - val_loss: 1.4217\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3502 - val_loss: 1.4233\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3443 - val_loss: 1.4212\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3624 - val_loss: 1.4357\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3492 - val_loss: 1.4354\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.3425 - val_loss: 1.4349\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3372 - val_loss: 1.4352\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3331 - val_loss: 1.4356\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 0s 730us/step - loss: 0.3295 - val_loss: 1.4348\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 0s 729us/step - loss: 0.3264 - val_loss: 1.4342\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 0s 729us/step - loss: 0.3236 - val_loss: 1.4334\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3210 - val_loss: 1.4321\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3184 - val_loss: 1.4283\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 0s 742us/step - loss: 0.3238 - val_loss: 1.4057\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3206 - val_loss: 1.4022\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 0s 727us/step - loss: 0.3181 - val_loss: 1.4015\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3160 - val_loss: 1.4001\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 0s 738us/step - loss: 0.3140 - val_loss: 1.3992\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 0s 739us/step - loss: 0.3123 - val_loss: 1.3989\n",
      "Текущий реальный скор(валидационная часть): 1.2786\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3108 - val_loss: 1.3988\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.3093 - val_loss: 1.3983\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.3080 - val_loss: 1.3980\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3068 - val_loss: 1.3983\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 0s 732us/step - loss: 0.3131 - val_loss: 1.3990\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3116 - val_loss: 1.3974\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3106 - val_loss: 1.3963\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 0s 726us/step - loss: 0.3097 - val_loss: 1.3960\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 0s 733us/step - loss: 0.3088 - val_loss: 1.3950\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.3080 - val_loss: 1.3944\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 0s 737us/step - loss: 0.3072 - val_loss: 1.3939\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 0s 734us/step - loss: 0.3065 - val_loss: 1.3931\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 0s 736us/step - loss: 0.3058 - val_loss: 1.3928\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 0s 735us/step - loss: 0.3051 - val_loss: 1.3924\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.3120 - val_loss: 1.3843\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3113 - val_loss: 1.3825\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - 0s 961us/step - loss: 0.3106 - val_loss: 1.3812\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.3100 - val_loss: 1.3801\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.3094 - val_loss: 1.3793\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3089 - val_loss: 1.3786\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3084 - val_loss: 1.3783\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3078 - val_loss: 1.3777\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3074 - val_loss: 1.3772\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3069 - val_loss: 1.3769\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3083 - val_loss: 1.3721\n",
      "Epoch 127/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3069 - val_loss: 1.3718\n",
      "Epoch 128/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3064 - val_loss: 1.3717\n",
      "Epoch 129/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3060 - val_loss: 1.3715\n",
      "Epoch 130/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3056 - val_loss: 1.3713\n",
      "Epoch 131/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3053 - val_loss: 1.3710\n",
      "Epoch 132/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3049 - val_loss: 1.3708\n",
      "Epoch 133/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3046 - val_loss: 1.3706\n",
      "Epoch 134/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.3043 - val_loss: 1.3703\n",
      "Epoch 135/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3040 - val_loss: 1.3702\n",
      "Epoch 136/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3030 - val_loss: 1.3693\n",
      "Epoch 137/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3026 - val_loss: 1.3690\n",
      "Epoch 138/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.3024 - val_loss: 1.3690\n",
      "Epoch 139/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3023 - val_loss: 1.3690\n",
      "Epoch 140/1000\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.3021 - val_loss: 1.3691\n",
      "Epoch 141/1000\n",
      "134/134 [==============================] - 0s 750us/step - loss: 0.3020 - val_loss: 1.3691\n",
      "Epoch 142/1000\n",
      "134/134 [==============================] - 0s 743us/step - loss: 0.3018 - val_loss: 1.3692\n",
      "Epoch 143/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3017 - val_loss: 1.3692\n",
      "Epoch 144/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3016 - val_loss: 1.3693\n",
      "Epoch 145/1000\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.3014 - val_loss: 1.3693\n",
      "Epoch 146/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3006 - val_loss: 1.3692\n",
      "Epoch 147/1000\n",
      "134/134 [==============================] - 0s 749us/step - loss: 0.3005 - val_loss: 1.3691\n",
      "Epoch 148/1000\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.3004 - val_loss: 1.3692\n",
      "Epoch 149/1000\n",
      "134/134 [==============================] - 0s 744us/step - loss: 0.3003 - val_loss: 1.3692\n",
      "Epoch 150/1000\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.3003 - val_loss: 1.3693\n",
      "Epoch 151/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3002 - val_loss: 1.3693\n",
      "Текущий реальный скор(валидационная часть): 1.2522\n",
      "Epoch 152/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3001 - val_loss: 1.3693\n",
      "Epoch 153/1000\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.3001 - val_loss: 1.3694\n",
      "Epoch 154/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3000 - val_loss: 1.3694\n",
      "Epoch 155/1000\n",
      "134/134 [==============================] - 0s 748us/step - loss: 0.3000 - val_loss: 1.3694\n",
      "Скор для фолда(19) : 1.1653 средний скор на префиксе = 1.3608 это заняло = 17 сек.\n",
      "Процесс обучения модели занял = 296 секунд\n"
     ]
    }
   ],
   "source": [
    "features_columns_order = get_columns_order(train.columns.values.tolist())\n",
    "split_list = get_standart_split(train, n_splits=20)\n",
    "\n",
    "start_train_model_time = time.time()\n",
    "# Размер батча для Dataset\n",
    "BATCH_SIZE = int(2 ** 5)\n",
    "# Количество эпох обучения\n",
    "EPOCHS = 1000\n",
    "# Количество численных входных переменных модели\n",
    "NUM_FEATURES = len(NUM_FEATURES_COLUMNS)\n",
    "# Макс. значения категориалных фичей\n",
    "MAX_REALTY = max(train['realty_type'].max(), test['realty_type'].max())\n",
    "MAX_REGION = max(train['region'].max(), test['region'].max())\n",
    "MAX_CITY = max(train['city'].max(), test['city'].max())\n",
    "# Коэффициент домножения таргета, с целью быстрейшего сходимости модельки и лучшего обучения\n",
    "MUL_TARGET = 5e-5\n",
    "\n",
    "scores = []\n",
    "nn_predicts = np.zeros(len(train))\n",
    "models_nn = []\n",
    "\n",
    "for fold_num, (train_indexes, valid_indexes) in enumerate(split_list):\n",
    "    start_time = time.time()\n",
    "    print(f\"Фолд: {fold_num}\")\n",
    "\n",
    "    train_sub_df = train[features_columns_order].loc[train_indexes].reset_index(drop=True)\n",
    "    valid_sub_df = train[features_columns_order].loc[valid_indexes].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Размер трейна = {train_sub_df.shape} Размер валидации = {valid_sub_df.shape}\")\n",
    "\n",
    "    # Строим датасеты\n",
    "    train_ds = get_dataset(\n",
    "        train_sub_df[NUM_FEATURES_COLUMNS].values,\n",
    "        train_sub_df[TARGET_COLUMNS].values * MUL_TARGET,\n",
    "        train_sub_df[['region']].values,\n",
    "        train_sub_df[['city']].values,\n",
    "        train_sub_df[['realty_type']].values,\n",
    "        BATCH_SIZE)\n",
    "    valid_ds = get_dataset(\n",
    "        valid_sub_df[NUM_FEATURES_COLUMNS].values,\n",
    "        valid_sub_df[TARGET_COLUMNS].values * MUL_TARGET,\n",
    "        valid_sub_df[['region']].values,\n",
    "        valid_sub_df[['city']].values,\n",
    "        valid_sub_df[['realty_type']].values,\n",
    "        len(valid_sub_df))\n",
    "\n",
    "    # Компилируем модель\n",
    "    model = compile_model(train_ds, valid_ds, NUM_FEATURES, MAX_REALTY, MAX_REGION, MAX_CITY)\n",
    "    # Обучаем модель\n",
    "    fit(model, EPOCHS, train_ds, valid_ds, valid_sub_df[TARGET_COLUMNS].values * MUL_TARGET)\n",
    "\n",
    "    predict_on_validation = model.predict(valid_ds)[:, 0] / MUL_TARGET\n",
    "    nn_predicts[valid_indexes] = predict_on_validation\n",
    "    targets_for_validation = valid_sub_df[TARGET_COLUMNS].values[:, 0]\n",
    "    current_score = deviation_metric(targets_for_validation, predict_on_validation)\n",
    "    scores += [current_score]\n",
    "    models_nn += [model]\n",
    "    print(\n",
    "        f\"Скор для фолда({fold_num}) : {np.round(current_score, 4)} средний скор на префиксе = {np.round(np.mean(scores), 4)} это заняло = {int(time.time() - start_time)} сек.\")\n",
    "print(f\"Процесс обучения модели занял = {int(time.time() - start_train_model_time)} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b32634-17b9-4b2c-b5d7-374760401577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8e3481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 160 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f162625cb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 161 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f15e43e30e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# Предикт нейронной сетью на test\n",
    "def get_nn_predict(models, test):\n",
    "    result = np.zeros(len(test))\n",
    "    test_ds = get_dataset(\n",
    "        test[NUM_FEATURES_COLUMNS].values,\n",
    "        np.zeros(len(test)),\n",
    "        test[['region']].values,\n",
    "        test[['city']].values,\n",
    "        test[['realty_type']].values,\n",
    "        len(test))\n",
    "    for model in models:\n",
    "        predict = model.predict(test_ds)[:, 0]\n",
    "        result += (predict / MUL_TARGET) / len(models)\n",
    "    return result\n",
    "\n",
    "\n",
    "test_nn_predict = get_nn_predict(models_nn, test)\n",
    "\n",
    "test_submission = pd.read_csv('dataset/test_submission.csv')\n",
    "\n",
    "test_submission['per_square_meter_price'] = test_nn_predict\n",
    "test_submission.to_csv('nn2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d2563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300df005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6902a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60901252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фолд: 0\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.83197\tvalid_1's deviation_error: 1.96792\n",
      "[200]\ttraining's deviation_error: 1.51318\tvalid_1's deviation_error: 1.8648\n",
      "[300]\ttraining's deviation_error: 1.37444\tvalid_1's deviation_error: 1.79724\n",
      "[400]\ttraining's deviation_error: 1.29135\tvalid_1's deviation_error: 1.75005\n",
      "[500]\ttraining's deviation_error: 1.23679\tvalid_1's deviation_error: 1.71761\n",
      "[600]\ttraining's deviation_error: 1.19414\tvalid_1's deviation_error: 1.69941\n",
      "[700]\ttraining's deviation_error: 1.16096\tvalid_1's deviation_error: 1.68737\n",
      "[800]\ttraining's deviation_error: 1.13221\tvalid_1's deviation_error: 1.68779\n",
      "[900]\ttraining's deviation_error: 1.11092\tvalid_1's deviation_error: 1.67793\n",
      "[1000]\ttraining's deviation_error: 1.0903\tvalid_1's deviation_error: 1.67273\n",
      "[1100]\ttraining's deviation_error: 1.07043\tvalid_1's deviation_error: 1.666\n",
      "[1200]\ttraining's deviation_error: 1.05227\tvalid_1's deviation_error: 1.66383\n",
      "[1300]\ttraining's deviation_error: 1.03609\tvalid_1's deviation_error: 1.65132\n",
      "[1400]\ttraining's deviation_error: 1.02038\tvalid_1's deviation_error: 1.6406\n",
      "[1500]\ttraining's deviation_error: 1.00628\tvalid_1's deviation_error: 1.63573\n",
      "[1600]\ttraining's deviation_error: 0.99464\tvalid_1's deviation_error: 1.63364\n",
      "[1700]\ttraining's deviation_error: 0.983399\tvalid_1's deviation_error: 1.62488\n",
      "[1800]\ttraining's deviation_error: 0.97269\tvalid_1's deviation_error: 1.62325\n",
      "[1900]\ttraining's deviation_error: 0.962194\tvalid_1's deviation_error: 1.62123\n",
      "[2000]\ttraining's deviation_error: 0.954375\tvalid_1's deviation_error: 1.62015\n",
      "[2100]\ttraining's deviation_error: 0.945385\tvalid_1's deviation_error: 1.61838\n",
      "[2200]\ttraining's deviation_error: 0.936612\tvalid_1's deviation_error: 1.62068\n",
      "[2300]\ttraining's deviation_error: 0.930476\tvalid_1's deviation_error: 1.62122\n",
      "Early stopping, best iteration is:\n",
      "[2099]\ttraining's deviation_error: 0.945451\tvalid_1's deviation_error: 1.61812\n",
      "Скор для фолда(0) : 9.0 средний скор на префиксе = 9.0 это заняло = 52 сек.\n",
      "Фолд: 1\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.84417\tvalid_1's deviation_error: 1.78448\n",
      "[200]\ttraining's deviation_error: 1.52426\tvalid_1's deviation_error: 1.61301\n",
      "[300]\ttraining's deviation_error: 1.37248\tvalid_1's deviation_error: 1.56565\n",
      "[400]\ttraining's deviation_error: 1.29516\tvalid_1's deviation_error: 1.53885\n",
      "[500]\ttraining's deviation_error: 1.24108\tvalid_1's deviation_error: 1.52886\n",
      "[600]\ttraining's deviation_error: 1.20354\tvalid_1's deviation_error: 1.52953\n",
      "[700]\ttraining's deviation_error: 1.17083\tvalid_1's deviation_error: 1.52024\n",
      "[800]\ttraining's deviation_error: 1.14683\tvalid_1's deviation_error: 1.50884\n",
      "[900]\ttraining's deviation_error: 1.12333\tvalid_1's deviation_error: 1.50943\n",
      "[1000]\ttraining's deviation_error: 1.10325\tvalid_1's deviation_error: 1.50805\n",
      "[1100]\ttraining's deviation_error: 1.08447\tvalid_1's deviation_error: 1.50415\n",
      "[1200]\ttraining's deviation_error: 1.06603\tvalid_1's deviation_error: 1.49653\n",
      "[1300]\ttraining's deviation_error: 1.05464\tvalid_1's deviation_error: 1.49525\n",
      "[1400]\ttraining's deviation_error: 1.04012\tvalid_1's deviation_error: 1.49044\n",
      "[1500]\ttraining's deviation_error: 1.02598\tvalid_1's deviation_error: 1.48501\n",
      "[1600]\ttraining's deviation_error: 1.01459\tvalid_1's deviation_error: 1.4841\n",
      "[1700]\ttraining's deviation_error: 1.00177\tvalid_1's deviation_error: 1.48225\n",
      "[1800]\ttraining's deviation_error: 0.991597\tvalid_1's deviation_error: 1.48078\n",
      "[1900]\ttraining's deviation_error: 0.980994\tvalid_1's deviation_error: 1.47669\n",
      "[2000]\ttraining's deviation_error: 0.971971\tvalid_1's deviation_error: 1.47242\n",
      "[2100]\ttraining's deviation_error: 0.964663\tvalid_1's deviation_error: 1.46812\n",
      "[2200]\ttraining's deviation_error: 0.957535\tvalid_1's deviation_error: 1.46756\n",
      "[2300]\ttraining's deviation_error: 0.951571\tvalid_1's deviation_error: 1.46563\n",
      "[2400]\ttraining's deviation_error: 0.945714\tvalid_1's deviation_error: 1.46468\n",
      "[2500]\ttraining's deviation_error: 0.939058\tvalid_1's deviation_error: 1.46545\n",
      "Early stopping, best iteration is:\n",
      "[2265]\ttraining's deviation_error: 0.95396\tvalid_1's deviation_error: 1.4634\n",
      "Скор для фолда(1) : 9.0 средний скор на префиксе = 9.0 это заняло = 56 сек.\n",
      "Фолд: 2\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.83412\tvalid_1's deviation_error: 1.85608\n",
      "[200]\ttraining's deviation_error: 1.52747\tvalid_1's deviation_error: 1.4147\n",
      "[300]\ttraining's deviation_error: 1.38377\tvalid_1's deviation_error: 1.29734\n",
      "[400]\ttraining's deviation_error: 1.30344\tvalid_1's deviation_error: 1.28272\n",
      "[500]\ttraining's deviation_error: 1.252\tvalid_1's deviation_error: 1.24828\n",
      "[600]\ttraining's deviation_error: 1.21008\tvalid_1's deviation_error: 1.23019\n",
      "[700]\ttraining's deviation_error: 1.17635\tvalid_1's deviation_error: 1.226\n",
      "[800]\ttraining's deviation_error: 1.14749\tvalid_1's deviation_error: 1.21551\n",
      "[900]\ttraining's deviation_error: 1.12443\tvalid_1's deviation_error: 1.21728\n",
      "[1000]\ttraining's deviation_error: 1.10511\tvalid_1's deviation_error: 1.21578\n",
      "[1100]\ttraining's deviation_error: 1.08837\tvalid_1's deviation_error: 1.20906\n",
      "[1200]\ttraining's deviation_error: 1.07158\tvalid_1's deviation_error: 1.20028\n",
      "[1300]\ttraining's deviation_error: 1.05706\tvalid_1's deviation_error: 1.1951\n",
      "[1400]\ttraining's deviation_error: 1.04523\tvalid_1's deviation_error: 1.19152\n",
      "[1500]\ttraining's deviation_error: 1.03306\tvalid_1's deviation_error: 1.18684\n",
      "[1600]\ttraining's deviation_error: 1.02166\tvalid_1's deviation_error: 1.17919\n",
      "[1700]\ttraining's deviation_error: 1.01187\tvalid_1's deviation_error: 1.17776\n",
      "[1800]\ttraining's deviation_error: 1.00029\tvalid_1's deviation_error: 1.17429\n",
      "[1900]\ttraining's deviation_error: 0.991771\tvalid_1's deviation_error: 1.17193\n",
      "[2000]\ttraining's deviation_error: 0.982627\tvalid_1's deviation_error: 1.16755\n",
      "[2100]\ttraining's deviation_error: 0.974231\tvalid_1's deviation_error: 1.16342\n",
      "[2200]\ttraining's deviation_error: 0.967566\tvalid_1's deviation_error: 1.15897\n",
      "[2300]\ttraining's deviation_error: 0.96124\tvalid_1's deviation_error: 1.15625\n",
      "[2400]\ttraining's deviation_error: 0.953808\tvalid_1's deviation_error: 1.15656\n",
      "[2500]\ttraining's deviation_error: 0.948189\tvalid_1's deviation_error: 1.15166\n",
      "[2600]\ttraining's deviation_error: 0.941654\tvalid_1's deviation_error: 1.15097\n",
      "[2700]\ttraining's deviation_error: 0.934875\tvalid_1's deviation_error: 1.14598\n",
      "[2800]\ttraining's deviation_error: 0.930447\tvalid_1's deviation_error: 1.14563\n",
      "[2900]\ttraining's deviation_error: 0.923974\tvalid_1's deviation_error: 1.14377\n",
      "[3000]\ttraining's deviation_error: 0.91934\tvalid_1's deviation_error: 1.14174\n",
      "[3100]\ttraining's deviation_error: 0.915063\tvalid_1's deviation_error: 1.14034\n",
      "[3200]\ttraining's deviation_error: 0.909524\tvalid_1's deviation_error: 1.13837\n",
      "[3300]\ttraining's deviation_error: 0.906237\tvalid_1's deviation_error: 1.13973\n",
      "[3400]\ttraining's deviation_error: 0.900922\tvalid_1's deviation_error: 1.13776\n",
      "[3500]\ttraining's deviation_error: 0.896267\tvalid_1's deviation_error: 1.13684\n",
      "[3600]\ttraining's deviation_error: 0.891145\tvalid_1's deviation_error: 1.13696\n",
      "[3700]\ttraining's deviation_error: 0.887155\tvalid_1's deviation_error: 1.13628\n",
      "[3800]\ttraining's deviation_error: 0.883641\tvalid_1's deviation_error: 1.1347\n",
      "[3900]\ttraining's deviation_error: 0.880058\tvalid_1's deviation_error: 1.13493\n",
      "[4000]\ttraining's deviation_error: 0.876713\tvalid_1's deviation_error: 1.13366\n",
      "Early stopping, best iteration is:\n",
      "[3773]\ttraining's deviation_error: 0.884248\tvalid_1's deviation_error: 1.1331\n",
      "Скор для фолда(2) : 9.0 средний скор на префиксе = 9.0 это заняло = 89 сек.\n",
      "Фолд: 3\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.83005\tvalid_1's deviation_error: 2.14931\n",
      "[200]\ttraining's deviation_error: 1.51326\tvalid_1's deviation_error: 1.8987\n",
      "[300]\ttraining's deviation_error: 1.37681\tvalid_1's deviation_error: 1.74536\n",
      "[400]\ttraining's deviation_error: 1.3009\tvalid_1's deviation_error: 1.69394\n",
      "[500]\ttraining's deviation_error: 1.24629\tvalid_1's deviation_error: 1.65559\n",
      "[600]\ttraining's deviation_error: 1.20397\tvalid_1's deviation_error: 1.62799\n",
      "[700]\ttraining's deviation_error: 1.1738\tvalid_1's deviation_error: 1.60164\n",
      "[800]\ttraining's deviation_error: 1.14927\tvalid_1's deviation_error: 1.58965\n",
      "[900]\ttraining's deviation_error: 1.12917\tvalid_1's deviation_error: 1.57769\n",
      "[1000]\ttraining's deviation_error: 1.10846\tvalid_1's deviation_error: 1.56875\n",
      "[1100]\ttraining's deviation_error: 1.09269\tvalid_1's deviation_error: 1.56065\n",
      "[1200]\ttraining's deviation_error: 1.0799\tvalid_1's deviation_error: 1.55324\n",
      "[1300]\ttraining's deviation_error: 1.06431\tvalid_1's deviation_error: 1.5419\n",
      "[1400]\ttraining's deviation_error: 1.05075\tvalid_1's deviation_error: 1.52786\n",
      "[1500]\ttraining's deviation_error: 1.03708\tvalid_1's deviation_error: 1.51722\n",
      "[1600]\ttraining's deviation_error: 1.02574\tvalid_1's deviation_error: 1.51248\n",
      "[1700]\ttraining's deviation_error: 1.01733\tvalid_1's deviation_error: 1.50827\n",
      "[1800]\ttraining's deviation_error: 1.00817\tvalid_1's deviation_error: 1.50222\n",
      "[1900]\ttraining's deviation_error: 0.999562\tvalid_1's deviation_error: 1.49964\n",
      "[2000]\ttraining's deviation_error: 0.989879\tvalid_1's deviation_error: 1.49643\n",
      "[2100]\ttraining's deviation_error: 0.980637\tvalid_1's deviation_error: 1.49276\n",
      "[2200]\ttraining's deviation_error: 0.972986\tvalid_1's deviation_error: 1.48738\n",
      "[2300]\ttraining's deviation_error: 0.965308\tvalid_1's deviation_error: 1.4839\n",
      "[2400]\ttraining's deviation_error: 0.960954\tvalid_1's deviation_error: 1.48437\n",
      "[2500]\ttraining's deviation_error: 0.952968\tvalid_1's deviation_error: 1.47921\n",
      "[2600]\ttraining's deviation_error: 0.945522\tvalid_1's deviation_error: 1.47457\n",
      "[2700]\ttraining's deviation_error: 0.938713\tvalid_1's deviation_error: 1.4722\n",
      "[2800]\ttraining's deviation_error: 0.932518\tvalid_1's deviation_error: 1.46502\n",
      "[2900]\ttraining's deviation_error: 0.926585\tvalid_1's deviation_error: 1.45974\n",
      "[3000]\ttraining's deviation_error: 0.921351\tvalid_1's deviation_error: 1.45711\n",
      "[3100]\ttraining's deviation_error: 0.916145\tvalid_1's deviation_error: 1.45475\n",
      "[3200]\ttraining's deviation_error: 0.910999\tvalid_1's deviation_error: 1.45178\n",
      "[3300]\ttraining's deviation_error: 0.905891\tvalid_1's deviation_error: 1.44965\n",
      "[3400]\ttraining's deviation_error: 0.901865\tvalid_1's deviation_error: 1.44769\n",
      "[3500]\ttraining's deviation_error: 0.896863\tvalid_1's deviation_error: 1.4467\n",
      "[3600]\ttraining's deviation_error: 0.892742\tvalid_1's deviation_error: 1.44528\n",
      "[3700]\ttraining's deviation_error: 0.88782\tvalid_1's deviation_error: 1.44407\n",
      "[3800]\ttraining's deviation_error: 0.884209\tvalid_1's deviation_error: 1.44398\n",
      "[3900]\ttraining's deviation_error: 0.881091\tvalid_1's deviation_error: 1.44258\n",
      "[4000]\ttraining's deviation_error: 0.878436\tvalid_1's deviation_error: 1.44138\n",
      "[4100]\ttraining's deviation_error: 0.874468\tvalid_1's deviation_error: 1.43996\n",
      "[4200]\ttraining's deviation_error: 0.870454\tvalid_1's deviation_error: 1.43947\n",
      "[4300]\ttraining's deviation_error: 0.866755\tvalid_1's deviation_error: 1.43709\n",
      "[4400]\ttraining's deviation_error: 0.864149\tvalid_1's deviation_error: 1.43549\n",
      "[4500]\ttraining's deviation_error: 0.861013\tvalid_1's deviation_error: 1.43187\n",
      "[4600]\ttraining's deviation_error: 0.857673\tvalid_1's deviation_error: 1.42936\n",
      "[4700]\ttraining's deviation_error: 0.854315\tvalid_1's deviation_error: 1.42769\n",
      "[4800]\ttraining's deviation_error: 0.851177\tvalid_1's deviation_error: 1.4269\n",
      "[4900]\ttraining's deviation_error: 0.848584\tvalid_1's deviation_error: 1.42694\n",
      "[5000]\ttraining's deviation_error: 0.845937\tvalid_1's deviation_error: 1.42668\n",
      "[5100]\ttraining's deviation_error: 0.843561\tvalid_1's deviation_error: 1.42592\n",
      "[5200]\ttraining's deviation_error: 0.841224\tvalid_1's deviation_error: 1.4258\n",
      "[5300]\ttraining's deviation_error: 0.839006\tvalid_1's deviation_error: 1.42628\n",
      "[5400]\ttraining's deviation_error: 0.836035\tvalid_1's deviation_error: 1.42511\n",
      "[5500]\ttraining's deviation_error: 0.833752\tvalid_1's deviation_error: 1.42381\n",
      "[5600]\ttraining's deviation_error: 0.831279\tvalid_1's deviation_error: 1.42276\n",
      "[5700]\ttraining's deviation_error: 0.828303\tvalid_1's deviation_error: 1.42296\n",
      "[5800]\ttraining's deviation_error: 0.825263\tvalid_1's deviation_error: 1.42096\n",
      "[5900]\ttraining's deviation_error: 0.823092\tvalid_1's deviation_error: 1.42069\n",
      "[6000]\ttraining's deviation_error: 0.820988\tvalid_1's deviation_error: 1.41912\n",
      "[6100]\ttraining's deviation_error: 0.818393\tvalid_1's deviation_error: 1.41802\n",
      "[6200]\ttraining's deviation_error: 0.815955\tvalid_1's deviation_error: 1.41552\n",
      "[6300]\ttraining's deviation_error: 0.814061\tvalid_1's deviation_error: 1.41463\n",
      "[6400]\ttraining's deviation_error: 0.812092\tvalid_1's deviation_error: 1.41313\n",
      "[6500]\ttraining's deviation_error: 0.810388\tvalid_1's deviation_error: 1.41371\n",
      "[6600]\ttraining's deviation_error: 0.808844\tvalid_1's deviation_error: 1.41225\n",
      "[6700]\ttraining's deviation_error: 0.807193\tvalid_1's deviation_error: 1.41251\n",
      "[6800]\ttraining's deviation_error: 0.805202\tvalid_1's deviation_error: 1.41194\n",
      "[6900]\ttraining's deviation_error: 0.803003\tvalid_1's deviation_error: 1.41079\n",
      "[7000]\ttraining's deviation_error: 0.800967\tvalid_1's deviation_error: 1.40936\n",
      "[7100]\ttraining's deviation_error: 0.799347\tvalid_1's deviation_error: 1.40882\n",
      "[7200]\ttraining's deviation_error: 0.797055\tvalid_1's deviation_error: 1.40802\n",
      "[7300]\ttraining's deviation_error: 0.795495\tvalid_1's deviation_error: 1.40791\n",
      "[7400]\ttraining's deviation_error: 0.794096\tvalid_1's deviation_error: 1.40747\n",
      "[7500]\ttraining's deviation_error: 0.792095\tvalid_1's deviation_error: 1.40566\n",
      "[7600]\ttraining's deviation_error: 0.789576\tvalid_1's deviation_error: 1.40371\n",
      "[7700]\ttraining's deviation_error: 0.787657\tvalid_1's deviation_error: 1.40414\n",
      "[7800]\ttraining's deviation_error: 0.785592\tvalid_1's deviation_error: 1.40139\n",
      "[7900]\ttraining's deviation_error: 0.783929\tvalid_1's deviation_error: 1.40081\n",
      "[8000]\ttraining's deviation_error: 0.782235\tvalid_1's deviation_error: 1.40124\n",
      "[8100]\ttraining's deviation_error: 0.780933\tvalid_1's deviation_error: 1.40177\n",
      "Early stopping, best iteration is:\n",
      "[7909]\ttraining's deviation_error: 0.783822\tvalid_1's deviation_error: 1.40052\n",
      "Скор для фолда(3) : 9.0 средний скор на префиксе = 9.0 это заняло = 182 сек.\n",
      "Фолд: 4\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.82085\tvalid_1's deviation_error: 2.10757\n",
      "[200]\ttraining's deviation_error: 1.49792\tvalid_1's deviation_error: 1.87181\n",
      "[300]\ttraining's deviation_error: 1.36664\tvalid_1's deviation_error: 1.71193\n",
      "[400]\ttraining's deviation_error: 1.29128\tvalid_1's deviation_error: 1.6525\n",
      "[500]\ttraining's deviation_error: 1.23692\tvalid_1's deviation_error: 1.61402\n",
      "[600]\ttraining's deviation_error: 1.19599\tvalid_1's deviation_error: 1.60553\n",
      "[700]\ttraining's deviation_error: 1.16503\tvalid_1's deviation_error: 1.60006\n",
      "[800]\ttraining's deviation_error: 1.13929\tvalid_1's deviation_error: 1.58872\n",
      "[900]\ttraining's deviation_error: 1.11609\tvalid_1's deviation_error: 1.58329\n",
      "[1000]\ttraining's deviation_error: 1.09766\tvalid_1's deviation_error: 1.57299\n",
      "[1100]\ttraining's deviation_error: 1.07931\tvalid_1's deviation_error: 1.56562\n",
      "[1200]\ttraining's deviation_error: 1.06252\tvalid_1's deviation_error: 1.55612\n",
      "[1300]\ttraining's deviation_error: 1.04731\tvalid_1's deviation_error: 1.5523\n",
      "[1400]\ttraining's deviation_error: 1.03408\tvalid_1's deviation_error: 1.5444\n",
      "[1500]\ttraining's deviation_error: 1.02088\tvalid_1's deviation_error: 1.53478\n",
      "[1600]\ttraining's deviation_error: 1.00952\tvalid_1's deviation_error: 1.53065\n",
      "[1700]\ttraining's deviation_error: 0.998122\tvalid_1's deviation_error: 1.52226\n",
      "[1800]\ttraining's deviation_error: 0.988277\tvalid_1's deviation_error: 1.51889\n",
      "[1900]\ttraining's deviation_error: 0.979028\tvalid_1's deviation_error: 1.5158\n",
      "[2000]\ttraining's deviation_error: 0.969295\tvalid_1's deviation_error: 1.50927\n",
      "[2100]\ttraining's deviation_error: 0.961105\tvalid_1's deviation_error: 1.50551\n",
      "[2200]\ttraining's deviation_error: 0.952991\tvalid_1's deviation_error: 1.50031\n",
      "[2300]\ttraining's deviation_error: 0.947202\tvalid_1's deviation_error: 1.50163\n",
      "[2400]\ttraining's deviation_error: 0.941599\tvalid_1's deviation_error: 1.49966\n",
      "[2500]\ttraining's deviation_error: 0.935232\tvalid_1's deviation_error: 1.49812\n",
      "[2600]\ttraining's deviation_error: 0.927994\tvalid_1's deviation_error: 1.49664\n",
      "[2700]\ttraining's deviation_error: 0.923211\tvalid_1's deviation_error: 1.4968\n",
      "[2800]\ttraining's deviation_error: 0.917544\tvalid_1's deviation_error: 1.49533\n",
      "[2900]\ttraining's deviation_error: 0.912847\tvalid_1's deviation_error: 1.49634\n",
      "[3000]\ttraining's deviation_error: 0.907894\tvalid_1's deviation_error: 1.49768\n",
      "Early stopping, best iteration is:\n",
      "[2798]\ttraining's deviation_error: 0.917778\tvalid_1's deviation_error: 1.49488\n",
      "Скор для фолда(4) : 9.0 средний скор на префиксе = 9.0 это заняло = 69 сек.\n",
      "Фолд: 5\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.81231\tvalid_1's deviation_error: 2.25022\n",
      "[200]\ttraining's deviation_error: 1.49666\tvalid_1's deviation_error: 2.0117\n",
      "[300]\ttraining's deviation_error: 1.35456\tvalid_1's deviation_error: 1.91474\n",
      "[400]\ttraining's deviation_error: 1.27885\tvalid_1's deviation_error: 1.8921\n",
      "[500]\ttraining's deviation_error: 1.22593\tvalid_1's deviation_error: 1.8679\n",
      "[600]\ttraining's deviation_error: 1.1871\tvalid_1's deviation_error: 1.86409\n",
      "[700]\ttraining's deviation_error: 1.15698\tvalid_1's deviation_error: 1.85836\n",
      "[800]\ttraining's deviation_error: 1.13206\tvalid_1's deviation_error: 1.85269\n",
      "[900]\ttraining's deviation_error: 1.10714\tvalid_1's deviation_error: 1.84402\n",
      "[1000]\ttraining's deviation_error: 1.08411\tvalid_1's deviation_error: 1.83424\n",
      "[1100]\ttraining's deviation_error: 1.06741\tvalid_1's deviation_error: 1.83409\n",
      "[1200]\ttraining's deviation_error: 1.04949\tvalid_1's deviation_error: 1.82706\n",
      "[1300]\ttraining's deviation_error: 1.03276\tvalid_1's deviation_error: 1.82839\n",
      "[1400]\ttraining's deviation_error: 1.01946\tvalid_1's deviation_error: 1.8212\n",
      "[1500]\ttraining's deviation_error: 1.00704\tvalid_1's deviation_error: 1.81529\n",
      "[1600]\ttraining's deviation_error: 0.995754\tvalid_1's deviation_error: 1.81244\n",
      "[1700]\ttraining's deviation_error: 0.983984\tvalid_1's deviation_error: 1.815\n",
      "[1800]\ttraining's deviation_error: 0.97231\tvalid_1's deviation_error: 1.80839\n",
      "[1900]\ttraining's deviation_error: 0.962561\tvalid_1's deviation_error: 1.80715\n",
      "[2000]\ttraining's deviation_error: 0.954383\tvalid_1's deviation_error: 1.80197\n",
      "[2100]\ttraining's deviation_error: 0.943254\tvalid_1's deviation_error: 1.80199\n",
      "[2200]\ttraining's deviation_error: 0.936568\tvalid_1's deviation_error: 1.802\n",
      "[2300]\ttraining's deviation_error: 0.930534\tvalid_1's deviation_error: 1.79864\n",
      "[2400]\ttraining's deviation_error: 0.922785\tvalid_1's deviation_error: 1.79846\n",
      "[2500]\ttraining's deviation_error: 0.917222\tvalid_1's deviation_error: 1.79898\n",
      "[2600]\ttraining's deviation_error: 0.910468\tvalid_1's deviation_error: 1.79742\n",
      "[2700]\ttraining's deviation_error: 0.904448\tvalid_1's deviation_error: 1.79587\n",
      "[2800]\ttraining's deviation_error: 0.89851\tvalid_1's deviation_error: 1.79301\n",
      "[2900]\ttraining's deviation_error: 0.892729\tvalid_1's deviation_error: 1.78853\n",
      "[3000]\ttraining's deviation_error: 0.887615\tvalid_1's deviation_error: 1.78925\n",
      "[3100]\ttraining's deviation_error: 0.882057\tvalid_1's deviation_error: 1.78921\n",
      "[3200]\ttraining's deviation_error: 0.876594\tvalid_1's deviation_error: 1.78803\n",
      "Early stopping, best iteration is:\n",
      "[3029]\ttraining's deviation_error: 0.884822\tvalid_1's deviation_error: 1.78695\n",
      "Скор для фолда(5) : 9.0 средний скор на префиксе = 9.0 это заняло = 73 сек.\n",
      "Фолд: 6\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.84135\tvalid_1's deviation_error: 1.81004\n",
      "[200]\ttraining's deviation_error: 1.52391\tvalid_1's deviation_error: 1.52011\n",
      "[300]\ttraining's deviation_error: 1.37957\tvalid_1's deviation_error: 1.4298\n",
      "[400]\ttraining's deviation_error: 1.30018\tvalid_1's deviation_error: 1.40324\n",
      "[500]\ttraining's deviation_error: 1.24714\tvalid_1's deviation_error: 1.38089\n",
      "[600]\ttraining's deviation_error: 1.20591\tvalid_1's deviation_error: 1.36053\n",
      "[700]\ttraining's deviation_error: 1.17756\tvalid_1's deviation_error: 1.35435\n",
      "[800]\ttraining's deviation_error: 1.15011\tvalid_1's deviation_error: 1.34857\n",
      "[900]\ttraining's deviation_error: 1.12109\tvalid_1's deviation_error: 1.34399\n",
      "[1000]\ttraining's deviation_error: 1.09969\tvalid_1's deviation_error: 1.34417\n",
      "[1100]\ttraining's deviation_error: 1.07743\tvalid_1's deviation_error: 1.33948\n",
      "[1200]\ttraining's deviation_error: 1.05856\tvalid_1's deviation_error: 1.33753\n",
      "[1300]\ttraining's deviation_error: 1.04193\tvalid_1's deviation_error: 1.33522\n",
      "[1400]\ttraining's deviation_error: 1.02829\tvalid_1's deviation_error: 1.33681\n",
      "[1500]\ttraining's deviation_error: 1.017\tvalid_1's deviation_error: 1.33745\n",
      "Early stopping, best iteration is:\n",
      "[1340]\ttraining's deviation_error: 1.0362\tvalid_1's deviation_error: 1.33389\n",
      "Скор для фолда(6) : 9.0 средний скор на префиксе = 9.0 это заняло = 35 сек.\n",
      "Фолд: 7\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.85654\tvalid_1's deviation_error: 2.29179\n",
      "[200]\ttraining's deviation_error: 1.54164\tvalid_1's deviation_error: 1.90974\n",
      "[300]\ttraining's deviation_error: 1.38551\tvalid_1's deviation_error: 1.77891\n",
      "[400]\ttraining's deviation_error: 1.30143\tvalid_1's deviation_error: 1.72223\n",
      "[500]\ttraining's deviation_error: 1.24307\tvalid_1's deviation_error: 1.68621\n",
      "[600]\ttraining's deviation_error: 1.2049\tvalid_1's deviation_error: 1.66263\n",
      "[700]\ttraining's deviation_error: 1.17575\tvalid_1's deviation_error: 1.64339\n",
      "[800]\ttraining's deviation_error: 1.15081\tvalid_1's deviation_error: 1.63234\n",
      "[900]\ttraining's deviation_error: 1.12909\tvalid_1's deviation_error: 1.61919\n",
      "[1000]\ttraining's deviation_error: 1.11104\tvalid_1's deviation_error: 1.61147\n",
      "[1100]\ttraining's deviation_error: 1.09128\tvalid_1's deviation_error: 1.60889\n",
      "[1200]\ttraining's deviation_error: 1.07685\tvalid_1's deviation_error: 1.60533\n",
      "[1300]\ttraining's deviation_error: 1.06364\tvalid_1's deviation_error: 1.60892\n",
      "[1400]\ttraining's deviation_error: 1.04881\tvalid_1's deviation_error: 1.60226\n",
      "[1500]\ttraining's deviation_error: 1.03777\tvalid_1's deviation_error: 1.59971\n",
      "[1600]\ttraining's deviation_error: 1.02551\tvalid_1's deviation_error: 1.59297\n",
      "[1700]\ttraining's deviation_error: 1.01354\tvalid_1's deviation_error: 1.59272\n",
      "[1800]\ttraining's deviation_error: 1.00383\tvalid_1's deviation_error: 1.58781\n",
      "[1900]\ttraining's deviation_error: 0.993796\tvalid_1's deviation_error: 1.58173\n",
      "[2000]\ttraining's deviation_error: 0.986434\tvalid_1's deviation_error: 1.57656\n",
      "[2100]\ttraining's deviation_error: 0.979467\tvalid_1's deviation_error: 1.57454\n",
      "[2200]\ttraining's deviation_error: 0.971855\tvalid_1's deviation_error: 1.57339\n",
      "[2300]\ttraining's deviation_error: 0.966223\tvalid_1's deviation_error: 1.57157\n",
      "[2400]\ttraining's deviation_error: 0.959751\tvalid_1's deviation_error: 1.57324\n",
      "[2500]\ttraining's deviation_error: 0.953525\tvalid_1's deviation_error: 1.5719\n",
      "[2600]\ttraining's deviation_error: 0.94489\tvalid_1's deviation_error: 1.5705\n",
      "[2700]\ttraining's deviation_error: 0.938277\tvalid_1's deviation_error: 1.56693\n",
      "[2800]\ttraining's deviation_error: 0.931044\tvalid_1's deviation_error: 1.55916\n",
      "[2900]\ttraining's deviation_error: 0.924884\tvalid_1's deviation_error: 1.55562\n",
      "[3000]\ttraining's deviation_error: 0.919041\tvalid_1's deviation_error: 1.55217\n",
      "[3100]\ttraining's deviation_error: 0.912289\tvalid_1's deviation_error: 1.54723\n",
      "[3200]\ttraining's deviation_error: 0.90684\tvalid_1's deviation_error: 1.54359\n",
      "[3300]\ttraining's deviation_error: 0.90311\tvalid_1's deviation_error: 1.54244\n",
      "[3400]\ttraining's deviation_error: 0.897665\tvalid_1's deviation_error: 1.54012\n",
      "[3500]\ttraining's deviation_error: 0.892809\tvalid_1's deviation_error: 1.53667\n",
      "[3600]\ttraining's deviation_error: 0.888288\tvalid_1's deviation_error: 1.5327\n",
      "[3700]\ttraining's deviation_error: 0.884164\tvalid_1's deviation_error: 1.53188\n",
      "[3800]\ttraining's deviation_error: 0.880132\tvalid_1's deviation_error: 1.53057\n",
      "[3900]\ttraining's deviation_error: 0.876171\tvalid_1's deviation_error: 1.52898\n",
      "[4000]\ttraining's deviation_error: 0.871791\tvalid_1's deviation_error: 1.52681\n",
      "[4100]\ttraining's deviation_error: 0.868213\tvalid_1's deviation_error: 1.52633\n",
      "[4200]\ttraining's deviation_error: 0.864099\tvalid_1's deviation_error: 1.52258\n",
      "[4300]\ttraining's deviation_error: 0.860854\tvalid_1's deviation_error: 1.51998\n",
      "[4400]\ttraining's deviation_error: 0.857338\tvalid_1's deviation_error: 1.51982\n",
      "[4500]\ttraining's deviation_error: 0.852881\tvalid_1's deviation_error: 1.51733\n",
      "[4600]\ttraining's deviation_error: 0.84954\tvalid_1's deviation_error: 1.51708\n",
      "[4700]\ttraining's deviation_error: 0.84776\tvalid_1's deviation_error: 1.51755\n",
      "[4800]\ttraining's deviation_error: 0.844561\tvalid_1's deviation_error: 1.51571\n",
      "[4900]\ttraining's deviation_error: 0.842428\tvalid_1's deviation_error: 1.51548\n",
      "[5000]\ttraining's deviation_error: 0.840203\tvalid_1's deviation_error: 1.51352\n",
      "[5100]\ttraining's deviation_error: 0.836693\tvalid_1's deviation_error: 1.51325\n",
      "[5200]\ttraining's deviation_error: 0.833273\tvalid_1's deviation_error: 1.51129\n",
      "[5300]\ttraining's deviation_error: 0.830419\tvalid_1's deviation_error: 1.51039\n",
      "[5400]\ttraining's deviation_error: 0.827795\tvalid_1's deviation_error: 1.50886\n",
      "[5500]\ttraining's deviation_error: 0.825044\tvalid_1's deviation_error: 1.50822\n",
      "[5600]\ttraining's deviation_error: 0.822299\tvalid_1's deviation_error: 1.50649\n",
      "[5700]\ttraining's deviation_error: 0.819917\tvalid_1's deviation_error: 1.50514\n",
      "[5800]\ttraining's deviation_error: 0.816887\tvalid_1's deviation_error: 1.50435\n",
      "[5900]\ttraining's deviation_error: 0.814293\tvalid_1's deviation_error: 1.50292\n",
      "[6000]\ttraining's deviation_error: 0.812237\tvalid_1's deviation_error: 1.50195\n",
      "[6100]\ttraining's deviation_error: 0.810103\tvalid_1's deviation_error: 1.50039\n",
      "[6200]\ttraining's deviation_error: 0.808576\tvalid_1's deviation_error: 1.49899\n",
      "[6300]\ttraining's deviation_error: 0.806969\tvalid_1's deviation_error: 1.49789\n",
      "[6400]\ttraining's deviation_error: 0.805342\tvalid_1's deviation_error: 1.49705\n",
      "[6500]\ttraining's deviation_error: 0.802452\tvalid_1's deviation_error: 1.49553\n",
      "[6600]\ttraining's deviation_error: 0.800487\tvalid_1's deviation_error: 1.49378\n",
      "[6700]\ttraining's deviation_error: 0.798494\tvalid_1's deviation_error: 1.49196\n",
      "[6800]\ttraining's deviation_error: 0.796299\tvalid_1's deviation_error: 1.4916\n",
      "[6900]\ttraining's deviation_error: 0.79469\tvalid_1's deviation_error: 1.49053\n",
      "[7000]\ttraining's deviation_error: 0.793292\tvalid_1's deviation_error: 1.49039\n",
      "[7100]\ttraining's deviation_error: 0.791615\tvalid_1's deviation_error: 1.48935\n",
      "[7200]\ttraining's deviation_error: 0.789616\tvalid_1's deviation_error: 1.48936\n",
      "[7300]\ttraining's deviation_error: 0.788138\tvalid_1's deviation_error: 1.48887\n",
      "[7400]\ttraining's deviation_error: 0.786573\tvalid_1's deviation_error: 1.48799\n",
      "[7500]\ttraining's deviation_error: 0.785224\tvalid_1's deviation_error: 1.48854\n",
      "[7600]\ttraining's deviation_error: 0.784045\tvalid_1's deviation_error: 1.48764\n",
      "[7700]\ttraining's deviation_error: 0.782649\tvalid_1's deviation_error: 1.48713\n",
      "[7800]\ttraining's deviation_error: 0.781273\tvalid_1's deviation_error: 1.48628\n",
      "[7900]\ttraining's deviation_error: 0.779718\tvalid_1's deviation_error: 1.48537\n",
      "[8000]\ttraining's deviation_error: 0.778131\tvalid_1's deviation_error: 1.48361\n",
      "[8100]\ttraining's deviation_error: 0.776538\tvalid_1's deviation_error: 1.4826\n",
      "[8200]\ttraining's deviation_error: 0.775235\tvalid_1's deviation_error: 1.48276\n",
      "[8300]\ttraining's deviation_error: 0.773883\tvalid_1's deviation_error: 1.48123\n",
      "[8400]\ttraining's deviation_error: 0.772236\tvalid_1's deviation_error: 1.48028\n",
      "[8500]\ttraining's deviation_error: 0.770821\tvalid_1's deviation_error: 1.47911\n",
      "[8600]\ttraining's deviation_error: 0.769785\tvalid_1's deviation_error: 1.47979\n",
      "[8700]\ttraining's deviation_error: 0.768459\tvalid_1's deviation_error: 1.4796\n",
      "Early stopping, best iteration is:\n",
      "[8475]\ttraining's deviation_error: 0.771461\tvalid_1's deviation_error: 1.47896\n",
      "Скор для фолда(7) : 9.0 средний скор на префиксе = 9.0 это заняло = 194 сек.\n",
      "Фолд: 8\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.85867\tvalid_1's deviation_error: 1.55609\n",
      "[200]\ttraining's deviation_error: 1.54286\tvalid_1's deviation_error: 1.25033\n",
      "[300]\ttraining's deviation_error: 1.39651\tvalid_1's deviation_error: 1.16245\n",
      "[400]\ttraining's deviation_error: 1.31684\tvalid_1's deviation_error: 1.11316\n",
      "[500]\ttraining's deviation_error: 1.26298\tvalid_1's deviation_error: 1.0993\n",
      "[600]\ttraining's deviation_error: 1.22226\tvalid_1's deviation_error: 1.09703\n",
      "[700]\ttraining's deviation_error: 1.19276\tvalid_1's deviation_error: 1.09503\n",
      "[800]\ttraining's deviation_error: 1.16503\tvalid_1's deviation_error: 1.09796\n",
      "[900]\ttraining's deviation_error: 1.14396\tvalid_1's deviation_error: 1.09543\n",
      "[1000]\ttraining's deviation_error: 1.12385\tvalid_1's deviation_error: 1.09343\n",
      "[1100]\ttraining's deviation_error: 1.1048\tvalid_1's deviation_error: 1.09527\n",
      "[1200]\ttraining's deviation_error: 1.08743\tvalid_1's deviation_error: 1.09215\n",
      "Early stopping, best iteration is:\n",
      "[1036]\ttraining's deviation_error: 1.11623\tvalid_1's deviation_error: 1.09004\n",
      "Скор для фолда(8) : 9.0 средний скор на префиксе = 9.0 это заняло = 29 сек.\n",
      "Фолд: 9\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.85044\tvalid_1's deviation_error: 1.91961\n",
      "[200]\ttraining's deviation_error: 1.52411\tvalid_1's deviation_error: 1.62841\n",
      "[300]\ttraining's deviation_error: 1.38106\tvalid_1's deviation_error: 1.52838\n",
      "[400]\ttraining's deviation_error: 1.30293\tvalid_1's deviation_error: 1.47376\n",
      "[500]\ttraining's deviation_error: 1.25259\tvalid_1's deviation_error: 1.4506\n",
      "[600]\ttraining's deviation_error: 1.20922\tvalid_1's deviation_error: 1.44184\n",
      "[700]\ttraining's deviation_error: 1.17874\tvalid_1's deviation_error: 1.43504\n",
      "[800]\ttraining's deviation_error: 1.15449\tvalid_1's deviation_error: 1.41943\n",
      "[900]\ttraining's deviation_error: 1.12966\tvalid_1's deviation_error: 1.41364\n",
      "[1000]\ttraining's deviation_error: 1.10732\tvalid_1's deviation_error: 1.40192\n",
      "[1100]\ttraining's deviation_error: 1.08691\tvalid_1's deviation_error: 1.39214\n",
      "[1200]\ttraining's deviation_error: 1.06989\tvalid_1's deviation_error: 1.38078\n",
      "[1300]\ttraining's deviation_error: 1.05378\tvalid_1's deviation_error: 1.37714\n",
      "[1400]\ttraining's deviation_error: 1.03987\tvalid_1's deviation_error: 1.37152\n",
      "[1500]\ttraining's deviation_error: 1.0271\tvalid_1's deviation_error: 1.36431\n",
      "[1600]\ttraining's deviation_error: 1.01507\tvalid_1's deviation_error: 1.35454\n",
      "[1700]\ttraining's deviation_error: 1.00557\tvalid_1's deviation_error: 1.34902\n",
      "[1800]\ttraining's deviation_error: 0.997433\tvalid_1's deviation_error: 1.34305\n",
      "[1900]\ttraining's deviation_error: 0.988286\tvalid_1's deviation_error: 1.34168\n",
      "[2000]\ttraining's deviation_error: 0.978149\tvalid_1's deviation_error: 1.3339\n",
      "[2100]\ttraining's deviation_error: 0.969332\tvalid_1's deviation_error: 1.32505\n",
      "[2200]\ttraining's deviation_error: 0.962017\tvalid_1's deviation_error: 1.32184\n",
      "[2300]\ttraining's deviation_error: 0.955898\tvalid_1's deviation_error: 1.31987\n",
      "[2400]\ttraining's deviation_error: 0.949732\tvalid_1's deviation_error: 1.31887\n",
      "[2500]\ttraining's deviation_error: 0.942925\tvalid_1's deviation_error: 1.3157\n",
      "[2600]\ttraining's deviation_error: 0.936344\tvalid_1's deviation_error: 1.31473\n",
      "[2700]\ttraining's deviation_error: 0.929804\tvalid_1's deviation_error: 1.30758\n",
      "[2800]\ttraining's deviation_error: 0.925626\tvalid_1's deviation_error: 1.30512\n",
      "[2900]\ttraining's deviation_error: 0.919435\tvalid_1's deviation_error: 1.30255\n",
      "[3000]\ttraining's deviation_error: 0.913794\tvalid_1's deviation_error: 1.30165\n",
      "[3100]\ttraining's deviation_error: 0.908888\tvalid_1's deviation_error: 1.30066\n",
      "[3200]\ttraining's deviation_error: 0.903896\tvalid_1's deviation_error: 1.2982\n",
      "[3300]\ttraining's deviation_error: 0.898946\tvalid_1's deviation_error: 1.29578\n",
      "[3400]\ttraining's deviation_error: 0.89406\tvalid_1's deviation_error: 1.29502\n",
      "[3500]\ttraining's deviation_error: 0.889987\tvalid_1's deviation_error: 1.29347\n",
      "[3600]\ttraining's deviation_error: 0.885374\tvalid_1's deviation_error: 1.28927\n",
      "[3700]\ttraining's deviation_error: 0.880947\tvalid_1's deviation_error: 1.2904\n",
      "[3800]\ttraining's deviation_error: 0.876796\tvalid_1's deviation_error: 1.29062\n",
      "Early stopping, best iteration is:\n",
      "[3620]\ttraining's deviation_error: 0.883961\tvalid_1's deviation_error: 1.28827\n",
      "Скор для фолда(9) : 9.0 средний скор на префиксе = 9.0 это заняло = 87 сек.\n",
      "Фолд: 10\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.83389\tvalid_1's deviation_error: 2.11776\n",
      "[200]\ttraining's deviation_error: 1.5186\tvalid_1's deviation_error: 1.72919\n",
      "[300]\ttraining's deviation_error: 1.38287\tvalid_1's deviation_error: 1.57001\n",
      "[400]\ttraining's deviation_error: 1.30594\tvalid_1's deviation_error: 1.50228\n",
      "[500]\ttraining's deviation_error: 1.25338\tvalid_1's deviation_error: 1.4724\n",
      "[600]\ttraining's deviation_error: 1.21336\tvalid_1's deviation_error: 1.45502\n",
      "[700]\ttraining's deviation_error: 1.17674\tvalid_1's deviation_error: 1.44051\n",
      "[800]\ttraining's deviation_error: 1.14768\tvalid_1's deviation_error: 1.43115\n",
      "[900]\ttraining's deviation_error: 1.12276\tvalid_1's deviation_error: 1.42725\n",
      "[1000]\ttraining's deviation_error: 1.10007\tvalid_1's deviation_error: 1.42286\n",
      "[1100]\ttraining's deviation_error: 1.08089\tvalid_1's deviation_error: 1.41941\n",
      "[1200]\ttraining's deviation_error: 1.06414\tvalid_1's deviation_error: 1.41806\n",
      "[1300]\ttraining's deviation_error: 1.0492\tvalid_1's deviation_error: 1.41382\n",
      "[1400]\ttraining's deviation_error: 1.03378\tvalid_1's deviation_error: 1.41426\n",
      "[1500]\ttraining's deviation_error: 1.01792\tvalid_1's deviation_error: 1.41017\n",
      "[1600]\ttraining's deviation_error: 1.00631\tvalid_1's deviation_error: 1.41315\n",
      "[1700]\ttraining's deviation_error: 0.992956\tvalid_1's deviation_error: 1.4116\n",
      "[1800]\ttraining's deviation_error: 0.98486\tvalid_1's deviation_error: 1.41178\n",
      "[1900]\ttraining's deviation_error: 0.975868\tvalid_1's deviation_error: 1.41776\n",
      "Early stopping, best iteration is:\n",
      "[1688]\ttraining's deviation_error: 0.994247\tvalid_1's deviation_error: 1.40845\n",
      "Скор для фолда(10) : 9.0 средний скор на префиксе = 9.0 это заняло = 43 сек.\n",
      "Фолд: 11\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.82269\tvalid_1's deviation_error: 2.3382\n",
      "[200]\ttraining's deviation_error: 1.50995\tvalid_1's deviation_error: 2.12923\n",
      "[300]\ttraining's deviation_error: 1.36624\tvalid_1's deviation_error: 1.98166\n",
      "[400]\ttraining's deviation_error: 1.28651\tvalid_1's deviation_error: 1.88001\n",
      "[500]\ttraining's deviation_error: 1.23732\tvalid_1's deviation_error: 1.83481\n",
      "[600]\ttraining's deviation_error: 1.20276\tvalid_1's deviation_error: 1.80853\n",
      "[700]\ttraining's deviation_error: 1.17448\tvalid_1's deviation_error: 1.79104\n",
      "[800]\ttraining's deviation_error: 1.14983\tvalid_1's deviation_error: 1.7726\n",
      "[900]\ttraining's deviation_error: 1.12661\tvalid_1's deviation_error: 1.76138\n",
      "[1000]\ttraining's deviation_error: 1.10891\tvalid_1's deviation_error: 1.75756\n",
      "[1100]\ttraining's deviation_error: 1.08761\tvalid_1's deviation_error: 1.74323\n",
      "[1200]\ttraining's deviation_error: 1.06815\tvalid_1's deviation_error: 1.73435\n",
      "[1300]\ttraining's deviation_error: 1.05165\tvalid_1's deviation_error: 1.72911\n",
      "[1400]\ttraining's deviation_error: 1.03782\tvalid_1's deviation_error: 1.72615\n",
      "[1500]\ttraining's deviation_error: 1.02505\tvalid_1's deviation_error: 1.72374\n",
      "[1600]\ttraining's deviation_error: 1.01412\tvalid_1's deviation_error: 1.71946\n",
      "[1700]\ttraining's deviation_error: 1.00394\tvalid_1's deviation_error: 1.717\n",
      "[1800]\ttraining's deviation_error: 0.996462\tvalid_1's deviation_error: 1.71697\n",
      "[1900]\ttraining's deviation_error: 0.985234\tvalid_1's deviation_error: 1.71325\n",
      "[2000]\ttraining's deviation_error: 0.976071\tvalid_1's deviation_error: 1.71139\n",
      "[2100]\ttraining's deviation_error: 0.967711\tvalid_1's deviation_error: 1.70888\n",
      "[2200]\ttraining's deviation_error: 0.959011\tvalid_1's deviation_error: 1.70811\n",
      "[2300]\ttraining's deviation_error: 0.951322\tvalid_1's deviation_error: 1.70722\n",
      "[2400]\ttraining's deviation_error: 0.94431\tvalid_1's deviation_error: 1.70811\n",
      "[2500]\ttraining's deviation_error: 0.936602\tvalid_1's deviation_error: 1.70399\n",
      "[2600]\ttraining's deviation_error: 0.929907\tvalid_1's deviation_error: 1.70338\n",
      "[2700]\ttraining's deviation_error: 0.922846\tvalid_1's deviation_error: 1.70703\n",
      "Early stopping, best iteration is:\n",
      "[2518]\ttraining's deviation_error: 0.935212\tvalid_1's deviation_error: 1.70234\n",
      "Скор для фолда(11) : 9.0 средний скор на префиксе = 9.0 это заняло = 63 сек.\n",
      "Фолд: 12\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.85888\tvalid_1's deviation_error: 1.93659\n",
      "[200]\ttraining's deviation_error: 1.52626\tvalid_1's deviation_error: 1.79532\n",
      "[300]\ttraining's deviation_error: 1.3769\tvalid_1's deviation_error: 1.70935\n",
      "[400]\ttraining's deviation_error: 1.29581\tvalid_1's deviation_error: 1.68665\n",
      "[500]\ttraining's deviation_error: 1.23748\tvalid_1's deviation_error: 1.67468\n",
      "[600]\ttraining's deviation_error: 1.20006\tvalid_1's deviation_error: 1.66301\n",
      "[700]\ttraining's deviation_error: 1.16656\tvalid_1's deviation_error: 1.65748\n",
      "[800]\ttraining's deviation_error: 1.13777\tvalid_1's deviation_error: 1.6559\n",
      "[900]\ttraining's deviation_error: 1.11294\tvalid_1's deviation_error: 1.65182\n",
      "[1000]\ttraining's deviation_error: 1.0934\tvalid_1's deviation_error: 1.64316\n",
      "[1100]\ttraining's deviation_error: 1.0751\tvalid_1's deviation_error: 1.63052\n",
      "[1200]\ttraining's deviation_error: 1.05765\tvalid_1's deviation_error: 1.62109\n",
      "[1300]\ttraining's deviation_error: 1.0449\tvalid_1's deviation_error: 1.6115\n",
      "[1400]\ttraining's deviation_error: 1.03099\tvalid_1's deviation_error: 1.60479\n",
      "[1500]\ttraining's deviation_error: 1.01863\tvalid_1's deviation_error: 1.59775\n",
      "[1600]\ttraining's deviation_error: 1.00767\tvalid_1's deviation_error: 1.5902\n",
      "[1700]\ttraining's deviation_error: 0.99665\tvalid_1's deviation_error: 1.58726\n",
      "[1800]\ttraining's deviation_error: 0.988155\tvalid_1's deviation_error: 1.5833\n",
      "[1900]\ttraining's deviation_error: 0.981014\tvalid_1's deviation_error: 1.57789\n",
      "[2000]\ttraining's deviation_error: 0.972606\tvalid_1's deviation_error: 1.57392\n",
      "[2100]\ttraining's deviation_error: 0.966386\tvalid_1's deviation_error: 1.57395\n",
      "[2200]\ttraining's deviation_error: 0.958371\tvalid_1's deviation_error: 1.56911\n",
      "[2300]\ttraining's deviation_error: 0.950727\tvalid_1's deviation_error: 1.56543\n",
      "[2400]\ttraining's deviation_error: 0.946584\tvalid_1's deviation_error: 1.56004\n",
      "[2500]\ttraining's deviation_error: 0.941512\tvalid_1's deviation_error: 1.55812\n",
      "[2600]\ttraining's deviation_error: 0.936121\tvalid_1's deviation_error: 1.55424\n",
      "[2700]\ttraining's deviation_error: 0.929989\tvalid_1's deviation_error: 1.55357\n",
      "[2800]\ttraining's deviation_error: 0.923763\tvalid_1's deviation_error: 1.55133\n",
      "[2900]\ttraining's deviation_error: 0.917665\tvalid_1's deviation_error: 1.54656\n",
      "[3000]\ttraining's deviation_error: 0.911543\tvalid_1's deviation_error: 1.54163\n",
      "[3100]\ttraining's deviation_error: 0.906735\tvalid_1's deviation_error: 1.53973\n",
      "[3200]\ttraining's deviation_error: 0.901386\tvalid_1's deviation_error: 1.53721\n",
      "[3300]\ttraining's deviation_error: 0.89614\tvalid_1's deviation_error: 1.53504\n",
      "[3400]\ttraining's deviation_error: 0.891502\tvalid_1's deviation_error: 1.53554\n",
      "[3500]\ttraining's deviation_error: 0.888154\tvalid_1's deviation_error: 1.53471\n",
      "[3600]\ttraining's deviation_error: 0.884717\tvalid_1's deviation_error: 1.53334\n",
      "[3700]\ttraining's deviation_error: 0.880671\tvalid_1's deviation_error: 1.53243\n",
      "[3800]\ttraining's deviation_error: 0.8762\tvalid_1's deviation_error: 1.53007\n",
      "[3900]\ttraining's deviation_error: 0.872286\tvalid_1's deviation_error: 1.52853\n",
      "[4000]\ttraining's deviation_error: 0.868777\tvalid_1's deviation_error: 1.5264\n",
      "[4100]\ttraining's deviation_error: 0.865583\tvalid_1's deviation_error: 1.52442\n",
      "[4200]\ttraining's deviation_error: 0.862984\tvalid_1's deviation_error: 1.52378\n",
      "[4300]\ttraining's deviation_error: 0.858941\tvalid_1's deviation_error: 1.52154\n",
      "[4400]\ttraining's deviation_error: 0.855595\tvalid_1's deviation_error: 1.51923\n",
      "[4500]\ttraining's deviation_error: 0.852532\tvalid_1's deviation_error: 1.51762\n",
      "[4600]\ttraining's deviation_error: 0.84956\tvalid_1's deviation_error: 1.51719\n",
      "[4700]\ttraining's deviation_error: 0.845717\tvalid_1's deviation_error: 1.51555\n",
      "[4800]\ttraining's deviation_error: 0.843866\tvalid_1's deviation_error: 1.51533\n",
      "[4900]\ttraining's deviation_error: 0.840775\tvalid_1's deviation_error: 1.51506\n",
      "[5000]\ttraining's deviation_error: 0.838173\tvalid_1's deviation_error: 1.51389\n",
      "[5100]\ttraining's deviation_error: 0.834832\tvalid_1's deviation_error: 1.5139\n",
      "[5200]\ttraining's deviation_error: 0.832088\tvalid_1's deviation_error: 1.5131\n",
      "[5300]\ttraining's deviation_error: 0.829406\tvalid_1's deviation_error: 1.51086\n",
      "[5400]\ttraining's deviation_error: 0.825739\tvalid_1's deviation_error: 1.50883\n",
      "[5500]\ttraining's deviation_error: 0.822907\tvalid_1's deviation_error: 1.50763\n",
      "[5600]\ttraining's deviation_error: 0.820207\tvalid_1's deviation_error: 1.50563\n",
      "[5700]\ttraining's deviation_error: 0.817747\tvalid_1's deviation_error: 1.5057\n",
      "[5800]\ttraining's deviation_error: 0.815617\tvalid_1's deviation_error: 1.50421\n",
      "[5900]\ttraining's deviation_error: 0.814055\tvalid_1's deviation_error: 1.50295\n",
      "[6000]\ttraining's deviation_error: 0.811477\tvalid_1's deviation_error: 1.5011\n",
      "[6100]\ttraining's deviation_error: 0.809784\tvalid_1's deviation_error: 1.50074\n",
      "[6200]\ttraining's deviation_error: 0.807285\tvalid_1's deviation_error: 1.49988\n",
      "[6300]\ttraining's deviation_error: 0.805358\tvalid_1's deviation_error: 1.4991\n",
      "[6400]\ttraining's deviation_error: 0.802984\tvalid_1's deviation_error: 1.49563\n",
      "[6500]\ttraining's deviation_error: 0.801696\tvalid_1's deviation_error: 1.49578\n",
      "[6600]\ttraining's deviation_error: 0.80047\tvalid_1's deviation_error: 1.49343\n",
      "[6700]\ttraining's deviation_error: 0.798813\tvalid_1's deviation_error: 1.49532\n",
      "[6800]\ttraining's deviation_error: 0.79615\tvalid_1's deviation_error: 1.49409\n",
      "Early stopping, best iteration is:\n",
      "[6592]\ttraining's deviation_error: 0.800538\tvalid_1's deviation_error: 1.4933\n",
      "Скор для фолда(12) : 9.0 средний скор на префиксе = 9.0 это заняло = 153 сек.\n",
      "Фолд: 13\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.82678\tvalid_1's deviation_error: 2.34107\n",
      "[200]\ttraining's deviation_error: 1.51211\tvalid_1's deviation_error: 2.06334\n",
      "[300]\ttraining's deviation_error: 1.36827\tvalid_1's deviation_error: 1.88163\n",
      "[400]\ttraining's deviation_error: 1.28784\tvalid_1's deviation_error: 1.78282\n",
      "[500]\ttraining's deviation_error: 1.23513\tvalid_1's deviation_error: 1.72515\n",
      "[600]\ttraining's deviation_error: 1.19158\tvalid_1's deviation_error: 1.70714\n",
      "[700]\ttraining's deviation_error: 1.16322\tvalid_1's deviation_error: 1.69054\n",
      "[800]\ttraining's deviation_error: 1.13822\tvalid_1's deviation_error: 1.67211\n",
      "[900]\ttraining's deviation_error: 1.11386\tvalid_1's deviation_error: 1.66119\n",
      "[1000]\ttraining's deviation_error: 1.09342\tvalid_1's deviation_error: 1.64357\n",
      "[1100]\ttraining's deviation_error: 1.07444\tvalid_1's deviation_error: 1.63601\n",
      "[1200]\ttraining's deviation_error: 1.06073\tvalid_1's deviation_error: 1.62317\n",
      "[1300]\ttraining's deviation_error: 1.04489\tvalid_1's deviation_error: 1.61404\n",
      "[1400]\ttraining's deviation_error: 1.0299\tvalid_1's deviation_error: 1.61149\n",
      "[1500]\ttraining's deviation_error: 1.01666\tvalid_1's deviation_error: 1.60244\n",
      "[1600]\ttraining's deviation_error: 1.00487\tvalid_1's deviation_error: 1.59599\n",
      "[1700]\ttraining's deviation_error: 0.992845\tvalid_1's deviation_error: 1.58817\n",
      "[1800]\ttraining's deviation_error: 0.981544\tvalid_1's deviation_error: 1.58032\n",
      "[1900]\ttraining's deviation_error: 0.971979\tvalid_1's deviation_error: 1.5777\n",
      "[2000]\ttraining's deviation_error: 0.963612\tvalid_1's deviation_error: 1.58221\n",
      "Early stopping, best iteration is:\n",
      "[1849]\ttraining's deviation_error: 0.976384\tvalid_1's deviation_error: 1.57556\n",
      "Скор для фолда(13) : 9.0 средний скор на префиксе = 9.0 это заняло = 47 сек.\n",
      "Фолд: 14\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.86436\tvalid_1's deviation_error: 1.63774\n",
      "[200]\ttraining's deviation_error: 1.53561\tvalid_1's deviation_error: 1.43388\n",
      "[300]\ttraining's deviation_error: 1.3919\tvalid_1's deviation_error: 1.38467\n",
      "[400]\ttraining's deviation_error: 1.31461\tvalid_1's deviation_error: 1.35834\n",
      "[500]\ttraining's deviation_error: 1.25832\tvalid_1's deviation_error: 1.31271\n",
      "[600]\ttraining's deviation_error: 1.21767\tvalid_1's deviation_error: 1.28891\n",
      "[700]\ttraining's deviation_error: 1.18876\tvalid_1's deviation_error: 1.28539\n",
      "[800]\ttraining's deviation_error: 1.15981\tvalid_1's deviation_error: 1.25876\n",
      "[900]\ttraining's deviation_error: 1.13637\tvalid_1's deviation_error: 1.25068\n",
      "[1000]\ttraining's deviation_error: 1.11351\tvalid_1's deviation_error: 1.2351\n",
      "[1100]\ttraining's deviation_error: 1.09416\tvalid_1's deviation_error: 1.22812\n",
      "[1200]\ttraining's deviation_error: 1.07707\tvalid_1's deviation_error: 1.22472\n",
      "[1300]\ttraining's deviation_error: 1.06138\tvalid_1's deviation_error: 1.2167\n",
      "[1400]\ttraining's deviation_error: 1.04687\tvalid_1's deviation_error: 1.21316\n",
      "[1500]\ttraining's deviation_error: 1.03443\tvalid_1's deviation_error: 1.20836\n",
      "[1600]\ttraining's deviation_error: 1.02167\tvalid_1's deviation_error: 1.20471\n",
      "[1700]\ttraining's deviation_error: 1.01001\tvalid_1's deviation_error: 1.19943\n",
      "[1800]\ttraining's deviation_error: 0.998761\tvalid_1's deviation_error: 1.19657\n",
      "[1900]\ttraining's deviation_error: 0.988736\tvalid_1's deviation_error: 1.19404\n",
      "[2000]\ttraining's deviation_error: 0.979142\tvalid_1's deviation_error: 1.19497\n",
      "[2100]\ttraining's deviation_error: 0.971076\tvalid_1's deviation_error: 1.18904\n",
      "[2200]\ttraining's deviation_error: 0.962625\tvalid_1's deviation_error: 1.18886\n",
      "[2300]\ttraining's deviation_error: 0.9554\tvalid_1's deviation_error: 1.18736\n",
      "[2400]\ttraining's deviation_error: 0.948415\tvalid_1's deviation_error: 1.18716\n",
      "[2500]\ttraining's deviation_error: 0.942431\tvalid_1's deviation_error: 1.18578\n",
      "Early stopping, best iteration is:\n",
      "[2338]\ttraining's deviation_error: 0.952393\tvalid_1's deviation_error: 1.1855\n",
      "Скор для фолда(14) : 9.0 средний скор на префиксе = 9.0 это заняло = 58 сек.\n",
      "Фолд: 15\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.83763\tvalid_1's deviation_error: 1.99123\n",
      "[200]\ttraining's deviation_error: 1.51318\tvalid_1's deviation_error: 1.7475\n",
      "[300]\ttraining's deviation_error: 1.36583\tvalid_1's deviation_error: 1.67018\n",
      "[400]\ttraining's deviation_error: 1.28921\tvalid_1's deviation_error: 1.63338\n",
      "[500]\ttraining's deviation_error: 1.2346\tvalid_1's deviation_error: 1.60514\n",
      "[600]\ttraining's deviation_error: 1.1999\tvalid_1's deviation_error: 1.59474\n",
      "[700]\ttraining's deviation_error: 1.16927\tvalid_1's deviation_error: 1.59818\n",
      "[800]\ttraining's deviation_error: 1.14184\tvalid_1's deviation_error: 1.60112\n",
      "Early stopping, best iteration is:\n",
      "[611]\ttraining's deviation_error: 1.1966\tvalid_1's deviation_error: 1.59353\n",
      "Скор для фолда(15) : 9.0 средний скор на префиксе = 9.0 это заняло = 19 сек.\n",
      "Фолд: 16\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.8404\tvalid_1's deviation_error: 2.02665\n",
      "[200]\ttraining's deviation_error: 1.51772\tvalid_1's deviation_error: 1.82453\n",
      "[300]\ttraining's deviation_error: 1.3826\tvalid_1's deviation_error: 1.73775\n",
      "[400]\ttraining's deviation_error: 1.30183\tvalid_1's deviation_error: 1.66143\n",
      "[500]\ttraining's deviation_error: 1.24825\tvalid_1's deviation_error: 1.6114\n",
      "[600]\ttraining's deviation_error: 1.20806\tvalid_1's deviation_error: 1.57984\n",
      "[700]\ttraining's deviation_error: 1.17666\tvalid_1's deviation_error: 1.5635\n",
      "[800]\ttraining's deviation_error: 1.15156\tvalid_1's deviation_error: 1.54131\n",
      "[900]\ttraining's deviation_error: 1.12116\tvalid_1's deviation_error: 1.51623\n",
      "[1000]\ttraining's deviation_error: 1.10145\tvalid_1's deviation_error: 1.5144\n",
      "[1100]\ttraining's deviation_error: 1.08423\tvalid_1's deviation_error: 1.50768\n",
      "[1200]\ttraining's deviation_error: 1.06695\tvalid_1's deviation_error: 1.50447\n",
      "[1300]\ttraining's deviation_error: 1.04941\tvalid_1's deviation_error: 1.49798\n",
      "[1400]\ttraining's deviation_error: 1.03448\tvalid_1's deviation_error: 1.48675\n",
      "[1500]\ttraining's deviation_error: 1.02361\tvalid_1's deviation_error: 1.48053\n",
      "[1600]\ttraining's deviation_error: 1.01223\tvalid_1's deviation_error: 1.47415\n",
      "[1700]\ttraining's deviation_error: 1.00193\tvalid_1's deviation_error: 1.47206\n",
      "[1800]\ttraining's deviation_error: 0.992372\tvalid_1's deviation_error: 1.46764\n",
      "[1900]\ttraining's deviation_error: 0.984838\tvalid_1's deviation_error: 1.46324\n",
      "[2000]\ttraining's deviation_error: 0.976995\tvalid_1's deviation_error: 1.46008\n",
      "[2100]\ttraining's deviation_error: 0.968492\tvalid_1's deviation_error: 1.45527\n",
      "[2200]\ttraining's deviation_error: 0.960805\tvalid_1's deviation_error: 1.45623\n",
      "[2300]\ttraining's deviation_error: 0.953365\tvalid_1's deviation_error: 1.4516\n",
      "[2400]\ttraining's deviation_error: 0.946278\tvalid_1's deviation_error: 1.44846\n",
      "[2500]\ttraining's deviation_error: 0.939468\tvalid_1's deviation_error: 1.44565\n",
      "[2600]\ttraining's deviation_error: 0.932347\tvalid_1's deviation_error: 1.44231\n",
      "[2700]\ttraining's deviation_error: 0.926278\tvalid_1's deviation_error: 1.44034\n",
      "[2800]\ttraining's deviation_error: 0.921151\tvalid_1's deviation_error: 1.43875\n",
      "[2900]\ttraining's deviation_error: 0.913699\tvalid_1's deviation_error: 1.43361\n",
      "[3000]\ttraining's deviation_error: 0.909262\tvalid_1's deviation_error: 1.42877\n",
      "[3100]\ttraining's deviation_error: 0.903861\tvalid_1's deviation_error: 1.4279\n",
      "[3200]\ttraining's deviation_error: 0.899178\tvalid_1's deviation_error: 1.42675\n",
      "[3300]\ttraining's deviation_error: 0.895016\tvalid_1's deviation_error: 1.42529\n",
      "[3400]\ttraining's deviation_error: 0.890632\tvalid_1's deviation_error: 1.42498\n",
      "[3500]\ttraining's deviation_error: 0.887216\tvalid_1's deviation_error: 1.42369\n",
      "[3600]\ttraining's deviation_error: 0.88323\tvalid_1's deviation_error: 1.42378\n",
      "[3700]\ttraining's deviation_error: 0.878171\tvalid_1's deviation_error: 1.4212\n",
      "[3800]\ttraining's deviation_error: 0.873819\tvalid_1's deviation_error: 1.41864\n",
      "[3900]\ttraining's deviation_error: 0.869868\tvalid_1's deviation_error: 1.41662\n",
      "[4000]\ttraining's deviation_error: 0.866402\tvalid_1's deviation_error: 1.41686\n",
      "[4100]\ttraining's deviation_error: 0.863229\tvalid_1's deviation_error: 1.41448\n",
      "[4200]\ttraining's deviation_error: 0.860293\tvalid_1's deviation_error: 1.41147\n",
      "[4300]\ttraining's deviation_error: 0.856578\tvalid_1's deviation_error: 1.40908\n",
      "[4400]\ttraining's deviation_error: 0.853836\tvalid_1's deviation_error: 1.409\n",
      "[4500]\ttraining's deviation_error: 0.850546\tvalid_1's deviation_error: 1.40602\n",
      "[4600]\ttraining's deviation_error: 0.847628\tvalid_1's deviation_error: 1.40551\n",
      "[4700]\ttraining's deviation_error: 0.844976\tvalid_1's deviation_error: 1.40427\n",
      "[4800]\ttraining's deviation_error: 0.842561\tvalid_1's deviation_error: 1.40028\n",
      "[4900]\ttraining's deviation_error: 0.839375\tvalid_1's deviation_error: 1.39769\n",
      "[5000]\ttraining's deviation_error: 0.836996\tvalid_1's deviation_error: 1.39775\n",
      "[5100]\ttraining's deviation_error: 0.834639\tvalid_1's deviation_error: 1.39677\n",
      "[5200]\ttraining's deviation_error: 0.832\tvalid_1's deviation_error: 1.39336\n",
      "[5300]\ttraining's deviation_error: 0.828889\tvalid_1's deviation_error: 1.39144\n",
      "[5400]\ttraining's deviation_error: 0.826737\tvalid_1's deviation_error: 1.39196\n",
      "[5500]\ttraining's deviation_error: 0.8244\tvalid_1's deviation_error: 1.39115\n",
      "[5600]\ttraining's deviation_error: 0.822278\tvalid_1's deviation_error: 1.38929\n",
      "[5700]\ttraining's deviation_error: 0.820177\tvalid_1's deviation_error: 1.38868\n",
      "[5800]\ttraining's deviation_error: 0.818406\tvalid_1's deviation_error: 1.38865\n",
      "[5900]\ttraining's deviation_error: 0.816407\tvalid_1's deviation_error: 1.3874\n",
      "[6000]\ttraining's deviation_error: 0.814498\tvalid_1's deviation_error: 1.38523\n",
      "[6100]\ttraining's deviation_error: 0.812375\tvalid_1's deviation_error: 1.38541\n",
      "[6200]\ttraining's deviation_error: 0.810848\tvalid_1's deviation_error: 1.38496\n",
      "[6300]\ttraining's deviation_error: 0.809042\tvalid_1's deviation_error: 1.38329\n",
      "[6400]\ttraining's deviation_error: 0.807452\tvalid_1's deviation_error: 1.38267\n",
      "[6500]\ttraining's deviation_error: 0.805726\tvalid_1's deviation_error: 1.38292\n",
      "[6600]\ttraining's deviation_error: 0.804242\tvalid_1's deviation_error: 1.38262\n",
      "[6700]\ttraining's deviation_error: 0.802539\tvalid_1's deviation_error: 1.38012\n",
      "[6800]\ttraining's deviation_error: 0.800897\tvalid_1's deviation_error: 1.37857\n",
      "[6900]\ttraining's deviation_error: 0.799704\tvalid_1's deviation_error: 1.3784\n",
      "[7000]\ttraining's deviation_error: 0.79816\tvalid_1's deviation_error: 1.37668\n",
      "[7100]\ttraining's deviation_error: 0.796512\tvalid_1's deviation_error: 1.3766\n",
      "[7200]\ttraining's deviation_error: 0.795026\tvalid_1's deviation_error: 1.37582\n",
      "[7300]\ttraining's deviation_error: 0.793319\tvalid_1's deviation_error: 1.37601\n",
      "[7400]\ttraining's deviation_error: 0.791506\tvalid_1's deviation_error: 1.37405\n",
      "[7500]\ttraining's deviation_error: 0.790051\tvalid_1's deviation_error: 1.3724\n",
      "[7600]\ttraining's deviation_error: 0.788839\tvalid_1's deviation_error: 1.37132\n",
      "[7700]\ttraining's deviation_error: 0.787648\tvalid_1's deviation_error: 1.37123\n",
      "[7800]\ttraining's deviation_error: 0.786315\tvalid_1's deviation_error: 1.37024\n",
      "[7900]\ttraining's deviation_error: 0.785052\tvalid_1's deviation_error: 1.3682\n",
      "[8000]\ttraining's deviation_error: 0.783711\tvalid_1's deviation_error: 1.36739\n",
      "[8100]\ttraining's deviation_error: 0.78269\tvalid_1's deviation_error: 1.36729\n",
      "Early stopping, best iteration is:\n",
      "[7934]\ttraining's deviation_error: 0.784598\tvalid_1's deviation_error: 1.36613\n",
      "Скор для фолда(16) : 9.0 средний скор на префиксе = 9.0 это заняло = 184 сек.\n",
      "Фолд: 17\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.8616\tvalid_1's deviation_error: 1.59595\n",
      "[200]\ttraining's deviation_error: 1.54765\tvalid_1's deviation_error: 1.32762\n",
      "[300]\ttraining's deviation_error: 1.39296\tvalid_1's deviation_error: 1.23475\n",
      "[400]\ttraining's deviation_error: 1.30568\tvalid_1's deviation_error: 1.18914\n",
      "[500]\ttraining's deviation_error: 1.24794\tvalid_1's deviation_error: 1.18054\n",
      "[600]\ttraining's deviation_error: 1.21122\tvalid_1's deviation_error: 1.17895\n",
      "[700]\ttraining's deviation_error: 1.17636\tvalid_1's deviation_error: 1.17601\n",
      "[800]\ttraining's deviation_error: 1.15011\tvalid_1's deviation_error: 1.17548\n",
      "[900]\ttraining's deviation_error: 1.12664\tvalid_1's deviation_error: 1.1772\n",
      "Early stopping, best iteration is:\n",
      "[675]\ttraining's deviation_error: 1.18618\tvalid_1's deviation_error: 1.17245\n",
      "Скор для фолда(17) : 9.0 средний скор на префиксе = 9.0 это заняло = 20 сек.\n",
      "Фолд: 18\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.84288\tvalid_1's deviation_error: 1.7433\n",
      "[200]\ttraining's deviation_error: 1.52271\tvalid_1's deviation_error: 1.51795\n",
      "[300]\ttraining's deviation_error: 1.37576\tvalid_1's deviation_error: 1.43762\n",
      "[400]\ttraining's deviation_error: 1.29684\tvalid_1's deviation_error: 1.3846\n",
      "[500]\ttraining's deviation_error: 1.24154\tvalid_1's deviation_error: 1.34587\n",
      "[600]\ttraining's deviation_error: 1.20405\tvalid_1's deviation_error: 1.32505\n",
      "[700]\ttraining's deviation_error: 1.16938\tvalid_1's deviation_error: 1.30898\n",
      "[800]\ttraining's deviation_error: 1.14729\tvalid_1's deviation_error: 1.29789\n",
      "[900]\ttraining's deviation_error: 1.12727\tvalid_1's deviation_error: 1.29187\n",
      "[1000]\ttraining's deviation_error: 1.1053\tvalid_1's deviation_error: 1.28218\n",
      "[1100]\ttraining's deviation_error: 1.08425\tvalid_1's deviation_error: 1.26899\n",
      "[1200]\ttraining's deviation_error: 1.06437\tvalid_1's deviation_error: 1.25392\n",
      "[1300]\ttraining's deviation_error: 1.04747\tvalid_1's deviation_error: 1.24089\n",
      "[1400]\ttraining's deviation_error: 1.03369\tvalid_1's deviation_error: 1.23121\n",
      "[1500]\ttraining's deviation_error: 1.02047\tvalid_1's deviation_error: 1.21949\n",
      "[1600]\ttraining's deviation_error: 1.00885\tvalid_1's deviation_error: 1.21136\n",
      "[1700]\ttraining's deviation_error: 0.998329\tvalid_1's deviation_error: 1.20533\n",
      "[1800]\ttraining's deviation_error: 0.987605\tvalid_1's deviation_error: 1.19767\n",
      "[1900]\ttraining's deviation_error: 0.977142\tvalid_1's deviation_error: 1.18825\n",
      "[2000]\ttraining's deviation_error: 0.967308\tvalid_1's deviation_error: 1.17974\n",
      "[2100]\ttraining's deviation_error: 0.957532\tvalid_1's deviation_error: 1.17473\n",
      "[2200]\ttraining's deviation_error: 0.949693\tvalid_1's deviation_error: 1.1667\n",
      "[2300]\ttraining's deviation_error: 0.942785\tvalid_1's deviation_error: 1.16202\n",
      "[2400]\ttraining's deviation_error: 0.935934\tvalid_1's deviation_error: 1.15664\n",
      "[2500]\ttraining's deviation_error: 0.929347\tvalid_1's deviation_error: 1.15702\n",
      "[2600]\ttraining's deviation_error: 0.923403\tvalid_1's deviation_error: 1.15225\n",
      "[2700]\ttraining's deviation_error: 0.916517\tvalid_1's deviation_error: 1.15087\n",
      "[2800]\ttraining's deviation_error: 0.910245\tvalid_1's deviation_error: 1.1454\n",
      "[2900]\ttraining's deviation_error: 0.905461\tvalid_1's deviation_error: 1.14308\n",
      "[3000]\ttraining's deviation_error: 0.900476\tvalid_1's deviation_error: 1.14178\n",
      "[3100]\ttraining's deviation_error: 0.896584\tvalid_1's deviation_error: 1.1394\n",
      "[3200]\ttraining's deviation_error: 0.892306\tvalid_1's deviation_error: 1.137\n",
      "[3300]\ttraining's deviation_error: 0.887885\tvalid_1's deviation_error: 1.13418\n",
      "[3400]\ttraining's deviation_error: 0.883294\tvalid_1's deviation_error: 1.1327\n",
      "[3500]\ttraining's deviation_error: 0.879911\tvalid_1's deviation_error: 1.1296\n",
      "[3600]\ttraining's deviation_error: 0.875193\tvalid_1's deviation_error: 1.12461\n",
      "[3700]\ttraining's deviation_error: 0.87138\tvalid_1's deviation_error: 1.12211\n",
      "[3800]\ttraining's deviation_error: 0.86787\tvalid_1's deviation_error: 1.11853\n",
      "[3900]\ttraining's deviation_error: 0.864115\tvalid_1's deviation_error: 1.11714\n",
      "[4000]\ttraining's deviation_error: 0.860639\tvalid_1's deviation_error: 1.11402\n",
      "[4100]\ttraining's deviation_error: 0.858225\tvalid_1's deviation_error: 1.11353\n",
      "[4200]\ttraining's deviation_error: 0.855319\tvalid_1's deviation_error: 1.1128\n",
      "[4300]\ttraining's deviation_error: 0.851236\tvalid_1's deviation_error: 1.10998\n",
      "[4400]\ttraining's deviation_error: 0.847977\tvalid_1's deviation_error: 1.10915\n",
      "[4500]\ttraining's deviation_error: 0.845212\tvalid_1's deviation_error: 1.1081\n",
      "[4600]\ttraining's deviation_error: 0.84247\tvalid_1's deviation_error: 1.10785\n",
      "[4700]\ttraining's deviation_error: 0.839149\tvalid_1's deviation_error: 1.10531\n",
      "[4800]\ttraining's deviation_error: 0.836439\tvalid_1's deviation_error: 1.10423\n",
      "[4900]\ttraining's deviation_error: 0.832334\tvalid_1's deviation_error: 1.10084\n",
      "[5000]\ttraining's deviation_error: 0.829735\tvalid_1's deviation_error: 1.09994\n",
      "[5100]\ttraining's deviation_error: 0.826636\tvalid_1's deviation_error: 1.09853\n",
      "[5200]\ttraining's deviation_error: 0.823358\tvalid_1's deviation_error: 1.09637\n",
      "[5300]\ttraining's deviation_error: 0.820431\tvalid_1's deviation_error: 1.09511\n",
      "[5400]\ttraining's deviation_error: 0.818122\tvalid_1's deviation_error: 1.09758\n",
      "[5500]\ttraining's deviation_error: 0.815102\tvalid_1's deviation_error: 1.09577\n",
      "Early stopping, best iteration is:\n",
      "[5302]\ttraining's deviation_error: 0.82043\tvalid_1's deviation_error: 1.09508\n",
      "Скор для фолда(18) : 9.0 средний скор на префиксе = 9.0 это заняло = 124 сек.\n",
      "Фолд: 19\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's deviation_error: 1.84693\tvalid_1's deviation_error: 1.79146\n",
      "[200]\ttraining's deviation_error: 1.51969\tvalid_1's deviation_error: 1.54439\n",
      "[300]\ttraining's deviation_error: 1.37029\tvalid_1's deviation_error: 1.43043\n",
      "[400]\ttraining's deviation_error: 1.28654\tvalid_1's deviation_error: 1.36663\n",
      "[500]\ttraining's deviation_error: 1.23945\tvalid_1's deviation_error: 1.34091\n",
      "[600]\ttraining's deviation_error: 1.19951\tvalid_1's deviation_error: 1.31338\n",
      "[700]\ttraining's deviation_error: 1.16701\tvalid_1's deviation_error: 1.28509\n",
      "[800]\ttraining's deviation_error: 1.14025\tvalid_1's deviation_error: 1.26162\n",
      "[900]\ttraining's deviation_error: 1.11461\tvalid_1's deviation_error: 1.23579\n",
      "[1000]\ttraining's deviation_error: 1.09621\tvalid_1's deviation_error: 1.21634\n",
      "[1100]\ttraining's deviation_error: 1.08026\tvalid_1's deviation_error: 1.20731\n",
      "[1200]\ttraining's deviation_error: 1.06383\tvalid_1's deviation_error: 1.19622\n",
      "[1300]\ttraining's deviation_error: 1.04872\tvalid_1's deviation_error: 1.18248\n",
      "[1400]\ttraining's deviation_error: 1.0356\tvalid_1's deviation_error: 1.17563\n",
      "[1500]\ttraining's deviation_error: 1.02302\tvalid_1's deviation_error: 1.16577\n",
      "[1600]\ttraining's deviation_error: 1.01312\tvalid_1's deviation_error: 1.15908\n",
      "[1700]\ttraining's deviation_error: 1.0003\tvalid_1's deviation_error: 1.15388\n",
      "[1800]\ttraining's deviation_error: 0.990607\tvalid_1's deviation_error: 1.1422\n",
      "[1900]\ttraining's deviation_error: 0.9818\tvalid_1's deviation_error: 1.13284\n",
      "[2000]\ttraining's deviation_error: 0.974517\tvalid_1's deviation_error: 1.12281\n",
      "[2100]\ttraining's deviation_error: 0.966497\tvalid_1's deviation_error: 1.12053\n",
      "[2200]\ttraining's deviation_error: 0.957701\tvalid_1's deviation_error: 1.11602\n",
      "[2300]\ttraining's deviation_error: 0.950559\tvalid_1's deviation_error: 1.11063\n",
      "[2400]\ttraining's deviation_error: 0.94413\tvalid_1's deviation_error: 1.10724\n",
      "[2500]\ttraining's deviation_error: 0.939087\tvalid_1's deviation_error: 1.10521\n",
      "[2600]\ttraining's deviation_error: 0.934062\tvalid_1's deviation_error: 1.10301\n",
      "[2700]\ttraining's deviation_error: 0.928019\tvalid_1's deviation_error: 1.09855\n",
      "[2800]\ttraining's deviation_error: 0.922835\tvalid_1's deviation_error: 1.09263\n",
      "[2900]\ttraining's deviation_error: 0.917373\tvalid_1's deviation_error: 1.09281\n",
      "[3000]\ttraining's deviation_error: 0.911965\tvalid_1's deviation_error: 1.0919\n",
      "[3100]\ttraining's deviation_error: 0.906306\tvalid_1's deviation_error: 1.09173\n",
      "[3200]\ttraining's deviation_error: 0.900605\tvalid_1's deviation_error: 1.0902\n",
      "[3300]\ttraining's deviation_error: 0.896215\tvalid_1's deviation_error: 1.08827\n",
      "[3400]\ttraining's deviation_error: 0.890602\tvalid_1's deviation_error: 1.0849\n",
      "[3500]\ttraining's deviation_error: 0.88682\tvalid_1's deviation_error: 1.08176\n",
      "[3600]\ttraining's deviation_error: 0.883241\tvalid_1's deviation_error: 1.08337\n",
      "[3700]\ttraining's deviation_error: 0.878536\tvalid_1's deviation_error: 1.08545\n",
      "Early stopping, best iteration is:\n",
      "[3501]\ttraining's deviation_error: 0.886792\tvalid_1's deviation_error: 1.08159\n",
      "Скор для фолда(19) : 9.0 средний скор на префиксе = 9.0 это заняло = 83 сек.\n",
      "Процесс обучения модели занял = 1670 секунд\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LightGBM кастомная метрика\n",
    "def feval_deviation(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'deviation_error', deviation_metric(np.exp(y_true), np.exp(y_pred)), False\n",
    "\n",
    "\n",
    "# Функция для обучения модели LightGBM\n",
    "def train_lgb(train, valid, num_features, categorical_features, target_train, target_valid, EPOCHS, params):\n",
    "    # feature_importances = np.zeros(len(features))\n",
    "    train_dataset = lgb.Dataset(train[num_features + categorical_features], np.log(target_train), \n",
    "                                categorical_feature=categorical_features)\n",
    "    valid_dataset = lgb.Dataset(valid[num_features + categorical_features], np.log(target_valid), \n",
    "                                categorical_feature=categorical_features)\n",
    "    model = lgb.train(\n",
    "        params=params,\n",
    "        num_boost_round=EPOCHS,\n",
    "        train_set=train_dataset,\n",
    "        valid_sets=[train_dataset, valid_dataset],\n",
    "        verbose_eval=100,\n",
    "        early_stopping_rounds=int(5 / params['learning_rate']),\n",
    "        feval=feval_deviation)\n",
    "\n",
    "    y_valid = model.predict(valid[num_features + categorical_features])\n",
    "    # feature_importances = model.feature_importance(importance_type='gain') / 5.0\n",
    "    # lgb.plot_importance(model,max_num_features = 41)\n",
    "\n",
    "    return model, np.exp(y_valid)\n",
    "\n",
    "\n",
    "start_train_model_time = time.time()\n",
    "\n",
    "boosting_seed = 41\n",
    "boosting_params = {\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 1,\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.9,\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.02,\n",
    "    'metric': 'custom',\n",
    "    'objective': 'regression_l1',\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': boosting_seed,\n",
    "    'feature_fraction_seed': boosting_seed,\n",
    "    'bagging_seed': boosting_seed,\n",
    "    'drop_seed': boosting_seed,\n",
    "    'data_random_seed': boosting_seed,\n",
    "}\n",
    "\n",
    "# Количество эпох обучения\n",
    "EPOCHS = 10000\n",
    "scores = []\n",
    "lgb_predicts = np.zeros(len(train))\n",
    "\n",
    "lgb_models = []\n",
    "for fold_num, (train_indexes, valid_indexes) in enumerate(split_list):\n",
    "    start_time = time.time()\n",
    "    print(f\"Фолд: {fold_num}\")\n",
    "\n",
    "    train_sub_df = train[features_columns_order].loc[train_indexes].reset_index(drop=True)\n",
    "    valid_sub_df = train[features_columns_order].loc[valid_indexes].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Размер трейна = {train_sub_df.shape} Размер валидации = {valid_sub_df.shape}\")\n",
    "    # Обучаем LightGBM и делаем предикт на валидационной выборке\n",
    "    model, predict_validation = train_lgb(\n",
    "        train_sub_df,\n",
    "        valid_sub_df,\n",
    "        NUM_FEATURES_COLUMNS,\n",
    "        CATEGORICAL_FEATURES_COLUMNS,\n",
    "        train_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        valid_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        EPOCHS,\n",
    "        boosting_params)\n",
    "\n",
    "    lgb_models += [model]\n",
    "    predict_on_validation = model.predict(valid_sub_df[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS])\n",
    "    lgb_predicts[valid_indexes] = np.exp(predict_on_validation)\n",
    "    targets_for_validation = valid_sub_df[TARGET_COLUMNS].values[:, 0]\n",
    "    current_score = deviation_metric(targets_for_validation, predict_on_validation)\n",
    "    scores += [current_score]\n",
    "    print(\n",
    "        f\"Скор для фолда({fold_num}) : {np.round(current_score, 4)} средний скор на префиксе = {np.round(np.mean(scores), 4)} это заняло = {int(time.time() - start_time)} сек.\")\n",
    "print(f\"Процесс обучения модели занял = {int(time.time() - start_train_model_time)} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85b507f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16618.962328515547, 468614.19895911, 60258.90236155056)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Предикт lgb на test\n",
    "def get_lgb_predict(models, test):\n",
    "    result = np.zeros(len(test))\n",
    "    for model in models:\n",
    "        predict = model.predict(test[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS])\n",
    "        result += np.exp(predict) / len(models)\n",
    "    return result\n",
    "\n",
    "\n",
    "test_lgb_predict = get_lgb_predict(lgb_models, test)\n",
    "\n",
    "test_lgb_predict.min(), test_lgb_predict.max(), test_lgb_predict.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723e7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690e234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eae0cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фолд: 0\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.41834\n",
      "[500]\tvalid-deviation_error:1.21503\n",
      "[750]\tvalid-deviation_error:1.33561\n",
      "[932]\tvalid-deviation_error:1.31440\n",
      "Скор для фолда(0) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 1\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.67476\n",
      "[500]\tvalid-deviation_error:1.14004\n",
      "[750]\tvalid-deviation_error:1.20935\n",
      "[971]\tvalid-deviation_error:1.19046\n",
      "Скор для фолда(1) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 2\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.69256\n",
      "[500]\tvalid-deviation_error:0.96898\n",
      "[750]\tvalid-deviation_error:1.15695\n",
      "[952]\tvalid-deviation_error:1.16055\n",
      "Скор для фолда(2) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 3\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.47539\n",
      "[500]\tvalid-deviation_error:1.11444\n",
      "[750]\tvalid-deviation_error:1.17655\n",
      "[955]\tvalid-deviation_error:1.15714\n",
      "Скор для фолда(3) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 4\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.45567\n",
      "[500]\tvalid-deviation_error:1.17223\n",
      "[750]\tvalid-deviation_error:1.26436\n",
      "[960]\tvalid-deviation_error:1.26749\n",
      "Скор для фолда(4) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 5\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.59836\n",
      "[500]\tvalid-deviation_error:1.46564\n",
      "[750]\tvalid-deviation_error:1.54984\n",
      "[942]\tvalid-deviation_error:1.51942\n",
      "Скор для фолда(5) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 6\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.49827\n",
      "[500]\tvalid-deviation_error:1.09277\n",
      "[750]\tvalid-deviation_error:1.19143\n",
      "[969]\tvalid-deviation_error:1.20229\n",
      "Скор для фолда(6) : 9.0 средний скор на префиксе = 9.0 это заняло = 4 сек.\n",
      "Фолд: 7\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.26227\n",
      "[500]\tvalid-deviation_error:1.15280\n",
      "[750]\tvalid-deviation_error:1.27506\n",
      "[951]\tvalid-deviation_error:1.25884\n",
      "Скор для фолда(7) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 8\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.53433\n",
      "[500]\tvalid-deviation_error:0.90101\n",
      "[750]\tvalid-deviation_error:0.96795\n",
      "[973]\tvalid-deviation_error:0.96130\n",
      "Скор для фолда(8) : 9.0 средний скор на префиксе = 9.0 это заняло = 4 сек.\n",
      "Фолд: 9\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.63816\n",
      "[500]\tvalid-deviation_error:1.14323\n",
      "[750]\tvalid-deviation_error:1.18332\n",
      "[977]\tvalid-deviation_error:1.17433\n",
      "Скор для фолда(9) : 9.0 средний скор на префиксе = 9.0 это заняло = 4 сек.\n",
      "Фолд: 10\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.46426\n",
      "[500]\tvalid-deviation_error:1.13250\n",
      "[750]\tvalid-deviation_error:1.35682\n",
      "[927]\tvalid-deviation_error:1.36978\n",
      "Скор для фолда(10) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 11\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.34049\n",
      "[500]\tvalid-deviation_error:1.37938\n",
      "[750]\tvalid-deviation_error:1.50255\n",
      "[943]\tvalid-deviation_error:1.47776\n",
      "Скор для фолда(11) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 12\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.45585\n",
      "[500]\tvalid-deviation_error:1.19863\n",
      "[750]\tvalid-deviation_error:1.36031\n",
      "[945]\tvalid-deviation_error:1.36225\n",
      "Скор для фолда(12) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 13\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.55820\n",
      "[500]\tvalid-deviation_error:1.24965\n",
      "[750]\tvalid-deviation_error:1.38946\n",
      "[953]\tvalid-deviation_error:1.36612\n",
      "Скор для фолда(13) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 14\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.56122\n",
      "[500]\tvalid-deviation_error:1.06088\n",
      "[750]\tvalid-deviation_error:1.14476\n",
      "[922]\tvalid-deviation_error:1.13827\n",
      "Скор для фолда(14) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 15\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.39387\n",
      "[500]\tvalid-deviation_error:1.34931\n",
      "[750]\tvalid-deviation_error:1.35729\n",
      "[1000]\tvalid-deviation_error:1.30668\n",
      "[1250]\tvalid-deviation_error:1.27812\n",
      "[1500]\tvalid-deviation_error:1.26621\n",
      "[1750]\tvalid-deviation_error:1.25478\n",
      "[2000]\tvalid-deviation_error:1.24268\n",
      "[2250]\tvalid-deviation_error:1.23526\n",
      "[2500]\tvalid-deviation_error:1.23223\n",
      "[2750]\tvalid-deviation_error:1.23289\n",
      "[2951]\tvalid-deviation_error:1.23262\n",
      "Скор для фолда(15) : 9.0 средний скор на префиксе = 9.0 это заняло = 12 сек.\n",
      "Фолд: 16\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.68295\n",
      "[500]\tvalid-deviation_error:1.35362\n",
      "[750]\tvalid-deviation_error:1.39210\n",
      "[989]\tvalid-deviation_error:1.35444\n",
      "Скор для фолда(16) : 9.0 средний скор на префиксе = 9.0 это заняло = 4 сек.\n",
      "Фолд: 17\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.86588\n",
      "[500]\tvalid-deviation_error:1.05334\n",
      "[750]\tvalid-deviation_error:1.08256\n",
      "[1000]\tvalid-deviation_error:1.06075\n",
      "[1040]\tvalid-deviation_error:1.05922\n",
      "Скор для фолда(17) : 9.0 средний скор на префиксе = 9.0 это заняло = 4 сек.\n",
      "Фолд: 18\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.66718\n",
      "[500]\tvalid-deviation_error:1.06634\n",
      "[750]\tvalid-deviation_error:1.17169\n",
      "[950]\tvalid-deviation_error:1.14534\n",
      "Скор для фолда(18) : 9.0 средний скор на префиксе = 9.0 это заняло = 3 сек.\n",
      "Фолд: 19\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:6.83084\n",
      "[500]\tvalid-deviation_error:1.02895\n",
      "[750]\tvalid-deviation_error:1.03028\n",
      "[1000]\tvalid-deviation_error:1.00346\n",
      "[1250]\tvalid-deviation_error:0.96573\n",
      "[1500]\tvalid-deviation_error:0.94925\n",
      "[1750]\tvalid-deviation_error:0.93911\n",
      "[2000]\tvalid-deviation_error:0.93485\n",
      "[2250]\tvalid-deviation_error:0.93785\n",
      "[2500]\tvalid-deviation_error:0.93524\n",
      "[2750]\tvalid-deviation_error:0.93538\n",
      "[3000]\tvalid-deviation_error:0.93793\n",
      "[3113]\tvalid-deviation_error:0.93686\n",
      "Скор для фолда(19) : 9.0 средний скор на префиксе = 9.0 это заняло = 12 сек.\n",
      "Процесс обучения модели занял = 96 секунд\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Кастомная метрика для xgboost\n",
    "def xbg_error(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    err = deviation_metric(np.exp(labels), np.exp(preds))\n",
    "    return 'deviation_error', err\n",
    "\n",
    "\n",
    "def train_xgb(train, valid, num_features, categorical_features, target_train, target_valid, EPOCHS, params):\n",
    "    dtest = xgb.DMatrix(test[num_features + categorical_features])\n",
    "    y_valid = np.zeros(len(valid))\n",
    "\n",
    "    dtrain = xgb.DMatrix(train[num_features + categorical_features], np.log(target_train), \n",
    "                        )\n",
    "    dvalid = xgb.DMatrix(valid[num_features + categorical_features], np.log(target_valid), \n",
    "                        )\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        EPOCHS,\n",
    "        [(dvalid, \"valid\")],\n",
    "        verbose_eval=250,\n",
    "        early_stopping_rounds=500,\n",
    "        feval=xbg_error,\n",
    "    )\n",
    "    y_valid = model.predict(dvalid)\n",
    "\n",
    "    return model, y_valid\n",
    "\n",
    "\n",
    "start_train_model_time = time.time()\n",
    "\n",
    "xgboost_seed = 41\n",
    "xgboost_params = {\n",
    "    \"subsample\": 0.60,\n",
    "    \"colsample_bytree\": 0.40,\n",
    "    \"max_depth\": 7,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'disable_default_eval_metric': 1,\n",
    "    \"nthread\": -1,\n",
    "    \"max_bin\": 64,\n",
    "    'min_child_weight': 0.0,\n",
    "    'reg_lambda': 0.0,\n",
    "    'reg_alpha': 0.0,\n",
    "    'seed': xgboost_seed,\n",
    "}\n",
    "\n",
    "# Количество эпох обучения\n",
    "EPOCHS = 10000\n",
    "scores = []\n",
    "xgb_predicts = np.zeros(len(train))\n",
    "\n",
    "xgb_models = []\n",
    "for fold_num, (train_indexes, valid_indexes) in enumerate(split_list):\n",
    "    start_time = time.time()\n",
    "    print(f\"Фолд: {fold_num}\")\n",
    "\n",
    "    train_sub_df = train[features_columns_order].loc[train_indexes].reset_index(drop=True)\n",
    "    valid_sub_df = train[features_columns_order].loc[valid_indexes].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Размер трейна = {train_sub_df.shape} Размер валидации = {valid_sub_df.shape}\")\n",
    "    # Обучаем Xgboost и делаем предикт на валидационной выборке\n",
    "    model, predict_validation = train_xgb(\n",
    "        train_sub_df,\n",
    "        valid_sub_df,\n",
    "        NUM_FEATURES_COLUMNS,\n",
    "        CATEGORICAL_FEATURES_COLUMNS,\n",
    "        train_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        valid_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        EPOCHS,\n",
    "        xgboost_params)\n",
    "\n",
    "    xgb_models += [model]\n",
    "    predict_on_validation = model.predict(\n",
    "        xgb.DMatrix(valid_sub_df[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS]))\n",
    "    xgb_predicts[valid_indexes] = np.exp(predict_on_validation)\n",
    "    targets_for_validation = valid_sub_df[TARGET_COLUMNS].values[:, 0]\n",
    "    current_score = deviation_metric(targets_for_validation, predict_on_validation)\n",
    "    scores += [current_score]\n",
    "    print(\n",
    "        f\"Скор для фолда({fold_num}) : {np.round(current_score, 4)} средний скор на префиксе = {np.round(np.mean(scores), 4)} это заняло = {int(time.time() - start_time)} сек.\")\n",
    "print(f\"Процесс обучения модели занял = {int(time.time() - start_train_model_time)} секунд\")\n",
    "\n",
    "\n",
    "# Предикт xgb на test\n",
    "def get_xgb_predict(models, test):\n",
    "    result = np.zeros(len(test))\n",
    "    for model in models:\n",
    "        predict = model.predict(xgb.DMatrix(test[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS]))\n",
    "        result += predict / len(models)\n",
    "    return result\n",
    "\n",
    "\n",
    "test_xgb_predict = get_xgb_predict(xgb_models, test)\n",
    "\n",
    "test_xgb_predict.min(), test_xgb_predict.max(), test_xgb_predict.mean()\n",
    "\n",
    "train_targets = train[TARGET_COLUMNS[0]].values\n",
    "\n",
    "\n",
    "def minimize_arit(W):\n",
    "    ypred = W[0] * nn_predicts + W[1] * lgb_predicts + W[2] * xgb_predicts\n",
    "    return deviation_metric(train_targets, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5c7b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from catboost import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd49528e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фолд: 0\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.6306521\ttest: 3.3506940\tbest: 3.3506940 (0)\ttotal: 153ms\tremaining: 38m 15s\n",
      "100:\tlearn: 2.2816934\ttest: 2.2319623\tbest: 2.2319623 (100)\ttotal: 540ms\tremaining: 1m 19s\n",
      "200:\tlearn: 1.8608139\ttest: 2.0075182\tbest: 2.0075182 (200)\ttotal: 930ms\tremaining: 1m 8s\n",
      "300:\tlearn: 1.6571693\ttest: 1.9604907\tbest: 1.9599099 (299)\ttotal: 1.31s\tremaining: 1m 4s\n",
      "400:\tlearn: 1.5344864\ttest: 1.8883493\tbest: 1.8883493 (400)\ttotal: 1.69s\tremaining: 1m 1s\n",
      "500:\tlearn: 1.4512465\ttest: 1.8371421\tbest: 1.8371421 (500)\ttotal: 2.07s\tremaining: 60s\n",
      "600:\tlearn: 1.3858743\ttest: 1.7849629\tbest: 1.7845136 (599)\ttotal: 2.45s\tremaining: 58.8s\n",
      "700:\tlearn: 1.3362125\ttest: 1.7603217\tbest: 1.7568215 (689)\ttotal: 2.83s\tremaining: 57.7s\n",
      "800:\tlearn: 1.2939424\ttest: 1.7489645\tbest: 1.7489645 (800)\ttotal: 3.21s\tremaining: 56.9s\n",
      "900:\tlearn: 1.2519733\ttest: 1.7312443\tbest: 1.7312443 (900)\ttotal: 3.59s\tremaining: 56.2s\n",
      "1000:\tlearn: 1.2161282\ttest: 1.7209376\tbest: 1.7208907 (995)\ttotal: 3.99s\tremaining: 55.8s\n",
      "1100:\tlearn: 1.1822973\ttest: 1.7040294\tbest: 1.7040294 (1100)\ttotal: 4.4s\tremaining: 55.5s\n",
      "1200:\tlearn: 1.1495779\ttest: 1.6827206\tbest: 1.6827206 (1200)\ttotal: 4.8s\tremaining: 55.2s\n",
      "1300:\tlearn: 1.1181823\ttest: 1.6657000\tbest: 1.6657000 (1300)\ttotal: 5.2s\tremaining: 54.7s\n",
      "1400:\tlearn: 1.0910208\ttest: 1.6536896\tbest: 1.6528638 (1394)\ttotal: 5.6s\tremaining: 54.4s\n",
      "1500:\tlearn: 1.0582789\ttest: 1.6335634\tbest: 1.6333866 (1495)\ttotal: 6s\tremaining: 54s\n",
      "1600:\tlearn: 1.0286377\ttest: 1.6267644\tbest: 1.6267644 (1600)\ttotal: 6.4s\tremaining: 53.6s\n",
      "1700:\tlearn: 0.9971757\ttest: 1.6115965\tbest: 1.6115805 (1699)\ttotal: 6.8s\tremaining: 53.2s\n",
      "1800:\tlearn: 0.9650589\ttest: 1.5959072\tbest: 1.5955667 (1789)\ttotal: 7.21s\tremaining: 52.8s\n",
      "1900:\tlearn: 0.9356412\ttest: 1.5809075\tbest: 1.5809075 (1900)\ttotal: 7.62s\tremaining: 52.5s\n",
      "2000:\tlearn: 0.9074805\ttest: 1.5704071\tbest: 1.5704071 (2000)\ttotal: 8.02s\tremaining: 52.1s\n",
      "2100:\tlearn: 0.8791972\ttest: 1.5622883\tbest: 1.5612963 (2075)\ttotal: 8.43s\tremaining: 51.7s\n",
      "2200:\tlearn: 0.8512486\ttest: 1.5521235\tbest: 1.5518429 (2185)\ttotal: 8.83s\tremaining: 51.4s\n",
      "2300:\tlearn: 0.8248257\ttest: 1.5450900\tbest: 1.5446239 (2299)\ttotal: 9.23s\tremaining: 51s\n",
      "2400:\tlearn: 0.8023184\ttest: 1.5398606\tbest: 1.5394698 (2380)\ttotal: 9.63s\tremaining: 50.5s\n",
      "2500:\tlearn: 0.7765880\ttest: 1.5310494\tbest: 1.5310494 (2500)\ttotal: 10s\tremaining: 50.2s\n",
      "2600:\tlearn: 0.7535262\ttest: 1.5240038\tbest: 1.5238906 (2599)\ttotal: 10.4s\tremaining: 49.8s\n",
      "2700:\tlearn: 0.7310971\ttest: 1.5145184\tbest: 1.5141420 (2693)\ttotal: 10.8s\tremaining: 49.4s\n",
      "2800:\tlearn: 0.7088713\ttest: 1.5093388\tbest: 1.5091743 (2798)\ttotal: 11.3s\tremaining: 49s\n",
      "2900:\tlearn: 0.6893077\ttest: 1.4976713\tbest: 1.4976691 (2898)\ttotal: 11.7s\tremaining: 48.6s\n",
      "3000:\tlearn: 0.6691454\ttest: 1.4880367\tbest: 1.4876663 (2994)\ttotal: 12.1s\tremaining: 48.3s\n",
      "3100:\tlearn: 0.6492350\ttest: 1.4853605\tbest: 1.4842428 (3078)\ttotal: 12.5s\tremaining: 47.9s\n",
      "3200:\tlearn: 0.6288025\ttest: 1.4823515\tbest: 1.4821118 (3198)\ttotal: 12.9s\tremaining: 47.5s\n",
      "3300:\tlearn: 0.6113067\ttest: 1.4764733\tbest: 1.4760454 (3284)\ttotal: 13.3s\tremaining: 47.1s\n",
      "3400:\tlearn: 0.5921180\ttest: 1.4743947\tbest: 1.4739506 (3376)\ttotal: 13.7s\tremaining: 46.7s\n",
      "3500:\tlearn: 0.5747531\ttest: 1.4709045\tbest: 1.4709045 (3500)\ttotal: 14.1s\tremaining: 46.3s\n",
      "3600:\tlearn: 0.5577541\ttest: 1.4642852\tbest: 1.4638548 (3577)\ttotal: 14.5s\tremaining: 45.9s\n",
      "3700:\tlearn: 0.5418315\ttest: 1.4573383\tbest: 1.4569220 (3696)\ttotal: 14.9s\tremaining: 45.6s\n",
      "3800:\tlearn: 0.5269404\ttest: 1.4517952\tbest: 1.4513582 (3790)\ttotal: 15.3s\tremaining: 45.2s\n",
      "3900:\tlearn: 0.5105641\ttest: 1.4490755\tbest: 1.4490755 (3900)\ttotal: 15.7s\tremaining: 44.8s\n",
      "4000:\tlearn: 0.4934088\ttest: 1.4468045\tbest: 1.4454953 (3938)\ttotal: 16.2s\tremaining: 44.4s\n",
      "4100:\tlearn: 0.4781853\ttest: 1.4434841\tbest: 1.4434136 (4091)\ttotal: 16.6s\tremaining: 44s\n",
      "4200:\tlearn: 0.4643242\ttest: 1.4409650\tbest: 1.4402801 (4142)\ttotal: 17s\tremaining: 43.7s\n",
      "4300:\tlearn: 0.4525293\ttest: 1.4387430\tbest: 1.4383589 (4293)\ttotal: 17.4s\tremaining: 43.3s\n",
      "4400:\tlearn: 0.4379405\ttest: 1.4376765\tbest: 1.4361799 (4377)\ttotal: 17.8s\tremaining: 42.9s\n",
      "4500:\tlearn: 0.4252218\ttest: 1.4335664\tbest: 1.4335664 (4500)\ttotal: 18.2s\tremaining: 42.5s\n",
      "4600:\tlearn: 0.4119067\ttest: 1.4246164\tbest: 1.4244533 (4597)\ttotal: 18.6s\tremaining: 42.1s\n",
      "4700:\tlearn: 0.3995381\ttest: 1.4201387\tbest: 1.4198394 (4699)\ttotal: 19s\tremaining: 41.7s\n",
      "4800:\tlearn: 0.3883028\ttest: 1.4159189\tbest: 1.4157142 (4789)\ttotal: 19.4s\tremaining: 41.3s\n",
      "4900:\tlearn: 0.3772730\ttest: 1.4123744\tbest: 1.4122233 (4898)\ttotal: 19.9s\tremaining: 40.9s\n",
      "5000:\tlearn: 0.3663589\ttest: 1.4085571\tbest: 1.4085486 (4996)\ttotal: 20.3s\tremaining: 40.5s\n",
      "5100:\tlearn: 0.3560374\ttest: 1.4066918\tbest: 1.4058508 (5095)\ttotal: 20.7s\tremaining: 40.1s\n",
      "5200:\tlearn: 0.3459033\ttest: 1.4046204\tbest: 1.4035511 (5152)\ttotal: 21.1s\tremaining: 39.7s\n",
      "5300:\tlearn: 0.3362812\ttest: 1.3986351\tbest: 1.3985323 (5299)\ttotal: 21.5s\tremaining: 39.3s\n",
      "5400:\tlearn: 0.3250980\ttest: 1.3935984\tbest: 1.3929398 (5389)\ttotal: 21.9s\tremaining: 38.9s\n",
      "5500:\tlearn: 0.3158825\ttest: 1.3943337\tbest: 1.3925340 (5432)\ttotal: 22.3s\tremaining: 38.5s\n",
      "5600:\tlearn: 0.3071434\ttest: 1.3893202\tbest: 1.3881834 (5573)\ttotal: 22.7s\tremaining: 38.1s\n",
      "5700:\tlearn: 0.2974218\ttest: 1.3825081\tbest: 1.3825081 (5700)\ttotal: 23.1s\tremaining: 37.7s\n",
      "5800:\tlearn: 0.2885667\ttest: 1.3800282\tbest: 1.3800197 (5798)\ttotal: 23.6s\tremaining: 37.4s\n",
      "5900:\tlearn: 0.2801048\ttest: 1.3764920\tbest: 1.3756222 (5883)\ttotal: 24s\tremaining: 37s\n",
      "6000:\tlearn: 0.2713970\ttest: 1.3747678\tbest: 1.3745047 (5998)\ttotal: 24.4s\tremaining: 36.6s\n",
      "6100:\tlearn: 0.2634333\ttest: 1.3724807\tbest: 1.3724807 (6100)\ttotal: 24.8s\tremaining: 36.2s\n",
      "6200:\tlearn: 0.2564192\ttest: 1.3696002\tbest: 1.3690819 (6194)\ttotal: 25.2s\tremaining: 35.8s\n",
      "6300:\tlearn: 0.2486263\ttest: 1.3674915\tbest: 1.3671341 (6293)\ttotal: 25.6s\tremaining: 35.4s\n",
      "6400:\tlearn: 0.2404487\ttest: 1.3636895\tbest: 1.3634961 (6395)\ttotal: 26s\tremaining: 35s\n",
      "6500:\tlearn: 0.2328082\ttest: 1.3591563\tbest: 1.3584159 (6489)\ttotal: 26.4s\tremaining: 34.6s\n",
      "6600:\tlearn: 0.2261505\ttest: 1.3573979\tbest: 1.3565373 (6539)\ttotal: 26.9s\tremaining: 34.2s\n",
      "6700:\tlearn: 0.2196274\ttest: 1.3567816\tbest: 1.3564884 (6621)\ttotal: 27.3s\tremaining: 33.8s\n",
      "6800:\tlearn: 0.2131063\ttest: 1.3515612\tbest: 1.3515612 (6800)\ttotal: 27.7s\tremaining: 33.4s\n",
      "6900:\tlearn: 0.2066338\ttest: 1.3482685\tbest: 1.3482618 (6899)\ttotal: 28.1s\tremaining: 33s\n",
      "7000:\tlearn: 0.2003366\ttest: 1.3453164\tbest: 1.3448116 (6963)\ttotal: 28.5s\tremaining: 32.6s\n",
      "7100:\tlearn: 0.1943870\ttest: 1.3415854\tbest: 1.3412004 (7082)\ttotal: 28.9s\tremaining: 32.2s\n",
      "7200:\tlearn: 0.1881351\ttest: 1.3388540\tbest: 1.3386984 (7192)\ttotal: 29.3s\tremaining: 31.8s\n",
      "7300:\tlearn: 0.1832279\ttest: 1.3359752\tbest: 1.3357921 (7299)\ttotal: 29.7s\tremaining: 31.4s\n",
      "7400:\tlearn: 0.1774972\ttest: 1.3347264\tbest: 1.3347264 (7400)\ttotal: 30.2s\tremaining: 31s\n",
      "7500:\tlearn: 0.1729029\ttest: 1.3337447\tbest: 1.3336191 (7437)\ttotal: 30.6s\tremaining: 30.6s\n",
      "7600:\tlearn: 0.1686757\ttest: 1.3323259\tbest: 1.3321719 (7598)\ttotal: 31s\tremaining: 30.2s\n",
      "7700:\tlearn: 0.1635641\ttest: 1.3334564\tbest: 1.3321719 (7598)\ttotal: 31.4s\tremaining: 29.8s\n",
      "7800:\tlearn: 0.1581208\ttest: 1.3324059\tbest: 1.3321719 (7598)\ttotal: 31.8s\tremaining: 29.4s\n",
      "7900:\tlearn: 0.1534257\ttest: 1.3299881\tbest: 1.3297507 (7895)\ttotal: 32.2s\tremaining: 29s\n",
      "8000:\tlearn: 0.1494615\ttest: 1.3270818\tbest: 1.3270818 (8000)\ttotal: 32.6s\tremaining: 28.6s\n",
      "8100:\tlearn: 0.1448721\ttest: 1.3261055\tbest: 1.3260311 (8086)\ttotal: 33.1s\tremaining: 28.2s\n",
      "8200:\tlearn: 0.1408536\ttest: 1.3234499\tbest: 1.3232771 (8191)\ttotal: 33.5s\tremaining: 27.8s\n",
      "8300:\tlearn: 0.1366383\ttest: 1.3195989\tbest: 1.3192172 (8280)\ttotal: 33.9s\tremaining: 27.3s\n",
      "8400:\tlearn: 0.1330258\ttest: 1.3171235\tbest: 1.3169345 (8353)\ttotal: 34.3s\tremaining: 26.9s\n",
      "8500:\tlearn: 0.1292110\ttest: 1.3137836\tbest: 1.3131566 (8484)\ttotal: 34.7s\tremaining: 26.5s\n",
      "8600:\tlearn: 0.1250556\ttest: 1.3125590\tbest: 1.3117674 (8579)\ttotal: 35.1s\tremaining: 26.1s\n",
      "8700:\tlearn: 0.1212772\ttest: 1.3125633\tbest: 1.3104242 (8640)\ttotal: 35.5s\tremaining: 25.7s\n",
      "8800:\tlearn: 0.1174022\ttest: 1.3066341\tbest: 1.3066341 (8800)\ttotal: 36s\tremaining: 25.3s\n",
      "8900:\tlearn: 0.1138548\ttest: 1.3006937\tbest: 1.3003010 (8893)\ttotal: 36.4s\tremaining: 24.9s\n",
      "9000:\tlearn: 0.1101835\ttest: 1.2990777\tbest: 1.2987036 (8988)\ttotal: 36.8s\tremaining: 24.5s\n",
      "9100:\tlearn: 0.1072732\ttest: 1.2985745\tbest: 1.2976341 (9072)\ttotal: 37.2s\tremaining: 24.1s\n",
      "9200:\tlearn: 0.1040267\ttest: 1.2956273\tbest: 1.2955076 (9199)\ttotal: 37.6s\tremaining: 23.7s\n",
      "9300:\tlearn: 0.1010600\ttest: 1.2972594\tbest: 1.2955076 (9199)\ttotal: 38s\tremaining: 23.3s\n",
      "9400:\tlearn: 0.0981991\ttest: 1.2957449\tbest: 1.2950452 (9383)\ttotal: 38.4s\tremaining: 22.9s\n",
      "9500:\tlearn: 0.0952985\ttest: 1.2949528\tbest: 1.2949528 (9500)\ttotal: 38.8s\tremaining: 22.5s\n",
      "9600:\tlearn: 0.0923416\ttest: 1.2931045\tbest: 1.2929238 (9577)\ttotal: 39.3s\tremaining: 22.1s\n",
      "9700:\tlearn: 0.0897860\ttest: 1.2919253\tbest: 1.2918038 (9694)\ttotal: 39.7s\tremaining: 21.7s\n",
      "9800:\tlearn: 0.0870952\ttest: 1.2910261\tbest: 1.2908043 (9792)\ttotal: 40.1s\tremaining: 21.3s\n",
      "9900:\tlearn: 0.0843454\ttest: 1.2879007\tbest: 1.2877704 (9896)\ttotal: 40.5s\tremaining: 20.9s\n",
      "10000:\tlearn: 0.0813128\ttest: 1.2868403\tbest: 1.2861651 (9978)\ttotal: 40.9s\tremaining: 20.4s\n",
      "10100:\tlearn: 0.0788292\ttest: 1.2860530\tbest: 1.2860248 (10093)\ttotal: 41.3s\tremaining: 20s\n",
      "10200:\tlearn: 0.0764379\ttest: 1.2859501\tbest: 1.2853818 (10143)\ttotal: 41.7s\tremaining: 19.6s\n",
      "10300:\tlearn: 0.0742883\ttest: 1.2848977\tbest: 1.2843758 (10271)\ttotal: 42.1s\tremaining: 19.2s\n",
      "10400:\tlearn: 0.0718078\ttest: 1.2861338\tbest: 1.2843758 (10271)\ttotal: 42.6s\tremaining: 18.8s\n",
      "10500:\tlearn: 0.0697305\ttest: 1.2862623\tbest: 1.2843758 (10271)\ttotal: 43s\tremaining: 18.4s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.284375799\n",
      "bestIteration = 10271\n",
      "\n",
      "Shrink model to first 10272 iterations.\n",
      "Скор для фолда(0) : 9.0 средний скор на префиксе = 9.0 это заняло = 43 сек.\n",
      "Фолд: 1\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.5956751\ttest: 3.4685541\tbest: 3.4685541 (0)\ttotal: 52.9ms\tremaining: 13m 12s\n",
      "100:\tlearn: 2.2665210\ttest: 2.1492417\tbest: 2.1492417 (100)\ttotal: 437ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8511002\ttest: 1.8099356\tbest: 1.8099356 (200)\ttotal: 878ms\tremaining: 1m 4s\n",
      "300:\tlearn: 1.6580147\ttest: 1.6913554\tbest: 1.6913554 (300)\ttotal: 1.32s\tremaining: 1m 4s\n",
      "400:\tlearn: 1.5479568\ttest: 1.6449970\tbest: 1.6449970 (400)\ttotal: 1.75s\tremaining: 1m 3s\n",
      "500:\tlearn: 1.4654375\ttest: 1.5953271\tbest: 1.5953271 (500)\ttotal: 2.19s\tremaining: 1m 3s\n",
      "600:\tlearn: 1.4052732\ttest: 1.5660224\tbest: 1.5660224 (600)\ttotal: 2.61s\tremaining: 1m 2s\n",
      "700:\tlearn: 1.3594636\ttest: 1.5475225\tbest: 1.5475225 (700)\ttotal: 3.01s\tremaining: 1m 1s\n",
      "800:\tlearn: 1.3191755\ttest: 1.5258390\tbest: 1.5256909 (799)\ttotal: 3.41s\tremaining: 1m\n",
      "900:\tlearn: 1.2875241\ttest: 1.5129597\tbest: 1.5129173 (899)\ttotal: 3.81s\tremaining: 59.6s\n",
      "1000:\tlearn: 1.2556710\ttest: 1.5042075\tbest: 1.5042075 (1000)\ttotal: 4.2s\tremaining: 58.7s\n",
      "1100:\tlearn: 1.2264165\ttest: 1.4979018\tbest: 1.4979018 (1100)\ttotal: 4.59s\tremaining: 58s\n",
      "1200:\tlearn: 1.1938831\ttest: 1.4941790\tbest: 1.4933260 (1194)\ttotal: 4.99s\tremaining: 57.3s\n",
      "1300:\tlearn: 1.1594967\ttest: 1.4882924\tbest: 1.4880385 (1296)\ttotal: 5.39s\tremaining: 56.7s\n",
      "1400:\tlearn: 1.1258293\ttest: 1.4833289\tbest: 1.4833289 (1400)\ttotal: 5.79s\tremaining: 56.2s\n",
      "1500:\tlearn: 1.0958681\ttest: 1.4792431\tbest: 1.4791329 (1491)\ttotal: 6.19s\tremaining: 55.7s\n",
      "1600:\tlearn: 1.0616351\ttest: 1.4754002\tbest: 1.4745101 (1589)\ttotal: 6.6s\tremaining: 55.2s\n",
      "1700:\tlearn: 1.0263128\ttest: 1.4720902\tbest: 1.4718010 (1687)\ttotal: 7s\tremaining: 54.7s\n",
      "1800:\tlearn: 0.9942052\ttest: 1.4709391\tbest: 1.4696016 (1765)\ttotal: 7.41s\tremaining: 54.3s\n",
      "1900:\tlearn: 0.9623695\ttest: 1.4683888\tbest: 1.4682491 (1879)\ttotal: 7.82s\tremaining: 53.9s\n",
      "2000:\tlearn: 0.9343957\ttest: 1.4670811\tbest: 1.4652277 (1963)\ttotal: 8.23s\tremaining: 53.4s\n",
      "2100:\tlearn: 0.9074489\ttest: 1.4624993\tbest: 1.4612248 (2078)\ttotal: 8.63s\tremaining: 53s\n",
      "2200:\tlearn: 0.8826609\ttest: 1.4630744\tbest: 1.4612248 (2078)\ttotal: 9.04s\tremaining: 52.6s\n",
      "2300:\tlearn: 0.8556501\ttest: 1.4636843\tbest: 1.4612248 (2078)\ttotal: 9.45s\tremaining: 52.2s\n",
      "2400:\tlearn: 0.8329404\ttest: 1.4582396\tbest: 1.4571411 (2368)\ttotal: 9.86s\tremaining: 51.7s\n",
      "2500:\tlearn: 0.8097130\ttest: 1.4582929\tbest: 1.4565260 (2491)\ttotal: 10.3s\tremaining: 51.3s\n",
      "2600:\tlearn: 0.7874554\ttest: 1.4552896\tbest: 1.4548190 (2596)\ttotal: 10.7s\tremaining: 50.9s\n",
      "2700:\tlearn: 0.7646531\ttest: 1.4558063\tbest: 1.4543171 (2683)\ttotal: 11.1s\tremaining: 50.4s\n",
      "2800:\tlearn: 0.7416126\ttest: 1.4483384\tbest: 1.4483384 (2800)\ttotal: 11.5s\tremaining: 50s\n",
      "2900:\tlearn: 0.7205014\ttest: 1.4452991\tbest: 1.4436437 (2884)\ttotal: 11.9s\tremaining: 49.6s\n",
      "3000:\tlearn: 0.6986978\ttest: 1.4412843\tbest: 1.4396037 (2991)\ttotal: 12.3s\tremaining: 49.2s\n",
      "3100:\tlearn: 0.6780847\ttest: 1.4363607\tbest: 1.4363607 (3100)\ttotal: 12.7s\tremaining: 48.8s\n",
      "3200:\tlearn: 0.6579098\ttest: 1.4361151\tbest: 1.4351495 (3151)\ttotal: 13.1s\tremaining: 48.4s\n",
      "3300:\tlearn: 0.6394408\ttest: 1.4324722\tbest: 1.4324477 (3268)\ttotal: 13.5s\tremaining: 47.9s\n",
      "3400:\tlearn: 0.6225209\ttest: 1.4300214\tbest: 1.4274888 (3362)\ttotal: 13.9s\tremaining: 47.5s\n",
      "3500:\tlearn: 0.6052356\ttest: 1.4248532\tbest: 1.4248532 (3500)\ttotal: 14.3s\tremaining: 47.1s\n",
      "3600:\tlearn: 0.5857763\ttest: 1.4176957\tbest: 1.4176957 (3600)\ttotal: 14.7s\tremaining: 46.7s\n",
      "3700:\tlearn: 0.5668767\ttest: 1.4136527\tbest: 1.4126690 (3658)\ttotal: 15.2s\tremaining: 46.3s\n",
      "3800:\tlearn: 0.5494361\ttest: 1.4065874\tbest: 1.4061758 (3780)\ttotal: 15.6s\tremaining: 45.9s\n",
      "3900:\tlearn: 0.5303927\ttest: 1.3995814\tbest: 1.3991525 (3892)\ttotal: 16s\tremaining: 45.5s\n",
      "4000:\tlearn: 0.5159847\ttest: 1.3931056\tbest: 1.3931056 (4000)\ttotal: 16.4s\tremaining: 45.1s\n",
      "4100:\tlearn: 0.4991751\ttest: 1.3871539\tbest: 1.3871539 (4100)\ttotal: 16.8s\tremaining: 44.6s\n",
      "4200:\tlearn: 0.4828732\ttest: 1.3810202\tbest: 1.3809812 (4194)\ttotal: 17.2s\tremaining: 44.2s\n",
      "4300:\tlearn: 0.4680697\ttest: 1.3793039\tbest: 1.3789358 (4294)\ttotal: 17.6s\tremaining: 43.8s\n",
      "4400:\tlearn: 0.4521084\ttest: 1.3769553\tbest: 1.3762910 (4323)\ttotal: 18s\tremaining: 43.4s\n",
      "4500:\tlearn: 0.4380600\ttest: 1.3761669\tbest: 1.3759147 (4498)\ttotal: 18.5s\tremaining: 43s\n",
      "4600:\tlearn: 0.4243774\ttest: 1.3748490\tbest: 1.3744837 (4594)\ttotal: 18.9s\tremaining: 42.6s\n",
      "4700:\tlearn: 0.4119517\ttest: 1.3704075\tbest: 1.3689429 (4678)\ttotal: 19.3s\tremaining: 42.2s\n",
      "4800:\tlearn: 0.3997203\ttest: 1.3679782\tbest: 1.3676369 (4798)\ttotal: 19.7s\tremaining: 41.8s\n",
      "4900:\tlearn: 0.3879920\ttest: 1.3625882\tbest: 1.3625882 (4900)\ttotal: 20.1s\tremaining: 41.4s\n",
      "5000:\tlearn: 0.3752346\ttest: 1.3572831\tbest: 1.3572831 (5000)\ttotal: 20.5s\tremaining: 41s\n",
      "5100:\tlearn: 0.3639446\ttest: 1.3539827\tbest: 1.3539827 (5100)\ttotal: 20.9s\tremaining: 40.6s\n",
      "5200:\tlearn: 0.3512302\ttest: 1.3503340\tbest: 1.3499055 (5177)\ttotal: 21.3s\tremaining: 40.2s\n",
      "5300:\tlearn: 0.3396819\ttest: 1.3479101\tbest: 1.3477191 (5292)\ttotal: 21.8s\tremaining: 39.8s\n",
      "5400:\tlearn: 0.3281028\ttest: 1.3476183\tbest: 1.3464777 (5333)\ttotal: 22.2s\tremaining: 39.4s\n",
      "5500:\tlearn: 0.3168051\ttest: 1.3385279\tbest: 1.3381438 (5494)\ttotal: 22.6s\tremaining: 39s\n",
      "5600:\tlearn: 0.3065385\ttest: 1.3365573\tbest: 1.3360235 (5567)\ttotal: 23s\tremaining: 38.6s\n",
      "5700:\tlearn: 0.2968967\ttest: 1.3352811\tbest: 1.3349327 (5677)\ttotal: 23.4s\tremaining: 38.2s\n",
      "5800:\tlearn: 0.2873053\ttest: 1.3318937\tbest: 1.3318937 (5800)\ttotal: 23.8s\tremaining: 37.8s\n",
      "5900:\tlearn: 0.2781927\ttest: 1.3263885\tbest: 1.3261294 (5896)\ttotal: 24.2s\tremaining: 37.4s\n",
      "6000:\tlearn: 0.2689344\ttest: 1.3237505\tbest: 1.3231352 (5987)\ttotal: 24.7s\tremaining: 37s\n",
      "6100:\tlearn: 0.2603402\ttest: 1.3211775\tbest: 1.3207063 (6087)\ttotal: 25.1s\tremaining: 36.6s\n",
      "6200:\tlearn: 0.2522451\ttest: 1.3188958\tbest: 1.3170529 (6164)\ttotal: 25.5s\tremaining: 36.2s\n",
      "6300:\tlearn: 0.2438729\ttest: 1.3180910\tbest: 1.3170529 (6164)\ttotal: 25.9s\tremaining: 35.8s\n",
      "6400:\tlearn: 0.2351899\ttest: 1.3175187\tbest: 1.3170529 (6164)\ttotal: 26.3s\tremaining: 35.4s\n",
      "6500:\tlearn: 0.2268161\ttest: 1.3145711\tbest: 1.3141988 (6461)\ttotal: 26.7s\tremaining: 34.9s\n",
      "6600:\tlearn: 0.2200467\ttest: 1.3128543\tbest: 1.3122454 (6568)\ttotal: 27.1s\tremaining: 34.5s\n",
      "6700:\tlearn: 0.2131233\ttest: 1.3111979\tbest: 1.3108923 (6672)\ttotal: 27.6s\tremaining: 34.1s\n",
      "6800:\tlearn: 0.2068470\ttest: 1.3108083\tbest: 1.3108083 (6800)\ttotal: 28s\tremaining: 33.7s\n",
      "6900:\tlearn: 0.2000803\ttest: 1.3100774\tbest: 1.3093327 (6830)\ttotal: 28.4s\tremaining: 33.3s\n",
      "7000:\tlearn: 0.1937327\ttest: 1.3054708\tbest: 1.3054708 (7000)\ttotal: 28.8s\tremaining: 32.9s\n",
      "7100:\tlearn: 0.1872867\ttest: 1.3038888\tbest: 1.3029763 (7059)\ttotal: 29.2s\tremaining: 32.5s\n",
      "7200:\tlearn: 0.1817333\ttest: 1.3002291\tbest: 1.3002291 (7200)\ttotal: 29.6s\tremaining: 32.1s\n",
      "7300:\tlearn: 0.1758779\ttest: 1.3002237\tbest: 1.2990748 (7225)\ttotal: 30s\tremaining: 31.7s\n",
      "7400:\tlearn: 0.1703829\ttest: 1.2978351\tbest: 1.2978351 (7400)\ttotal: 30.5s\tremaining: 31.3s\n",
      "7500:\tlearn: 0.1642342\ttest: 1.2934268\tbest: 1.2934268 (7500)\ttotal: 30.9s\tremaining: 30.9s\n",
      "7600:\tlearn: 0.1590253\ttest: 1.2941965\tbest: 1.2930323 (7537)\ttotal: 31.3s\tremaining: 30.5s\n",
      "7700:\tlearn: 0.1543940\ttest: 1.2948148\tbest: 1.2930323 (7537)\ttotal: 31.7s\tremaining: 30.1s\n",
      "7800:\tlearn: 0.1496820\ttest: 1.2949173\tbest: 1.2930323 (7537)\ttotal: 32.1s\tremaining: 29.7s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.29303233\n",
      "bestIteration = 7537\n",
      "\n",
      "Shrink model to first 7538 iterations.\n",
      "Скор для фолда(1) : 9.0 средний скор на префиксе = 9.0 это заняло = 32 сек.\n",
      "Фолд: 2\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.5890253\ttest: 3.6815244\tbest: 3.6815244 (0)\ttotal: 52.2ms\tremaining: 13m 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 2.2713789\ttest: 2.1993631\tbest: 2.1993631 (100)\ttotal: 432ms\tremaining: 1m 3s\n",
      "200:\tlearn: 1.8602873\ttest: 1.7019493\tbest: 1.7019493 (200)\ttotal: 837ms\tremaining: 1m 1s\n",
      "300:\tlearn: 1.6724229\ttest: 1.5583451\tbest: 1.5583451 (300)\ttotal: 1.25s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5507042\ttest: 1.4558377\tbest: 1.4558377 (400)\ttotal: 1.66s\tremaining: 1m\n",
      "500:\tlearn: 1.4692820\ttest: 1.3907886\tbest: 1.3907886 (500)\ttotal: 2.07s\tremaining: 59.9s\n",
      "600:\tlearn: 1.4128081\ttest: 1.3524901\tbest: 1.3520312 (597)\ttotal: 2.48s\tremaining: 59.3s\n",
      "700:\tlearn: 1.3659360\ttest: 1.3239218\tbest: 1.3226357 (698)\ttotal: 2.88s\tremaining: 58.8s\n",
      "800:\tlearn: 1.3276786\ttest: 1.3109933\tbest: 1.3109933 (800)\ttotal: 3.29s\tremaining: 58.3s\n",
      "900:\tlearn: 1.2911525\ttest: 1.2909525\tbest: 1.2904603 (898)\ttotal: 3.69s\tremaining: 57.8s\n",
      "1000:\tlearn: 1.2578328\ttest: 1.2709168\tbest: 1.2704744 (998)\ttotal: 4.1s\tremaining: 57.3s\n",
      "1100:\tlearn: 1.2228342\ttest: 1.2474744\tbest: 1.2474495 (1097)\ttotal: 4.5s\tremaining: 56.8s\n",
      "1200:\tlearn: 1.1840379\ttest: 1.2316162\tbest: 1.2310934 (1196)\ttotal: 4.91s\tremaining: 56.4s\n",
      "1300:\tlearn: 1.1529030\ttest: 1.2259266\tbest: 1.2257263 (1293)\ttotal: 5.31s\tremaining: 55.9s\n",
      "1400:\tlearn: 1.1186001\ttest: 1.2181018\tbest: 1.2181018 (1400)\ttotal: 5.72s\tremaining: 55.5s\n",
      "1500:\tlearn: 1.0895262\ttest: 1.2036592\tbest: 1.2036532 (1499)\ttotal: 6.13s\tremaining: 55.1s\n",
      "1600:\tlearn: 1.0576497\ttest: 1.1958782\tbest: 1.1957563 (1591)\ttotal: 6.54s\tremaining: 54.8s\n",
      "1700:\tlearn: 1.0268245\ttest: 1.1854318\tbest: 1.1853890 (1699)\ttotal: 6.95s\tremaining: 54.4s\n",
      "1800:\tlearn: 0.9988771\ttest: 1.1776117\tbest: 1.1772088 (1799)\ttotal: 7.37s\tremaining: 54s\n",
      "1900:\tlearn: 0.9711949\ttest: 1.1694939\tbest: 1.1694939 (1900)\ttotal: 7.78s\tremaining: 53.6s\n",
      "2000:\tlearn: 0.9420878\ttest: 1.1588511\tbest: 1.1588511 (2000)\ttotal: 8.19s\tremaining: 53.2s\n",
      "2100:\tlearn: 0.9127180\ttest: 1.1597980\tbest: 1.1579945 (2006)\ttotal: 8.6s\tremaining: 52.8s\n",
      "2200:\tlearn: 0.8864260\ttest: 1.1526470\tbest: 1.1526470 (2200)\ttotal: 9.01s\tremaining: 52.4s\n",
      "2300:\tlearn: 0.8609374\ttest: 1.1496047\tbest: 1.1491471 (2298)\ttotal: 9.42s\tremaining: 52s\n",
      "2400:\tlearn: 0.8346050\ttest: 1.1492156\tbest: 1.1484203 (2375)\ttotal: 9.83s\tremaining: 51.6s\n",
      "2500:\tlearn: 0.8104518\ttest: 1.1478187\tbest: 1.1456465 (2465)\ttotal: 10.2s\tremaining: 51.2s\n",
      "2600:\tlearn: 0.7856167\ttest: 1.1414018\tbest: 1.1412716 (2595)\ttotal: 10.6s\tremaining: 50.8s\n",
      "2700:\tlearn: 0.7605224\ttest: 1.1364420\tbest: 1.1358393 (2668)\ttotal: 11.1s\tremaining: 50.4s\n",
      "2800:\tlearn: 0.7373592\ttest: 1.1367562\tbest: 1.1345076 (2744)\ttotal: 11.5s\tremaining: 49.9s\n",
      "2900:\tlearn: 0.7135290\ttest: 1.1328963\tbest: 1.1323794 (2864)\ttotal: 11.9s\tremaining: 49.5s\n",
      "3000:\tlearn: 0.6930785\ttest: 1.1303627\tbest: 1.1298975 (2975)\ttotal: 12.3s\tremaining: 49.1s\n",
      "3100:\tlearn: 0.6718845\ttest: 1.1287696\tbest: 1.1284916 (3094)\ttotal: 12.7s\tremaining: 48.7s\n",
      "3200:\tlearn: 0.6517673\ttest: 1.1282059\tbest: 1.1273087 (3158)\ttotal: 13.1s\tremaining: 48.3s\n",
      "3300:\tlearn: 0.6309401\ttest: 1.1261964\tbest: 1.1259106 (3299)\ttotal: 13.5s\tremaining: 47.9s\n",
      "3400:\tlearn: 0.6118631\ttest: 1.1260614\tbest: 1.1249316 (3361)\ttotal: 13.9s\tremaining: 47.5s\n",
      "3500:\tlearn: 0.5949346\ttest: 1.1249562\tbest: 1.1238050 (3477)\ttotal: 14.3s\tremaining: 47.1s\n",
      "3600:\tlearn: 0.5745489\ttest: 1.1219819\tbest: 1.1219819 (3600)\ttotal: 14.8s\tremaining: 46.7s\n",
      "3700:\tlearn: 0.5586874\ttest: 1.1201354\tbest: 1.1192885 (3683)\ttotal: 15.2s\tremaining: 46.3s\n",
      "3800:\tlearn: 0.5422156\ttest: 1.1147906\tbest: 1.1145409 (3797)\ttotal: 15.6s\tremaining: 45.9s\n",
      "3900:\tlearn: 0.5248542\ttest: 1.1111205\tbest: 1.1107971 (3886)\ttotal: 16s\tremaining: 45.5s\n",
      "4000:\tlearn: 0.5072160\ttest: 1.1098866\tbest: 1.1098866 (4000)\ttotal: 16.4s\tremaining: 45.1s\n",
      "4100:\tlearn: 0.4922312\ttest: 1.1096413\tbest: 1.1077964 (4055)\ttotal: 16.8s\tremaining: 44.7s\n",
      "4200:\tlearn: 0.4765805\ttest: 1.1100719\tbest: 1.1077964 (4055)\ttotal: 17.2s\tremaining: 44.3s\n",
      "4300:\tlearn: 0.4598674\ttest: 1.1108956\tbest: 1.1077964 (4055)\ttotal: 17.7s\tremaining: 43.9s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.107796362\n",
      "bestIteration = 4055\n",
      "\n",
      "Shrink model to first 4056 iterations.\n",
      "Скор для фолда(2) : 9.0 средний скор на префиксе = 9.0 это заняло = 18 сек.\n",
      "Фолд: 3\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.6256010\ttest: 3.6210548\tbest: 3.6210548 (0)\ttotal: 52.6ms\tremaining: 13m 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 2.2820651\ttest: 2.4190933\tbest: 2.4190933 (100)\ttotal: 436ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8682024\ttest: 2.0010787\tbest: 2.0010787 (200)\ttotal: 847ms\tremaining: 1m 2s\n",
      "300:\tlearn: 1.6795690\ttest: 1.8104984\tbest: 1.8104984 (300)\ttotal: 1.26s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5644668\ttest: 1.6962294\tbest: 1.6962294 (400)\ttotal: 1.67s\tremaining: 1m\n",
      "500:\tlearn: 1.4845197\ttest: 1.6160277\tbest: 1.6159948 (499)\ttotal: 2.08s\tremaining: 1m\n",
      "600:\tlearn: 1.4229979\ttest: 1.5714169\tbest: 1.5714169 (600)\ttotal: 2.48s\tremaining: 59.5s\n",
      "700:\tlearn: 1.3737605\ttest: 1.5423659\tbest: 1.5423659 (700)\ttotal: 2.9s\tremaining: 59.1s\n",
      "800:\tlearn: 1.3307976\ttest: 1.5254365\tbest: 1.5248348 (794)\ttotal: 3.3s\tremaining: 58.5s\n",
      "900:\tlearn: 1.2901456\ttest: 1.5068471\tbest: 1.5065648 (898)\ttotal: 3.71s\tremaining: 58s\n",
      "1000:\tlearn: 1.2527881\ttest: 1.5056993\tbest: 1.5042068 (947)\ttotal: 4.11s\tremaining: 57.5s\n",
      "1100:\tlearn: 1.2131286\ttest: 1.4913624\tbest: 1.4913624 (1100)\ttotal: 4.51s\tremaining: 56.9s\n",
      "1200:\tlearn: 1.1735173\ttest: 1.4931714\tbest: 1.4860586 (1116)\ttotal: 4.92s\tremaining: 56.5s\n",
      "1300:\tlearn: 1.1410203\ttest: 1.4875512\tbest: 1.4860586 (1116)\ttotal: 5.32s\tremaining: 56s\n",
      "1400:\tlearn: 1.1094435\ttest: 1.4863730\tbest: 1.4860554 (1306)\ttotal: 5.73s\tremaining: 55.6s\n",
      "1500:\tlearn: 1.0771746\ttest: 1.4834846\tbest: 1.4831706 (1499)\ttotal: 6.13s\tremaining: 55.2s\n",
      "1600:\tlearn: 1.0481962\ttest: 1.4794444\tbest: 1.4790347 (1599)\ttotal: 6.54s\tremaining: 54.7s\n",
      "1700:\tlearn: 1.0162492\ttest: 1.4679968\tbest: 1.4679968 (1700)\ttotal: 6.94s\tremaining: 54.3s\n",
      "1800:\tlearn: 0.9851528\ttest: 1.4567004\tbest: 1.4564473 (1794)\ttotal: 7.35s\tremaining: 53.9s\n",
      "1900:\tlearn: 0.9571149\ttest: 1.4421861\tbest: 1.4419394 (1899)\ttotal: 7.76s\tremaining: 53.5s\n",
      "2000:\tlearn: 0.9275775\ttest: 1.4238633\tbest: 1.4238633 (2000)\ttotal: 8.17s\tremaining: 53.1s\n",
      "2100:\tlearn: 0.9013394\ttest: 1.4138603\tbest: 1.4133877 (2086)\ttotal: 8.58s\tremaining: 52.7s\n",
      "2200:\tlearn: 0.8741811\ttest: 1.4056640\tbest: 1.4052632 (2193)\ttotal: 8.98s\tremaining: 52.2s\n",
      "2300:\tlearn: 0.8475853\ttest: 1.3930048\tbest: 1.3922778 (2293)\ttotal: 9.39s\tremaining: 51.8s\n",
      "2400:\tlearn: 0.8230541\ttest: 1.3830903\tbest: 1.3830903 (2400)\ttotal: 9.8s\tremaining: 51.4s\n",
      "2500:\tlearn: 0.7984171\ttest: 1.3763263\tbest: 1.3763263 (2500)\ttotal: 10.2s\tremaining: 51.1s\n",
      "2600:\tlearn: 0.7767170\ttest: 1.3639865\tbest: 1.3638019 (2598)\ttotal: 10.6s\tremaining: 50.7s\n",
      "2700:\tlearn: 0.7544223\ttest: 1.3502855\tbest: 1.3502855 (2700)\ttotal: 11s\tremaining: 50.2s\n",
      "2800:\tlearn: 0.7315148\ttest: 1.3381252\tbest: 1.3381252 (2800)\ttotal: 11.4s\tremaining: 49.8s\n",
      "2900:\tlearn: 0.7093763\ttest: 1.3305248\tbest: 1.3304450 (2898)\ttotal: 11.9s\tremaining: 49.5s\n",
      "3000:\tlearn: 0.6874583\ttest: 1.3226931\tbest: 1.3226931 (3000)\ttotal: 12.3s\tremaining: 49.1s\n",
      "3100:\tlearn: 0.6638119\ttest: 1.3137366\tbest: 1.3130446 (3090)\ttotal: 12.7s\tremaining: 48.7s\n",
      "3200:\tlearn: 0.6413153\ttest: 1.3030292\tbest: 1.3029989 (3199)\ttotal: 13.1s\tremaining: 48.3s\n",
      "3300:\tlearn: 0.6229627\ttest: 1.2943495\tbest: 1.2933400 (3291)\ttotal: 13.5s\tremaining: 47.9s\n",
      "3400:\tlearn: 0.6008113\ttest: 1.2817986\tbest: 1.2817986 (3400)\ttotal: 13.9s\tremaining: 47.5s\n",
      "3500:\tlearn: 0.5818708\ttest: 1.2733582\tbest: 1.2733582 (3500)\ttotal: 14.3s\tremaining: 47.1s\n",
      "3600:\tlearn: 0.5626206\ttest: 1.2704203\tbest: 1.2693014 (3564)\ttotal: 14.7s\tremaining: 46.7s\n",
      "3700:\tlearn: 0.5437616\ttest: 1.2670396\tbest: 1.2670396 (3700)\ttotal: 15.2s\tremaining: 46.3s\n",
      "3800:\tlearn: 0.5244933\ttest: 1.2575609\tbest: 1.2575609 (3800)\ttotal: 15.6s\tremaining: 45.9s\n",
      "3900:\tlearn: 0.5066812\ttest: 1.2503717\tbest: 1.2503717 (3900)\ttotal: 16s\tremaining: 45.5s\n",
      "4000:\tlearn: 0.4900434\ttest: 1.2415452\tbest: 1.2415452 (4000)\ttotal: 16.4s\tremaining: 45.1s\n",
      "4100:\tlearn: 0.4741202\ttest: 1.2364912\tbest: 1.2364912 (4100)\ttotal: 16.8s\tremaining: 44.7s\n",
      "4200:\tlearn: 0.4598172\ttest: 1.2321945\tbest: 1.2321945 (4200)\ttotal: 17.2s\tremaining: 44.3s\n",
      "4300:\tlearn: 0.4451569\ttest: 1.2300321\tbest: 1.2299570 (4286)\ttotal: 17.6s\tremaining: 43.9s\n",
      "4400:\tlearn: 0.4299250\ttest: 1.2210691\tbest: 1.2210691 (4400)\ttotal: 18.1s\tremaining: 43.5s\n",
      "4500:\tlearn: 0.4163334\ttest: 1.2158791\tbest: 1.2155430 (4472)\ttotal: 18.5s\tremaining: 43.1s\n",
      "4600:\tlearn: 0.4039130\ttest: 1.2119471\tbest: 1.2119431 (4599)\ttotal: 18.9s\tremaining: 42.7s\n",
      "4700:\tlearn: 0.3888501\ttest: 1.2075658\tbest: 1.2075658 (4700)\ttotal: 19.3s\tremaining: 42.3s\n",
      "4800:\tlearn: 0.3758985\ttest: 1.2047108\tbest: 1.2046205 (4764)\ttotal: 19.7s\tremaining: 41.9s\n",
      "4900:\tlearn: 0.3644548\ttest: 1.1981860\tbest: 1.1981860 (4900)\ttotal: 20.1s\tremaining: 41.5s\n",
      "5000:\tlearn: 0.3530106\ttest: 1.1936537\tbest: 1.1936501 (4986)\ttotal: 20.5s\tremaining: 41.1s\n",
      "5100:\tlearn: 0.3420799\ttest: 1.1891165\tbest: 1.1886057 (5088)\ttotal: 20.9s\tremaining: 40.6s\n",
      "5200:\tlearn: 0.3323627\ttest: 1.1868344\tbest: 1.1862798 (5188)\ttotal: 21.4s\tremaining: 40.2s\n",
      "5300:\tlearn: 0.3223162\ttest: 1.1829017\tbest: 1.1829017 (5300)\ttotal: 21.8s\tremaining: 39.8s\n",
      "5400:\tlearn: 0.3126697\ttest: 1.1795160\tbest: 1.1794500 (5398)\ttotal: 22.2s\tremaining: 39.4s\n",
      "5500:\tlearn: 0.3023370\ttest: 1.1765732\tbest: 1.1765318 (5499)\ttotal: 22.6s\tremaining: 39s\n",
      "5600:\tlearn: 0.2929539\ttest: 1.1735572\tbest: 1.1735572 (5600)\ttotal: 23s\tremaining: 38.6s\n",
      "5700:\tlearn: 0.2838234\ttest: 1.1674332\tbest: 1.1674332 (5700)\ttotal: 23.4s\tremaining: 38.2s\n",
      "5800:\tlearn: 0.2747138\ttest: 1.1619618\tbest: 1.1619408 (5798)\ttotal: 23.8s\tremaining: 37.8s\n",
      "5900:\tlearn: 0.2662408\ttest: 1.1569777\tbest: 1.1568038 (5895)\ttotal: 24.3s\tremaining: 37.4s\n",
      "6000:\tlearn: 0.2579669\ttest: 1.1530397\tbest: 1.1528502 (5998)\ttotal: 24.7s\tremaining: 37s\n",
      "6100:\tlearn: 0.2503715\ttest: 1.1481201\tbest: 1.1478250 (6092)\ttotal: 25.1s\tremaining: 36.6s\n",
      "6200:\tlearn: 0.2433716\ttest: 1.1430218\tbest: 1.1430218 (6200)\ttotal: 25.5s\tremaining: 36.2s\n",
      "6300:\tlearn: 0.2364098\ttest: 1.1384360\tbest: 1.1384360 (6300)\ttotal: 25.9s\tremaining: 35.8s\n",
      "6400:\tlearn: 0.2288355\ttest: 1.1336202\tbest: 1.1336198 (6399)\ttotal: 26.3s\tremaining: 35.4s\n",
      "6500:\tlearn: 0.2216516\ttest: 1.1290664\tbest: 1.1289840 (6496)\ttotal: 26.8s\tremaining: 35s\n",
      "6600:\tlearn: 0.2151348\ttest: 1.1258866\tbest: 1.1257170 (6582)\ttotal: 27.2s\tremaining: 34.6s\n",
      "6700:\tlearn: 0.2091180\ttest: 1.1240047\tbest: 1.1231397 (6695)\ttotal: 27.6s\tremaining: 34.2s\n",
      "6800:\tlearn: 0.2029581\ttest: 1.1206350\tbest: 1.1206275 (6797)\ttotal: 28s\tremaining: 33.8s\n",
      "6900:\tlearn: 0.1979657\ttest: 1.1191375\tbest: 1.1189847 (6896)\ttotal: 28.4s\tremaining: 33.4s\n",
      "7000:\tlearn: 0.1929896\ttest: 1.1158938\tbest: 1.1158938 (7000)\ttotal: 28.8s\tremaining: 33s\n",
      "7100:\tlearn: 0.1867911\ttest: 1.1167815\tbest: 1.1157982 (7004)\ttotal: 29.3s\tremaining: 32.5s\n",
      "7200:\tlearn: 0.1813676\ttest: 1.1109675\tbest: 1.1108134 (7196)\ttotal: 29.7s\tremaining: 32.1s\n",
      "7300:\tlearn: 0.1763068\ttest: 1.1081504\tbest: 1.1075512 (7283)\ttotal: 30.1s\tremaining: 31.7s\n",
      "7400:\tlearn: 0.1712329\ttest: 1.1047112\tbest: 1.1046129 (7380)\ttotal: 30.5s\tremaining: 31.3s\n",
      "7500:\tlearn: 0.1660103\ttest: 1.1024368\tbest: 1.1024102 (7489)\ttotal: 30.9s\tremaining: 30.9s\n",
      "7600:\tlearn: 0.1608449\ttest: 1.1012391\tbest: 1.1012188 (7598)\ttotal: 31.3s\tremaining: 30.5s\n",
      "7700:\tlearn: 0.1563532\ttest: 1.0993503\tbest: 1.0993074 (7698)\ttotal: 31.8s\tremaining: 30.1s\n",
      "7800:\tlearn: 0.1513463\ttest: 1.0962173\tbest: 1.0962003 (7799)\ttotal: 32.2s\tremaining: 29.7s\n",
      "7900:\tlearn: 0.1470536\ttest: 1.0940376\tbest: 1.0938524 (7891)\ttotal: 32.6s\tremaining: 29.3s\n",
      "8000:\tlearn: 0.1430905\ttest: 1.0921278\tbest: 1.0919628 (7996)\ttotal: 33s\tremaining: 28.9s\n",
      "8100:\tlearn: 0.1388930\ttest: 1.0928395\tbest: 1.0919255 (8041)\ttotal: 33.4s\tremaining: 28.5s\n",
      "8200:\tlearn: 0.1348558\ttest: 1.0895196\tbest: 1.0895196 (8200)\ttotal: 33.8s\tremaining: 28.1s\n",
      "8300:\tlearn: 0.1305639\ttest: 1.0862672\tbest: 1.0858463 (8295)\ttotal: 34.3s\tremaining: 27.6s\n",
      "8400:\tlearn: 0.1269645\ttest: 1.0836980\tbest: 1.0835999 (8387)\ttotal: 34.7s\tremaining: 27.2s\n",
      "8500:\tlearn: 0.1228680\ttest: 1.0829438\tbest: 1.0828039 (8483)\ttotal: 35.1s\tremaining: 26.8s\n",
      "8600:\tlearn: 0.1193633\ttest: 1.0838285\tbest: 1.0819402 (8512)\ttotal: 35.5s\tremaining: 26.4s\n",
      "8700:\tlearn: 0.1158209\ttest: 1.0842978\tbest: 1.0819402 (8512)\ttotal: 35.9s\tremaining: 26s\n",
      "8800:\tlearn: 0.1124906\ttest: 1.0833398\tbest: 1.0819402 (8512)\ttotal: 36.3s\tremaining: 25.6s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.081940162\n",
      "bestIteration = 8512\n",
      "\n",
      "Shrink model to first 8513 iterations.\n",
      "Скор для фолда(3) : 9.0 средний скор на префиксе = 9.0 это заняло = 36 сек.\n",
      "Фолд: 4\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.6063420\ttest: 3.7375832\tbest: 3.7375832 (0)\ttotal: 53.4ms\tremaining: 13m 20s\n",
      "100:\tlearn: 2.2591604\ttest: 2.4757102\tbest: 2.4757102 (100)\ttotal: 435ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8355695\ttest: 2.1116617\tbest: 2.1116617 (200)\ttotal: 848ms\tremaining: 1m 2s\n",
      "300:\tlearn: 1.6484432\ttest: 1.9217747\tbest: 1.9217747 (300)\ttotal: 1.27s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5376102\ttest: 1.7864071\tbest: 1.7864071 (400)\ttotal: 1.68s\tremaining: 1m 1s\n",
      "500:\tlearn: 1.4616987\ttest: 1.6990474\tbest: 1.6990025 (499)\ttotal: 2.09s\tremaining: 1m\n",
      "600:\tlearn: 1.4070561\ttest: 1.6343958\tbest: 1.6343958 (600)\ttotal: 2.5s\tremaining: 59.8s\n",
      "700:\tlearn: 1.3546584\ttest: 1.6006275\tbest: 1.6006275 (700)\ttotal: 2.9s\tremaining: 59.2s\n",
      "800:\tlearn: 1.3109032\ttest: 1.5792414\tbest: 1.5792414 (800)\ttotal: 3.3s\tremaining: 58.6s\n",
      "900:\tlearn: 1.2707011\ttest: 1.5447523\tbest: 1.5439265 (898)\ttotal: 3.72s\tremaining: 58.2s\n",
      "1000:\tlearn: 1.2346458\ttest: 1.5163497\tbest: 1.5160291 (993)\ttotal: 4.12s\tremaining: 57.6s\n",
      "1100:\tlearn: 1.1986600\ttest: 1.4907849\tbest: 1.4907849 (1100)\ttotal: 4.52s\tremaining: 57.1s\n",
      "1200:\tlearn: 1.1637120\ttest: 1.4772575\tbest: 1.4770564 (1197)\ttotal: 4.93s\tremaining: 56.6s\n",
      "1300:\tlearn: 1.1292111\ttest: 1.4672408\tbest: 1.4667886 (1281)\ttotal: 5.34s\tremaining: 56.2s\n",
      "1400:\tlearn: 1.0947654\ttest: 1.4532613\tbest: 1.4532613 (1400)\ttotal: 5.75s\tremaining: 55.8s\n",
      "1500:\tlearn: 1.0638468\ttest: 1.4414773\tbest: 1.4397309 (1494)\ttotal: 6.15s\tremaining: 55.3s\n",
      "1600:\tlearn: 1.0311975\ttest: 1.4242624\tbest: 1.4242624 (1600)\ttotal: 6.56s\tremaining: 54.9s\n",
      "1700:\tlearn: 1.0011124\ttest: 1.4089302\tbest: 1.4089022 (1699)\ttotal: 6.96s\tremaining: 54.4s\n",
      "1800:\tlearn: 0.9676771\ttest: 1.3937280\tbest: 1.3934926 (1799)\ttotal: 7.37s\tremaining: 54s\n",
      "1900:\tlearn: 0.9391352\ttest: 1.3855340\tbest: 1.3852018 (1892)\ttotal: 7.78s\tremaining: 53.6s\n",
      "2000:\tlearn: 0.9130242\ttest: 1.3731549\tbest: 1.3731549 (2000)\ttotal: 8.18s\tremaining: 53.2s\n",
      "2100:\tlearn: 0.8872284\ttest: 1.3625375\tbest: 1.3624992 (2099)\ttotal: 8.59s\tremaining: 52.7s\n",
      "2200:\tlearn: 0.8622828\ttest: 1.3587157\tbest: 1.3586740 (2192)\ttotal: 9s\tremaining: 52.3s\n",
      "2300:\tlearn: 0.8342103\ttest: 1.3544772\tbest: 1.3544486 (2297)\ttotal: 9.41s\tremaining: 51.9s\n",
      "2400:\tlearn: 0.8101302\ttest: 1.3466040\tbest: 1.3446106 (2373)\ttotal: 9.82s\tremaining: 51.5s\n",
      "2500:\tlearn: 0.7846752\ttest: 1.3390838\tbest: 1.3379627 (2497)\ttotal: 10.2s\tremaining: 51.1s\n",
      "2600:\tlearn: 0.7624601\ttest: 1.3356488\tbest: 1.3349278 (2586)\ttotal: 10.6s\tremaining: 50.7s\n",
      "2700:\tlearn: 0.7367940\ttest: 1.3301933\tbest: 1.3301933 (2700)\ttotal: 11.1s\tremaining: 50.3s\n",
      "2800:\tlearn: 0.7157129\ttest: 1.3258194\tbest: 1.3255676 (2793)\ttotal: 11.5s\tremaining: 49.9s\n",
      "2900:\tlearn: 0.6941666\ttest: 1.3201322\tbest: 1.3201322 (2900)\ttotal: 11.9s\tremaining: 49.5s\n",
      "3000:\tlearn: 0.6716333\ttest: 1.3133241\tbest: 1.3133241 (3000)\ttotal: 12.3s\tremaining: 49.1s\n",
      "3100:\tlearn: 0.6511186\ttest: 1.3102139\tbest: 1.3090816 (3079)\ttotal: 12.7s\tremaining: 48.7s\n",
      "3200:\tlearn: 0.6318964\ttest: 1.3018507\tbest: 1.3016951 (3190)\ttotal: 13.1s\tremaining: 48.3s\n",
      "3300:\tlearn: 0.6127948\ttest: 1.2956155\tbest: 1.2953216 (3296)\ttotal: 13.5s\tremaining: 47.9s\n",
      "3400:\tlearn: 0.5936226\ttest: 1.2880902\tbest: 1.2880902 (3400)\ttotal: 13.9s\tremaining: 47.5s\n",
      "3500:\tlearn: 0.5752643\ttest: 1.2838715\tbest: 1.2837388 (3497)\ttotal: 14.3s\tremaining: 47.1s\n",
      "3600:\tlearn: 0.5571079\ttest: 1.2809725\tbest: 1.2809725 (3600)\ttotal: 14.8s\tremaining: 46.7s\n",
      "3700:\tlearn: 0.5401323\ttest: 1.2773806\tbest: 1.2756262 (3690)\ttotal: 15.2s\tremaining: 46.3s\n",
      "3800:\tlearn: 0.5238986\ttest: 1.2755602\tbest: 1.2745334 (3735)\ttotal: 15.6s\tremaining: 45.9s\n",
      "3900:\tlearn: 0.5085973\ttest: 1.2757356\tbest: 1.2739334 (3867)\ttotal: 16s\tremaining: 45.5s\n",
      "4000:\tlearn: 0.4941422\ttest: 1.2724449\tbest: 1.2709537 (3947)\ttotal: 16.4s\tremaining: 45.1s\n",
      "4100:\tlearn: 0.4787048\ttest: 1.2715418\tbest: 1.2709537 (3947)\ttotal: 16.8s\tremaining: 44.7s\n",
      "4200:\tlearn: 0.4641534\ttest: 1.2669287\tbest: 1.2666801 (4195)\ttotal: 17.2s\tremaining: 44.3s\n",
      "4300:\tlearn: 0.4493815\ttest: 1.2690033\tbest: 1.2655307 (4219)\ttotal: 17.6s\tremaining: 43.9s\n",
      "4400:\tlearn: 0.4351906\ttest: 1.2692300\tbest: 1.2655307 (4219)\ttotal: 18.1s\tremaining: 43.5s\n",
      "4500:\tlearn: 0.4218617\ttest: 1.2703092\tbest: 1.2655307 (4219)\ttotal: 18.5s\tremaining: 43.1s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.26553074\n",
      "bestIteration = 4219\n",
      "\n",
      "Shrink model to first 4220 iterations.\n",
      "Скор для фолда(4) : 9.0 средний скор на префиксе = 9.0 это заняло = 18 сек.\n",
      "Фолд: 5\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.5858702\ttest: 3.5956380\tbest: 3.5956380 (0)\ttotal: 53.9ms\tremaining: 13m 28s\n",
      "100:\tlearn: 2.2505649\ttest: 2.5385997\tbest: 2.5385997 (100)\ttotal: 436ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8263268\ttest: 2.2001189\tbest: 2.2001189 (200)\ttotal: 846ms\tremaining: 1m 2s\n",
      "300:\tlearn: 1.6426821\ttest: 2.0674813\tbest: 2.0674813 (300)\ttotal: 1.29s\tremaining: 1m 2s\n",
      "400:\tlearn: 1.5266160\ttest: 1.9990530\tbest: 1.9990530 (400)\ttotal: 1.73s\tremaining: 1m 3s\n",
      "500:\tlearn: 1.4455735\ttest: 1.9527475\tbest: 1.9527475 (500)\ttotal: 2.16s\tremaining: 1m 2s\n",
      "600:\tlearn: 1.3820168\ttest: 1.9193397\tbest: 1.9191524 (599)\ttotal: 2.61s\tremaining: 1m 2s\n",
      "700:\tlearn: 1.3306568\ttest: 1.8953612\tbest: 1.8950210 (699)\ttotal: 3.04s\tremaining: 1m 2s\n",
      "800:\tlearn: 1.2890930\ttest: 1.8769644\tbest: 1.8769644 (800)\ttotal: 3.45s\tremaining: 1m 1s\n",
      "900:\tlearn: 1.2458338\ttest: 1.8538230\tbest: 1.8538230 (900)\ttotal: 3.85s\tremaining: 1m\n",
      "1000:\tlearn: 1.2085066\ttest: 1.8421369\tbest: 1.8421369 (1000)\ttotal: 4.25s\tremaining: 59.5s\n",
      "1100:\tlearn: 1.1749312\ttest: 1.8331399\tbest: 1.8329814 (1096)\ttotal: 4.67s\tremaining: 58.9s\n",
      "1200:\tlearn: 1.1407524\ttest: 1.8204250\tbest: 1.8204250 (1200)\ttotal: 5.07s\tremaining: 58.3s\n",
      "1300:\tlearn: 1.1078276\ttest: 1.8085462\tbest: 1.8085293 (1299)\ttotal: 5.48s\tremaining: 57.7s\n",
      "1400:\tlearn: 1.0779676\ttest: 1.8065205\tbest: 1.8056376 (1381)\ttotal: 5.88s\tremaining: 57.1s\n",
      "1500:\tlearn: 1.0471441\ttest: 1.7982337\tbest: 1.7982337 (1500)\ttotal: 6.3s\tremaining: 56.6s\n",
      "1600:\tlearn: 1.0161849\ttest: 1.7896607\tbest: 1.7893277 (1599)\ttotal: 6.71s\tremaining: 56.1s\n",
      "1700:\tlearn: 0.9846328\ttest: 1.7847943\tbest: 1.7847591 (1699)\ttotal: 7.12s\tremaining: 55.6s\n",
      "1800:\tlearn: 0.9556449\ttest: 1.7788676\tbest: 1.7788676 (1800)\ttotal: 7.52s\tremaining: 55.1s\n",
      "1900:\tlearn: 0.9272019\ttest: 1.7748595\tbest: 1.7746920 (1861)\ttotal: 7.93s\tremaining: 54.7s\n",
      "2000:\tlearn: 0.8997655\ttest: 1.7701001\tbest: 1.7701001 (2000)\ttotal: 8.34s\tremaining: 54.2s\n",
      "2100:\tlearn: 0.8750170\ttest: 1.7646043\tbest: 1.7644333 (2098)\ttotal: 8.75s\tremaining: 53.7s\n",
      "2200:\tlearn: 0.8498542\ttest: 1.7512088\tbest: 1.7512088 (2200)\ttotal: 9.16s\tremaining: 53.3s\n",
      "2300:\tlearn: 0.8240386\ttest: 1.7407727\tbest: 1.7407727 (2300)\ttotal: 9.57s\tremaining: 52.8s\n",
      "2400:\tlearn: 0.8018734\ttest: 1.7344714\tbest: 1.7341989 (2394)\ttotal: 9.98s\tremaining: 52.4s\n",
      "2500:\tlearn: 0.7762887\ttest: 1.7277773\tbest: 1.7277773 (2500)\ttotal: 10.4s\tremaining: 51.9s\n",
      "2600:\tlearn: 0.7560269\ttest: 1.7190804\tbest: 1.7186420 (2592)\ttotal: 10.8s\tremaining: 51.4s\n",
      "2700:\tlearn: 0.7332993\ttest: 1.7104016\tbest: 1.7097075 (2691)\ttotal: 11.2s\tremaining: 51s\n",
      "2800:\tlearn: 0.7084093\ttest: 1.7015972\tbest: 1.7014543 (2791)\ttotal: 11.6s\tremaining: 50.6s\n",
      "2900:\tlearn: 0.6891523\ttest: 1.6965807\tbest: 1.6965807 (2900)\ttotal: 12s\tremaining: 50.1s\n",
      "3000:\tlearn: 0.6701765\ttest: 1.6935685\tbest: 1.6934992 (2999)\ttotal: 12.4s\tremaining: 49.7s\n",
      "3100:\tlearn: 0.6503128\ttest: 1.6895094\tbest: 1.6887902 (3083)\ttotal: 12.8s\tremaining: 49.3s\n",
      "3200:\tlearn: 0.6299137\ttest: 1.6837452\tbest: 1.6830553 (3197)\ttotal: 13.3s\tremaining: 48.9s\n",
      "3300:\tlearn: 0.6117499\ttest: 1.6806005\tbest: 1.6805410 (3298)\ttotal: 13.7s\tremaining: 48.4s\n",
      "3400:\tlearn: 0.5934833\ttest: 1.6782962\tbest: 1.6776912 (3394)\ttotal: 14.1s\tremaining: 48s\n",
      "3500:\tlearn: 0.5764216\ttest: 1.6708836\tbest: 1.6704410 (3498)\ttotal: 14.5s\tremaining: 47.6s\n",
      "3600:\tlearn: 0.5595609\ttest: 1.6644754\tbest: 1.6640691 (3596)\ttotal: 14.9s\tremaining: 47.2s\n",
      "3700:\tlearn: 0.5426571\ttest: 1.6669454\tbest: 1.6640591 (3612)\ttotal: 15.3s\tremaining: 46.8s\n",
      "3800:\tlearn: 0.5256666\ttest: 1.6632671\tbest: 1.6628855 (3795)\ttotal: 15.7s\tremaining: 46.4s\n",
      "3900:\tlearn: 0.5087327\ttest: 1.6593295\tbest: 1.6585600 (3890)\ttotal: 16.2s\tremaining: 46s\n",
      "4000:\tlearn: 0.4928083\ttest: 1.6578992\tbest: 1.6575285 (3951)\ttotal: 16.6s\tremaining: 45.5s\n",
      "4100:\tlearn: 0.4771287\ttest: 1.6542134\tbest: 1.6541722 (4099)\ttotal: 17s\tremaining: 45.1s\n",
      "4200:\tlearn: 0.4619018\ttest: 1.6532504\tbest: 1.6525379 (4175)\ttotal: 17.4s\tremaining: 44.7s\n",
      "4300:\tlearn: 0.4484090\ttest: 1.6521866\tbest: 1.6519575 (4297)\ttotal: 17.8s\tremaining: 44.3s\n",
      "4400:\tlearn: 0.4358802\ttest: 1.6500750\tbest: 1.6500309 (4399)\ttotal: 18.2s\tremaining: 43.9s\n",
      "4500:\tlearn: 0.4217085\ttest: 1.6481674\tbest: 1.6481377 (4498)\ttotal: 18.6s\tremaining: 43.4s\n",
      "4600:\tlearn: 0.4093407\ttest: 1.6463334\tbest: 1.6454730 (4559)\ttotal: 19s\tremaining: 43s\n",
      "4700:\tlearn: 0.3965748\ttest: 1.6428669\tbest: 1.6428669 (4700)\ttotal: 19.5s\tremaining: 42.6s\n",
      "4800:\tlearn: 0.3839553\ttest: 1.6401055\tbest: 1.6397384 (4796)\ttotal: 19.9s\tremaining: 42.2s\n",
      "4900:\tlearn: 0.3735041\ttest: 1.6353885\tbest: 1.6350977 (4898)\ttotal: 20.3s\tremaining: 41.8s\n",
      "5000:\tlearn: 0.3612071\ttest: 1.6338088\tbest: 1.6335090 (4997)\ttotal: 20.7s\tremaining: 41.4s\n",
      "5100:\tlearn: 0.3489385\ttest: 1.6302800\tbest: 1.6302800 (5100)\ttotal: 21.1s\tremaining: 41s\n",
      "5200:\tlearn: 0.3377133\ttest: 1.6269457\tbest: 1.6266085 (5162)\ttotal: 21.5s\tremaining: 40.5s\n",
      "5300:\tlearn: 0.3273967\ttest: 1.6287444\tbest: 1.6266085 (5162)\ttotal: 21.9s\tremaining: 40.1s\n",
      "5400:\tlearn: 0.3181959\ttest: 1.6275003\tbest: 1.6266085 (5162)\ttotal: 22.4s\tremaining: 39.7s\n",
      "5500:\tlearn: 0.3087357\ttest: 1.6245303\tbest: 1.6244449 (5498)\ttotal: 22.8s\tremaining: 39.3s\n",
      "5600:\tlearn: 0.2993768\ttest: 1.6224385\tbest: 1.6224385 (5600)\ttotal: 23.2s\tremaining: 38.9s\n",
      "5700:\tlearn: 0.2905645\ttest: 1.6211278\tbest: 1.6207146 (5637)\ttotal: 23.6s\tremaining: 38.5s\n",
      "5800:\tlearn: 0.2820103\ttest: 1.6206002\tbest: 1.6197460 (5747)\ttotal: 24s\tremaining: 38.1s\n",
      "5900:\tlearn: 0.2732672\ttest: 1.6195450\tbest: 1.6194260 (5887)\ttotal: 24.4s\tremaining: 37.7s\n",
      "6000:\tlearn: 0.2649604\ttest: 1.6162849\tbest: 1.6160738 (5991)\ttotal: 24.8s\tremaining: 37.2s\n",
      "6100:\tlearn: 0.2567620\ttest: 1.6147410\tbest: 1.6144280 (6095)\ttotal: 25.3s\tremaining: 36.8s\n",
      "6200:\tlearn: 0.2489385\ttest: 1.6115156\tbest: 1.6113895 (6197)\ttotal: 25.7s\tremaining: 36.4s\n",
      "6300:\tlearn: 0.2410217\ttest: 1.6089139\tbest: 1.6088924 (6298)\ttotal: 26.1s\tremaining: 36s\n",
      "6400:\tlearn: 0.2345518\ttest: 1.6073318\tbest: 1.6072919 (6399)\ttotal: 26.5s\tremaining: 35.6s\n",
      "6500:\tlearn: 0.2279267\ttest: 1.6068999\tbest: 1.6061065 (6451)\ttotal: 26.9s\tremaining: 35.2s\n",
      "6600:\tlearn: 0.2214261\ttest: 1.6062678\tbest: 1.6061065 (6451)\ttotal: 27.3s\tremaining: 34.8s\n",
      "6700:\tlearn: 0.2151070\ttest: 1.6057998\tbest: 1.6044693 (6647)\ttotal: 27.7s\tremaining: 34.3s\n",
      "6800:\tlearn: 0.2093926\ttest: 1.6045660\tbest: 1.6044693 (6647)\ttotal: 28.1s\tremaining: 33.9s\n",
      "6900:\tlearn: 0.2036874\ttest: 1.6030606\tbest: 1.6028325 (6892)\ttotal: 28.6s\tremaining: 33.5s\n",
      "7000:\tlearn: 0.1973529\ttest: 1.6027903\tbest: 1.6017695 (6979)\ttotal: 29s\tremaining: 33.1s\n",
      "7100:\tlearn: 0.1912800\ttest: 1.6012199\tbest: 1.6012199 (7100)\ttotal: 29.4s\tremaining: 32.7s\n",
      "7200:\tlearn: 0.1860331\ttest: 1.6015352\tbest: 1.6011145 (7101)\ttotal: 29.8s\tremaining: 32.3s\n",
      "7300:\tlearn: 0.1811064\ttest: 1.5987692\tbest: 1.5987692 (7300)\ttotal: 30.2s\tremaining: 31.9s\n",
      "7400:\tlearn: 0.1754677\ttest: 1.5984084\tbest: 1.5976547 (7340)\ttotal: 30.6s\tremaining: 31.5s\n",
      "7500:\tlearn: 0.1706854\ttest: 1.5999181\tbest: 1.5976547 (7340)\ttotal: 31.1s\tremaining: 31s\n",
      "7600:\tlearn: 0.1647621\ttest: 1.5965688\tbest: 1.5957120 (7588)\ttotal: 31.5s\tremaining: 30.6s\n",
      "7700:\tlearn: 0.1601492\ttest: 1.5963822\tbest: 1.5957120 (7588)\ttotal: 31.9s\tremaining: 30.2s\n",
      "7800:\tlearn: 0.1547665\ttest: 1.5947574\tbest: 1.5947574 (7800)\ttotal: 32.3s\tremaining: 29.8s\n",
      "7900:\tlearn: 0.1501337\ttest: 1.5939844\tbest: 1.5932840 (7870)\ttotal: 32.7s\tremaining: 29.4s\n",
      "8000:\tlearn: 0.1457041\ttest: 1.5937350\tbest: 1.5932840 (7870)\ttotal: 33.1s\tremaining: 29s\n",
      "8100:\tlearn: 0.1414221\ttest: 1.5921309\tbest: 1.5917686 (8080)\ttotal: 33.6s\tremaining: 28.6s\n",
      "8200:\tlearn: 0.1369974\ttest: 1.5914565\tbest: 1.5905273 (8160)\ttotal: 34s\tremaining: 28.2s\n",
      "8300:\tlearn: 0.1327640\ttest: 1.5899672\tbest: 1.5898168 (8291)\ttotal: 34.4s\tremaining: 27.8s\n",
      "8400:\tlearn: 0.1285030\ttest: 1.5884378\tbest: 1.5879009 (8391)\ttotal: 34.8s\tremaining: 27.4s\n",
      "8500:\tlearn: 0.1251281\ttest: 1.5898453\tbest: 1.5878103 (8422)\ttotal: 35.2s\tremaining: 26.9s\n",
      "8600:\tlearn: 0.1215816\ttest: 1.5900818\tbest: 1.5878103 (8422)\ttotal: 35.7s\tremaining: 26.5s\n",
      "8700:\tlearn: 0.1181216\ttest: 1.5894219\tbest: 1.5878103 (8422)\ttotal: 36.1s\tremaining: 26.1s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.587810329\n",
      "bestIteration = 8422\n",
      "\n",
      "Shrink model to first 8423 iterations.\n",
      "Скор для фолда(5) : 9.0 средний скор на префиксе = 9.0 это заняло = 36 сек.\n",
      "Фолд: 6\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.5997946\ttest: 3.7303716\tbest: 3.7303716 (0)\ttotal: 53ms\tremaining: 13m 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 2.2892446\ttest: 2.3234340\tbest: 2.3234340 (100)\ttotal: 435ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8725100\ttest: 1.7365216\tbest: 1.7365216 (200)\ttotal: 846ms\tremaining: 1m 2s\n",
      "300:\tlearn: 1.6784571\ttest: 1.5327579\tbest: 1.5327579 (300)\ttotal: 1.26s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5501856\ttest: 1.4323333\tbest: 1.4323333 (400)\ttotal: 1.67s\tremaining: 1m\n",
      "500:\tlearn: 1.4671639\ttest: 1.3897365\tbest: 1.3897365 (500)\ttotal: 2.08s\tremaining: 1m\n",
      "600:\tlearn: 1.4070228\ttest: 1.3629995\tbest: 1.3629995 (600)\ttotal: 2.49s\tremaining: 59.7s\n",
      "700:\tlearn: 1.3570050\ttest: 1.3277727\tbest: 1.3277727 (700)\ttotal: 2.9s\tremaining: 59.2s\n",
      "800:\tlearn: 1.3140365\ttest: 1.3142976\tbest: 1.3142976 (800)\ttotal: 3.31s\tremaining: 58.6s\n",
      "900:\tlearn: 1.2718682\ttest: 1.2995603\tbest: 1.2977248 (889)\ttotal: 3.72s\tremaining: 58.2s\n",
      "1000:\tlearn: 1.2354415\ttest: 1.2861292\tbest: 1.2860331 (997)\ttotal: 4.12s\tremaining: 57.7s\n",
      "1100:\tlearn: 1.2030544\ttest: 1.2766925\tbest: 1.2766925 (1100)\ttotal: 4.53s\tremaining: 57.2s\n",
      "1200:\tlearn: 1.1677834\ttest: 1.2653706\tbest: 1.2651662 (1199)\ttotal: 4.93s\tremaining: 56.7s\n",
      "1300:\tlearn: 1.1350012\ttest: 1.2575733\tbest: 1.2573577 (1293)\ttotal: 5.34s\tremaining: 56.2s\n",
      "1400:\tlearn: 1.1033194\ttest: 1.2504381\tbest: 1.2504381 (1400)\ttotal: 5.74s\tremaining: 55.8s\n",
      "1500:\tlearn: 1.0719850\ttest: 1.2450276\tbest: 1.2433148 (1496)\ttotal: 6.15s\tremaining: 55.3s\n",
      "1600:\tlearn: 1.0418463\ttest: 1.2411253\tbest: 1.2405898 (1592)\ttotal: 6.56s\tremaining: 54.9s\n",
      "1700:\tlearn: 1.0117747\ttest: 1.2353368\tbest: 1.2345697 (1676)\ttotal: 6.97s\tremaining: 54.5s\n",
      "1800:\tlearn: 0.9808096\ttest: 1.2250000\tbest: 1.2246390 (1799)\ttotal: 7.38s\tremaining: 54.1s\n",
      "1900:\tlearn: 0.9545252\ttest: 1.2249043\tbest: 1.2230418 (1844)\ttotal: 7.79s\tremaining: 53.7s\n",
      "2000:\tlearn: 0.9247562\ttest: 1.2213215\tbest: 1.2213215 (2000)\ttotal: 8.21s\tremaining: 53.3s\n",
      "2100:\tlearn: 0.8967849\ttest: 1.2180657\tbest: 1.2166544 (2097)\ttotal: 8.63s\tremaining: 53s\n",
      "2200:\tlearn: 0.8699298\ttest: 1.2189448\tbest: 1.2165861 (2166)\ttotal: 9.04s\tremaining: 52.6s\n",
      "2300:\tlearn: 0.8428717\ttest: 1.2178104\tbest: 1.2165861 (2166)\ttotal: 9.45s\tremaining: 52.2s\n",
      "2400:\tlearn: 0.8187716\ttest: 1.2145271\tbest: 1.2132103 (2375)\ttotal: 9.87s\tremaining: 51.8s\n",
      "2500:\tlearn: 0.7936637\ttest: 1.2084496\tbest: 1.2073037 (2485)\ttotal: 10.3s\tremaining: 51.4s\n",
      "2600:\tlearn: 0.7701184\ttest: 1.2069814\tbest: 1.2059459 (2547)\ttotal: 10.7s\tremaining: 51s\n",
      "2700:\tlearn: 0.7449437\ttest: 1.2054688\tbest: 1.2054688 (2700)\ttotal: 11.1s\tremaining: 50.6s\n",
      "2800:\tlearn: 0.7229146\ttest: 1.2041354\tbest: 1.2033466 (2798)\ttotal: 11.5s\tremaining: 50.2s\n",
      "2900:\tlearn: 0.6972927\ttest: 1.2024532\tbest: 1.2002255 (2870)\ttotal: 11.9s\tremaining: 49.8s\n",
      "3000:\tlearn: 0.6722183\ttest: 1.1969795\tbest: 1.1968118 (2995)\ttotal: 12.3s\tremaining: 49.3s\n",
      "3100:\tlearn: 0.6509723\ttest: 1.1943130\tbest: 1.1938032 (3044)\ttotal: 12.8s\tremaining: 49s\n",
      "3200:\tlearn: 0.6289482\ttest: 1.1917345\tbest: 1.1908107 (3165)\ttotal: 13.2s\tremaining: 48.6s\n",
      "3300:\tlearn: 0.6075116\ttest: 1.1900102\tbest: 1.1896781 (3296)\ttotal: 13.6s\tremaining: 48.2s\n",
      "3400:\tlearn: 0.5882288\ttest: 1.1888641\tbest: 1.1884507 (3392)\ttotal: 14s\tremaining: 47.8s\n",
      "3500:\tlearn: 0.5698489\ttest: 1.1884756\tbest: 1.1871973 (3446)\ttotal: 14.4s\tremaining: 47.4s\n",
      "3600:\tlearn: 0.5521620\ttest: 1.1891942\tbest: 1.1866605 (3549)\ttotal: 14.8s\tremaining: 47s\n",
      "3700:\tlearn: 0.5342362\ttest: 1.1870416\tbest: 1.1866605 (3549)\ttotal: 15.2s\tremaining: 46.6s\n",
      "3800:\tlearn: 0.5162743\ttest: 1.1817920\tbest: 1.1817468 (3783)\ttotal: 15.7s\tremaining: 46.1s\n",
      "3900:\tlearn: 0.4992684\ttest: 1.1795968\tbest: 1.1793505 (3897)\ttotal: 16.1s\tremaining: 45.7s\n",
      "4000:\tlearn: 0.4847500\ttest: 1.1795211\tbest: 1.1782562 (3927)\ttotal: 16.5s\tremaining: 45.3s\n",
      "4100:\tlearn: 0.4702054\ttest: 1.1802697\tbest: 1.1782562 (3927)\ttotal: 16.9s\tremaining: 44.9s\n",
      "4200:\tlearn: 0.4550176\ttest: 1.1834411\tbest: 1.1782562 (3927)\ttotal: 17.3s\tremaining: 44.5s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.178256186\n",
      "bestIteration = 3927\n",
      "\n",
      "Shrink model to first 3928 iterations.\n",
      "Скор для фолда(6) : 9.0 средний скор на префиксе = 9.0 это заняло = 17 сек.\n",
      "Фолд: 7\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.5959039\ttest: 4.1806534\tbest: 4.1806534 (0)\ttotal: 53.6ms\tremaining: 13m 23s\n",
      "100:\tlearn: 2.2765378\ttest: 2.6903588\tbest: 2.6903588 (100)\ttotal: 443ms\tremaining: 1m 5s\n",
      "200:\tlearn: 1.8576017\ttest: 2.2172943\tbest: 2.2172943 (200)\ttotal: 853ms\tremaining: 1m 2s\n",
      "300:\tlearn: 1.6887901\ttest: 2.0311366\tbest: 2.0311366 (300)\ttotal: 1.26s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5930300\ttest: 1.9366652\tbest: 1.9366652 (400)\ttotal: 1.65s\tremaining: 1m\n",
      "500:\tlearn: 1.5260922\ttest: 1.8846165\tbest: 1.8846165 (500)\ttotal: 2.04s\tremaining: 59.1s\n",
      "600:\tlearn: 1.4680369\ttest: 1.8180481\tbest: 1.8180194 (599)\ttotal: 2.43s\tremaining: 58.2s\n",
      "700:\tlearn: 1.4215352\ttest: 1.7624831\tbest: 1.7624831 (700)\ttotal: 2.82s\tremaining: 57.5s\n",
      "800:\tlearn: 1.3846493\ttest: 1.7270565\tbest: 1.7270565 (800)\ttotal: 3.21s\tremaining: 56.9s\n",
      "900:\tlearn: 1.3505153\ttest: 1.7024461\tbest: 1.7023271 (897)\ttotal: 3.6s\tremaining: 56.3s\n",
      "1000:\tlearn: 1.3162042\ttest: 1.6868175\tbest: 1.6867814 (999)\ttotal: 3.99s\tremaining: 55.8s\n",
      "1100:\tlearn: 1.2827252\ttest: 1.6628024\tbest: 1.6624110 (1097)\ttotal: 4.39s\tremaining: 55.4s\n",
      "1200:\tlearn: 1.2441354\ttest: 1.6445163\tbest: 1.6445163 (1200)\ttotal: 4.78s\tremaining: 55s\n",
      "1300:\tlearn: 1.2027155\ttest: 1.6187002\tbest: 1.6187002 (1300)\ttotal: 5.19s\tremaining: 54.6s\n",
      "1400:\tlearn: 1.1611293\ttest: 1.6048908\tbest: 1.6048908 (1400)\ttotal: 5.59s\tremaining: 54.3s\n",
      "1500:\tlearn: 1.1233334\ttest: 1.5902165\tbest: 1.5886357 (1495)\ttotal: 6s\tremaining: 54s\n",
      "1600:\tlearn: 1.0883710\ttest: 1.5850940\tbest: 1.5842578 (1595)\ttotal: 6.41s\tremaining: 53.6s\n",
      "1700:\tlearn: 1.0517801\ttest: 1.5732502\tbest: 1.5724176 (1697)\ttotal: 6.82s\tremaining: 53.3s\n",
      "1800:\tlearn: 1.0195558\ttest: 1.5633735\tbest: 1.5630396 (1792)\ttotal: 7.23s\tremaining: 53s\n",
      "1900:\tlearn: 0.9863517\ttest: 1.5534113\tbest: 1.5523277 (1888)\ttotal: 7.64s\tremaining: 52.7s\n",
      "2000:\tlearn: 0.9597519\ttest: 1.5434988\tbest: 1.5434988 (2000)\ttotal: 8.05s\tremaining: 52.3s\n",
      "2100:\tlearn: 0.9312192\ttest: 1.5280043\tbest: 1.5280043 (2100)\ttotal: 8.46s\tremaining: 51.9s\n",
      "2200:\tlearn: 0.9006595\ttest: 1.5182929\tbest: 1.5182929 (2200)\ttotal: 8.87s\tremaining: 51.6s\n",
      "2300:\tlearn: 0.8780196\ttest: 1.5073181\tbest: 1.5068482 (2297)\ttotal: 9.27s\tremaining: 51.2s\n",
      "2400:\tlearn: 0.8513982\ttest: 1.4963172\tbest: 1.4963172 (2400)\ttotal: 9.68s\tremaining: 50.8s\n",
      "2500:\tlearn: 0.8271016\ttest: 1.4815003\tbest: 1.4815003 (2500)\ttotal: 10.1s\tremaining: 50.4s\n",
      "2600:\tlearn: 0.8019651\ttest: 1.4663399\tbest: 1.4656430 (2589)\ttotal: 10.5s\tremaining: 50.1s\n",
      "2700:\tlearn: 0.7795418\ttest: 1.4513574\tbest: 1.4508885 (2699)\ttotal: 10.9s\tremaining: 49.7s\n",
      "2800:\tlearn: 0.7524728\ttest: 1.4409190\tbest: 1.4404738 (2799)\ttotal: 11.3s\tremaining: 49.3s\n",
      "2900:\tlearn: 0.7281249\ttest: 1.4278564\tbest: 1.4278352 (2899)\ttotal: 11.7s\tremaining: 49s\n",
      "3000:\tlearn: 0.7060806\ttest: 1.4162262\tbest: 1.4161819 (2999)\ttotal: 12.2s\tremaining: 48.6s\n",
      "3100:\tlearn: 0.6860686\ttest: 1.4072262\tbest: 1.4072262 (3100)\ttotal: 12.6s\tremaining: 48.2s\n",
      "3200:\tlearn: 0.6653882\ttest: 1.3965796\tbest: 1.3961480 (3197)\ttotal: 13s\tremaining: 47.8s\n",
      "3300:\tlearn: 0.6442359\ttest: 1.3854431\tbest: 1.3854431 (3300)\ttotal: 13.4s\tremaining: 47.4s\n",
      "3400:\tlearn: 0.6228391\ttest: 1.3788321\tbest: 1.3788321 (3400)\ttotal: 13.8s\tremaining: 47s\n",
      "3500:\tlearn: 0.6033682\ttest: 1.3710213\tbest: 1.3710213 (3500)\ttotal: 14.2s\tremaining: 46.6s\n",
      "3600:\tlearn: 0.5861493\ttest: 1.3660212\tbest: 1.3659767 (3598)\ttotal: 14.6s\tremaining: 46.3s\n",
      "3700:\tlearn: 0.5645620\ttest: 1.3657706\tbest: 1.3644942 (3644)\ttotal: 15s\tremaining: 45.9s\n",
      "3800:\tlearn: 0.5449214\ttest: 1.3640117\tbest: 1.3614618 (3743)\ttotal: 15.4s\tremaining: 45.5s\n",
      "3900:\tlearn: 0.5266191\ttest: 1.3624402\tbest: 1.3614618 (3743)\ttotal: 15.9s\tremaining: 45.1s\n",
      "4000:\tlearn: 0.5080541\ttest: 1.3588630\tbest: 1.3587404 (3992)\ttotal: 16.3s\tremaining: 44.7s\n",
      "4100:\tlearn: 0.4910740\ttest: 1.3499224\tbest: 1.3498939 (4097)\ttotal: 16.7s\tremaining: 44.3s\n",
      "4200:\tlearn: 0.4740404\ttest: 1.3410709\tbest: 1.3410709 (4200)\ttotal: 17.1s\tremaining: 43.9s\n",
      "4300:\tlearn: 0.4583931\ttest: 1.3348575\tbest: 1.3348575 (4300)\ttotal: 17.5s\tremaining: 43.5s\n",
      "4400:\tlearn: 0.4440477\ttest: 1.3301429\tbest: 1.3291371 (4395)\ttotal: 17.9s\tremaining: 43.1s\n",
      "4500:\tlearn: 0.4309567\ttest: 1.3277561\tbest: 1.3277561 (4500)\ttotal: 18.3s\tremaining: 42.7s\n",
      "4600:\tlearn: 0.4173885\ttest: 1.3196508\tbest: 1.3190271 (4586)\ttotal: 18.7s\tremaining: 42.3s\n",
      "4700:\tlearn: 0.4033487\ttest: 1.3138787\tbest: 1.3138418 (4697)\ttotal: 19.1s\tremaining: 42s\n",
      "4800:\tlearn: 0.3902993\ttest: 1.3125262\tbest: 1.3111838 (4774)\ttotal: 19.6s\tremaining: 41.6s\n",
      "4900:\tlearn: 0.3781804\ttest: 1.3113110\tbest: 1.3104711 (4810)\ttotal: 20s\tremaining: 41.2s\n",
      "5000:\tlearn: 0.3662571\ttest: 1.3067945\tbest: 1.3057700 (4970)\ttotal: 20.4s\tremaining: 40.8s\n",
      "5100:\tlearn: 0.3539997\ttest: 1.3024457\tbest: 1.3017988 (5089)\ttotal: 20.8s\tremaining: 40.4s\n",
      "5200:\tlearn: 0.3429317\ttest: 1.2963244\tbest: 1.2962023 (5199)\ttotal: 21.2s\tremaining: 40s\n",
      "5300:\tlearn: 0.3313474\ttest: 1.2934027\tbest: 1.2929521 (5297)\ttotal: 21.6s\tremaining: 39.6s\n",
      "5400:\tlearn: 0.3203970\ttest: 1.2893004\tbest: 1.2891798 (5397)\ttotal: 22.1s\tremaining: 39.2s\n",
      "5500:\tlearn: 0.3092431\ttest: 1.2882548\tbest: 1.2880664 (5490)\ttotal: 22.5s\tremaining: 38.8s\n",
      "5600:\tlearn: 0.2989500\ttest: 1.2810098\tbest: 1.2804462 (5588)\ttotal: 22.9s\tremaining: 38.4s\n",
      "5700:\tlearn: 0.2892996\ttest: 1.2757739\tbest: 1.2743790 (5676)\ttotal: 23.3s\tremaining: 38s\n",
      "5800:\tlearn: 0.2789987\ttest: 1.2720705\tbest: 1.2717899 (5793)\ttotal: 23.7s\tremaining: 37.6s\n",
      "5900:\tlearn: 0.2683422\ttest: 1.2636519\tbest: 1.2636519 (5900)\ttotal: 24.1s\tremaining: 37.2s\n",
      "6000:\tlearn: 0.2604118\ttest: 1.2598466\tbest: 1.2597405 (5996)\ttotal: 24.6s\tremaining: 36.8s\n",
      "6100:\tlearn: 0.2511692\ttest: 1.2567034\tbest: 1.2566094 (6097)\ttotal: 25s\tremaining: 36.4s\n",
      "6200:\tlearn: 0.2432057\ttest: 1.2552592\tbest: 1.2549626 (6195)\ttotal: 25.4s\tremaining: 36s\n",
      "6300:\tlearn: 0.2363693\ttest: 1.2538034\tbest: 1.2529609 (6297)\ttotal: 25.8s\tremaining: 35.6s\n",
      "6400:\tlearn: 0.2291776\ttest: 1.2536023\tbest: 1.2529609 (6297)\ttotal: 26.2s\tremaining: 35.2s\n",
      "6500:\tlearn: 0.2217499\ttest: 1.2517993\tbest: 1.2513612 (6490)\ttotal: 26.6s\tremaining: 34.8s\n",
      "6600:\tlearn: 0.2145120\ttest: 1.2475335\tbest: 1.2474133 (6597)\ttotal: 27s\tremaining: 34.4s\n",
      "6700:\tlearn: 0.2069592\ttest: 1.2471119\tbest: 1.2464453 (6691)\ttotal: 27.5s\tremaining: 34s\n",
      "6800:\tlearn: 0.2003772\ttest: 1.2432398\tbest: 1.2432398 (6800)\ttotal: 27.9s\tremaining: 33.6s\n",
      "6900:\tlearn: 0.1945261\ttest: 1.2392428\tbest: 1.2391287 (6897)\ttotal: 28.3s\tremaining: 33.2s\n",
      "7000:\tlearn: 0.1889921\ttest: 1.2379071\tbest: 1.2375741 (6988)\ttotal: 28.7s\tremaining: 32.8s\n",
      "7100:\tlearn: 0.1828682\ttest: 1.2388861\tbest: 1.2370233 (7034)\ttotal: 29.1s\tremaining: 32.4s\n",
      "7200:\tlearn: 0.1774875\ttest: 1.2363110\tbest: 1.2362164 (7199)\ttotal: 29.5s\tremaining: 32s\n",
      "7300:\tlearn: 0.1728597\ttest: 1.2359890\tbest: 1.2357345 (7296)\ttotal: 29.9s\tremaining: 31.6s\n",
      "7400:\tlearn: 0.1679267\ttest: 1.2327788\tbest: 1.2327514 (7399)\ttotal: 30.4s\tremaining: 31.2s\n",
      "7500:\tlearn: 0.1625887\ttest: 1.2277981\tbest: 1.2266974 (7487)\ttotal: 30.8s\tremaining: 30.8s\n",
      "7600:\tlearn: 0.1578138\ttest: 1.2245713\tbest: 1.2245713 (7600)\ttotal: 31.2s\tremaining: 30.4s\n",
      "7700:\tlearn: 0.1531509\ttest: 1.2225487\tbest: 1.2224320 (7698)\ttotal: 31.6s\tremaining: 30s\n",
      "7800:\tlearn: 0.1487256\ttest: 1.2231342\tbest: 1.2224320 (7698)\ttotal: 32s\tremaining: 29.6s\n",
      "7900:\tlearn: 0.1441026\ttest: 1.2213362\tbest: 1.2210153 (7896)\ttotal: 32.4s\tremaining: 29.1s\n",
      "8000:\tlearn: 0.1405044\ttest: 1.2195792\tbest: 1.2191837 (7944)\ttotal: 32.9s\tremaining: 28.7s\n",
      "8100:\tlearn: 0.1363892\ttest: 1.2184128\tbest: 1.2184128 (8100)\ttotal: 33.3s\tremaining: 28.3s\n",
      "8200:\tlearn: 0.1325562\ttest: 1.2173205\tbest: 1.2171831 (8130)\ttotal: 33.7s\tremaining: 27.9s\n",
      "8300:\tlearn: 0.1285881\ttest: 1.2128087\tbest: 1.2126789 (8289)\ttotal: 34.1s\tremaining: 27.5s\n",
      "8400:\tlearn: 0.1242459\ttest: 1.2088930\tbest: 1.2087809 (8397)\ttotal: 34.5s\tremaining: 27.1s\n",
      "8500:\tlearn: 0.1198016\ttest: 1.2073432\tbest: 1.2066644 (8491)\ttotal: 34.9s\tremaining: 26.7s\n",
      "8600:\tlearn: 0.1162429\ttest: 1.2041224\tbest: 1.2038703 (8594)\ttotal: 35.4s\tremaining: 26.3s\n",
      "8700:\tlearn: 0.1125533\ttest: 1.2018795\tbest: 1.2018795 (8700)\ttotal: 35.8s\tremaining: 25.9s\n",
      "8800:\tlearn: 0.1090589\ttest: 1.2010496\tbest: 1.2005833 (8727)\ttotal: 36.2s\tremaining: 25.5s\n",
      "8900:\tlearn: 0.1057823\ttest: 1.2009201\tbest: 1.2002666 (8847)\ttotal: 36.6s\tremaining: 25.1s\n",
      "9000:\tlearn: 0.1022823\ttest: 1.1970915\tbest: 1.1968218 (8999)\ttotal: 37.1s\tremaining: 24.7s\n",
      "9100:\tlearn: 0.0990572\ttest: 1.1941848\tbest: 1.1938587 (9064)\ttotal: 37.5s\tremaining: 24.3s\n",
      "9200:\tlearn: 0.0960343\ttest: 1.1909220\tbest: 1.1907719 (9190)\ttotal: 37.9s\tremaining: 23.9s\n",
      "9300:\tlearn: 0.0931777\ttest: 1.1896951\tbest: 1.1894280 (9248)\ttotal: 38.3s\tremaining: 23.5s\n",
      "9400:\tlearn: 0.0904520\ttest: 1.1873590\tbest: 1.1873590 (9400)\ttotal: 38.7s\tremaining: 23.1s\n",
      "9500:\tlearn: 0.0877113\ttest: 1.1855991\tbest: 1.1852671 (9491)\ttotal: 39.1s\tremaining: 22.7s\n",
      "9600:\tlearn: 0.0848964\ttest: 1.1832681\tbest: 1.1832485 (9599)\ttotal: 39.6s\tremaining: 22.2s\n",
      "9700:\tlearn: 0.0821363\ttest: 1.1811438\tbest: 1.1811438 (9700)\ttotal: 40s\tremaining: 21.8s\n",
      "9800:\tlearn: 0.0793763\ttest: 1.1802468\tbest: 1.1796155 (9734)\ttotal: 40.4s\tremaining: 21.4s\n",
      "9900:\tlearn: 0.0770306\ttest: 1.1792161\tbest: 1.1787421 (9866)\ttotal: 40.8s\tremaining: 21s\n",
      "10000:\tlearn: 0.0746577\ttest: 1.1788802\tbest: 1.1783791 (9992)\ttotal: 41.2s\tremaining: 20.6s\n",
      "10100:\tlearn: 0.0722101\ttest: 1.1790425\tbest: 1.1783791 (9992)\ttotal: 41.7s\tremaining: 20.2s\n",
      "10200:\tlearn: 0.0698598\ttest: 1.1792576\tbest: 1.1783791 (9992)\ttotal: 42.1s\tremaining: 19.8s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.178379098\n",
      "bestIteration = 9992\n",
      "\n",
      "Shrink model to first 9993 iterations.\n",
      "Скор для фолда(7) : 9.0 средний скор на префиксе = 9.0 это заняло = 42 сек.\n",
      "Фолд: 8\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.6208332\ttest: 3.4494664\tbest: 3.4494664 (0)\ttotal: 52.5ms\tremaining: 13m 6s\n",
      "100:\tlearn: 2.2894691\ttest: 1.9872266\tbest: 1.9872266 (100)\ttotal: 432ms\tremaining: 1m 3s\n",
      "200:\tlearn: 1.8809759\ttest: 1.5788248\tbest: 1.5788248 (200)\ttotal: 841ms\tremaining: 1m 1s\n",
      "300:\tlearn: 1.6967370\ttest: 1.4478439\tbest: 1.4478439 (300)\ttotal: 1.26s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5826403\ttest: 1.3950269\tbest: 1.3950269 (400)\ttotal: 1.67s\tremaining: 1m\n",
      "500:\tlearn: 1.5025258\ttest: 1.3403741\tbest: 1.3403741 (500)\ttotal: 2.07s\tremaining: 1m\n",
      "600:\tlearn: 1.4411726\ttest: 1.3068349\tbest: 1.3068349 (600)\ttotal: 2.49s\tremaining: 59.6s\n",
      "700:\tlearn: 1.3914870\ttest: 1.2852815\tbest: 1.2848278 (693)\ttotal: 2.89s\tremaining: 59s\n",
      "800:\tlearn: 1.3461759\ttest: 1.2644898\tbest: 1.2640648 (799)\ttotal: 3.3s\tremaining: 58.6s\n",
      "900:\tlearn: 1.3072232\ttest: 1.2497622\tbest: 1.2497622 (900)\ttotal: 3.71s\tremaining: 58s\n",
      "1000:\tlearn: 1.2672945\ttest: 1.2479215\tbest: 1.2474457 (996)\ttotal: 4.12s\tremaining: 57.6s\n",
      "1100:\tlearn: 1.2316001\ttest: 1.2443237\tbest: 1.2417838 (1095)\ttotal: 4.52s\tremaining: 57.1s\n",
      "1200:\tlearn: 1.1983070\ttest: 1.2365995\tbest: 1.2363599 (1198)\ttotal: 4.93s\tremaining: 56.7s\n",
      "1300:\tlearn: 1.1627883\ttest: 1.2276613\tbest: 1.2276408 (1298)\ttotal: 5.34s\tremaining: 56.2s\n",
      "1400:\tlearn: 1.1347685\ttest: 1.2182797\tbest: 1.2182445 (1399)\ttotal: 5.74s\tremaining: 55.8s\n",
      "1500:\tlearn: 1.1042235\ttest: 1.2120452\tbest: 1.2119564 (1499)\ttotal: 6.15s\tremaining: 55.3s\n",
      "1600:\tlearn: 1.0746110\ttest: 1.2067119\tbest: 1.2064983 (1595)\ttotal: 6.56s\tremaining: 54.9s\n",
      "1700:\tlearn: 1.0433314\ttest: 1.2035494\tbest: 1.2027358 (1687)\ttotal: 6.97s\tremaining: 54.5s\n",
      "1800:\tlearn: 1.0171801\ttest: 1.1957468\tbest: 1.1954919 (1781)\ttotal: 7.37s\tremaining: 54s\n",
      "1900:\tlearn: 0.9904365\ttest: 1.1898541\tbest: 1.1898541 (1900)\ttotal: 7.79s\tremaining: 53.7s\n",
      "2000:\tlearn: 0.9632934\ttest: 1.1855780\tbest: 1.1855780 (2000)\ttotal: 8.2s\tremaining: 53.3s\n",
      "2100:\tlearn: 0.9336825\ttest: 1.1805914\tbest: 1.1802398 (2095)\ttotal: 8.61s\tremaining: 52.9s\n",
      "2200:\tlearn: 0.9087335\ttest: 1.1760355\tbest: 1.1760355 (2200)\ttotal: 9.02s\tremaining: 52.4s\n",
      "2300:\tlearn: 0.8796733\ttest: 1.1680837\tbest: 1.1680837 (2300)\ttotal: 9.43s\tremaining: 52s\n",
      "2400:\tlearn: 0.8506630\ttest: 1.1626140\tbest: 1.1625709 (2394)\ttotal: 9.84s\tremaining: 51.7s\n",
      "2500:\tlearn: 0.8279712\ttest: 1.1551284\tbest: 1.1551284 (2500)\ttotal: 10.3s\tremaining: 51.3s\n",
      "2600:\tlearn: 0.8049461\ttest: 1.1508358\tbest: 1.1507782 (2595)\ttotal: 10.7s\tremaining: 50.8s\n",
      "2700:\tlearn: 0.7830163\ttest: 1.1480530\tbest: 1.1457362 (2657)\ttotal: 11.1s\tremaining: 50.5s\n",
      "2800:\tlearn: 0.7620390\ttest: 1.1450259\tbest: 1.1450259 (2800)\ttotal: 11.5s\tremaining: 50.1s\n",
      "2900:\tlearn: 0.7398126\ttest: 1.1402034\tbest: 1.1402034 (2900)\ttotal: 11.9s\tremaining: 49.7s\n",
      "3000:\tlearn: 0.7167869\ttest: 1.1335251\tbest: 1.1334952 (2999)\ttotal: 12.3s\tremaining: 49.3s\n",
      "3100:\tlearn: 0.6989158\ttest: 1.1312984\tbest: 1.1304255 (3095)\ttotal: 12.7s\tremaining: 48.9s\n",
      "3200:\tlearn: 0.6789953\ttest: 1.1288773\tbest: 1.1288773 (3200)\ttotal: 13.1s\tremaining: 48.5s\n",
      "3300:\tlearn: 0.6592484\ttest: 1.1281511\tbest: 1.1265974 (3288)\ttotal: 13.6s\tremaining: 48.1s\n",
      "3400:\tlearn: 0.6407534\ttest: 1.1261964\tbest: 1.1258540 (3384)\ttotal: 14s\tremaining: 47.7s\n",
      "3500:\tlearn: 0.6203762\ttest: 1.1232730\tbest: 1.1223695 (3476)\ttotal: 14.4s\tremaining: 47.3s\n",
      "3600:\tlearn: 0.6035792\ttest: 1.1200894\tbest: 1.1200273 (3559)\ttotal: 14.8s\tremaining: 46.9s\n",
      "3700:\tlearn: 0.5848123\ttest: 1.1170339\tbest: 1.1170339 (3700)\ttotal: 15.2s\tremaining: 46.5s\n",
      "3800:\tlearn: 0.5657040\ttest: 1.1137849\tbest: 1.1135650 (3794)\ttotal: 15.6s\tremaining: 46.1s\n",
      "3900:\tlearn: 0.5488464\ttest: 1.1069432\tbest: 1.1060070 (3892)\ttotal: 16s\tremaining: 45.7s\n",
      "4000:\tlearn: 0.5330121\ttest: 1.1044191\tbest: 1.1044191 (4000)\ttotal: 16.5s\tremaining: 45.3s\n",
      "4100:\tlearn: 0.5182673\ttest: 1.0993876\tbest: 1.0992836 (4096)\ttotal: 16.9s\tremaining: 44.8s\n",
      "4200:\tlearn: 0.5034159\ttest: 1.1002374\tbest: 1.0984755 (4111)\ttotal: 17.3s\tremaining: 44.5s\n",
      "4300:\tlearn: 0.4869558\ttest: 1.0962167\tbest: 1.0959735 (4298)\ttotal: 17.7s\tremaining: 44.1s\n",
      "4400:\tlearn: 0.4710215\ttest: 1.0962176\tbest: 1.0957466 (4343)\ttotal: 18.1s\tremaining: 43.6s\n",
      "4500:\tlearn: 0.4588878\ttest: 1.0928126\tbest: 1.0924830 (4488)\ttotal: 18.5s\tremaining: 43.2s\n",
      "4600:\tlearn: 0.4453229\ttest: 1.0898254\tbest: 1.0894932 (4599)\ttotal: 19s\tremaining: 42.8s\n",
      "4700:\tlearn: 0.4326327\ttest: 1.0878578\tbest: 1.0878578 (4700)\ttotal: 19.4s\tremaining: 42.4s\n",
      "4800:\tlearn: 0.4207557\ttest: 1.0843205\tbest: 1.0843205 (4800)\ttotal: 19.8s\tremaining: 42s\n",
      "4900:\tlearn: 0.4082744\ttest: 1.0797768\tbest: 1.0797768 (4900)\ttotal: 20.2s\tremaining: 41.6s\n",
      "5000:\tlearn: 0.3963485\ttest: 1.0769969\tbest: 1.0765458 (4996)\ttotal: 20.6s\tremaining: 41.2s\n",
      "5100:\tlearn: 0.3841522\ttest: 1.0762748\tbest: 1.0756466 (5070)\ttotal: 21s\tremaining: 40.8s\n",
      "5200:\tlearn: 0.3708861\ttest: 1.0727184\tbest: 1.0719518 (5176)\ttotal: 21.5s\tremaining: 40.4s\n",
      "5300:\tlearn: 0.3588148\ttest: 1.0716049\tbest: 1.0702786 (5281)\ttotal: 21.9s\tremaining: 40s\n",
      "5400:\tlearn: 0.3478335\ttest: 1.0711624\tbest: 1.0702786 (5281)\ttotal: 22.3s\tremaining: 39.6s\n",
      "5500:\tlearn: 0.3370421\ttest: 1.0710733\tbest: 1.0702786 (5281)\ttotal: 22.7s\tremaining: 39.2s\n",
      "5600:\tlearn: 0.3275321\ttest: 1.0690464\tbest: 1.0688768 (5598)\ttotal: 23.1s\tremaining: 38.8s\n",
      "5700:\tlearn: 0.3179074\ttest: 1.0668298\tbest: 1.0665344 (5696)\ttotal: 23.5s\tremaining: 38.4s\n",
      "5800:\tlearn: 0.3076539\ttest: 1.0651613\tbest: 1.0649366 (5784)\ttotal: 24s\tremaining: 38s\n",
      "5900:\tlearn: 0.2989646\ttest: 1.0665757\tbest: 1.0647589 (5826)\ttotal: 24.4s\tremaining: 37.6s\n",
      "6000:\tlearn: 0.2904095\ttest: 1.0668905\tbest: 1.0647589 (5826)\ttotal: 24.8s\tremaining: 37.2s\n",
      "6100:\tlearn: 0.2820944\ttest: 1.0673093\tbest: 1.0647589 (5826)\ttotal: 25.2s\tremaining: 36.8s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.064758944\n",
      "bestIteration = 5826\n",
      "\n",
      "Shrink model to first 5827 iterations.\n",
      "Скор для фолда(8) : 9.0 средний скор на префиксе = 9.0 это заняло = 25 сек.\n",
      "Фолд: 9\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.5856830\ttest: 3.7247990\tbest: 3.7247990 (0)\ttotal: 50.9ms\tremaining: 12m 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 2.2578959\ttest: 2.2293408\tbest: 2.2293408 (100)\ttotal: 437ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8449108\ttest: 1.7343715\tbest: 1.7343715 (200)\ttotal: 846ms\tremaining: 1m 2s\n",
      "300:\tlearn: 1.6638176\ttest: 1.5809180\tbest: 1.5809180 (300)\ttotal: 1.26s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5564237\ttest: 1.5248136\tbest: 1.5248136 (400)\ttotal: 1.67s\tremaining: 1m\n",
      "500:\tlearn: 1.4856655\ttest: 1.4782255\tbest: 1.4782255 (500)\ttotal: 2.08s\tremaining: 1m\n",
      "600:\tlearn: 1.4258691\ttest: 1.4146555\tbest: 1.4146555 (600)\ttotal: 2.47s\tremaining: 59.3s\n",
      "700:\tlearn: 1.3718551\ttest: 1.3743947\tbest: 1.3743947 (700)\ttotal: 2.88s\tremaining: 58.8s\n",
      "800:\tlearn: 1.3283817\ttest: 1.3440469\tbest: 1.3440469 (800)\ttotal: 3.28s\tremaining: 58.2s\n",
      "900:\tlearn: 1.2911296\ttest: 1.3253418\tbest: 1.3253418 (900)\ttotal: 3.69s\tremaining: 57.7s\n",
      "1000:\tlearn: 1.2531519\ttest: 1.2998406\tbest: 1.2998406 (1000)\ttotal: 4.08s\tremaining: 57.1s\n",
      "1100:\tlearn: 1.2161406\ttest: 1.2791872\tbest: 1.2785207 (1097)\ttotal: 4.49s\tremaining: 56.6s\n",
      "1200:\tlearn: 1.1822079\ttest: 1.2704044\tbest: 1.2704044 (1200)\ttotal: 4.89s\tremaining: 56.2s\n",
      "1300:\tlearn: 1.1437597\ttest: 1.2509316\tbest: 1.2508949 (1299)\ttotal: 5.29s\tremaining: 55.7s\n",
      "1400:\tlearn: 1.1116777\ttest: 1.2407446\tbest: 1.2403941 (1372)\ttotal: 5.7s\tremaining: 55.3s\n",
      "1500:\tlearn: 1.0803935\ttest: 1.2366947\tbest: 1.2366947 (1500)\ttotal: 6.1s\tremaining: 54.9s\n",
      "1600:\tlearn: 1.0501452\ttest: 1.2323982\tbest: 1.2320247 (1599)\ttotal: 6.51s\tremaining: 54.5s\n",
      "1700:\tlearn: 1.0181273\ttest: 1.2286485\tbest: 1.2259331 (1657)\ttotal: 6.91s\tremaining: 54.1s\n",
      "1800:\tlearn: 0.9900733\ttest: 1.2210086\tbest: 1.2210086 (1800)\ttotal: 7.32s\tremaining: 53.7s\n",
      "1900:\tlearn: 0.9595736\ttest: 1.2187757\tbest: 1.2165847 (1881)\ttotal: 7.73s\tremaining: 53.3s\n",
      "2000:\tlearn: 0.9304867\ttest: 1.2119749\tbest: 1.2101477 (1998)\ttotal: 8.14s\tremaining: 52.9s\n",
      "2100:\tlearn: 0.9035825\ttest: 1.2027600\tbest: 1.2024718 (2099)\ttotal: 8.55s\tremaining: 52.5s\n",
      "2200:\tlearn: 0.8808197\ttest: 1.1946142\tbest: 1.1945587 (2192)\ttotal: 8.95s\tremaining: 52.1s\n",
      "2300:\tlearn: 0.8560402\ttest: 1.1843612\tbest: 1.1842708 (2298)\ttotal: 9.36s\tremaining: 51.6s\n",
      "2400:\tlearn: 0.8307658\ttest: 1.1772132\tbest: 1.1770671 (2397)\ttotal: 9.77s\tremaining: 51.2s\n",
      "2500:\tlearn: 0.8080238\ttest: 1.1692791\tbest: 1.1692791 (2500)\ttotal: 10.2s\tremaining: 50.9s\n",
      "2600:\tlearn: 0.7859613\ttest: 1.1650144\tbest: 1.1650111 (2599)\ttotal: 10.6s\tremaining: 50.5s\n",
      "2700:\tlearn: 0.7668321\ttest: 1.1580010\tbest: 1.1580010 (2700)\ttotal: 11s\tremaining: 50.1s\n",
      "2800:\tlearn: 0.7450590\ttest: 1.1543979\tbest: 1.1542717 (2782)\ttotal: 11.4s\tremaining: 49.7s\n",
      "2900:\tlearn: 0.7253226\ttest: 1.1503453\tbest: 1.1503453 (2900)\ttotal: 11.8s\tremaining: 49.3s\n",
      "3000:\tlearn: 0.7052939\ttest: 1.1431758\tbest: 1.1431515 (2998)\ttotal: 12.2s\tremaining: 48.9s\n",
      "3100:\tlearn: 0.6832195\ttest: 1.1392143\tbest: 1.1387593 (3068)\ttotal: 12.6s\tremaining: 48.5s\n",
      "3200:\tlearn: 0.6645790\ttest: 1.1359277\tbest: 1.1359277 (3200)\ttotal: 13.1s\tremaining: 48.1s\n",
      "3300:\tlearn: 0.6452935\ttest: 1.1317564\tbest: 1.1314528 (3282)\ttotal: 13.5s\tremaining: 47.7s\n",
      "3400:\tlearn: 0.6265858\ttest: 1.1288400\tbest: 1.1286788 (3393)\ttotal: 13.9s\tremaining: 47.3s\n",
      "3500:\tlearn: 0.6083310\ttest: 1.1259789\tbest: 1.1258509 (3493)\ttotal: 14.3s\tremaining: 46.9s\n",
      "3600:\tlearn: 0.5886145\ttest: 1.1201498\tbest: 1.1197197 (3597)\ttotal: 14.7s\tremaining: 46.6s\n",
      "3700:\tlearn: 0.5710774\ttest: 1.1205205\tbest: 1.1193491 (3661)\ttotal: 15.1s\tremaining: 46.2s\n",
      "3800:\tlearn: 0.5535604\ttest: 1.1176485\tbest: 1.1164012 (3777)\ttotal: 15.5s\tremaining: 45.8s\n",
      "3900:\tlearn: 0.5369133\ttest: 1.1186356\tbest: 1.1164012 (3777)\ttotal: 15.9s\tremaining: 45.4s\n",
      "4000:\tlearn: 0.5203630\ttest: 1.1153629\tbest: 1.1153629 (4000)\ttotal: 16.4s\tremaining: 45s\n",
      "4100:\tlearn: 0.5050050\ttest: 1.1142911\tbest: 1.1140503 (4084)\ttotal: 16.8s\tremaining: 44.6s\n",
      "4200:\tlearn: 0.4912611\ttest: 1.1129959\tbest: 1.1123358 (4178)\ttotal: 17.2s\tremaining: 44.2s\n",
      "4300:\tlearn: 0.4764839\ttest: 1.1068411\tbest: 1.1067690 (4299)\ttotal: 17.6s\tremaining: 43.8s\n",
      "4400:\tlearn: 0.4623559\ttest: 1.1037574\tbest: 1.1036575 (4398)\ttotal: 18s\tremaining: 43.4s\n",
      "4500:\tlearn: 0.4461530\ttest: 1.1016434\tbest: 1.1015889 (4496)\ttotal: 18.4s\tremaining: 43s\n",
      "4600:\tlearn: 0.4304692\ttest: 1.1015161\tbest: 1.1010318 (4560)\ttotal: 18.9s\tremaining: 42.6s\n",
      "4700:\tlearn: 0.4177438\ttest: 1.1017527\tbest: 1.1010318 (4560)\ttotal: 19.3s\tremaining: 42.2s\n",
      "4800:\tlearn: 0.4064557\ttest: 1.0999881\tbest: 1.0998515 (4796)\ttotal: 19.7s\tremaining: 41.8s\n",
      "4900:\tlearn: 0.3932493\ttest: 1.1005758\tbest: 1.0994205 (4803)\ttotal: 20.1s\tremaining: 41.4s\n",
      "5000:\tlearn: 0.3809135\ttest: 1.1014048\tbest: 1.0994205 (4803)\ttotal: 20.5s\tremaining: 41s\n",
      "5100:\tlearn: 0.3690046\ttest: 1.1009646\tbest: 1.0994205 (4803)\ttotal: 20.9s\tremaining: 40.6s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.099420474\n",
      "bestIteration = 4803\n",
      "\n",
      "Shrink model to first 4804 iterations.\n",
      "Скор для фолда(9) : 9.0 средний скор на префиксе = 9.0 это заняло = 21 сек.\n",
      "Фолд: 10\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.6091797\ttest: 3.6583250\tbest: 3.6583250 (0)\ttotal: 53.8ms\tremaining: 13m 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 2.2781699\ttest: 2.4472949\tbest: 2.4472949 (100)\ttotal: 436ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8580891\ttest: 1.9917153\tbest: 1.9917153 (200)\ttotal: 843ms\tremaining: 1m 2s\n",
      "300:\tlearn: 1.6660933\ttest: 1.8101806\tbest: 1.8101806 (300)\ttotal: 1.26s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5434389\ttest: 1.7076125\tbest: 1.7076125 (400)\ttotal: 1.67s\tremaining: 1m\n",
      "500:\tlearn: 1.4608359\ttest: 1.6491472\tbest: 1.6491472 (500)\ttotal: 2.08s\tremaining: 1m\n",
      "600:\tlearn: 1.3989525\ttest: 1.6258771\tbest: 1.6245994 (599)\ttotal: 2.49s\tremaining: 59.7s\n",
      "700:\tlearn: 1.3472341\ttest: 1.6012206\tbest: 1.6008355 (696)\ttotal: 2.9s\tremaining: 59.1s\n",
      "800:\tlearn: 1.3048386\ttest: 1.5944643\tbest: 1.5937002 (799)\ttotal: 3.3s\tremaining: 58.6s\n",
      "900:\tlearn: 1.2600271\ttest: 1.5912742\tbest: 1.5906614 (892)\ttotal: 3.71s\tremaining: 58.1s\n",
      "1000:\tlearn: 1.2192132\ttest: 1.5798077\tbest: 1.5778476 (969)\ttotal: 4.11s\tremaining: 57.5s\n",
      "1100:\tlearn: 1.1802876\ttest: 1.5642288\tbest: 1.5633630 (1095)\ttotal: 4.52s\tremaining: 57.1s\n",
      "1200:\tlearn: 1.1392103\ttest: 1.5575154\tbest: 1.5550370 (1182)\ttotal: 4.93s\tremaining: 56.6s\n",
      "1300:\tlearn: 1.1040106\ttest: 1.5514423\tbest: 1.5507913 (1297)\ttotal: 5.33s\tremaining: 56.2s\n",
      "1400:\tlearn: 1.0710697\ttest: 1.5532411\tbest: 1.5507913 (1297)\ttotal: 5.74s\tremaining: 55.7s\n",
      "1500:\tlearn: 1.0390001\ttest: 1.5470852\tbest: 1.5470852 (1500)\ttotal: 6.15s\tremaining: 55.3s\n",
      "1600:\tlearn: 1.0049670\ttest: 1.5416252\tbest: 1.5415155 (1598)\ttotal: 6.55s\tremaining: 54.9s\n",
      "1700:\tlearn: 0.9714913\ttest: 1.5421749\tbest: 1.5402868 (1643)\ttotal: 6.96s\tremaining: 54.4s\n",
      "1800:\tlearn: 0.9393834\ttest: 1.5377194\tbest: 1.5377194 (1800)\ttotal: 7.37s\tremaining: 54s\n",
      "1900:\tlearn: 0.9070710\ttest: 1.5308533\tbest: 1.5305722 (1896)\ttotal: 7.79s\tremaining: 53.6s\n",
      "2000:\tlearn: 0.8783543\ttest: 1.5241777\tbest: 1.5241777 (2000)\ttotal: 8.19s\tremaining: 53.2s\n",
      "2100:\tlearn: 0.8497618\ttest: 1.5214064\tbest: 1.5196690 (2066)\ttotal: 8.61s\tremaining: 52.9s\n",
      "2200:\tlearn: 0.8225107\ttest: 1.5139034\tbest: 1.5137870 (2193)\ttotal: 9.02s\tremaining: 52.4s\n",
      "2300:\tlearn: 0.7970013\ttest: 1.5097607\tbest: 1.5083508 (2291)\ttotal: 9.43s\tremaining: 52s\n",
      "2400:\tlearn: 0.7710286\ttest: 1.5074523\tbest: 1.5066022 (2328)\ttotal: 9.84s\tremaining: 51.6s\n",
      "2500:\tlearn: 0.7465976\ttest: 1.5041728\tbest: 1.5041384 (2498)\ttotal: 10.2s\tremaining: 51.2s\n",
      "2600:\tlearn: 0.7229765\ttest: 1.5051279\tbest: 1.5033028 (2506)\ttotal: 10.7s\tremaining: 50.8s\n",
      "2700:\tlearn: 0.6988131\ttest: 1.5049051\tbest: 1.5033028 (2506)\ttotal: 11.1s\tremaining: 50.5s\n",
      "2800:\tlearn: 0.6746969\ttest: 1.5056932\tbest: 1.5033028 (2506)\ttotal: 11.5s\tremaining: 50.1s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.503302766\n",
      "bestIteration = 2506\n",
      "\n",
      "Shrink model to first 2507 iterations.\n",
      "Скор для фолда(10) : 9.0 средний скор на префиксе = 9.0 это заняло = 11 сек.\n",
      "Фолд: 11\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.6078656\ttest: 3.7042164\tbest: 3.7042164 (0)\ttotal: 52.5ms\tremaining: 13m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 2.2781289\ttest: 2.5806910\tbest: 2.5806910 (100)\ttotal: 439ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8441340\ttest: 2.3441520\tbest: 2.3441520 (200)\ttotal: 847ms\tremaining: 1m 2s\n",
      "300:\tlearn: 1.6613869\ttest: 2.1756669\tbest: 2.1756669 (300)\ttotal: 1.26s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5411778\ttest: 2.0349199\tbest: 2.0349199 (400)\ttotal: 1.67s\tremaining: 1m\n",
      "500:\tlearn: 1.4596866\ttest: 1.9425825\tbest: 1.9425825 (500)\ttotal: 2.08s\tremaining: 1m\n",
      "600:\tlearn: 1.4004927\ttest: 1.8870225\tbest: 1.8870225 (600)\ttotal: 2.49s\tremaining: 59.7s\n",
      "700:\tlearn: 1.3492258\ttest: 1.8438788\tbest: 1.8435335 (699)\ttotal: 2.9s\tremaining: 59.1s\n",
      "800:\tlearn: 1.3038881\ttest: 1.7990129\tbest: 1.7990129 (800)\ttotal: 3.3s\tremaining: 58.5s\n",
      "900:\tlearn: 1.2645651\ttest: 1.7676735\tbest: 1.7676735 (900)\ttotal: 3.7s\tremaining: 58s\n",
      "1000:\tlearn: 1.2235257\ttest: 1.7470723\tbest: 1.7470723 (1000)\ttotal: 4.11s\tremaining: 57.4s\n",
      "1100:\tlearn: 1.1865449\ttest: 1.7256325\tbest: 1.7255431 (1090)\ttotal: 4.51s\tremaining: 57s\n",
      "1200:\tlearn: 1.1553588\ttest: 1.7021114\tbest: 1.7021114 (1200)\ttotal: 4.92s\tremaining: 56.5s\n",
      "1300:\tlearn: 1.1189052\ttest: 1.6820006\tbest: 1.6817209 (1298)\ttotal: 5.33s\tremaining: 56.1s\n",
      "1400:\tlearn: 1.0863531\ttest: 1.6702985\tbest: 1.6702985 (1400)\ttotal: 5.74s\tremaining: 55.7s\n",
      "1500:\tlearn: 1.0585764\ttest: 1.6595199\tbest: 1.6595199 (1500)\ttotal: 6.14s\tremaining: 55.2s\n",
      "1600:\tlearn: 1.0266650\ttest: 1.6435239\tbest: 1.6432712 (1598)\ttotal: 6.54s\tremaining: 54.8s\n",
      "1700:\tlearn: 0.9966985\ttest: 1.6327621\tbest: 1.6327621 (1700)\ttotal: 6.95s\tremaining: 54.4s\n",
      "1800:\tlearn: 0.9643466\ttest: 1.6214114\tbest: 1.6214114 (1800)\ttotal: 7.36s\tremaining: 54s\n",
      "1900:\tlearn: 0.9357432\ttest: 1.6160641\tbest: 1.6160641 (1900)\ttotal: 7.77s\tremaining: 53.5s\n",
      "2000:\tlearn: 0.9081843\ttest: 1.6109349\tbest: 1.6107290 (1999)\ttotal: 8.18s\tremaining: 53.1s\n",
      "2100:\tlearn: 0.8782638\ttest: 1.6009158\tbest: 1.6009158 (2100)\ttotal: 8.59s\tremaining: 52.7s\n",
      "2200:\tlearn: 0.8519475\ttest: 1.5938030\tbest: 1.5937722 (2199)\ttotal: 8.99s\tremaining: 52.3s\n",
      "2300:\tlearn: 0.8239243\ttest: 1.5884472\tbest: 1.5882327 (2297)\ttotal: 9.41s\tremaining: 51.9s\n",
      "2400:\tlearn: 0.8014201\ttest: 1.5811798\tbest: 1.5811798 (2400)\ttotal: 9.82s\tremaining: 51.5s\n",
      "2500:\tlearn: 0.7773072\ttest: 1.5782583\tbest: 1.5782401 (2496)\ttotal: 10.2s\tremaining: 51.1s\n",
      "2600:\tlearn: 0.7541060\ttest: 1.5735771\tbest: 1.5735771 (2600)\ttotal: 10.6s\tremaining: 50.7s\n",
      "2700:\tlearn: 0.7329293\ttest: 1.5634839\tbest: 1.5634839 (2700)\ttotal: 11s\tremaining: 50.3s\n",
      "2800:\tlearn: 0.7104782\ttest: 1.5602671\tbest: 1.5595617 (2794)\ttotal: 11.5s\tremaining: 49.9s\n",
      "2900:\tlearn: 0.6864678\ttest: 1.5573143\tbest: 1.5567041 (2899)\ttotal: 11.9s\tremaining: 49.5s\n",
      "3000:\tlearn: 0.6650931\ttest: 1.5537433\tbest: 1.5529234 (2969)\ttotal: 12.3s\tremaining: 49.1s\n",
      "3100:\tlearn: 0.6452155\ttest: 1.5481792\tbest: 1.5481281 (3098)\ttotal: 12.7s\tremaining: 48.7s\n",
      "3200:\tlearn: 0.6271376\ttest: 1.5493857\tbest: 1.5478356 (3104)\ttotal: 13.1s\tremaining: 48.3s\n",
      "3300:\tlearn: 0.6064260\ttest: 1.5462927\tbest: 1.5455845 (3292)\ttotal: 13.5s\tremaining: 47.9s\n",
      "3400:\tlearn: 0.5891851\ttest: 1.5443011\tbest: 1.5443011 (3400)\ttotal: 13.9s\tremaining: 47.5s\n",
      "3500:\tlearn: 0.5689494\ttest: 1.5427249\tbest: 1.5423129 (3494)\ttotal: 14.3s\tremaining: 47.1s\n",
      "3600:\tlearn: 0.5519627\ttest: 1.5420205\tbest: 1.5412677 (3542)\ttotal: 14.7s\tremaining: 46.7s\n",
      "3700:\tlearn: 0.5357645\ttest: 1.5411045\tbest: 1.5411045 (3700)\ttotal: 15.2s\tremaining: 46.3s\n",
      "3800:\tlearn: 0.5183878\ttest: 1.5377518\tbest: 1.5377518 (3800)\ttotal: 15.6s\tremaining: 45.9s\n",
      "3900:\tlearn: 0.5022140\ttest: 1.5346499\tbest: 1.5341410 (3875)\ttotal: 16s\tremaining: 45.5s\n",
      "4000:\tlearn: 0.4884006\ttest: 1.5374026\tbest: 1.5341146 (3922)\ttotal: 16.4s\tremaining: 45.1s\n",
      "4100:\tlearn: 0.4759030\ttest: 1.5358758\tbest: 1.5341146 (3922)\ttotal: 16.8s\tremaining: 44.7s\n",
      "4200:\tlearn: 0.4618817\ttest: 1.5344720\tbest: 1.5333714 (4160)\ttotal: 17.2s\tremaining: 44.3s\n",
      "4300:\tlearn: 0.4472660\ttest: 1.5331637\tbest: 1.5324013 (4286)\ttotal: 17.6s\tremaining: 43.9s\n",
      "4400:\tlearn: 0.4355984\ttest: 1.5330671\tbest: 1.5300862 (4339)\ttotal: 18.1s\tremaining: 43.5s\n",
      "4500:\tlearn: 0.4227613\ttest: 1.5313825\tbest: 1.5300862 (4339)\ttotal: 18.5s\tremaining: 43.1s\n",
      "4600:\tlearn: 0.4096115\ttest: 1.5274826\tbest: 1.5274677 (4598)\ttotal: 18.9s\tremaining: 42.7s\n",
      "4700:\tlearn: 0.3972717\ttest: 1.5272846\tbest: 1.5265454 (4676)\ttotal: 19.3s\tremaining: 42.3s\n",
      "4800:\tlearn: 0.3854383\ttest: 1.5259204\tbest: 1.5257983 (4787)\ttotal: 19.7s\tremaining: 41.9s\n",
      "4900:\tlearn: 0.3743085\ttest: 1.5226062\tbest: 1.5220124 (4870)\ttotal: 20.1s\tremaining: 41.5s\n",
      "5000:\tlearn: 0.3633111\ttest: 1.5217274\tbest: 1.5214225 (4943)\ttotal: 20.5s\tremaining: 41.1s\n",
      "5100:\tlearn: 0.3506703\ttest: 1.5184902\tbest: 1.5178672 (5074)\ttotal: 21s\tremaining: 40.7s\n",
      "5200:\tlearn: 0.3390656\ttest: 1.5171590\tbest: 1.5162561 (5187)\ttotal: 21.4s\tremaining: 40.3s\n",
      "5300:\tlearn: 0.3289289\ttest: 1.5166951\tbest: 1.5162561 (5187)\ttotal: 21.8s\tremaining: 39.9s\n",
      "5400:\tlearn: 0.3172922\ttest: 1.5173182\tbest: 1.5152081 (5337)\ttotal: 22.2s\tremaining: 39.5s\n",
      "5500:\tlearn: 0.3060007\ttest: 1.5169245\tbest: 1.5152081 (5337)\ttotal: 22.6s\tremaining: 39.1s\n",
      "5600:\tlearn: 0.2954856\ttest: 1.5194650\tbest: 1.5152081 (5337)\ttotal: 23.1s\tremaining: 38.7s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.515208091\n",
      "bestIteration = 5337\n",
      "\n",
      "Shrink model to first 5338 iterations.\n",
      "Скор для фолда(11) : 9.0 средний скор на префиксе = 9.0 это заняло = 23 сек.\n",
      "Фолд: 12\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.5973186\ttest: 3.5874154\tbest: 3.5874154 (0)\ttotal: 53.6ms\tremaining: 13m 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 2.2741111\ttest: 2.1081658\tbest: 2.1081658 (100)\ttotal: 437ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8686395\ttest: 1.8941318\tbest: 1.8941318 (200)\ttotal: 850ms\tremaining: 1m 2s\n",
      "300:\tlearn: 1.6772161\ttest: 1.8706775\tbest: 1.8691407 (298)\ttotal: 1.27s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5577352\ttest: 1.8342161\tbest: 1.8322597 (396)\ttotal: 1.68s\tremaining: 1m 1s\n",
      "500:\tlearn: 1.4742572\ttest: 1.8145560\tbest: 1.8141148 (498)\ttotal: 2.09s\tremaining: 1m\n",
      "600:\tlearn: 1.4181788\ttest: 1.7912077\tbest: 1.7911524 (594)\ttotal: 2.5s\tremaining: 59.9s\n",
      "700:\tlearn: 1.3714399\ttest: 1.7692425\tbest: 1.7692425 (700)\ttotal: 2.9s\tremaining: 59.2s\n",
      "800:\tlearn: 1.3346837\ttest: 1.7578514\tbest: 1.7552849 (789)\ttotal: 3.31s\tremaining: 58.7s\n",
      "900:\tlearn: 1.2991144\ttest: 1.7437171\tbest: 1.7437171 (900)\ttotal: 3.71s\tremaining: 58.1s\n",
      "1000:\tlearn: 1.2658163\ttest: 1.7270271\tbest: 1.7270271 (1000)\ttotal: 4.11s\tremaining: 57.5s\n",
      "1100:\tlearn: 1.2319374\ttest: 1.7130885\tbest: 1.7130885 (1100)\ttotal: 4.51s\tremaining: 57s\n",
      "1200:\tlearn: 1.1975670\ttest: 1.6946567\tbest: 1.6946567 (1200)\ttotal: 4.92s\tremaining: 56.5s\n",
      "1300:\tlearn: 1.1613949\ttest: 1.6784784\tbest: 1.6783400 (1299)\ttotal: 5.32s\tremaining: 56s\n",
      "1400:\tlearn: 1.1267080\ttest: 1.6598036\tbest: 1.6598036 (1400)\ttotal: 5.73s\tremaining: 55.6s\n",
      "1500:\tlearn: 1.0905825\ttest: 1.6450863\tbest: 1.6450863 (1500)\ttotal: 6.14s\tremaining: 55.2s\n",
      "1600:\tlearn: 1.0561438\ttest: 1.6307779\tbest: 1.6301257 (1594)\ttotal: 6.55s\tremaining: 54.8s\n",
      "1700:\tlearn: 1.0228500\ttest: 1.6120443\tbest: 1.6117080 (1699)\ttotal: 6.96s\tremaining: 54.4s\n",
      "1800:\tlearn: 0.9882626\ttest: 1.5933966\tbest: 1.5933966 (1800)\ttotal: 7.36s\tremaining: 54s\n",
      "1900:\tlearn: 0.9596230\ttest: 1.5821521\tbest: 1.5816646 (1895)\ttotal: 7.77s\tremaining: 53.6s\n",
      "2000:\tlearn: 0.9283008\ttest: 1.5690313\tbest: 1.5690313 (2000)\ttotal: 8.18s\tremaining: 53.2s\n",
      "2100:\tlearn: 0.8995764\ttest: 1.5580934\tbest: 1.5580934 (2100)\ttotal: 8.59s\tremaining: 52.8s\n",
      "2200:\tlearn: 0.8731977\ttest: 1.5487042\tbest: 1.5484862 (2199)\ttotal: 9.01s\tremaining: 52.4s\n",
      "2300:\tlearn: 0.8448134\ttest: 1.5399089\tbest: 1.5396361 (2294)\ttotal: 9.42s\tremaining: 52s\n",
      "2400:\tlearn: 0.8195244\ttest: 1.5341597\tbest: 1.5339397 (2397)\ttotal: 9.83s\tremaining: 51.6s\n",
      "2500:\tlearn: 0.7933724\ttest: 1.5275532\tbest: 1.5271566 (2492)\ttotal: 10.2s\tremaining: 51.2s\n",
      "2600:\tlearn: 0.7699935\ttest: 1.5186273\tbest: 1.5184508 (2597)\ttotal: 10.7s\tremaining: 50.8s\n",
      "2700:\tlearn: 0.7489079\ttest: 1.5146834\tbest: 1.5145501 (2690)\ttotal: 11.1s\tremaining: 50.4s\n",
      "2800:\tlearn: 0.7266721\ttest: 1.5079284\tbest: 1.5079284 (2800)\ttotal: 11.5s\tremaining: 49.9s\n",
      "2900:\tlearn: 0.7058581\ttest: 1.5025486\tbest: 1.5025486 (2900)\ttotal: 11.9s\tremaining: 49.5s\n",
      "3000:\tlearn: 0.6867312\ttest: 1.4969565\tbest: 1.4967034 (2994)\ttotal: 12.3s\tremaining: 49.1s\n",
      "3100:\tlearn: 0.6677245\ttest: 1.4891272\tbest: 1.4886717 (3088)\ttotal: 12.7s\tremaining: 48.7s\n",
      "3200:\tlearn: 0.6491617\ttest: 1.4846547\tbest: 1.4840825 (3190)\ttotal: 13.1s\tremaining: 48.3s\n",
      "3300:\tlearn: 0.6290664\ttest: 1.4756249\tbest: 1.4756249 (3300)\ttotal: 13.5s\tremaining: 47.9s\n",
      "3400:\tlearn: 0.6095670\ttest: 1.4731534\tbest: 1.4723777 (3384)\ttotal: 13.9s\tremaining: 47.5s\n",
      "3500:\tlearn: 0.5907582\ttest: 1.4680605\tbest: 1.4678331 (3495)\ttotal: 14.3s\tremaining: 47.1s\n",
      "3600:\tlearn: 0.5747799\ttest: 1.4629655\tbest: 1.4629655 (3600)\ttotal: 14.7s\tremaining: 46.7s\n",
      "3700:\tlearn: 0.5553539\ttest: 1.4611270\tbest: 1.4606612 (3657)\ttotal: 15.2s\tremaining: 46.3s\n",
      "3800:\tlearn: 0.5398685\ttest: 1.4563244\tbest: 1.4563244 (3800)\ttotal: 15.6s\tremaining: 45.9s\n",
      "3900:\tlearn: 0.5237046\ttest: 1.4541249\tbest: 1.4540002 (3894)\ttotal: 16s\tremaining: 45.5s\n",
      "4000:\tlearn: 0.5095267\ttest: 1.4505262\tbest: 1.4503876 (3996)\ttotal: 16.4s\tremaining: 45.1s\n",
      "4100:\tlearn: 0.4945355\ttest: 1.4479835\tbest: 1.4475985 (4098)\ttotal: 16.8s\tremaining: 44.7s\n",
      "4200:\tlearn: 0.4816891\ttest: 1.4446510\tbest: 1.4446510 (4200)\ttotal: 17.2s\tremaining: 44.3s\n",
      "4300:\tlearn: 0.4659661\ttest: 1.4378946\tbest: 1.4378801 (4299)\ttotal: 17.6s\tremaining: 43.9s\n",
      "4400:\tlearn: 0.4525140\ttest: 1.4320055\tbest: 1.4318145 (4388)\ttotal: 18.1s\tremaining: 43.5s\n",
      "4500:\tlearn: 0.4391954\ttest: 1.4268095\tbest: 1.4267854 (4498)\ttotal: 18.5s\tremaining: 43.1s\n",
      "4600:\tlearn: 0.4266944\ttest: 1.4238020\tbest: 1.4237785 (4599)\ttotal: 18.9s\tremaining: 42.7s\n",
      "4700:\tlearn: 0.4138751\ttest: 1.4206272\tbest: 1.4201658 (4693)\ttotal: 19.3s\tremaining: 42.3s\n",
      "4800:\tlearn: 0.4015606\ttest: 1.4161789\tbest: 1.4161628 (4794)\ttotal: 19.7s\tremaining: 41.9s\n",
      "4900:\tlearn: 0.3895413\ttest: 1.4115365\tbest: 1.4110154 (4885)\ttotal: 20.1s\tremaining: 41.5s\n",
      "5000:\tlearn: 0.3775571\ttest: 1.4094533\tbest: 1.4093315 (4996)\ttotal: 20.5s\tremaining: 41.1s\n",
      "5100:\tlearn: 0.3675942\ttest: 1.4064958\tbest: 1.4064958 (5100)\ttotal: 20.9s\tremaining: 40.7s\n",
      "5200:\tlearn: 0.3569887\ttest: 1.4052611\tbest: 1.4043436 (5174)\ttotal: 21.4s\tremaining: 40.2s\n",
      "5300:\tlearn: 0.3452572\ttest: 1.4005162\tbest: 1.4005162 (5300)\ttotal: 21.8s\tremaining: 39.8s\n",
      "5400:\tlearn: 0.3339218\ttest: 1.3974679\tbest: 1.3973162 (5397)\ttotal: 22.2s\tremaining: 39.4s\n",
      "5500:\tlearn: 0.3241244\ttest: 1.3944478\tbest: 1.3944478 (5500)\ttotal: 22.6s\tremaining: 39s\n",
      "5600:\tlearn: 0.3141727\ttest: 1.3908368\tbest: 1.3906817 (5592)\ttotal: 23s\tremaining: 38.6s\n",
      "5700:\tlearn: 0.3040034\ttest: 1.3895003\tbest: 1.3894839 (5697)\ttotal: 23.4s\tremaining: 38.2s\n",
      "5800:\tlearn: 0.2953642\ttest: 1.3857446\tbest: 1.3854920 (5786)\ttotal: 23.8s\tremaining: 37.8s\n",
      "5900:\tlearn: 0.2875164\ttest: 1.3846586\tbest: 1.3841430 (5877)\ttotal: 24.3s\tremaining: 37.4s\n",
      "6000:\tlearn: 0.2788100\ttest: 1.3828932\tbest: 1.3827117 (5999)\ttotal: 24.7s\tremaining: 37s\n",
      "6100:\tlearn: 0.2703392\ttest: 1.3788395\tbest: 1.3785581 (6095)\ttotal: 25.1s\tremaining: 36.6s\n",
      "6200:\tlearn: 0.2614127\ttest: 1.3757704\tbest: 1.3757704 (6200)\ttotal: 25.5s\tremaining: 36.2s\n",
      "6300:\tlearn: 0.2524805\ttest: 1.3728675\tbest: 1.3728549 (6297)\ttotal: 25.9s\tremaining: 35.8s\n",
      "6400:\tlearn: 0.2441035\ttest: 1.3699795\tbest: 1.3698977 (6395)\ttotal: 26.3s\tremaining: 35.4s\n",
      "6500:\tlearn: 0.2362883\ttest: 1.3690814\tbest: 1.3690814 (6500)\ttotal: 26.7s\tremaining: 35s\n",
      "6600:\tlearn: 0.2291538\ttest: 1.3683233\tbest: 1.3680733 (6598)\ttotal: 27.2s\tremaining: 34.6s\n",
      "6700:\tlearn: 0.2220963\ttest: 1.3664819\tbest: 1.3658603 (6661)\ttotal: 27.6s\tremaining: 34.1s\n",
      "6800:\tlearn: 0.2148180\ttest: 1.3625404\tbest: 1.3625038 (6799)\ttotal: 28s\tremaining: 33.7s\n",
      "6900:\tlearn: 0.2077619\ttest: 1.3622472\tbest: 1.3617781 (6833)\ttotal: 28.4s\tremaining: 33.3s\n",
      "7000:\tlearn: 0.2002746\ttest: 1.3613356\tbest: 1.3600428 (6978)\ttotal: 28.8s\tremaining: 32.9s\n",
      "7100:\tlearn: 0.1943801\ttest: 1.3596573\tbest: 1.3594621 (7072)\ttotal: 29.2s\tremaining: 32.5s\n",
      "7200:\tlearn: 0.1885778\ttest: 1.3558416\tbest: 1.3556957 (7199)\ttotal: 29.7s\tremaining: 32.1s\n",
      "7300:\tlearn: 0.1829773\ttest: 1.3545946\tbest: 1.3542498 (7299)\ttotal: 30.1s\tremaining: 31.7s\n",
      "7400:\tlearn: 0.1771580\ttest: 1.3516554\tbest: 1.3513941 (7394)\ttotal: 30.5s\tremaining: 31.3s\n",
      "7500:\tlearn: 0.1713387\ttest: 1.3471071\tbest: 1.3469868 (7495)\ttotal: 30.9s\tremaining: 30.9s\n",
      "7600:\tlearn: 0.1656216\ttest: 1.3460738\tbest: 1.3459710 (7599)\ttotal: 31.3s\tremaining: 30.5s\n",
      "7700:\tlearn: 0.1601522\ttest: 1.3415681\tbest: 1.3415681 (7700)\ttotal: 31.8s\tremaining: 30.1s\n",
      "7800:\tlearn: 0.1547655\ttest: 1.3398403\tbest: 1.3396850 (7796)\ttotal: 32.2s\tremaining: 29.7s\n",
      "7900:\tlearn: 0.1495045\ttest: 1.3379737\tbest: 1.3377645 (7895)\ttotal: 32.6s\tremaining: 29.3s\n",
      "8000:\tlearn: 0.1446437\ttest: 1.3368800\tbest: 1.3361043 (7971)\ttotal: 33s\tremaining: 28.9s\n",
      "8100:\tlearn: 0.1397920\ttest: 1.3363345\tbest: 1.3361043 (7971)\ttotal: 33.4s\tremaining: 28.5s\n",
      "8200:\tlearn: 0.1354755\ttest: 1.3337407\tbest: 1.3337407 (8200)\ttotal: 33.9s\tremaining: 28.1s\n",
      "8300:\tlearn: 0.1310292\ttest: 1.3307994\tbest: 1.3307994 (8300)\ttotal: 34.3s\tremaining: 27.7s\n",
      "8400:\tlearn: 0.1269765\ttest: 1.3303291\tbest: 1.3302437 (8390)\ttotal: 34.7s\tremaining: 27.3s\n",
      "8500:\tlearn: 0.1231198\ttest: 1.3268927\tbest: 1.3268863 (8497)\ttotal: 35.1s\tremaining: 26.9s\n",
      "8600:\tlearn: 0.1191679\ttest: 1.3232404\tbest: 1.3230591 (8590)\ttotal: 35.5s\tremaining: 26.4s\n",
      "8700:\tlearn: 0.1153941\ttest: 1.3189336\tbest: 1.3185293 (8696)\ttotal: 36s\tremaining: 26s\n",
      "8800:\tlearn: 0.1117773\ttest: 1.3166309\tbest: 1.3165998 (8799)\ttotal: 36.4s\tremaining: 25.6s\n",
      "8900:\tlearn: 0.1083716\ttest: 1.3134996\tbest: 1.3134506 (8899)\ttotal: 36.8s\tremaining: 25.2s\n",
      "9000:\tlearn: 0.1045037\ttest: 1.3101342\tbest: 1.3100576 (8995)\ttotal: 37.2s\tremaining: 24.8s\n",
      "9100:\tlearn: 0.1014340\ttest: 1.3065071\tbest: 1.3061739 (9083)\ttotal: 37.7s\tremaining: 24.4s\n",
      "9200:\tlearn: 0.0981565\ttest: 1.3039830\tbest: 1.3038125 (9191)\ttotal: 38.1s\tremaining: 24s\n",
      "9300:\tlearn: 0.0956154\ttest: 1.3029412\tbest: 1.3029412 (9300)\ttotal: 38.5s\tremaining: 23.6s\n",
      "9400:\tlearn: 0.0926594\ttest: 1.3010659\tbest: 1.3006142 (9375)\ttotal: 38.9s\tremaining: 23.2s\n",
      "9500:\tlearn: 0.0900986\ttest: 1.3004488\tbest: 1.2999587 (9473)\ttotal: 39.3s\tremaining: 22.8s\n",
      "9600:\tlearn: 0.0873072\ttest: 1.2992456\tbest: 1.2991352 (9588)\ttotal: 39.8s\tremaining: 22.4s\n",
      "9700:\tlearn: 0.0848191\ttest: 1.2978508\tbest: 1.2978508 (9700)\ttotal: 40.2s\tremaining: 21.9s\n",
      "9800:\tlearn: 0.0820019\ttest: 1.2979638\tbest: 1.2970344 (9762)\ttotal: 40.6s\tremaining: 21.5s\n",
      "9900:\tlearn: 0.0795193\ttest: 1.2967691\tbest: 1.2967031 (9894)\ttotal: 41s\tremaining: 21.1s\n",
      "10000:\tlearn: 0.0772447\ttest: 1.2959050\tbest: 1.2959031 (9999)\ttotal: 41.4s\tremaining: 20.7s\n",
      "10100:\tlearn: 0.0748166\ttest: 1.2936629\tbest: 1.2936629 (10100)\ttotal: 41.9s\tremaining: 20.3s\n",
      "10200:\tlearn: 0.0726748\ttest: 1.2911807\tbest: 1.2911442 (10194)\ttotal: 42.3s\tremaining: 19.9s\n",
      "10300:\tlearn: 0.0706399\ttest: 1.2887605\tbest: 1.2887605 (10300)\ttotal: 42.7s\tremaining: 19.5s\n",
      "10400:\tlearn: 0.0684133\ttest: 1.2859053\tbest: 1.2858900 (10399)\ttotal: 43.1s\tremaining: 19.1s\n",
      "10500:\tlearn: 0.0664056\ttest: 1.2826665\tbest: 1.2826665 (10500)\ttotal: 43.5s\tremaining: 18.7s\n",
      "10600:\tlearn: 0.0644143\ttest: 1.2809499\tbest: 1.2807299 (10598)\ttotal: 44s\tremaining: 18.2s\n",
      "10700:\tlearn: 0.0622763\ttest: 1.2803460\tbest: 1.2799105 (10621)\ttotal: 44.4s\tremaining: 17.8s\n",
      "10800:\tlearn: 0.0605309\ttest: 1.2797891\tbest: 1.2797322 (10799)\ttotal: 44.8s\tremaining: 17.4s\n",
      "10900:\tlearn: 0.0585487\ttest: 1.2791012\tbest: 1.2791012 (10900)\ttotal: 45.2s\tremaining: 17s\n",
      "11000:\tlearn: 0.0568807\ttest: 1.2785320\tbest: 1.2785320 (11000)\ttotal: 45.6s\tremaining: 16.6s\n",
      "11100:\tlearn: 0.0553304\ttest: 1.2769086\tbest: 1.2766382 (11086)\ttotal: 46.1s\tremaining: 16.2s\n",
      "11200:\tlearn: 0.0538812\ttest: 1.2755480\tbest: 1.2755480 (11200)\ttotal: 46.5s\tremaining: 15.8s\n",
      "11300:\tlearn: 0.0522125\ttest: 1.2735228\tbest: 1.2735228 (11300)\ttotal: 46.9s\tremaining: 15.4s\n",
      "11400:\tlearn: 0.0505864\ttest: 1.2724530\tbest: 1.2722718 (11384)\ttotal: 47.3s\tremaining: 14.9s\n",
      "11500:\tlearn: 0.0489946\ttest: 1.2716681\tbest: 1.2715613 (11441)\ttotal: 47.7s\tremaining: 14.5s\n",
      "11600:\tlearn: 0.0476921\ttest: 1.2699263\tbest: 1.2698699 (11597)\ttotal: 48.2s\tremaining: 14.1s\n",
      "11700:\tlearn: 0.0463005\ttest: 1.2685342\tbest: 1.2684123 (11694)\ttotal: 48.6s\tremaining: 13.7s\n",
      "11800:\tlearn: 0.0449965\ttest: 1.2679702\tbest: 1.2678867 (11748)\ttotal: 49s\tremaining: 13.3s\n",
      "11900:\tlearn: 0.0434223\ttest: 1.2673901\tbest: 1.2673744 (11899)\ttotal: 49.4s\tremaining: 12.9s\n",
      "12000:\tlearn: 0.0420898\ttest: 1.2674037\tbest: 1.2672793 (11991)\ttotal: 49.9s\tremaining: 12.5s\n",
      "12100:\tlearn: 0.0408477\ttest: 1.2664122\tbest: 1.2663820 (12097)\ttotal: 50.3s\tremaining: 12s\n",
      "12200:\tlearn: 0.0395626\ttest: 1.2662060\tbest: 1.2659769 (12140)\ttotal: 50.7s\tremaining: 11.6s\n",
      "12300:\tlearn: 0.0381602\ttest: 1.2653187\tbest: 1.2653187 (12300)\ttotal: 51.1s\tremaining: 11.2s\n",
      "12400:\tlearn: 0.0370044\ttest: 1.2657620\tbest: 1.2651642 (12347)\ttotal: 51.5s\tremaining: 10.8s\n",
      "12500:\tlearn: 0.0356041\ttest: 1.2650721\tbest: 1.2647462 (12491)\ttotal: 52s\tremaining: 10.4s\n",
      "12600:\tlearn: 0.0344698\ttest: 1.2647830\tbest: 1.2645652 (12598)\ttotal: 52.4s\tremaining: 9.97s\n",
      "12700:\tlearn: 0.0333444\ttest: 1.2643466\tbest: 1.2643049 (12699)\ttotal: 52.8s\tremaining: 9.56s\n",
      "12800:\tlearn: 0.0323121\ttest: 1.2629762\tbest: 1.2629513 (12792)\ttotal: 53.2s\tremaining: 9.14s\n",
      "12900:\tlearn: 0.0313819\ttest: 1.2630432\tbest: 1.2627382 (12864)\ttotal: 53.6s\tremaining: 8.73s\n",
      "13000:\tlearn: 0.0303831\ttest: 1.2624019\tbest: 1.2622526 (12981)\ttotal: 54.1s\tremaining: 8.31s\n",
      "13100:\tlearn: 0.0294498\ttest: 1.2606119\tbest: 1.2605688 (13069)\ttotal: 54.5s\tremaining: 7.9s\n",
      "13200:\tlearn: 0.0284197\ttest: 1.2598663\tbest: 1.2595959 (13168)\ttotal: 54.9s\tremaining: 7.48s\n",
      "13300:\tlearn: 0.0275497\ttest: 1.2586383\tbest: 1.2586383 (13300)\ttotal: 55.3s\tremaining: 7.07s\n",
      "13400:\tlearn: 0.0266346\ttest: 1.2587605\tbest: 1.2585119 (13393)\ttotal: 55.7s\tremaining: 6.65s\n",
      "13500:\tlearn: 0.0258348\ttest: 1.2581655\tbest: 1.2581641 (13499)\ttotal: 56.2s\tremaining: 6.23s\n",
      "13600:\tlearn: 0.0251271\ttest: 1.2584291\tbest: 1.2579196 (13512)\ttotal: 56.6s\tremaining: 5.82s\n",
      "13700:\tlearn: 0.0242929\ttest: 1.2580894\tbest: 1.2579196 (13512)\ttotal: 57s\tremaining: 5.4s\n",
      "13800:\tlearn: 0.0235138\ttest: 1.2582478\tbest: 1.2579196 (13512)\ttotal: 57.4s\tremaining: 4.99s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.257919604\n",
      "bestIteration = 13512\n",
      "\n",
      "Shrink model to first 13513 iterations.\n",
      "Скор для фолда(12) : 9.0 средний скор на префиксе = 9.0 это заняло = 58 сек.\n",
      "Фолд: 13\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "0:\tlearn: 3.5703591\ttest: 3.8774906\tbest: 3.8774906 (0)\ttotal: 52.5ms\tremaining: 13m 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 2.2451768\ttest: 2.7101555\tbest: 2.7101555 (100)\ttotal: 429ms\tremaining: 1m 3s\n",
      "200:\tlearn: 1.8278955\ttest: 2.2774447\tbest: 2.2774447 (200)\ttotal: 833ms\tremaining: 1m 1s\n",
      "300:\tlearn: 1.6435356\ttest: 2.1070696\tbest: 2.1070696 (300)\ttotal: 1.25s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5277810\ttest: 1.9934603\tbest: 1.9934603 (400)\ttotal: 1.67s\tremaining: 1m\n",
      "500:\tlearn: 1.4434127\ttest: 1.9021353\tbest: 1.9016791 (499)\ttotal: 2.07s\tremaining: 1m\n",
      "600:\tlearn: 1.3839069\ttest: 1.8483446\tbest: 1.8473074 (597)\ttotal: 2.49s\tremaining: 59.6s\n",
      "700:\tlearn: 1.3330710\ttest: 1.8096389\tbest: 1.8084086 (693)\ttotal: 2.9s\tremaining: 59.1s\n",
      "800:\tlearn: 1.2940991\ttest: 1.7747221\tbest: 1.7743251 (796)\ttotal: 3.3s\tremaining: 58.6s\n",
      "900:\tlearn: 1.2536001\ttest: 1.7418086\tbest: 1.7418086 (900)\ttotal: 3.71s\tremaining: 58.1s\n",
      "1000:\tlearn: 1.2181969\ttest: 1.7216079\tbest: 1.7216079 (1000)\ttotal: 4.12s\tremaining: 57.6s\n",
      "1100:\tlearn: 1.1860602\ttest: 1.7005914\tbest: 1.7005914 (1100)\ttotal: 4.53s\tremaining: 57.2s\n",
      "1200:\tlearn: 1.1539154\ttest: 1.6731583\tbest: 1.6729018 (1196)\ttotal: 4.94s\tremaining: 56.8s\n",
      "1300:\tlearn: 1.1211130\ttest: 1.6560170\tbest: 1.6560170 (1300)\ttotal: 5.35s\tremaining: 56.3s\n",
      "1400:\tlearn: 1.0881492\ttest: 1.6332460\tbest: 1.6332197 (1399)\ttotal: 5.76s\tremaining: 55.9s\n",
      "1500:\tlearn: 1.0581853\ttest: 1.6140848\tbest: 1.6140848 (1500)\ttotal: 6.17s\tremaining: 55.5s\n",
      "1600:\tlearn: 1.0245413\ttest: 1.5987364\tbest: 1.5986990 (1596)\ttotal: 6.58s\tremaining: 55.1s\n",
      "1700:\tlearn: 0.9922769\ttest: 1.5832735\tbest: 1.5830485 (1697)\ttotal: 6.99s\tremaining: 54.7s\n",
      "1800:\tlearn: 0.9582398\ttest: 1.5667781\tbest: 1.5667781 (1800)\ttotal: 7.4s\tremaining: 54.3s\n",
      "1900:\tlearn: 0.9285598\ttest: 1.5582242\tbest: 1.5578272 (1893)\ttotal: 7.82s\tremaining: 53.9s\n",
      "2000:\tlearn: 0.8988964\ttest: 1.5470578\tbest: 1.5470578 (2000)\ttotal: 8.23s\tremaining: 53.5s\n",
      "2100:\tlearn: 0.8714972\ttest: 1.5340839\tbest: 1.5337843 (2095)\ttotal: 8.64s\tremaining: 53.1s\n",
      "2200:\tlearn: 0.8460107\ttest: 1.5216714\tbest: 1.5216305 (2196)\ttotal: 9.05s\tremaining: 52.7s\n",
      "2300:\tlearn: 0.8191561\ttest: 1.5035435\tbest: 1.5035435 (2300)\ttotal: 9.47s\tremaining: 52.2s\n",
      "2400:\tlearn: 0.7911021\ttest: 1.4887816\tbest: 1.4887816 (2400)\ttotal: 9.88s\tremaining: 51.8s\n",
      "2500:\tlearn: 0.7676710\ttest: 1.4772963\tbest: 1.4772963 (2500)\ttotal: 10.3s\tremaining: 51.4s\n",
      "2600:\tlearn: 0.7439739\ttest: 1.4691823\tbest: 1.4691823 (2600)\ttotal: 10.7s\tremaining: 51.1s\n",
      "2700:\tlearn: 0.7190533\ttest: 1.4619901\tbest: 1.4619801 (2699)\ttotal: 11.1s\tremaining: 50.6s\n",
      "2800:\tlearn: 0.6961090\ttest: 1.4508511\tbest: 1.4507679 (2799)\ttotal: 11.5s\tremaining: 50.2s\n",
      "2900:\tlearn: 0.6747135\ttest: 1.4438963\tbest: 1.4438255 (2899)\ttotal: 11.9s\tremaining: 49.8s\n",
      "3000:\tlearn: 0.6524261\ttest: 1.4399540\tbest: 1.4399355 (2998)\ttotal: 12.4s\tremaining: 49.4s\n",
      "3100:\tlearn: 0.6331398\ttest: 1.4368154\tbest: 1.4364525 (3099)\ttotal: 12.8s\tremaining: 49s\n",
      "3200:\tlearn: 0.6138242\ttest: 1.4291953\tbest: 1.4291738 (3199)\ttotal: 13.2s\tremaining: 48.7s\n",
      "3300:\tlearn: 0.5943010\ttest: 1.4229921\tbest: 1.4228278 (3298)\ttotal: 13.6s\tremaining: 48.3s\n",
      "3400:\tlearn: 0.5745555\ttest: 1.4187548\tbest: 1.4187548 (3400)\ttotal: 14s\tremaining: 47.9s\n",
      "3500:\tlearn: 0.5572110\ttest: 1.4145073\tbest: 1.4145073 (3500)\ttotal: 14.5s\tremaining: 47.5s\n",
      "3600:\tlearn: 0.5401510\ttest: 1.4076295\tbest: 1.4076295 (3600)\ttotal: 14.9s\tremaining: 47.1s\n",
      "3700:\tlearn: 0.5251339\ttest: 1.4058166\tbest: 1.4056793 (3699)\ttotal: 15.3s\tremaining: 46.7s\n",
      "3800:\tlearn: 0.5095603\ttest: 1.4032127\tbest: 1.4032127 (3800)\ttotal: 15.7s\tremaining: 46.3s\n",
      "3900:\tlearn: 0.4937017\ttest: 1.3967350\tbest: 1.3966707 (3894)\ttotal: 16.1s\tremaining: 45.9s\n",
      "4000:\tlearn: 0.4778923\ttest: 1.3895213\tbest: 1.3895213 (4000)\ttotal: 16.5s\tremaining: 45.4s\n",
      "4100:\tlearn: 0.4637727\ttest: 1.3831293\tbest: 1.3831293 (4100)\ttotal: 17s\tremaining: 45.1s\n",
      "4200:\tlearn: 0.4518220\ttest: 1.3766274\tbest: 1.3765935 (4195)\ttotal: 17.4s\tremaining: 44.6s\n",
      "4300:\tlearn: 0.4379890\ttest: 1.3696378\tbest: 1.3692016 (4298)\ttotal: 17.8s\tremaining: 44.2s\n",
      "4400:\tlearn: 0.4235699\ttest: 1.3653732\tbest: 1.3652553 (4398)\ttotal: 18.2s\tremaining: 43.8s\n",
      "4500:\tlearn: 0.4094973\ttest: 1.3584756\tbest: 1.3579144 (4489)\ttotal: 18.6s\tremaining: 43.4s\n",
      "4600:\tlearn: 0.3960043\ttest: 1.3561048\tbest: 1.3561048 (4600)\ttotal: 19s\tremaining: 43s\n",
      "4700:\tlearn: 0.3843377\ttest: 1.3526904\tbest: 1.3522038 (4689)\ttotal: 19.5s\tremaining: 42.6s\n",
      "4800:\tlearn: 0.3727041\ttest: 1.3479944\tbest: 1.3479944 (4800)\ttotal: 19.9s\tremaining: 42.2s\n",
      "4900:\tlearn: 0.3613110\ttest: 1.3446830\tbest: 1.3444452 (4865)\ttotal: 20.3s\tremaining: 41.8s\n",
      "5000:\tlearn: 0.3509869\ttest: 1.3430258\tbest: 1.3430258 (5000)\ttotal: 20.7s\tremaining: 41.4s\n",
      "5100:\tlearn: 0.3393210\ttest: 1.3375401\tbest: 1.3373902 (5098)\ttotal: 21.1s\tremaining: 41s\n",
      "5200:\tlearn: 0.3288683\ttest: 1.3359709\tbest: 1.3351035 (5191)\ttotal: 21.6s\tremaining: 40.6s\n",
      "5300:\tlearn: 0.3179297\ttest: 1.3336043\tbest: 1.3329958 (5287)\ttotal: 22s\tremaining: 40.2s\n",
      "5400:\tlearn: 0.3088122\ttest: 1.3314610\tbest: 1.3309193 (5388)\ttotal: 22.4s\tremaining: 39.8s\n",
      "5500:\tlearn: 0.2986691\ttest: 1.3294091\tbest: 1.3287178 (5440)\ttotal: 22.8s\tremaining: 39.4s\n",
      "5600:\tlearn: 0.2899122\ttest: 1.3239595\tbest: 1.3238607 (5596)\ttotal: 23.2s\tremaining: 39s\n",
      "5700:\tlearn: 0.2807217\ttest: 1.3179254\tbest: 1.3179098 (5692)\ttotal: 23.6s\tremaining: 38.6s\n",
      "5800:\tlearn: 0.2724324\ttest: 1.3152352\tbest: 1.3151883 (5798)\ttotal: 24.1s\tremaining: 38.2s\n",
      "5900:\tlearn: 0.2640584\ttest: 1.3141306\tbest: 1.3140823 (5890)\ttotal: 24.5s\tremaining: 37.8s\n",
      "6000:\tlearn: 0.2557793\ttest: 1.3097593\tbest: 1.3097593 (6000)\ttotal: 24.9s\tremaining: 37.3s\n",
      "6100:\tlearn: 0.2474105\ttest: 1.3085171\tbest: 1.3082972 (6075)\ttotal: 25.3s\tremaining: 36.9s\n",
      "6200:\tlearn: 0.2400963\ttest: 1.3074243\tbest: 1.3064325 (6194)\ttotal: 25.7s\tremaining: 36.5s\n",
      "6300:\tlearn: 0.2321958\ttest: 1.3041971\tbest: 1.3041204 (6298)\ttotal: 26.2s\tremaining: 36.1s\n",
      "6400:\tlearn: 0.2257856\ttest: 1.3026281\tbest: 1.3025090 (6397)\ttotal: 26.6s\tremaining: 35.7s\n",
      "6500:\tlearn: 0.2184683\ttest: 1.3003382\tbest: 1.2996954 (6481)\ttotal: 27s\tremaining: 35.3s\n",
      "6600:\tlearn: 0.2114849\ttest: 1.2991346\tbest: 1.2987870 (6578)\ttotal: 27.4s\tremaining: 34.9s\n",
      "6700:\tlearn: 0.2043009\ttest: 1.2957472\tbest: 1.2954697 (6695)\ttotal: 27.8s\tremaining: 34.5s\n",
      "6800:\tlearn: 0.1975239\ttest: 1.2903010\tbest: 1.2893807 (6789)\ttotal: 28.3s\tremaining: 34.1s\n",
      "6900:\tlearn: 0.1916091\ttest: 1.2896136\tbest: 1.2893112 (6837)\ttotal: 28.7s\tremaining: 33.7s\n",
      "7000:\tlearn: 0.1856809\ttest: 1.2868145\tbest: 1.2868145 (7000)\ttotal: 29.1s\tremaining: 33.2s\n",
      "7100:\tlearn: 0.1803372\ttest: 1.2843734\tbest: 1.2843734 (7100)\ttotal: 29.5s\tremaining: 32.8s\n",
      "7200:\tlearn: 0.1737465\ttest: 1.2842601\tbest: 1.2827706 (7132)\ttotal: 29.9s\tremaining: 32.4s\n",
      "7300:\tlearn: 0.1684299\ttest: 1.2837707\tbest: 1.2827706 (7132)\ttotal: 30.4s\tremaining: 32s\n",
      "7400:\tlearn: 0.1627148\ttest: 1.2833621\tbest: 1.2823791 (7319)\ttotal: 30.8s\tremaining: 31.6s\n",
      "7500:\tlearn: 0.1572057\ttest: 1.2819797\tbest: 1.2813357 (7480)\ttotal: 31.2s\tremaining: 31.2s\n",
      "7600:\tlearn: 0.1523005\ttest: 1.2811422\tbest: 1.2810142 (7593)\ttotal: 31.6s\tremaining: 30.8s\n",
      "7700:\tlearn: 0.1478822\ttest: 1.2784724\tbest: 1.2784724 (7700)\ttotal: 32s\tremaining: 30.4s\n",
      "7800:\tlearn: 0.1433015\ttest: 1.2782201\tbest: 1.2768731 (7733)\ttotal: 32.4s\tremaining: 29.9s\n",
      "7900:\tlearn: 0.1392951\ttest: 1.2771430\tbest: 1.2768731 (7733)\ttotal: 32.9s\tremaining: 29.5s\n",
      "8000:\tlearn: 0.1354570\ttest: 1.2767060\tbest: 1.2766153 (7999)\ttotal: 33.3s\tremaining: 29.1s\n",
      "8100:\tlearn: 0.1313962\ttest: 1.2749282\tbest: 1.2747597 (8098)\ttotal: 33.7s\tremaining: 28.7s\n",
      "8200:\tlearn: 0.1278183\ttest: 1.2744785\tbest: 1.2739262 (8179)\ttotal: 34.1s\tremaining: 28.3s\n",
      "8300:\tlearn: 0.1237300\ttest: 1.2729871\tbest: 1.2729322 (8296)\ttotal: 34.5s\tremaining: 27.9s\n",
      "8400:\tlearn: 0.1200751\ttest: 1.2734758\tbest: 1.2725733 (8305)\ttotal: 35s\tremaining: 27.5s\n",
      "8500:\tlearn: 0.1163137\ttest: 1.2734623\tbest: 1.2725733 (8305)\ttotal: 35.4s\tremaining: 27.1s\n",
      "8600:\tlearn: 0.1126991\ttest: 1.2729656\tbest: 1.2719996 (8569)\ttotal: 35.8s\tremaining: 26.6s\n",
      "8700:\tlearn: 0.1091552\ttest: 1.2713956\tbest: 1.2713749 (8697)\ttotal: 36.2s\tremaining: 26.2s\n",
      "8800:\tlearn: 0.1061867\ttest: 1.2723362\tbest: 1.2710847 (8721)\ttotal: 36.6s\tremaining: 25.8s\n",
      "8900:\tlearn: 0.1029306\ttest: 1.2717761\tbest: 1.2710847 (8721)\ttotal: 37.1s\tremaining: 25.4s\n",
      "9000:\tlearn: 0.0997419\ttest: 1.2704012\tbest: 1.2700667 (8973)\ttotal: 37.5s\tremaining: 25s\n",
      "9100:\tlearn: 0.0966651\ttest: 1.2684026\tbest: 1.2678838 (9088)\ttotal: 37.9s\tremaining: 24.6s\n",
      "9200:\tlearn: 0.0935005\ttest: 1.2675690\tbest: 1.2671254 (9177)\ttotal: 38.3s\tremaining: 24.2s\n",
      "9300:\tlearn: 0.0908402\ttest: 1.2671077\tbest: 1.2669083 (9248)\ttotal: 38.8s\tremaining: 23.7s\n",
      "9400:\tlearn: 0.0880430\ttest: 1.2653158\tbest: 1.2652915 (9398)\ttotal: 39.2s\tremaining: 23.3s\n",
      "9500:\tlearn: 0.0855040\ttest: 1.2650601\tbest: 1.2648338 (9432)\ttotal: 39.6s\tremaining: 22.9s\n",
      "9600:\tlearn: 0.0829974\ttest: 1.2620714\tbest: 1.2620714 (9600)\ttotal: 40s\tremaining: 22.5s\n",
      "9700:\tlearn: 0.0804760\ttest: 1.2610683\tbest: 1.2601805 (9673)\ttotal: 40.4s\tremaining: 22.1s\n",
      "9800:\tlearn: 0.0778702\ttest: 1.2601068\tbest: 1.2596803 (9761)\ttotal: 40.9s\tremaining: 21.7s\n",
      "9900:\tlearn: 0.0752020\ttest: 1.2600005\tbest: 1.2595603 (9845)\ttotal: 41.3s\tremaining: 21.3s\n",
      "10000:\tlearn: 0.0729928\ttest: 1.2609614\tbest: 1.2595603 (9845)\ttotal: 41.7s\tremaining: 20.8s\n",
      "10100:\tlearn: 0.0708861\ttest: 1.2608748\tbest: 1.2595603 (9845)\ttotal: 42.1s\tremaining: 20.4s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.259560294\n",
      "bestIteration = 9845\n",
      "\n",
      "Shrink model to first 9846 iterations.\n",
      "Скор для фолда(13) : 9.0 средний скор на префиксе = 9.0 это заняло = 42 сек.\n",
      "Фолд: 14\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "0:\tlearn: 3.6212224\ttest: 3.3030188\tbest: 3.3030188 (0)\ttotal: 52.1ms\tremaining: 13m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 2.2909616\ttest: 1.9735892\tbest: 1.9735892 (100)\ttotal: 431ms\tremaining: 1m 3s\n",
      "200:\tlearn: 1.8833660\ttest: 1.6089466\tbest: 1.6089466 (200)\ttotal: 839ms\tremaining: 1m 1s\n",
      "300:\tlearn: 1.6926518\ttest: 1.4698206\tbest: 1.4698206 (300)\ttotal: 1.26s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5732936\ttest: 1.4194986\tbest: 1.4194986 (400)\ttotal: 1.67s\tremaining: 1m\n",
      "500:\tlearn: 1.4918474\ttest: 1.3985310\tbest: 1.3978291 (495)\ttotal: 2.08s\tremaining: 1m\n",
      "600:\tlearn: 1.4308692\ttest: 1.3994373\tbest: 1.3938539 (532)\ttotal: 2.5s\tremaining: 59.8s\n",
      "700:\tlearn: 1.3789152\ttest: 1.3806574\tbest: 1.3806574 (700)\ttotal: 2.91s\tremaining: 59.4s\n",
      "800:\tlearn: 1.3331137\ttest: 1.3721648\tbest: 1.3710821 (754)\ttotal: 3.32s\tremaining: 58.9s\n",
      "900:\tlearn: 1.2912423\ttest: 1.3638892\tbest: 1.3629718 (888)\ttotal: 3.73s\tremaining: 58.4s\n",
      "1000:\tlearn: 1.2510510\ttest: 1.3597785\tbest: 1.3597785 (1000)\ttotal: 4.13s\tremaining: 57.8s\n",
      "1100:\tlearn: 1.2159348\ttest: 1.3557855\tbest: 1.3552232 (1099)\ttotal: 4.54s\tremaining: 57.3s\n",
      "1200:\tlearn: 1.1752795\ttest: 1.3506437\tbest: 1.3504786 (1198)\ttotal: 4.95s\tremaining: 56.9s\n",
      "1300:\tlearn: 1.1438830\ttest: 1.3440528\tbest: 1.3440528 (1300)\ttotal: 5.36s\tremaining: 56.5s\n",
      "1400:\tlearn: 1.1135234\ttest: 1.3417568\tbest: 1.3405735 (1398)\ttotal: 5.78s\tremaining: 56.1s\n",
      "1500:\tlearn: 1.0799616\ttest: 1.3307433\tbest: 1.3305712 (1499)\ttotal: 6.18s\tremaining: 55.6s\n",
      "1600:\tlearn: 1.0505341\ttest: 1.3244200\tbest: 1.3233954 (1592)\ttotal: 6.59s\tremaining: 55.2s\n",
      "1700:\tlearn: 1.0208303\ttest: 1.3155405\tbest: 1.3149670 (1686)\ttotal: 7s\tremaining: 54.7s\n",
      "1800:\tlearn: 0.9910607\ttest: 1.3072682\tbest: 1.3072181 (1799)\ttotal: 7.41s\tremaining: 54.3s\n",
      "1900:\tlearn: 0.9607893\ttest: 1.3031261\tbest: 1.3029466 (1899)\ttotal: 7.82s\tremaining: 53.9s\n",
      "2000:\tlearn: 0.9305171\ttest: 1.2971631\tbest: 1.2967522 (1994)\ttotal: 8.23s\tremaining: 53.5s\n",
      "2100:\tlearn: 0.9017910\ttest: 1.2915012\tbest: 1.2907950 (2097)\ttotal: 8.64s\tremaining: 53s\n",
      "2200:\tlearn: 0.8761510\ttest: 1.2849708\tbest: 1.2848957 (2197)\ttotal: 9.05s\tremaining: 52.6s\n",
      "2300:\tlearn: 0.8506050\ttest: 1.2778554\tbest: 1.2778374 (2299)\ttotal: 9.46s\tremaining: 52.2s\n",
      "2400:\tlearn: 0.8262992\ttest: 1.2699114\tbest: 1.2699114 (2400)\ttotal: 9.87s\tremaining: 51.8s\n",
      "2500:\tlearn: 0.8052819\ttest: 1.2610824\tbest: 1.2610824 (2500)\ttotal: 10.3s\tremaining: 51.4s\n",
      "2600:\tlearn: 0.7797747\ttest: 1.2586554\tbest: 1.2586554 (2600)\ttotal: 10.7s\tremaining: 51s\n",
      "2700:\tlearn: 0.7575115\ttest: 1.2558636\tbest: 1.2554163 (2696)\ttotal: 11.1s\tremaining: 50.5s\n",
      "2800:\tlearn: 0.7362577\ttest: 1.2478347\tbest: 1.2478256 (2799)\ttotal: 11.5s\tremaining: 50.1s\n",
      "2900:\tlearn: 0.7163947\ttest: 1.2405837\tbest: 1.2405758 (2899)\ttotal: 11.9s\tremaining: 49.7s\n",
      "3000:\tlearn: 0.6964826\ttest: 1.2361220\tbest: 1.2361220 (3000)\ttotal: 12.3s\tremaining: 49.3s\n",
      "3100:\tlearn: 0.6774256\ttest: 1.2250310\tbest: 1.2248731 (3096)\ttotal: 12.7s\tremaining: 48.9s\n",
      "3200:\tlearn: 0.6571811\ttest: 1.2153569\tbest: 1.2151722 (3199)\ttotal: 13.2s\tremaining: 48.5s\n",
      "3300:\tlearn: 0.6379513\ttest: 1.2109200\tbest: 1.2107042 (3298)\ttotal: 13.6s\tremaining: 48.1s\n",
      "3400:\tlearn: 0.6212594\ttest: 1.2094001\tbest: 1.2094001 (3400)\ttotal: 14s\tremaining: 47.7s\n",
      "3500:\tlearn: 0.6029534\ttest: 1.2069866\tbest: 1.2063820 (3495)\ttotal: 14.4s\tremaining: 47.3s\n",
      "3600:\tlearn: 0.5847119\ttest: 1.2022474\tbest: 1.2022222 (3599)\ttotal: 14.8s\tremaining: 46.9s\n",
      "3700:\tlearn: 0.5670837\ttest: 1.1981868\tbest: 1.1971837 (3679)\ttotal: 15.2s\tremaining: 46.5s\n",
      "3800:\tlearn: 0.5494096\ttest: 1.1925620\tbest: 1.1918679 (3796)\ttotal: 15.6s\tremaining: 46.1s\n",
      "3900:\tlearn: 0.5332021\ttest: 1.1865956\tbest: 1.1865956 (3900)\ttotal: 16.1s\tremaining: 45.7s\n",
      "4000:\tlearn: 0.5184107\ttest: 1.1823270\tbest: 1.1807665 (3990)\ttotal: 16.5s\tremaining: 45.3s\n",
      "4100:\tlearn: 0.5032707\ttest: 1.1828580\tbest: 1.1807665 (3990)\ttotal: 16.9s\tremaining: 44.9s\n",
      "4200:\tlearn: 0.4884959\ttest: 1.1801988\tbest: 1.1801988 (4200)\ttotal: 17.3s\tremaining: 44.5s\n",
      "4300:\tlearn: 0.4736091\ttest: 1.1758126\tbest: 1.1758126 (4300)\ttotal: 17.7s\tremaining: 44.1s\n",
      "4400:\tlearn: 0.4613683\ttest: 1.1726630\tbest: 1.1722198 (4367)\ttotal: 18.1s\tremaining: 43.7s\n",
      "4500:\tlearn: 0.4475936\ttest: 1.1687365\tbest: 1.1687365 (4500)\ttotal: 18.5s\tremaining: 43.3s\n",
      "4600:\tlearn: 0.4329127\ttest: 1.1628731\tbest: 1.1622801 (4590)\ttotal: 19s\tremaining: 42.9s\n",
      "4700:\tlearn: 0.4198848\ttest: 1.1594284\tbest: 1.1594284 (4700)\ttotal: 19.4s\tremaining: 42.5s\n",
      "4800:\tlearn: 0.4057899\ttest: 1.1582772\tbest: 1.1560893 (4747)\ttotal: 19.8s\tremaining: 42.1s\n",
      "4900:\tlearn: 0.3951636\ttest: 1.1561695\tbest: 1.1560460 (4895)\ttotal: 20.2s\tremaining: 41.7s\n",
      "5000:\tlearn: 0.3810449\ttest: 1.1515344\tbest: 1.1515344 (5000)\ttotal: 20.6s\tremaining: 41.3s\n",
      "5100:\tlearn: 0.3698348\ttest: 1.1462622\tbest: 1.1461208 (5099)\ttotal: 21.1s\tremaining: 40.9s\n",
      "5200:\tlearn: 0.3582764\ttest: 1.1460897\tbest: 1.1449312 (5185)\ttotal: 21.5s\tremaining: 40.4s\n",
      "5300:\tlearn: 0.3478575\ttest: 1.1445937\tbest: 1.1439769 (5235)\ttotal: 21.9s\tremaining: 40.1s\n",
      "5400:\tlearn: 0.3377305\ttest: 1.1438712\tbest: 1.1431767 (5386)\ttotal: 22.3s\tremaining: 39.7s\n",
      "5500:\tlearn: 0.3273965\ttest: 1.1420529\tbest: 1.1417354 (5478)\ttotal: 22.7s\tremaining: 39.2s\n",
      "5600:\tlearn: 0.3189313\ttest: 1.1384028\tbest: 1.1377228 (5592)\ttotal: 23.1s\tremaining: 38.8s\n",
      "5700:\tlearn: 0.3086148\ttest: 1.1351058\tbest: 1.1351058 (5700)\ttotal: 23.6s\tremaining: 38.4s\n",
      "5800:\tlearn: 0.2984494\ttest: 1.1317012\tbest: 1.1314322 (5797)\ttotal: 24s\tremaining: 38s\n",
      "5900:\tlearn: 0.2902730\ttest: 1.1305907\tbest: 1.1305907 (5900)\ttotal: 24.4s\tremaining: 37.6s\n",
      "6000:\tlearn: 0.2811098\ttest: 1.1282928\tbest: 1.1279956 (5985)\ttotal: 24.8s\tremaining: 37.2s\n",
      "6100:\tlearn: 0.2732588\ttest: 1.1260805\tbest: 1.1260805 (6100)\ttotal: 25.2s\tremaining: 36.8s\n",
      "6200:\tlearn: 0.2648487\ttest: 1.1251608\tbest: 1.1247403 (6185)\ttotal: 25.7s\tremaining: 36.4s\n",
      "6300:\tlearn: 0.2567845\ttest: 1.1214481\tbest: 1.1211877 (6297)\ttotal: 26.1s\tremaining: 36s\n",
      "6400:\tlearn: 0.2493204\ttest: 1.1186167\tbest: 1.1184829 (6386)\ttotal: 26.5s\tremaining: 35.6s\n",
      "6500:\tlearn: 0.2418817\ttest: 1.1160301\tbest: 1.1158199 (6489)\ttotal: 26.9s\tremaining: 35.2s\n",
      "6600:\tlearn: 0.2352134\ttest: 1.1152200\tbest: 1.1150788 (6515)\ttotal: 27.3s\tremaining: 34.8s\n",
      "6700:\tlearn: 0.2275882\ttest: 1.1142808\tbest: 1.1138424 (6658)\ttotal: 27.7s\tremaining: 34.4s\n",
      "6800:\tlearn: 0.2210436\ttest: 1.1122747\tbest: 1.1120559 (6797)\ttotal: 28.2s\tremaining: 34s\n",
      "6900:\tlearn: 0.2142480\ttest: 1.1067622\tbest: 1.1067406 (6898)\ttotal: 28.6s\tremaining: 33.5s\n",
      "7000:\tlearn: 0.2071175\ttest: 1.1055856\tbest: 1.1055110 (6974)\ttotal: 29s\tremaining: 33.1s\n",
      "7100:\tlearn: 0.2009929\ttest: 1.1033985\tbest: 1.1024826 (7092)\ttotal: 29.4s\tremaining: 32.7s\n",
      "7200:\tlearn: 0.1955126\ttest: 1.1026877\tbest: 1.1024826 (7092)\ttotal: 29.8s\tremaining: 32.3s\n",
      "7300:\tlearn: 0.1895875\ttest: 1.1022585\tbest: 1.1020009 (7229)\ttotal: 30.2s\tremaining: 31.9s\n",
      "7400:\tlearn: 0.1838823\ttest: 1.1020377\tbest: 1.1017283 (7395)\ttotal: 30.7s\tremaining: 31.5s\n",
      "7500:\tlearn: 0.1782256\ttest: 1.0990666\tbest: 1.0988239 (7496)\ttotal: 31.1s\tremaining: 31.1s\n",
      "7600:\tlearn: 0.1729319\ttest: 1.0984470\tbest: 1.0978761 (7592)\ttotal: 31.5s\tremaining: 30.7s\n",
      "7700:\tlearn: 0.1676407\ttest: 1.0975591\tbest: 1.0973258 (7696)\ttotal: 31.9s\tremaining: 30.3s\n",
      "7800:\tlearn: 0.1631361\ttest: 1.0971767\tbest: 1.0966926 (7773)\ttotal: 32.3s\tremaining: 29.8s\n",
      "7900:\tlearn: 0.1576997\ttest: 1.0941418\tbest: 1.0941084 (7899)\ttotal: 32.8s\tremaining: 29.4s\n",
      "8000:\tlearn: 0.1526846\ttest: 1.0927131\tbest: 1.0927131 (8000)\ttotal: 33.2s\tremaining: 29s\n",
      "8100:\tlearn: 0.1479695\ttest: 1.0910411\tbest: 1.0907972 (8093)\ttotal: 33.6s\tremaining: 28.6s\n",
      "8200:\tlearn: 0.1431990\ttest: 1.0905382\tbest: 1.0903775 (8160)\ttotal: 34s\tremaining: 28.2s\n",
      "8300:\tlearn: 0.1390795\ttest: 1.0875988\tbest: 1.0875240 (8289)\ttotal: 34.4s\tremaining: 27.8s\n",
      "8400:\tlearn: 0.1347852\ttest: 1.0866833\tbest: 1.0866546 (8399)\ttotal: 34.8s\tremaining: 27.4s\n",
      "8500:\tlearn: 0.1304533\ttest: 1.0845516\tbest: 1.0845516 (8500)\ttotal: 35.3s\tremaining: 27s\n",
      "8600:\tlearn: 0.1261702\ttest: 1.0812021\tbest: 1.0811080 (8598)\ttotal: 35.7s\tremaining: 26.6s\n",
      "8700:\tlearn: 0.1223325\ttest: 1.0793991\tbest: 1.0793991 (8700)\ttotal: 36.1s\tremaining: 26.1s\n",
      "8800:\tlearn: 0.1187522\ttest: 1.0789105\tbest: 1.0787786 (8799)\ttotal: 36.5s\tremaining: 25.7s\n",
      "8900:\tlearn: 0.1155263\ttest: 1.0767592\tbest: 1.0763994 (8872)\ttotal: 37s\tremaining: 25.3s\n",
      "9000:\tlearn: 0.1119250\ttest: 1.0771428\tbest: 1.0763994 (8872)\ttotal: 37.4s\tremaining: 24.9s\n",
      "9100:\tlearn: 0.1085143\ttest: 1.0756964\tbest: 1.0756964 (9100)\ttotal: 37.8s\tremaining: 24.5s\n",
      "9200:\tlearn: 0.1051773\ttest: 1.0745805\tbest: 1.0742236 (9160)\ttotal: 38.2s\tremaining: 24.1s\n",
      "9300:\tlearn: 0.1015039\ttest: 1.0725094\tbest: 1.0724301 (9297)\ttotal: 38.6s\tremaining: 23.7s\n",
      "9400:\tlearn: 0.0983449\ttest: 1.0701645\tbest: 1.0699385 (9398)\ttotal: 39s\tremaining: 23.3s\n",
      "9500:\tlearn: 0.0956482\ttest: 1.0687431\tbest: 1.0687341 (9497)\ttotal: 39.5s\tremaining: 22.8s\n",
      "9600:\tlearn: 0.0930494\ttest: 1.0678304\tbest: 1.0675339 (9593)\ttotal: 39.9s\tremaining: 22.4s\n",
      "9700:\tlearn: 0.0904514\ttest: 1.0668141\tbest: 1.0662970 (9655)\ttotal: 40.3s\tremaining: 22s\n",
      "9800:\tlearn: 0.0876422\ttest: 1.0652764\tbest: 1.0651750 (9784)\ttotal: 40.7s\tremaining: 21.6s\n",
      "9900:\tlearn: 0.0850351\ttest: 1.0645268\tbest: 1.0639741 (9850)\ttotal: 41.1s\tremaining: 21.2s\n",
      "10000:\tlearn: 0.0827644\ttest: 1.0633128\tbest: 1.0633110 (9999)\ttotal: 41.5s\tremaining: 20.8s\n",
      "10100:\tlearn: 0.0807161\ttest: 1.0622714\tbest: 1.0622714 (10100)\ttotal: 42s\tremaining: 20.4s\n",
      "10200:\tlearn: 0.0784100\ttest: 1.0614870\tbest: 1.0612499 (10188)\ttotal: 42.4s\tremaining: 19.9s\n",
      "10300:\tlearn: 0.0763451\ttest: 1.0600078\tbest: 1.0598778 (10291)\ttotal: 42.8s\tremaining: 19.5s\n",
      "10400:\tlearn: 0.0739709\ttest: 1.0580354\tbest: 1.0578890 (10381)\ttotal: 43.2s\tremaining: 19.1s\n",
      "10500:\tlearn: 0.0719522\ttest: 1.0562168\tbest: 1.0559724 (10497)\ttotal: 43.6s\tremaining: 18.7s\n",
      "10600:\tlearn: 0.0698890\ttest: 1.0555213\tbest: 1.0554157 (10562)\ttotal: 44.1s\tremaining: 18.3s\n",
      "10700:\tlearn: 0.0678362\ttest: 1.0530486\tbest: 1.0529981 (10698)\ttotal: 44.5s\tremaining: 17.9s\n",
      "10800:\tlearn: 0.0659878\ttest: 1.0529840\tbest: 1.0529579 (10775)\ttotal: 44.9s\tremaining: 17.5s\n",
      "10900:\tlearn: 0.0644194\ttest: 1.0536242\tbest: 1.0528485 (10805)\ttotal: 45.3s\tremaining: 17s\n",
      "11000:\tlearn: 0.0627470\ttest: 1.0536994\tbest: 1.0528485 (10805)\ttotal: 45.7s\tremaining: 16.6s\n",
      "11100:\tlearn: 0.0610003\ttest: 1.0523704\tbest: 1.0522848 (11098)\ttotal: 46.2s\tremaining: 16.2s\n",
      "11200:\tlearn: 0.0592532\ttest: 1.0501518\tbest: 1.0500053 (11197)\ttotal: 46.6s\tremaining: 15.8s\n",
      "11300:\tlearn: 0.0575090\ttest: 1.0480899\tbest: 1.0478473 (11298)\ttotal: 47s\tremaining: 15.4s\n",
      "11400:\tlearn: 0.0561484\ttest: 1.0472707\tbest: 1.0469497 (11377)\ttotal: 47.4s\tremaining: 15s\n",
      "11500:\tlearn: 0.0546249\ttest: 1.0484869\tbest: 1.0469443 (11409)\ttotal: 47.8s\tremaining: 14.6s\n",
      "11600:\tlearn: 0.0530838\ttest: 1.0472394\tbest: 1.0469443 (11409)\ttotal: 48.3s\tremaining: 14.1s\n",
      "11700:\tlearn: 0.0515968\ttest: 1.0470469\tbest: 1.0469392 (11611)\ttotal: 48.7s\tremaining: 13.7s\n",
      "11800:\tlearn: 0.0502496\ttest: 1.0463346\tbest: 1.0460546 (11792)\ttotal: 49.1s\tremaining: 13.3s\n",
      "11900:\tlearn: 0.0487427\ttest: 1.0453038\tbest: 1.0452379 (11894)\ttotal: 49.5s\tremaining: 12.9s\n",
      "12000:\tlearn: 0.0475121\ttest: 1.0445743\tbest: 1.0443813 (11993)\ttotal: 49.9s\tremaining: 12.5s\n",
      "12100:\tlearn: 0.0463572\ttest: 1.0440512\tbest: 1.0439604 (12095)\ttotal: 50.4s\tremaining: 12.1s\n",
      "12200:\tlearn: 0.0450681\ttest: 1.0443681\tbest: 1.0439604 (12095)\ttotal: 50.8s\tremaining: 11.7s\n",
      "12300:\tlearn: 0.0436965\ttest: 1.0443622\tbest: 1.0439409 (12229)\ttotal: 51.2s\tremaining: 11.2s\n",
      "12400:\tlearn: 0.0424087\ttest: 1.0441543\tbest: 1.0437247 (12383)\ttotal: 51.6s\tremaining: 10.8s\n",
      "12500:\tlearn: 0.0412269\ttest: 1.0442636\tbest: 1.0437247 (12383)\ttotal: 52.1s\tremaining: 10.4s\n",
      "12600:\tlearn: 0.0400283\ttest: 1.0433365\tbest: 1.0431309 (12538)\ttotal: 52.5s\tremaining: 9.99s\n",
      "12700:\tlearn: 0.0389036\ttest: 1.0418576\tbest: 1.0418576 (12700)\ttotal: 52.9s\tremaining: 9.57s\n",
      "12800:\tlearn: 0.0376615\ttest: 1.0405998\tbest: 1.0405939 (12795)\ttotal: 53.3s\tremaining: 9.16s\n",
      "12900:\tlearn: 0.0366801\ttest: 1.0409574\tbest: 1.0405692 (12820)\ttotal: 53.7s\tremaining: 8.74s\n",
      "13000:\tlearn: 0.0357708\ttest: 1.0413726\tbest: 1.0405692 (12820)\ttotal: 54.1s\tremaining: 8.32s\n",
      "13100:\tlearn: 0.0347896\ttest: 1.0413277\tbest: 1.0405692 (12820)\ttotal: 54.6s\tremaining: 7.91s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.040569188\n",
      "bestIteration = 12820\n",
      "\n",
      "Shrink model to first 12821 iterations.\n",
      "Скор для фолда(14) : 9.0 средний скор на префиксе = 9.0 это заняло = 55 сек.\n",
      "Фолд: 15\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "0:\tlearn: 3.6359650\ttest: 3.0727521\tbest: 3.0727521 (0)\ttotal: 53.1ms\tremaining: 13m 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 2.2823710\ttest: 2.2270637\tbest: 2.2270637 (100)\ttotal: 432ms\tremaining: 1m 3s\n",
      "200:\tlearn: 1.8579320\ttest: 1.9256308\tbest: 1.9256308 (200)\ttotal: 840ms\tremaining: 1m 1s\n",
      "300:\tlearn: 1.6710584\ttest: 1.8054847\tbest: 1.8054847 (300)\ttotal: 1.25s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5499173\ttest: 1.7349975\tbest: 1.7349975 (400)\ttotal: 1.67s\tremaining: 1m\n",
      "500:\tlearn: 1.4697319\ttest: 1.6931968\tbest: 1.6921800 (499)\ttotal: 2.07s\tremaining: 1m\n",
      "600:\tlearn: 1.4068767\ttest: 1.6596299\tbest: 1.6594033 (599)\ttotal: 2.48s\tremaining: 59.5s\n",
      "700:\tlearn: 1.3554709\ttest: 1.6412504\tbest: 1.6412504 (700)\ttotal: 2.9s\tremaining: 59.1s\n",
      "800:\tlearn: 1.3084631\ttest: 1.6370500\tbest: 1.6323973 (781)\ttotal: 3.3s\tremaining: 58.6s\n",
      "900:\tlearn: 1.2661027\ttest: 1.6402623\tbest: 1.6323973 (781)\ttotal: 3.71s\tremaining: 58.1s\n",
      "1000:\tlearn: 1.2273907\ttest: 1.6296934\tbest: 1.6296934 (1000)\ttotal: 4.12s\tremaining: 57.6s\n",
      "1100:\tlearn: 1.1851306\ttest: 1.6193054\tbest: 1.6187720 (1096)\ttotal: 4.53s\tremaining: 57.1s\n",
      "1200:\tlearn: 1.1506586\ttest: 1.6081795\tbest: 1.6081795 (1200)\ttotal: 4.93s\tremaining: 56.7s\n",
      "1300:\tlearn: 1.1216844\ttest: 1.5878200\tbest: 1.5876838 (1298)\ttotal: 5.34s\tremaining: 56.2s\n",
      "1400:\tlearn: 1.0915032\ttest: 1.5739740\tbest: 1.5739740 (1400)\ttotal: 5.75s\tremaining: 55.8s\n",
      "1500:\tlearn: 1.0617892\ttest: 1.5607946\tbest: 1.5607946 (1500)\ttotal: 6.16s\tremaining: 55.4s\n",
      "1600:\tlearn: 1.0346708\ttest: 1.5487876\tbest: 1.5482061 (1584)\ttotal: 6.56s\tremaining: 54.9s\n",
      "1700:\tlearn: 1.0040989\ttest: 1.5394033\tbest: 1.5392275 (1698)\ttotal: 6.98s\tremaining: 54.5s\n",
      "1800:\tlearn: 0.9739219\ttest: 1.5259863\tbest: 1.5259238 (1799)\ttotal: 7.39s\tremaining: 54.2s\n",
      "1900:\tlearn: 0.9479045\ttest: 1.5158224\tbest: 1.5157887 (1898)\ttotal: 7.8s\tremaining: 53.7s\n",
      "2000:\tlearn: 0.9199432\ttest: 1.5093579\tbest: 1.5091829 (1999)\ttotal: 8.21s\tremaining: 53.3s\n",
      "2100:\tlearn: 0.8949216\ttest: 1.5006985\tbest: 1.5004627 (2094)\ttotal: 8.62s\tremaining: 52.9s\n",
      "2200:\tlearn: 0.8690984\ttest: 1.4970816\tbest: 1.4949497 (2151)\ttotal: 9.04s\tremaining: 52.5s\n",
      "2300:\tlearn: 0.8448045\ttest: 1.4922284\tbest: 1.4911995 (2297)\ttotal: 9.45s\tremaining: 52.1s\n",
      "2400:\tlearn: 0.8194713\ttest: 1.4894092\tbest: 1.4885505 (2394)\ttotal: 9.86s\tremaining: 51.7s\n",
      "2500:\tlearn: 0.7981179\ttest: 1.4835895\tbest: 1.4831935 (2488)\ttotal: 10.3s\tremaining: 51.4s\n",
      "2600:\tlearn: 0.7745034\ttest: 1.4782239\tbest: 1.4782239 (2600)\ttotal: 10.7s\tremaining: 51s\n",
      "2700:\tlearn: 0.7544556\ttest: 1.4719303\tbest: 1.4705754 (2684)\ttotal: 11.1s\tremaining: 50.6s\n",
      "2800:\tlearn: 0.7318688\ttest: 1.4670528\tbest: 1.4661318 (2779)\ttotal: 11.5s\tremaining: 50.2s\n",
      "2900:\tlearn: 0.7097877\ttest: 1.4613892\tbest: 1.4613892 (2900)\ttotal: 11.9s\tremaining: 49.8s\n",
      "3000:\tlearn: 0.6907296\ttest: 1.4588989\tbest: 1.4578371 (2971)\ttotal: 12.3s\tremaining: 49.4s\n",
      "3100:\tlearn: 0.6719296\ttest: 1.4535586\tbest: 1.4535586 (3100)\ttotal: 12.8s\tremaining: 48.9s\n",
      "3200:\tlearn: 0.6554019\ttest: 1.4476541\tbest: 1.4476343 (3199)\ttotal: 13.2s\tremaining: 48.5s\n",
      "3300:\tlearn: 0.6375582\ttest: 1.4447810\tbest: 1.4433611 (3290)\ttotal: 13.6s\tremaining: 48.1s\n",
      "3400:\tlearn: 0.6211303\ttest: 1.4405301\tbest: 1.4405301 (3400)\ttotal: 14s\tremaining: 47.7s\n",
      "3500:\tlearn: 0.6021619\ttest: 1.4349611\tbest: 1.4349479 (3499)\ttotal: 14.4s\tremaining: 47.3s\n",
      "3600:\tlearn: 0.5842832\ttest: 1.4308132\tbest: 1.4308132 (3600)\ttotal: 14.8s\tremaining: 46.9s\n",
      "3700:\tlearn: 0.5676444\ttest: 1.4277257\tbest: 1.4272663 (3699)\ttotal: 15.2s\tremaining: 46.5s\n",
      "3800:\tlearn: 0.5509424\ttest: 1.4240587\tbest: 1.4240587 (3800)\ttotal: 15.6s\tremaining: 46.1s\n",
      "3900:\tlearn: 0.5336633\ttest: 1.4166863\tbest: 1.4166863 (3900)\ttotal: 16.1s\tremaining: 45.7s\n",
      "4000:\tlearn: 0.5184449\ttest: 1.4131160\tbest: 1.4129984 (3996)\ttotal: 16.5s\tremaining: 45.3s\n",
      "4100:\tlearn: 0.5035661\ttest: 1.4091166\tbest: 1.4082549 (4089)\ttotal: 16.9s\tremaining: 44.9s\n",
      "4200:\tlearn: 0.4891637\ttest: 1.4058312\tbest: 1.4058312 (4200)\ttotal: 17.3s\tremaining: 44.5s\n",
      "4300:\tlearn: 0.4750233\ttest: 1.4008801\tbest: 1.4008801 (4300)\ttotal: 17.7s\tremaining: 44.1s\n",
      "4400:\tlearn: 0.4612684\ttest: 1.3959469\tbest: 1.3959469 (4400)\ttotal: 18.1s\tremaining: 43.7s\n",
      "4500:\tlearn: 0.4469990\ttest: 1.3927594\tbest: 1.3927594 (4500)\ttotal: 18.5s\tremaining: 43.3s\n",
      "4600:\tlearn: 0.4348188\ttest: 1.3884293\tbest: 1.3884293 (4600)\ttotal: 19s\tremaining: 42.9s\n",
      "4700:\tlearn: 0.4224771\ttest: 1.3859169\tbest: 1.3848327 (4661)\ttotal: 19.4s\tremaining: 42.5s\n",
      "4800:\tlearn: 0.4107144\ttest: 1.3824005\tbest: 1.3823685 (4799)\ttotal: 19.8s\tremaining: 42s\n",
      "4900:\tlearn: 0.3987469\ttest: 1.3778912\tbest: 1.3778912 (4900)\ttotal: 20.2s\tremaining: 41.6s\n",
      "5000:\tlearn: 0.3863086\ttest: 1.3734173\tbest: 1.3733491 (4996)\ttotal: 20.6s\tremaining: 41.2s\n",
      "5100:\tlearn: 0.3743831\ttest: 1.3682511\tbest: 1.3682131 (5092)\ttotal: 21s\tremaining: 40.8s\n",
      "5200:\tlearn: 0.3631632\ttest: 1.3634239\tbest: 1.3633939 (5199)\ttotal: 21.5s\tremaining: 40.4s\n",
      "5300:\tlearn: 0.3528563\ttest: 1.3612476\tbest: 1.3610770 (5286)\ttotal: 21.9s\tremaining: 40s\n",
      "5400:\tlearn: 0.3433581\ttest: 1.3562333\tbest: 1.3562063 (5399)\ttotal: 22.3s\tremaining: 39.6s\n",
      "5500:\tlearn: 0.3334678\ttest: 1.3532942\tbest: 1.3532942 (5500)\ttotal: 22.7s\tremaining: 39.2s\n",
      "5600:\tlearn: 0.3231913\ttest: 1.3478635\tbest: 1.3477055 (5597)\ttotal: 23.1s\tremaining: 38.8s\n",
      "5700:\tlearn: 0.3141090\ttest: 1.3410485\tbest: 1.3408197 (5697)\ttotal: 23.5s\tremaining: 38.4s\n",
      "5800:\tlearn: 0.3046393\ttest: 1.3350478\tbest: 1.3350478 (5800)\ttotal: 24s\tremaining: 38s\n",
      "5900:\tlearn: 0.2949022\ttest: 1.3312997\tbest: 1.3311193 (5896)\ttotal: 24.4s\tremaining: 37.6s\n",
      "6000:\tlearn: 0.2851878\ttest: 1.3266386\tbest: 1.3264899 (5992)\ttotal: 24.8s\tremaining: 37.2s\n",
      "6100:\tlearn: 0.2763471\ttest: 1.3235320\tbest: 1.3235320 (6100)\ttotal: 25.2s\tremaining: 36.8s\n",
      "6200:\tlearn: 0.2683043\ttest: 1.3207677\tbest: 1.3204816 (6192)\ttotal: 25.6s\tremaining: 36.4s\n",
      "6300:\tlearn: 0.2599541\ttest: 1.3168200\tbest: 1.3165501 (6285)\ttotal: 26.1s\tremaining: 36s\n",
      "6400:\tlearn: 0.2526708\ttest: 1.3124080\tbest: 1.3110139 (6376)\ttotal: 26.5s\tremaining: 35.6s\n",
      "6500:\tlearn: 0.2453281\ttest: 1.3095195\tbest: 1.3095195 (6500)\ttotal: 26.9s\tremaining: 35.2s\n",
      "6600:\tlearn: 0.2382212\ttest: 1.3085825\tbest: 1.3081149 (6596)\ttotal: 27.3s\tremaining: 34.8s\n",
      "6700:\tlearn: 0.2315684\ttest: 1.3048814\tbest: 1.3047660 (6696)\ttotal: 27.7s\tremaining: 34.4s\n",
      "6800:\tlearn: 0.2245451\ttest: 1.3006845\tbest: 1.3003898 (6792)\ttotal: 28.2s\tremaining: 33.9s\n",
      "6900:\tlearn: 0.2182772\ttest: 1.3002409\tbest: 1.2998134 (6815)\ttotal: 28.6s\tremaining: 33.5s\n",
      "7000:\tlearn: 0.2121531\ttest: 1.2982723\tbest: 1.2982723 (7000)\ttotal: 29s\tremaining: 33.1s\n",
      "7100:\tlearn: 0.2060773\ttest: 1.2969543\tbest: 1.2968152 (7030)\ttotal: 29.4s\tremaining: 32.7s\n",
      "7200:\tlearn: 0.2002154\ttest: 1.2950103\tbest: 1.2950103 (7200)\ttotal: 29.8s\tremaining: 32.3s\n",
      "7300:\tlearn: 0.1946614\ttest: 1.2917804\tbest: 1.2917804 (7300)\ttotal: 30.3s\tremaining: 31.9s\n",
      "7400:\tlearn: 0.1887163\ttest: 1.2917653\tbest: 1.2912788 (7316)\ttotal: 30.7s\tremaining: 31.5s\n",
      "7500:\tlearn: 0.1832922\ttest: 1.2882153\tbest: 1.2881979 (7499)\ttotal: 31.1s\tremaining: 31.1s\n",
      "7600:\tlearn: 0.1778604\ttest: 1.2843595\tbest: 1.2843453 (7599)\ttotal: 31.5s\tremaining: 30.7s\n",
      "7700:\tlearn: 0.1726746\ttest: 1.2830484\tbest: 1.2830484 (7700)\ttotal: 31.9s\tremaining: 30.3s\n",
      "7800:\tlearn: 0.1675389\ttest: 1.2809125\tbest: 1.2800283 (7775)\ttotal: 32.4s\tremaining: 29.9s\n",
      "7900:\tlearn: 0.1625021\ttest: 1.2785312\tbest: 1.2784308 (7898)\ttotal: 32.8s\tremaining: 29.5s\n",
      "8000:\tlearn: 0.1580143\ttest: 1.2762342\tbest: 1.2762342 (8000)\ttotal: 33.2s\tremaining: 29s\n",
      "8100:\tlearn: 0.1532486\ttest: 1.2750226\tbest: 1.2750166 (8099)\ttotal: 33.6s\tremaining: 28.6s\n",
      "8200:\tlearn: 0.1488024\ttest: 1.2744032\tbest: 1.2734256 (8170)\ttotal: 34s\tremaining: 28.2s\n",
      "8300:\tlearn: 0.1436250\ttest: 1.2729108\tbest: 1.2727629 (8299)\ttotal: 34.5s\tremaining: 27.8s\n",
      "8400:\tlearn: 0.1393396\ttest: 1.2706971\tbest: 1.2706793 (8399)\ttotal: 34.9s\tremaining: 27.4s\n",
      "8500:\tlearn: 0.1349139\ttest: 1.2687954\tbest: 1.2687954 (8500)\ttotal: 35.3s\tremaining: 27s\n",
      "8600:\tlearn: 0.1305510\ttest: 1.2682516\tbest: 1.2682175 (8599)\ttotal: 35.7s\tremaining: 26.6s\n",
      "8700:\tlearn: 0.1263439\ttest: 1.2677304\tbest: 1.2674466 (8675)\ttotal: 36.1s\tremaining: 26.2s\n",
      "8800:\tlearn: 0.1225042\ttest: 1.2673794\tbest: 1.2673794 (8800)\ttotal: 36.6s\tremaining: 25.7s\n",
      "8900:\tlearn: 0.1189285\ttest: 1.2659238\tbest: 1.2658202 (8881)\ttotal: 37s\tremaining: 25.3s\n",
      "9000:\tlearn: 0.1150860\ttest: 1.2653633\tbest: 1.2651344 (8931)\ttotal: 37.4s\tremaining: 24.9s\n",
      "9100:\tlearn: 0.1114814\ttest: 1.2645389\tbest: 1.2644194 (9095)\ttotal: 37.8s\tremaining: 24.5s\n",
      "9200:\tlearn: 0.1080692\ttest: 1.2634147\tbest: 1.2632416 (9189)\ttotal: 38.2s\tremaining: 24.1s\n",
      "9300:\tlearn: 0.1046857\ttest: 1.2613892\tbest: 1.2610491 (9271)\ttotal: 38.7s\tremaining: 23.7s\n",
      "9400:\tlearn: 0.1014968\ttest: 1.2605459\tbest: 1.2600829 (9341)\ttotal: 39.1s\tremaining: 23.3s\n",
      "9500:\tlearn: 0.0982975\ttest: 1.2601517\tbest: 1.2600086 (9498)\ttotal: 39.5s\tremaining: 22.9s\n",
      "9600:\tlearn: 0.0952899\ttest: 1.2583779\tbest: 1.2582945 (9579)\ttotal: 39.9s\tremaining: 22.4s\n",
      "9700:\tlearn: 0.0924099\ttest: 1.2582314\tbest: 1.2575014 (9681)\ttotal: 40.4s\tremaining: 22s\n",
      "9800:\tlearn: 0.0893663\ttest: 1.2577797\tbest: 1.2575014 (9681)\ttotal: 40.8s\tremaining: 21.6s\n",
      "9900:\tlearn: 0.0869529\ttest: 1.2574203\tbest: 1.2567257 (9886)\ttotal: 41.2s\tremaining: 21.2s\n",
      "10000:\tlearn: 0.0841151\ttest: 1.2577221\tbest: 1.2567257 (9886)\ttotal: 41.6s\tremaining: 20.8s\n",
      "10100:\tlearn: 0.0819304\ttest: 1.2556586\tbest: 1.2555476 (10094)\ttotal: 42s\tremaining: 20.4s\n",
      "10200:\tlearn: 0.0793134\ttest: 1.2548412\tbest: 1.2548412 (10200)\ttotal: 42.5s\tremaining: 20s\n",
      "10300:\tlearn: 0.0767214\ttest: 1.2541517\tbest: 1.2538634 (10246)\ttotal: 42.9s\tremaining: 19.6s\n",
      "10400:\tlearn: 0.0741996\ttest: 1.2546694\tbest: 1.2538634 (10246)\ttotal: 43.3s\tremaining: 19.1s\n",
      "10500:\tlearn: 0.0718627\ttest: 1.2528636\tbest: 1.2528636 (10500)\ttotal: 43.7s\tremaining: 18.7s\n",
      "10600:\tlearn: 0.0695765\ttest: 1.2527314\tbest: 1.2519592 (10535)\ttotal: 44.1s\tremaining: 18.3s\n",
      "10700:\tlearn: 0.0672875\ttest: 1.2525091\tbest: 1.2519344 (10664)\ttotal: 44.6s\tremaining: 17.9s\n",
      "10800:\tlearn: 0.0651475\ttest: 1.2525221\tbest: 1.2518977 (10775)\ttotal: 45s\tremaining: 17.5s\n",
      "10900:\tlearn: 0.0632771\ttest: 1.2526509\tbest: 1.2518977 (10775)\ttotal: 45.4s\tremaining: 17.1s\n",
      "11000:\tlearn: 0.0615501\ttest: 1.2527736\tbest: 1.2518977 (10775)\ttotal: 45.8s\tremaining: 16.7s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.251897714\n",
      "bestIteration = 10775\n",
      "\n",
      "Shrink model to first 10776 iterations.\n",
      "Скор для фолда(15) : 9.0 средний скор на префиксе = 9.0 это заняло = 46 сек.\n",
      "Фолд: 16\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.5631075\ttest: 3.9645199\tbest: 3.9645199 (0)\ttotal: 53.7ms\tremaining: 13m 25s\n",
      "100:\tlearn: 2.2375504\ttest: 2.3550841\tbest: 2.3550841 (100)\ttotal: 437ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8342268\ttest: 2.0434953\tbest: 2.0434953 (200)\ttotal: 842ms\tremaining: 1m 2s\n",
      "300:\tlearn: 1.6557779\ttest: 1.8800266\tbest: 1.8800266 (300)\ttotal: 1.26s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5389589\ttest: 1.7855804\tbest: 1.7855804 (400)\ttotal: 1.68s\tremaining: 1m 1s\n",
      "500:\tlearn: 1.4582512\ttest: 1.7111873\tbest: 1.7111873 (500)\ttotal: 2.09s\tremaining: 1m\n",
      "600:\tlearn: 1.3927412\ttest: 1.6575787\tbest: 1.6575787 (600)\ttotal: 2.5s\tremaining: 1m\n",
      "700:\tlearn: 1.3419549\ttest: 1.6191689\tbest: 1.6191689 (700)\ttotal: 2.92s\tremaining: 59.5s\n",
      "800:\tlearn: 1.2966493\ttest: 1.5984371\tbest: 1.5984371 (800)\ttotal: 3.33s\tremaining: 59s\n",
      "900:\tlearn: 1.2560023\ttest: 1.5902312\tbest: 1.5902312 (900)\ttotal: 3.73s\tremaining: 58.4s\n",
      "1000:\tlearn: 1.2165368\ttest: 1.5708201\tbest: 1.5702368 (998)\ttotal: 4.14s\tremaining: 57.9s\n",
      "1100:\tlearn: 1.1807701\ttest: 1.5647110\tbest: 1.5612263 (1076)\ttotal: 4.54s\tremaining: 57.4s\n",
      "1200:\tlearn: 1.1438212\ttest: 1.5516315\tbest: 1.5513048 (1172)\ttotal: 4.95s\tremaining: 56.9s\n",
      "1300:\tlearn: 1.1118580\ttest: 1.5386694\tbest: 1.5379135 (1291)\ttotal: 5.35s\tremaining: 56.4s\n",
      "1400:\tlearn: 1.0808790\ttest: 1.5217144\tbest: 1.5217000 (1399)\ttotal: 5.76s\tremaining: 55.9s\n",
      "1500:\tlearn: 1.0451197\ttest: 1.5056478\tbest: 1.5056478 (1500)\ttotal: 6.17s\tremaining: 55.5s\n",
      "1600:\tlearn: 1.0096032\ttest: 1.4892947\tbest: 1.4892861 (1599)\ttotal: 6.58s\tremaining: 55.1s\n",
      "1700:\tlearn: 0.9730090\ttest: 1.4687799\tbest: 1.4687458 (1699)\ttotal: 6.99s\tremaining: 54.7s\n",
      "1800:\tlearn: 0.9398349\ttest: 1.4519523\tbest: 1.4519523 (1800)\ttotal: 7.41s\tremaining: 54.3s\n",
      "1900:\tlearn: 0.9095070\ttest: 1.4375252\tbest: 1.4375252 (1900)\ttotal: 7.82s\tremaining: 53.9s\n",
      "2000:\tlearn: 0.8806028\ttest: 1.4260467\tbest: 1.4257076 (1996)\ttotal: 8.23s\tremaining: 53.5s\n",
      "2100:\tlearn: 0.8572924\ttest: 1.4195722\tbest: 1.4183208 (2094)\ttotal: 8.65s\tremaining: 53.1s\n",
      "2200:\tlearn: 0.8326838\ttest: 1.4077628\tbest: 1.4073880 (2186)\ttotal: 9.11s\tremaining: 53s\n",
      "2300:\tlearn: 0.8077132\ttest: 1.3982392\tbest: 1.3982392 (2300)\ttotal: 9.55s\tremaining: 52.7s\n",
      "2400:\tlearn: 0.7830354\ttest: 1.3893389\tbest: 1.3890443 (2391)\ttotal: 9.99s\tremaining: 52.4s\n",
      "2500:\tlearn: 0.7606388\ttest: 1.3892439\tbest: 1.3871982 (2432)\ttotal: 10.4s\tremaining: 52.2s\n",
      "2600:\tlearn: 0.7358420\ttest: 1.3843968\tbest: 1.3835467 (2594)\ttotal: 10.9s\tremaining: 51.8s\n",
      "2700:\tlearn: 0.7140778\ttest: 1.3813900\tbest: 1.3801216 (2677)\ttotal: 11.3s\tremaining: 51.3s\n",
      "2800:\tlearn: 0.6923022\ttest: 1.3726768\tbest: 1.3721854 (2794)\ttotal: 11.7s\tremaining: 50.9s\n",
      "2900:\tlearn: 0.6714640\ttest: 1.3644452\tbest: 1.3644452 (2900)\ttotal: 12.1s\tremaining: 50.5s\n",
      "3000:\tlearn: 0.6507371\ttest: 1.3584095\tbest: 1.3582983 (2998)\ttotal: 12.5s\tremaining: 50s\n",
      "3100:\tlearn: 0.6298128\ttest: 1.3505303\tbest: 1.3497543 (3092)\ttotal: 12.9s\tremaining: 49.6s\n",
      "3200:\tlearn: 0.6098801\ttest: 1.3458557\tbest: 1.3458557 (3200)\ttotal: 13.3s\tremaining: 49.2s\n",
      "3300:\tlearn: 0.5910524\ttest: 1.3418327\tbest: 1.3412576 (3289)\ttotal: 13.8s\tremaining: 48.8s\n",
      "3400:\tlearn: 0.5704173\ttest: 1.3389830\tbest: 1.3389531 (3399)\ttotal: 14.2s\tremaining: 48.3s\n",
      "3500:\tlearn: 0.5543159\ttest: 1.3368217\tbest: 1.3367918 (3497)\ttotal: 14.6s\tremaining: 47.9s\n",
      "3600:\tlearn: 0.5372325\ttest: 1.3326334\tbest: 1.3326334 (3600)\ttotal: 15s\tremaining: 47.5s\n",
      "3700:\tlearn: 0.5204521\ttest: 1.3320237\tbest: 1.3302923 (3645)\ttotal: 15.4s\tremaining: 47.1s\n",
      "3800:\tlearn: 0.5034839\ttest: 1.3279178\tbest: 1.3279178 (3800)\ttotal: 15.8s\tremaining: 46.7s\n",
      "3900:\tlearn: 0.4896439\ttest: 1.3233479\tbest: 1.3233479 (3900)\ttotal: 16.2s\tremaining: 46.2s\n",
      "4000:\tlearn: 0.4727664\ttest: 1.3253285\tbest: 1.3222037 (3914)\ttotal: 16.7s\tremaining: 45.8s\n",
      "4100:\tlearn: 0.4569625\ttest: 1.3181463\tbest: 1.3178346 (4097)\ttotal: 17.1s\tremaining: 45.4s\n",
      "4200:\tlearn: 0.4428812\ttest: 1.3180138\tbest: 1.3173599 (4178)\ttotal: 17.5s\tremaining: 45s\n",
      "4300:\tlearn: 0.4283537\ttest: 1.3141095\tbest: 1.3135051 (4275)\ttotal: 17.9s\tremaining: 44.6s\n",
      "4400:\tlearn: 0.4154656\ttest: 1.3124997\tbest: 1.3117920 (4383)\ttotal: 18.3s\tremaining: 44.1s\n",
      "4500:\tlearn: 0.4035710\ttest: 1.3112623\tbest: 1.3111021 (4497)\ttotal: 18.7s\tremaining: 43.7s\n",
      "4600:\tlearn: 0.3919779\ttest: 1.3077700\tbest: 1.3077700 (4600)\ttotal: 19.2s\tremaining: 43.3s\n",
      "4700:\tlearn: 0.3807657\ttest: 1.3034810\tbest: 1.3032802 (4695)\ttotal: 19.6s\tremaining: 42.9s\n",
      "4800:\tlearn: 0.3682371\ttest: 1.3054925\tbest: 1.3026868 (4724)\ttotal: 20s\tremaining: 42.5s\n",
      "4900:\tlearn: 0.3569456\ttest: 1.3015269\tbest: 1.3014326 (4882)\ttotal: 20.4s\tremaining: 42.1s\n",
      "5000:\tlearn: 0.3459240\ttest: 1.2965629\tbest: 1.2964841 (4998)\ttotal: 20.8s\tremaining: 41.7s\n",
      "5100:\tlearn: 0.3338273\ttest: 1.2956132\tbest: 1.2946616 (5067)\ttotal: 21.3s\tremaining: 41.2s\n",
      "5200:\tlearn: 0.3248670\ttest: 1.2930932\tbest: 1.2924256 (5192)\ttotal: 21.7s\tremaining: 40.8s\n",
      "5300:\tlearn: 0.3143070\ttest: 1.2916461\tbest: 1.2916461 (5300)\ttotal: 22.1s\tremaining: 40.4s\n",
      "5400:\tlearn: 0.3036677\ttest: 1.2905803\tbest: 1.2903238 (5390)\ttotal: 22.5s\tremaining: 40s\n",
      "5500:\tlearn: 0.2943701\ttest: 1.2891083\tbest: 1.2888773 (5499)\ttotal: 22.9s\tremaining: 39.6s\n",
      "5600:\tlearn: 0.2846926\ttest: 1.2867949\tbest: 1.2865958 (5592)\ttotal: 23.3s\tremaining: 39.2s\n",
      "5700:\tlearn: 0.2752503\ttest: 1.2865931\tbest: 1.2858603 (5678)\ttotal: 23.8s\tremaining: 38.7s\n",
      "5800:\tlearn: 0.2668176\ttest: 1.2835452\tbest: 1.2835452 (5800)\ttotal: 24.2s\tremaining: 38.3s\n",
      "5900:\tlearn: 0.2588109\ttest: 1.2833523\tbest: 1.2832445 (5899)\ttotal: 24.6s\tremaining: 37.9s\n",
      "6000:\tlearn: 0.2512990\ttest: 1.2815845\tbest: 1.2815506 (5996)\ttotal: 25s\tremaining: 37.5s\n",
      "6100:\tlearn: 0.2430995\ttest: 1.2794635\tbest: 1.2793563 (6098)\ttotal: 25.4s\tremaining: 37.1s\n",
      "6200:\tlearn: 0.2353861\ttest: 1.2776344\tbest: 1.2776344 (6200)\ttotal: 25.8s\tremaining: 36.7s\n",
      "6300:\tlearn: 0.2277843\ttest: 1.2751419\tbest: 1.2748418 (6281)\ttotal: 26.3s\tremaining: 36.3s\n",
      "6400:\tlearn: 0.2200739\ttest: 1.2760199\tbest: 1.2748418 (6281)\ttotal: 26.7s\tremaining: 35.8s\n",
      "6500:\tlearn: 0.2136282\ttest: 1.2729307\tbest: 1.2722673 (6471)\ttotal: 27.1s\tremaining: 35.4s\n",
      "6600:\tlearn: 0.2071545\ttest: 1.2718279\tbest: 1.2713716 (6589)\ttotal: 27.5s\tremaining: 35s\n",
      "6700:\tlearn: 0.2003844\ttest: 1.2706794\tbest: 1.2703203 (6694)\ttotal: 27.9s\tremaining: 34.6s\n",
      "6800:\tlearn: 0.1939211\ttest: 1.2704954\tbest: 1.2698508 (6790)\ttotal: 28.3s\tremaining: 34.2s\n",
      "6900:\tlearn: 0.1869508\ttest: 1.2715403\tbest: 1.2698508 (6790)\ttotal: 28.8s\tremaining: 33.8s\n",
      "7000:\tlearn: 0.1808324\ttest: 1.2704630\tbest: 1.2698508 (6790)\ttotal: 29.2s\tremaining: 33.3s\n",
      "7100:\tlearn: 0.1742536\ttest: 1.2693712\tbest: 1.2693712 (7100)\ttotal: 29.6s\tremaining: 32.9s\n",
      "7200:\tlearn: 0.1682085\ttest: 1.2680261\tbest: 1.2677260 (7191)\ttotal: 30s\tremaining: 32.5s\n",
      "7300:\tlearn: 0.1628146\ttest: 1.2667858\tbest: 1.2665392 (7297)\ttotal: 30.4s\tremaining: 32.1s\n",
      "7400:\tlearn: 0.1572665\ttest: 1.2668673\tbest: 1.2665392 (7297)\ttotal: 30.9s\tremaining: 31.7s\n",
      "7500:\tlearn: 0.1518886\ttest: 1.2667506\tbest: 1.2662820 (7416)\ttotal: 31.3s\tremaining: 31.3s\n",
      "7600:\tlearn: 0.1463509\ttest: 1.2667619\tbest: 1.2653596 (7541)\ttotal: 31.7s\tremaining: 30.8s\n",
      "7700:\tlearn: 0.1410781\ttest: 1.2651758\tbest: 1.2647857 (7693)\ttotal: 32.1s\tremaining: 30.4s\n",
      "7800:\tlearn: 0.1363048\ttest: 1.2645645\tbest: 1.2633665 (7756)\ttotal: 32.5s\tremaining: 30s\n",
      "7900:\tlearn: 0.1312878\ttest: 1.2646918\tbest: 1.2633665 (7756)\ttotal: 32.9s\tremaining: 29.6s\n",
      "8000:\tlearn: 0.1275229\ttest: 1.2650003\tbest: 1.2633665 (7756)\ttotal: 33.4s\tremaining: 29.2s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.263366463\n",
      "bestIteration = 7756\n",
      "\n",
      "Shrink model to first 7757 iterations.\n",
      "Скор для фолда(16) : 9.0 средний скор на префиксе = 9.0 это заняло = 34 сек.\n",
      "Фолд: 17\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.5805699\ttest: 3.5348576\tbest: 3.5348576 (0)\ttotal: 53.4ms\tremaining: 13m 20s\n",
      "100:\tlearn: 2.2749076\ttest: 2.0091391\tbest: 2.0091391 (100)\ttotal: 437ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8551599\ttest: 1.5998641\tbest: 1.5998641 (200)\ttotal: 849ms\tremaining: 1m 2s\n",
      "300:\tlearn: 1.6638910\ttest: 1.4446922\tbest: 1.4446922 (300)\ttotal: 1.27s\tremaining: 1m 1s\n",
      "400:\tlearn: 1.5407124\ttest: 1.3611662\tbest: 1.3609150 (399)\ttotal: 1.68s\tremaining: 1m 1s\n",
      "500:\tlearn: 1.4563038\ttest: 1.3218093\tbest: 1.3218093 (500)\ttotal: 2.09s\tremaining: 1m\n",
      "600:\tlearn: 1.3950900\ttest: 1.2978193\tbest: 1.2977158 (599)\ttotal: 2.5s\tremaining: 60s\n",
      "700:\tlearn: 1.3431564\ttest: 1.2784039\tbest: 1.2784039 (700)\ttotal: 2.91s\tremaining: 59.3s\n",
      "800:\tlearn: 1.2978466\ttest: 1.2650589\tbest: 1.2650589 (800)\ttotal: 3.32s\tremaining: 58.8s\n",
      "900:\tlearn: 1.2556805\ttest: 1.2602835\tbest: 1.2587932 (882)\ttotal: 3.73s\tremaining: 58.3s\n",
      "1000:\tlearn: 1.2223171\ttest: 1.2515799\tbest: 1.2493306 (992)\ttotal: 4.13s\tremaining: 57.8s\n",
      "1100:\tlearn: 1.1894978\ttest: 1.2500588\tbest: 1.2493306 (992)\ttotal: 4.54s\tremaining: 57.3s\n",
      "1200:\tlearn: 1.1557982\ttest: 1.2437905\tbest: 1.2432015 (1193)\ttotal: 4.96s\tremaining: 57s\n",
      "1300:\tlearn: 1.1252414\ttest: 1.2315573\tbest: 1.2313235 (1298)\ttotal: 5.37s\tremaining: 56.5s\n",
      "1400:\tlearn: 1.0947835\ttest: 1.2224144\tbest: 1.2224053 (1399)\ttotal: 5.78s\tremaining: 56.1s\n",
      "1500:\tlearn: 1.0647922\ttest: 1.2191835\tbest: 1.2186182 (1489)\ttotal: 6.2s\tremaining: 55.7s\n",
      "1600:\tlearn: 1.0360130\ttest: 1.2113708\tbest: 1.2111922 (1597)\ttotal: 6.61s\tremaining: 55.3s\n",
      "1700:\tlearn: 1.0073254\ttest: 1.2063538\tbest: 1.2059791 (1698)\ttotal: 7.02s\tremaining: 54.9s\n",
      "1800:\tlearn: 0.9783139\ttest: 1.2031649\tbest: 1.2025661 (1788)\ttotal: 7.43s\tremaining: 54.4s\n",
      "1900:\tlearn: 0.9569273\ttest: 1.2079718\tbest: 1.2025661 (1788)\ttotal: 7.84s\tremaining: 54s\n",
      "2000:\tlearn: 0.9319751\ttest: 1.2079149\tbest: 1.2025661 (1788)\ttotal: 8.25s\tremaining: 53.6s\n",
      "2100:\tlearn: 0.9059826\ttest: 1.2018436\tbest: 1.2017134 (2082)\ttotal: 8.66s\tremaining: 53.2s\n",
      "2200:\tlearn: 0.8793659\ttest: 1.1959296\tbest: 1.1956171 (2188)\ttotal: 9.07s\tremaining: 52.7s\n",
      "2300:\tlearn: 0.8544940\ttest: 1.1899875\tbest: 1.1892594 (2289)\ttotal: 9.48s\tremaining: 52.3s\n",
      "2400:\tlearn: 0.8296634\ttest: 1.1860586\tbest: 1.1852655 (2394)\ttotal: 9.91s\tremaining: 52s\n",
      "2500:\tlearn: 0.8064823\ttest: 1.1854962\tbest: 1.1841350 (2443)\ttotal: 10.3s\tremaining: 51.6s\n",
      "2600:\tlearn: 0.7822612\ttest: 1.1813456\tbest: 1.1792160 (2581)\ttotal: 10.7s\tremaining: 51.2s\n",
      "2700:\tlearn: 0.7594335\ttest: 1.1760841\tbest: 1.1760841 (2700)\ttotal: 11.1s\tremaining: 50.8s\n",
      "2800:\tlearn: 0.7343013\ttest: 1.1716548\tbest: 1.1714529 (2796)\ttotal: 11.6s\tremaining: 50.3s\n",
      "2900:\tlearn: 0.7115884\ttest: 1.1697977\tbest: 1.1691684 (2878)\ttotal: 12s\tremaining: 49.9s\n",
      "3000:\tlearn: 0.6878101\ttest: 1.1664277\tbest: 1.1664277 (3000)\ttotal: 12.4s\tremaining: 49.5s\n",
      "3100:\tlearn: 0.6671740\ttest: 1.1647547\tbest: 1.1635949 (3091)\ttotal: 12.8s\tremaining: 49.1s\n",
      "3200:\tlearn: 0.6462303\ttest: 1.1641361\tbest: 1.1635949 (3091)\ttotal: 13.2s\tremaining: 48.7s\n",
      "3300:\tlearn: 0.6264269\ttest: 1.1645765\tbest: 1.1622109 (3248)\ttotal: 13.6s\tremaining: 48.3s\n",
      "3400:\tlearn: 0.6078536\ttest: 1.1634458\tbest: 1.1620056 (3371)\ttotal: 14s\tremaining: 47.9s\n",
      "3500:\tlearn: 0.5884683\ttest: 1.1615657\tbest: 1.1600524 (3469)\ttotal: 14.5s\tremaining: 47.5s\n",
      "3600:\tlearn: 0.5699221\ttest: 1.1596946\tbest: 1.1583001 (3575)\ttotal: 14.9s\tremaining: 47.1s\n",
      "3700:\tlearn: 0.5534203\ttest: 1.1577856\tbest: 1.1567340 (3685)\ttotal: 15.3s\tremaining: 46.7s\n",
      "3800:\tlearn: 0.5362097\ttest: 1.1518774\tbest: 1.1515461 (3794)\ttotal: 15.7s\tremaining: 46.3s\n",
      "3900:\tlearn: 0.5206107\ttest: 1.1520178\tbest: 1.1504701 (3844)\ttotal: 16.1s\tremaining: 45.9s\n",
      "4000:\tlearn: 0.5054990\ttest: 1.1494316\tbest: 1.1469932 (3985)\ttotal: 16.5s\tremaining: 45.5s\n",
      "4100:\tlearn: 0.4896480\ttest: 1.1470663\tbest: 1.1464727 (4097)\ttotal: 17s\tremaining: 45.1s\n",
      "4200:\tlearn: 0.4747428\ttest: 1.1458280\tbest: 1.1447110 (4194)\ttotal: 17.4s\tremaining: 44.7s\n",
      "4300:\tlearn: 0.4608734\ttest: 1.1411776\tbest: 1.1406968 (4296)\ttotal: 17.8s\tremaining: 44.2s\n",
      "4400:\tlearn: 0.4467977\ttest: 1.1409543\tbest: 1.1395596 (4342)\ttotal: 18.2s\tremaining: 43.8s\n",
      "4500:\tlearn: 0.4328557\ttest: 1.1369958\tbest: 1.1364829 (4498)\ttotal: 18.6s\tremaining: 43.4s\n",
      "4600:\tlearn: 0.4190604\ttest: 1.1323718\tbest: 1.1322127 (4596)\ttotal: 19s\tremaining: 43s\n",
      "4700:\tlearn: 0.4063486\ttest: 1.1283967\tbest: 1.1283967 (4700)\ttotal: 19.5s\tremaining: 42.6s\n",
      "4800:\tlearn: 0.3936829\ttest: 1.1275906\tbest: 1.1265426 (4771)\ttotal: 19.9s\tremaining: 42.2s\n",
      "4900:\tlearn: 0.3805648\ttest: 1.1252578\tbest: 1.1251937 (4899)\ttotal: 20.3s\tremaining: 41.8s\n",
      "5000:\tlearn: 0.3699734\ttest: 1.1231919\tbest: 1.1224205 (4969)\ttotal: 20.7s\tremaining: 41.4s\n",
      "5100:\tlearn: 0.3593396\ttest: 1.1216920\tbest: 1.1216920 (5100)\ttotal: 21.1s\tremaining: 41s\n",
      "5200:\tlearn: 0.3480411\ttest: 1.1176767\tbest: 1.1176767 (5200)\ttotal: 21.5s\tremaining: 40.6s\n",
      "5300:\tlearn: 0.3377157\ttest: 1.1176516\tbest: 1.1172668 (5207)\ttotal: 22s\tremaining: 40.2s\n",
      "5400:\tlearn: 0.3270631\ttest: 1.1172136\tbest: 1.1164884 (5357)\ttotal: 22.4s\tremaining: 39.8s\n",
      "5500:\tlearn: 0.3174437\ttest: 1.1158828\tbest: 1.1152552 (5491)\ttotal: 22.8s\tremaining: 39.4s\n",
      "5600:\tlearn: 0.3074943\ttest: 1.1163351\tbest: 1.1152552 (5491)\ttotal: 23.2s\tremaining: 38.9s\n",
      "5700:\tlearn: 0.2980622\ttest: 1.1162992\tbest: 1.1152552 (5491)\ttotal: 23.6s\tremaining: 38.5s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.115255172\n",
      "bestIteration = 5491\n",
      "\n",
      "Shrink model to first 5492 iterations.\n",
      "Скор для фолда(17) : 9.0 средний скор на префиксе = 9.0 это заняло = 24 сек.\n",
      "Фолд: 18\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "0:\tlearn: 3.6226362\ttest: 3.2512653\tbest: 3.2512653 (0)\ttotal: 53.6ms\tremaining: 13m 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 2.2874461\ttest: 1.9611819\tbest: 1.9611819 (100)\ttotal: 443ms\tremaining: 1m 5s\n",
      "200:\tlearn: 1.8582581\ttest: 1.7463254\tbest: 1.7460603 (199)\ttotal: 856ms\tremaining: 1m 3s\n",
      "300:\tlearn: 1.6670895\ttest: 1.6234341\tbest: 1.6234341 (300)\ttotal: 1.27s\tremaining: 1m 2s\n",
      "400:\tlearn: 1.5500209\ttest: 1.5635847\tbest: 1.5635847 (400)\ttotal: 1.69s\tremaining: 1m 1s\n",
      "500:\tlearn: 1.4694045\ttest: 1.5095406\tbest: 1.5095406 (500)\ttotal: 2.1s\tremaining: 1m\n",
      "600:\tlearn: 1.4096235\ttest: 1.4751204\tbest: 1.4751204 (600)\ttotal: 2.51s\tremaining: 1m\n",
      "700:\tlearn: 1.3612508\ttest: 1.4491031\tbest: 1.4489617 (699)\ttotal: 2.92s\tremaining: 59.6s\n",
      "800:\tlearn: 1.3198053\ttest: 1.4285682\tbest: 1.4285682 (800)\ttotal: 3.33s\tremaining: 59s\n",
      "900:\tlearn: 1.2789784\ttest: 1.4095265\tbest: 1.4090160 (898)\ttotal: 3.73s\tremaining: 58.4s\n",
      "1000:\tlearn: 1.2397467\ttest: 1.3908417\tbest: 1.3908417 (1000)\ttotal: 4.14s\tremaining: 57.9s\n",
      "1100:\tlearn: 1.2016456\ttest: 1.3700755\tbest: 1.3698920 (1099)\ttotal: 4.54s\tremaining: 57.4s\n",
      "1200:\tlearn: 1.1695679\ttest: 1.3563681\tbest: 1.3563681 (1200)\ttotal: 4.95s\tremaining: 56.9s\n",
      "1300:\tlearn: 1.1334331\ttest: 1.3384346\tbest: 1.3384346 (1300)\ttotal: 5.36s\tremaining: 56.4s\n",
      "1400:\tlearn: 1.1020633\ttest: 1.3261294\tbest: 1.3261294 (1400)\ttotal: 5.77s\tremaining: 56s\n",
      "1500:\tlearn: 1.0732408\ttest: 1.3085661\tbest: 1.3082932 (1497)\ttotal: 6.17s\tremaining: 55.5s\n",
      "1600:\tlearn: 1.0407742\ttest: 1.2913157\tbest: 1.2911216 (1598)\ttotal: 6.58s\tremaining: 55.1s\n",
      "1700:\tlearn: 1.0121905\ttest: 1.2804619\tbest: 1.2802709 (1693)\ttotal: 6.98s\tremaining: 54.6s\n",
      "1800:\tlearn: 0.9795936\ttest: 1.2688008\tbest: 1.2681591 (1789)\ttotal: 7.39s\tremaining: 54.2s\n",
      "1900:\tlearn: 0.9479286\ttest: 1.2591432\tbest: 1.2580971 (1896)\ttotal: 7.8s\tremaining: 53.8s\n",
      "2000:\tlearn: 0.9195282\ttest: 1.2496179\tbest: 1.2494605 (1996)\ttotal: 8.21s\tremaining: 53.4s\n",
      "2100:\tlearn: 0.8888881\ttest: 1.2371331\tbest: 1.2367893 (2089)\ttotal: 8.62s\tremaining: 52.9s\n",
      "2200:\tlearn: 0.8579888\ttest: 1.2241854\tbest: 1.2241661 (2199)\ttotal: 9.03s\tremaining: 52.5s\n",
      "2300:\tlearn: 0.8314173\ttest: 1.2179648\tbest: 1.2177512 (2298)\ttotal: 9.44s\tremaining: 52.1s\n",
      "2400:\tlearn: 0.8039377\ttest: 1.2050265\tbest: 1.2050265 (2400)\ttotal: 9.85s\tremaining: 51.7s\n",
      "2500:\tlearn: 0.7818980\ttest: 1.1978142\tbest: 1.1976994 (2498)\ttotal: 10.3s\tremaining: 51.3s\n",
      "2600:\tlearn: 0.7531646\ttest: 1.1930609\tbest: 1.1929005 (2590)\ttotal: 10.7s\tremaining: 51s\n",
      "2700:\tlearn: 0.7288975\ttest: 1.1833059\tbest: 1.1829488 (2698)\ttotal: 11.1s\tremaining: 50.6s\n",
      "2800:\tlearn: 0.7075920\ttest: 1.1762629\tbest: 1.1762563 (2799)\ttotal: 11.5s\tremaining: 50.2s\n",
      "2900:\tlearn: 0.6859730\ttest: 1.1719426\tbest: 1.1719426 (2900)\ttotal: 11.9s\tremaining: 49.8s\n",
      "3000:\tlearn: 0.6656416\ttest: 1.1659597\tbest: 1.1659597 (3000)\ttotal: 12.4s\tremaining: 49.4s\n",
      "3100:\tlearn: 0.6447910\ttest: 1.1622408\tbest: 1.1620917 (3068)\ttotal: 12.8s\tremaining: 49s\n",
      "3200:\tlearn: 0.6240993\ttest: 1.1581316\tbest: 1.1581316 (3200)\ttotal: 13.2s\tremaining: 48.6s\n",
      "3300:\tlearn: 0.6053097\ttest: 1.1524633\tbest: 1.1524633 (3300)\ttotal: 13.6s\tremaining: 48.2s\n",
      "3400:\tlearn: 0.5847910\ttest: 1.1439608\tbest: 1.1439128 (3390)\ttotal: 14s\tremaining: 47.8s\n",
      "3500:\tlearn: 0.5674970\ttest: 1.1389190\tbest: 1.1389039 (3498)\ttotal: 14.4s\tremaining: 47.4s\n",
      "3600:\tlearn: 0.5515177\ttest: 1.1359465\tbest: 1.1354826 (3584)\ttotal: 14.8s\tremaining: 47s\n",
      "3700:\tlearn: 0.5344960\ttest: 1.1300524\tbest: 1.1300524 (3700)\ttotal: 15.3s\tremaining: 46.6s\n",
      "3800:\tlearn: 0.5180829\ttest: 1.1282857\tbest: 1.1270409 (3762)\ttotal: 15.7s\tremaining: 46.2s\n",
      "3900:\tlearn: 0.5007762\ttest: 1.1260017\tbest: 1.1257943 (3894)\ttotal: 16.1s\tremaining: 45.8s\n",
      "4000:\tlearn: 0.4870049\ttest: 1.1200072\tbest: 1.1195780 (3995)\ttotal: 16.5s\tremaining: 45.4s\n",
      "4100:\tlearn: 0.4709068\ttest: 1.1179404\tbest: 1.1178357 (4098)\ttotal: 16.9s\tremaining: 45s\n",
      "4200:\tlearn: 0.4552951\ttest: 1.1168896\tbest: 1.1158289 (4157)\ttotal: 17.3s\tremaining: 44.6s\n",
      "4300:\tlearn: 0.4415763\ttest: 1.1187738\tbest: 1.1158289 (4157)\ttotal: 17.8s\tremaining: 44.2s\n",
      "4400:\tlearn: 0.4277990\ttest: 1.1179039\tbest: 1.1158289 (4157)\ttotal: 18.2s\tremaining: 43.8s\n",
      "4500:\tlearn: 0.4140907\ttest: 1.1166328\tbest: 1.1154236 (4454)\ttotal: 18.6s\tremaining: 43.4s\n",
      "4600:\tlearn: 0.4009240\ttest: 1.1132272\tbest: 1.1132272 (4600)\ttotal: 19s\tremaining: 43s\n",
      "4700:\tlearn: 0.3884971\ttest: 1.1125866\tbest: 1.1113773 (4639)\ttotal: 19.4s\tremaining: 42.6s\n",
      "4800:\tlearn: 0.3763819\ttest: 1.1105621\tbest: 1.1094237 (4787)\ttotal: 19.8s\tremaining: 42.2s\n",
      "4900:\tlearn: 0.3632498\ttest: 1.1070331\tbest: 1.1070331 (4900)\ttotal: 20.3s\tremaining: 41.8s\n",
      "5000:\tlearn: 0.3507612\ttest: 1.1061413\tbest: 1.1059298 (4995)\ttotal: 20.7s\tremaining: 41.4s\n",
      "5100:\tlearn: 0.3399229\ttest: 1.1033345\tbest: 1.1029594 (5094)\ttotal: 21.1s\tremaining: 41s\n",
      "5200:\tlearn: 0.3288359\ttest: 1.1032929\tbest: 1.1029594 (5094)\ttotal: 21.5s\tremaining: 40.5s\n",
      "5300:\tlearn: 0.3188151\ttest: 1.0999953\tbest: 1.0998250 (5296)\ttotal: 21.9s\tremaining: 40.1s\n",
      "5400:\tlearn: 0.3095501\ttest: 1.0990479\tbest: 1.0988102 (5395)\ttotal: 22.4s\tremaining: 39.7s\n",
      "5500:\tlearn: 0.2999494\ttest: 1.0991844\tbest: 1.0984843 (5471)\ttotal: 22.8s\tremaining: 39.3s\n",
      "5600:\tlearn: 0.2910599\ttest: 1.0970651\tbest: 1.0965634 (5579)\ttotal: 23.2s\tremaining: 38.9s\n",
      "5700:\tlearn: 0.2816772\ttest: 1.0980777\tbest: 1.0960377 (5611)\ttotal: 23.6s\tremaining: 38.5s\n",
      "5800:\tlearn: 0.2734024\ttest: 1.0982762\tbest: 1.0960377 (5611)\ttotal: 24s\tremaining: 38.1s\n",
      "5900:\tlearn: 0.2645528\ttest: 1.0965208\tbest: 1.0960377 (5611)\ttotal: 24.5s\tremaining: 37.7s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.096037654\n",
      "bestIteration = 5611\n",
      "\n",
      "Shrink model to first 5612 iterations.\n",
      "Скор для фолда(18) : 9.0 средний скор на префиксе = 9.0 это заняло = 24 сек.\n",
      "Фолд: 19\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.6010025\ttest: 3.5506341\tbest: 3.5506341 (0)\ttotal: 53.1ms\tremaining: 13m 16s\n",
      "100:\tlearn: 2.2829011\ttest: 2.1106872\tbest: 2.1106872 (100)\ttotal: 437ms\tremaining: 1m 4s\n",
      "200:\tlearn: 1.8702343\ttest: 1.7458089\tbest: 1.7458089 (200)\ttotal: 857ms\tremaining: 1m 3s\n",
      "300:\tlearn: 1.6756832\ttest: 1.5492084\tbest: 1.5492084 (300)\ttotal: 1.27s\tremaining: 1m 2s\n",
      "400:\tlearn: 1.5573759\ttest: 1.4786759\tbest: 1.4786759 (400)\ttotal: 1.69s\tremaining: 1m 1s\n",
      "500:\tlearn: 1.4795572\ttest: 1.4247589\tbest: 1.4247589 (500)\ttotal: 2.1s\tremaining: 1m\n",
      "600:\tlearn: 1.4196923\ttest: 1.3884986\tbest: 1.3881891 (593)\ttotal: 2.51s\tremaining: 1m\n",
      "700:\tlearn: 1.3689058\ttest: 1.3667969\tbest: 1.3667495 (693)\ttotal: 2.93s\tremaining: 59.7s\n",
      "800:\tlearn: 1.3229831\ttest: 1.3514663\tbest: 1.3513452 (799)\ttotal: 3.33s\tremaining: 59.1s\n",
      "900:\tlearn: 1.2842701\ttest: 1.3301991\tbest: 1.3293276 (898)\ttotal: 3.74s\tremaining: 58.5s\n",
      "1000:\tlearn: 1.2497323\ttest: 1.3201893\tbest: 1.3197656 (997)\ttotal: 4.15s\tremaining: 58s\n",
      "1100:\tlearn: 1.2147746\ttest: 1.3014337\tbest: 1.3014337 (1100)\ttotal: 4.55s\tremaining: 57.5s\n",
      "1200:\tlearn: 1.1785538\ttest: 1.2963265\tbest: 1.2961417 (1181)\ttotal: 4.96s\tremaining: 57s\n",
      "1300:\tlearn: 1.1425396\ttest: 1.2850136\tbest: 1.2850136 (1300)\ttotal: 5.37s\tremaining: 56.5s\n",
      "1400:\tlearn: 1.1097966\ttest: 1.2723829\tbest: 1.2723829 (1400)\ttotal: 5.78s\tremaining: 56.1s\n",
      "1500:\tlearn: 1.0722987\ttest: 1.2540191\tbest: 1.2535505 (1499)\ttotal: 6.19s\tremaining: 55.7s\n",
      "1600:\tlearn: 1.0377277\ttest: 1.2371546\tbest: 1.2371546 (1600)\ttotal: 6.6s\tremaining: 55.2s\n",
      "1700:\tlearn: 1.0040528\ttest: 1.2204024\tbest: 1.2204024 (1700)\ttotal: 7.01s\tremaining: 54.8s\n",
      "1800:\tlearn: 0.9725647\ttest: 1.2104113\tbest: 1.2104113 (1800)\ttotal: 7.44s\tremaining: 54.5s\n",
      "1900:\tlearn: 0.9443169\ttest: 1.2037040\tbest: 1.2037040 (1900)\ttotal: 7.86s\tremaining: 54.1s\n",
      "2000:\tlearn: 0.9159458\ttest: 1.1941847\tbest: 1.1941721 (1997)\ttotal: 8.27s\tremaining: 53.7s\n",
      "2100:\tlearn: 0.8897245\ttest: 1.1813368\tbest: 1.1809746 (2095)\ttotal: 8.68s\tremaining: 53.3s\n",
      "2200:\tlearn: 0.8635584\ttest: 1.1733650\tbest: 1.1733650 (2200)\ttotal: 9.09s\tremaining: 52.9s\n",
      "2300:\tlearn: 0.8426674\ttest: 1.1649313\tbest: 1.1649313 (2300)\ttotal: 9.5s\tremaining: 52.4s\n",
      "2400:\tlearn: 0.8181366\ttest: 1.1540384\tbest: 1.1540384 (2400)\ttotal: 9.91s\tremaining: 52s\n",
      "2500:\tlearn: 0.7967145\ttest: 1.1432264\tbest: 1.1429785 (2485)\ttotal: 10.3s\tremaining: 51.6s\n",
      "2600:\tlearn: 0.7744437\ttest: 1.1280571\tbest: 1.1280571 (2600)\ttotal: 10.7s\tremaining: 51.2s\n",
      "2700:\tlearn: 0.7522329\ttest: 1.1150012\tbest: 1.1147520 (2695)\ttotal: 11.2s\tremaining: 50.8s\n",
      "2800:\tlearn: 0.7279001\ttest: 1.1047980\tbest: 1.1047980 (2800)\ttotal: 11.6s\tremaining: 50.4s\n",
      "2900:\tlearn: 0.7062583\ttest: 1.0979191\tbest: 1.0978700 (2884)\ttotal: 12s\tremaining: 50s\n",
      "3000:\tlearn: 0.6855614\ttest: 1.0918396\tbest: 1.0908198 (2952)\ttotal: 12.4s\tremaining: 49.6s\n",
      "3100:\tlearn: 0.6638400\ttest: 1.0848947\tbest: 1.0848912 (3099)\ttotal: 12.8s\tremaining: 49.1s\n",
      "3200:\tlearn: 0.6425645\ttest: 1.0779793\tbest: 1.0773431 (3192)\ttotal: 13.2s\tremaining: 48.7s\n",
      "3300:\tlearn: 0.6224893\ttest: 1.0717785\tbest: 1.0714765 (3298)\ttotal: 13.6s\tremaining: 48.3s\n",
      "3400:\tlearn: 0.6037313\ttest: 1.0648285\tbest: 1.0644971 (3399)\ttotal: 14.1s\tremaining: 47.9s\n",
      "3500:\tlearn: 0.5841110\ttest: 1.0547407\tbest: 1.0547382 (3499)\ttotal: 14.5s\tremaining: 47.5s\n",
      "3600:\tlearn: 0.5658442\ttest: 1.0483659\tbest: 1.0481135 (3597)\ttotal: 14.9s\tremaining: 47.1s\n",
      "3700:\tlearn: 0.5488076\ttest: 1.0439985\tbest: 1.0436460 (3668)\ttotal: 15.3s\tremaining: 46.7s\n",
      "3800:\tlearn: 0.5320796\ttest: 1.0402279\tbest: 1.0400205 (3785)\ttotal: 15.7s\tremaining: 46.3s\n",
      "3900:\tlearn: 0.5147036\ttest: 1.0330289\tbest: 1.0327760 (3895)\ttotal: 16.1s\tremaining: 45.9s\n",
      "4000:\tlearn: 0.4987804\ttest: 1.0270442\tbest: 1.0268772 (3998)\ttotal: 16.6s\tremaining: 45.5s\n",
      "4100:\tlearn: 0.4809060\ttest: 1.0232136\tbest: 1.0232136 (4100)\ttotal: 17s\tremaining: 45.1s\n",
      "4200:\tlearn: 0.4652024\ttest: 1.0193607\tbest: 1.0192240 (4199)\ttotal: 17.4s\tremaining: 44.7s\n",
      "4300:\tlearn: 0.4499636\ttest: 1.0186047\tbest: 1.0185737 (4298)\ttotal: 17.8s\tremaining: 44.3s\n",
      "4400:\tlearn: 0.4335610\ttest: 1.0144999\tbest: 1.0144854 (4397)\ttotal: 18.2s\tremaining: 43.9s\n",
      "4500:\tlearn: 0.4190880\ttest: 1.0082177\tbest: 1.0079612 (4498)\ttotal: 18.7s\tremaining: 43.5s\n",
      "4600:\tlearn: 0.4062572\ttest: 1.0032613\tbest: 1.0023088 (4577)\ttotal: 19.1s\tremaining: 43.1s\n",
      "4700:\tlearn: 0.3937105\ttest: 0.9986580\tbest: 0.9984898 (4699)\ttotal: 19.5s\tremaining: 42.7s\n",
      "4800:\tlearn: 0.3791029\ttest: 0.9926731\tbest: 0.9926731 (4800)\ttotal: 19.9s\tremaining: 42.3s\n",
      "4900:\tlearn: 0.3669967\ttest: 0.9915017\tbest: 0.9902067 (4877)\ttotal: 20.3s\tremaining: 41.9s\n",
      "5000:\tlearn: 0.3550968\ttest: 0.9872255\tbest: 0.9868522 (4996)\ttotal: 20.8s\tremaining: 41.5s\n",
      "5100:\tlearn: 0.3444668\ttest: 0.9843953\tbest: 0.9843953 (5100)\ttotal: 21.2s\tremaining: 41.1s\n",
      "5200:\tlearn: 0.3333798\ttest: 0.9802956\tbest: 0.9801706 (5196)\ttotal: 21.6s\tremaining: 40.7s\n",
      "5300:\tlearn: 0.3224400\ttest: 0.9779341\tbest: 0.9778088 (5299)\ttotal: 22s\tremaining: 40.3s\n",
      "5400:\tlearn: 0.3113897\ttest: 0.9782398\tbest: 0.9775467 (5310)\ttotal: 22.4s\tremaining: 39.9s\n",
      "5500:\tlearn: 0.3011226\ttest: 0.9769684\tbest: 0.9769684 (5500)\ttotal: 22.9s\tremaining: 39.5s\n",
      "5600:\tlearn: 0.2913016\ttest: 0.9733587\tbest: 0.9733587 (5600)\ttotal: 23.3s\tremaining: 39s\n",
      "5700:\tlearn: 0.2826129\ttest: 0.9718818\tbest: 0.9718818 (5700)\ttotal: 23.7s\tremaining: 38.6s\n",
      "5800:\tlearn: 0.2745387\ttest: 0.9690760\tbest: 0.9690577 (5793)\ttotal: 24.1s\tremaining: 38.2s\n",
      "5900:\tlearn: 0.2655304\ttest: 0.9641806\tbest: 0.9641420 (5899)\ttotal: 24.5s\tremaining: 37.8s\n",
      "6000:\tlearn: 0.2557584\ttest: 0.9624403\tbest: 0.9621283 (5960)\ttotal: 24.9s\tremaining: 37.4s\n",
      "6100:\tlearn: 0.2475848\ttest: 0.9596376\tbest: 0.9596376 (6100)\ttotal: 25.4s\tremaining: 37s\n",
      "6200:\tlearn: 0.2397630\ttest: 0.9551513\tbest: 0.9545713 (6193)\ttotal: 25.8s\tremaining: 36.6s\n",
      "6300:\tlearn: 0.2324666\ttest: 0.9532093\tbest: 0.9532093 (6300)\ttotal: 26.2s\tremaining: 36.2s\n",
      "6400:\tlearn: 0.2251771\ttest: 0.9508957\tbest: 0.9505141 (6375)\ttotal: 26.6s\tremaining: 35.8s\n",
      "6500:\tlearn: 0.2182627\ttest: 0.9500754\tbest: 0.9495853 (6486)\ttotal: 27s\tremaining: 35.4s\n",
      "6600:\tlearn: 0.2106019\ttest: 0.9486925\tbest: 0.9485244 (6559)\ttotal: 27.5s\tremaining: 34.9s\n",
      "6700:\tlearn: 0.2033401\ttest: 0.9458707\tbest: 0.9457761 (6675)\ttotal: 27.9s\tremaining: 34.5s\n",
      "6800:\tlearn: 0.1963099\ttest: 0.9444136\tbest: 0.9437831 (6777)\ttotal: 28.3s\tremaining: 34.1s\n",
      "6900:\tlearn: 0.1899007\ttest: 0.9434957\tbest: 0.9434957 (6900)\ttotal: 28.7s\tremaining: 33.7s\n",
      "7000:\tlearn: 0.1842607\ttest: 0.9443491\tbest: 0.9432174 (6917)\ttotal: 29.2s\tremaining: 33.3s\n",
      "7100:\tlearn: 0.1786800\ttest: 0.9459051\tbest: 0.9432174 (6917)\ttotal: 29.6s\tremaining: 32.9s\n",
      "7200:\tlearn: 0.1731572\ttest: 0.9436363\tbest: 0.9432174 (6917)\ttotal: 30s\tremaining: 32.5s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.943217447\n",
      "bestIteration = 6917\n",
      "\n",
      "Shrink model to first 6918 iterations.\n",
      "Скор для фолда(19) : 9.0 средний скор на префиксе = 9.0 это заняло = 30 сек.\n",
      "Процесс обучения модели занял = 646 секунд\n"
     ]
    }
   ],
   "source": [
    "class CatBoostEvalMetricPearson(object):\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        preds = np.array(approxes[0])\n",
    "        target = np.array(target)\n",
    "        err = deviation_metric(np.exp(target), np.exp(preds))\n",
    "        return err, 0\n",
    "\n",
    "\n",
    "def train_cat(train, valid, num_features, categorical_features, target_train, target_valid, EPOCHS):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    test_data = Pool(data=test[num_features + categorical_features],\n",
    "                  cat_features=categorical_features)\n",
    "\n",
    "\n",
    "    train_data = Pool(data=train[num_features + categorical_features],\n",
    "                      cat_features=categorical_features,\n",
    "                      label=np.log(target_train))\n",
    "\n",
    "    val_data = Pool(data=valid[num_features + categorical_features],\n",
    "                cat_features=categorical_features,\n",
    "                  label=np.log(target_valid))\n",
    "    \n",
    "\n",
    "    cat_model = CatBoostRegressor(\n",
    "        learning_rate=0.012,\n",
    "        iterations=15000,\n",
    "        metric_period=100,\n",
    "        eval_metric=CatBoostEvalMetricPearson(),\n",
    "    )\n",
    "    cat_model.fit(train_data, eval_set=val_data, use_best_model=True, early_stopping_rounds=300)\n",
    "  \n",
    "    y_valid = cat_model.predict(test_data)\n",
    "\n",
    "    return cat_model, y_valid\n",
    "\n",
    "\n",
    "start_train_model_time = time.time()\n",
    "\n",
    "scores = []\n",
    "cat_predicts = np.zeros(len(train))\n",
    "\n",
    "cat_models = []\n",
    "for fold_num, (train_indexes, valid_indexes) in enumerate(split_list):\n",
    "    start_time = time.time()\n",
    "    print(f\"Фолд: {fold_num}\")\n",
    "\n",
    "    train_sub_df = train[features_columns_order].loc[train_indexes].reset_index(drop=True)\n",
    "    valid_sub_df = train[features_columns_order].loc[valid_indexes].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Размер трейна = {train_sub_df.shape} Размер валидации = {valid_sub_df.shape}\")\n",
    "    model, predict_validation = train_cat(\n",
    "        train_sub_df,\n",
    "        valid_sub_df,\n",
    "        NUM_FEATURES_COLUMNS,\n",
    "        CATEGORICAL_FEATURES_COLUMNS,\n",
    "        train_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        valid_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        EPOCHS\n",
    "        )\n",
    "\n",
    "    cat_models += [model]\n",
    "    predict_on_validation = model.predict(valid_sub_df[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS])\n",
    "    cat_predicts[valid_indexes] = np.exp(predict_on_validation)\n",
    "    targets_for_validation = valid_sub_df[TARGET_COLUMNS].values[:, 0]\n",
    "    current_score = deviation_metric(targets_for_validation, predict_on_validation)\n",
    "    scores += [current_score]\n",
    "    print(\n",
    "        f\"Скор для фолда({fold_num}) : {np.round(current_score, 4)} средний скор на префиксе = {np.round(np.mean(scores), 4)} это заняло = {int(time.time() - start_time)} сек.\")\n",
    "print(f\"Процесс обучения модели занял = {int(time.time() - start_train_model_time)} секунд\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02607e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16538.684613884474, 1271158.006455984, 61562.51109312501)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Предикт xgb на test\n",
    "def get_cat_predict(models, test):\n",
    "    result = np.zeros(len(test))\n",
    "    for model in cat_models:\n",
    "        predict = model.predict(test[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS])\n",
    "        result += np.exp(predict) / len(models)\n",
    "    return result\n",
    "\n",
    "\n",
    "test_cat_predict = get_cat_predict(xgb_models, test)\n",
    "\n",
    "test_cat_predict.min(), test_cat_predict.max(), test_cat_predict.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45587c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4bb4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('nn_predicts.npy', nn_predicts)\n",
    "np.save('lgb_predicts.npy', lgb_predicts)\n",
    "np.save('xgb_predicts.npy', xgb_predicts)\n",
    "np.save('cat_predicts.npy', cat_predicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e98ac1dd-032a-4272-9bc2-10a9860988ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.017171\n",
      "         Iterations: 17\n",
      "         Function evaluations: 176\n",
      "         Gradient evaluations: 22\n"
     ]
    }
   ],
   "source": [
    "def minimize_arit(W):\n",
    "    \n",
    "    vect = train.city.apply(lambda x: W[4] if x == 0 else W[5] if x == 4 else 1.0).values\n",
    "    \n",
    "    ypred = (W[0] * nn_predicts + W[1] * lgb_predicts + W[2] * xgb_predicts + W[3] * cat_predicts) * vect\n",
    "    return deviation_metric(train_targets, ypred)\n",
    "\n",
    "W = minimize(minimize_arit, [1.0 / 4] * 4 + [1.0] * 2, options={'gtol': 1e-6, 'disp': True}).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1928a1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11291272, -0.03197168,  0.41792838,  0.41104496,  1.00082998,\n",
       "        0.99003515])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "677681d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = test.city.apply(lambda x: W[4] if x == 0 else W[5] if x == 4 else 1.0).values\n",
    "\n",
    "test_submission = pd.read_csv('dataset/test_submission.csv')\n",
    "test_submission['per_square_meter_price'] = (test_nn_predict * W[0] + test_lgb_predict * W[1] + np.exp(test_xgb_predict) * W[2] + test_cat_predict * W[3]) * vect\n",
    "test_submission['per_square_meter_price'] = test_submission['per_square_meter_price'].apply(lambda x: max(0.0, x))\n",
    "test_submission.to_csv('submission_city.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d759994",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b2a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xgb_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20625160-8774-4a5a-9efc-b9938faa2c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e18485c2-ab2f-488c-9834-180f4c62cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub118 = pd.read_csv('submission_1.18.csv')\n",
    "sub = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "be161d00-91cd-4281-8f63-e7094185f340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>per_square_meter_price</th>\n",
       "      <th>pred_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COL_289284</td>\n",
       "      <td>39867.435371</td>\n",
       "      <td>40259.468314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COL_289305</td>\n",
       "      <td>39655.637291</td>\n",
       "      <td>40036.357894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COL_289318</td>\n",
       "      <td>38896.851638</td>\n",
       "      <td>39364.412040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COL_289354</td>\n",
       "      <td>92529.584903</td>\n",
       "      <td>89562.368291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COL_289399</td>\n",
       "      <td>45660.643114</td>\n",
       "      <td>46518.927106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>COL_455089</td>\n",
       "      <td>24861.348343</td>\n",
       "      <td>24744.822612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>COL_455212</td>\n",
       "      <td>40821.884639</td>\n",
       "      <td>40702.485920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>COL_455261</td>\n",
       "      <td>40610.014172</td>\n",
       "      <td>41730.787348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>COL_455381</td>\n",
       "      <td>42825.089013</td>\n",
       "      <td>42580.386226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>COL_455397</td>\n",
       "      <td>44680.607468</td>\n",
       "      <td>43554.683287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2974 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  per_square_meter_price     pred_city\n",
       "0     COL_289284            39867.435371  40259.468314\n",
       "1     COL_289305            39655.637291  40036.357894\n",
       "2     COL_289318            38896.851638  39364.412040\n",
       "3     COL_289354            92529.584903  89562.368291\n",
       "4     COL_289399            45660.643114  46518.927106\n",
       "...          ...                     ...           ...\n",
       "2969  COL_455089            24861.348343  24744.822612\n",
       "2970  COL_455212            40821.884639  40702.485920\n",
       "2971  COL_455261            40610.014172  41730.787348\n",
       "2972  COL_455381            42825.089013  42580.386226\n",
       "2973  COL_455397            44680.607468  43554.683287\n",
       "\n",
       "[2974 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub118['pred_city'] = sub.per_square_meter_price\n",
    "sub118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3a3d1-613c-4d34-942b-c60611b74f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0ac5c553-f9a9-4a6d-a50f-f83b98dd956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = pd.read_csv('dataset/train.csv')\n",
    "train_ = train_[train_.price_type == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0afcd3d0-31d5-49a0-b0c6-d51a292472fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Красноярск', 0),\n",
       " ('Саратов', 1),\n",
       " ('Красноярск', 0),\n",
       " ('Иркутск', 2),\n",
       " ('Белгород', 3),\n",
       " ('Санкт-Петербург', 4),\n",
       " ('Калуга', 5),\n",
       " ('Сургут', 6),\n",
       " ('Иркутск', 2),\n",
       " ('Иркутск', 2),\n",
       " ('Кемерово', 7),\n",
       " ('Иркутск', 2),\n",
       " ('Новокузнецк', 8),\n",
       " ('Новокузнецк', 8),\n",
       " ('Калуга', 5),\n",
       " ('Белгород', 3),\n",
       " ('Пермь', 9),\n",
       " ('Пермь', 9),\n",
       " ('Владивосток', 10),\n",
       " ('Петрозаводск', 11)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(train_[:20].city, train[:20].city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76427604-7a24-472e-a538-86ae87e07156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b99113-9f6f-4567-9f97-03050f4836ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
