{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3492153",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_GPU = False\n",
    "# Импорт нужных библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from neighbors import Neighborhoods\n",
    "\n",
    "from indices import MainDataset\n",
    "from dnn_utils import preprocess_floor\n",
    "from metric import metrics_stat, deviation_metric\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import Pool\n",
    "\n",
    "def reset_tensorflow_session():\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(41)\n",
    "    np.random.seed(41)\n",
    "\n",
    "\n",
    "THRESHOLD = 0.15\n",
    "NEGATIVE_WEIGHT = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a313a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Категориальные данные\n",
    "CATEGORICAL_FEATURES_COLUMNS = ['region', 'city', 'realty_type', 'floor', 'osm_city_nearest_name', 'street']\n",
    "# Численные данные\n",
    "NUM_FEATURES_COLUMNS = ['lat', 'lng', 'osm_amenity_points_in_0.001',\n",
    "                        'osm_amenity_points_in_0.005', 'osm_amenity_points_in_0.0075',\n",
    "                        'osm_amenity_points_in_0.01', 'osm_building_points_in_0.001',\n",
    "                        'osm_building_points_in_0.005', 'osm_building_points_in_0.0075',\n",
    "                        'osm_building_points_in_0.01', 'osm_catering_points_in_0.001',\n",
    "                        'osm_catering_points_in_0.005', 'osm_catering_points_in_0.0075',\n",
    "                        'osm_catering_points_in_0.01', 'osm_city_closest_dist',\n",
    "                        'osm_city_nearest_population',\n",
    "                        'osm_crossing_closest_dist', 'osm_crossing_points_in_0.001',\n",
    "                        'osm_crossing_points_in_0.005', 'osm_crossing_points_in_0.0075',\n",
    "                        'osm_crossing_points_in_0.01', 'osm_culture_points_in_0.001',\n",
    "                        'osm_culture_points_in_0.005', 'osm_culture_points_in_0.0075',\n",
    "                        'osm_culture_points_in_0.01', 'osm_finance_points_in_0.001',\n",
    "                        'osm_finance_points_in_0.005', 'osm_finance_points_in_0.0075',\n",
    "                        'osm_finance_points_in_0.01', 'osm_healthcare_points_in_0.005',\n",
    "                        'osm_healthcare_points_in_0.0075', 'osm_healthcare_points_in_0.01',\n",
    "                        'osm_historic_points_in_0.005', 'osm_historic_points_in_0.0075',\n",
    "                        'osm_historic_points_in_0.01', 'osm_hotels_points_in_0.005',\n",
    "                        'osm_hotels_points_in_0.0075', 'osm_hotels_points_in_0.01',\n",
    "                        'osm_leisure_points_in_0.005', 'osm_leisure_points_in_0.0075',\n",
    "                        'osm_leisure_points_in_0.01', 'osm_offices_points_in_0.001',\n",
    "                        'osm_offices_points_in_0.005', 'osm_offices_points_in_0.0075',\n",
    "                        'osm_offices_points_in_0.01', 'osm_shops_points_in_0.001',\n",
    "                        'osm_shops_points_in_0.005', 'osm_shops_points_in_0.0075',\n",
    "                        'osm_shops_points_in_0.01', 'osm_subway_closest_dist',\n",
    "                        'osm_train_stop_closest_dist', 'osm_train_stop_points_in_0.005',\n",
    "                        'osm_train_stop_points_in_0.0075', 'osm_train_stop_points_in_0.01',\n",
    "                        'osm_transport_stop_closest_dist', 'osm_transport_stop_points_in_0.005',\n",
    "                        'osm_transport_stop_points_in_0.0075',\n",
    "                        'osm_transport_stop_points_in_0.01',\n",
    "                        'reform_count_of_houses_1000', 'reform_count_of_houses_500',\n",
    "                        'reform_house_population_1000', 'reform_house_population_500',\n",
    "                        'reform_mean_floor_count_1000', 'reform_mean_floor_count_500',\n",
    "                        'reform_mean_year_building_1000', 'reform_mean_year_building_500', 'total_square',\n",
    "                        \"neighbor_dist\", \"neighbor_total_price\", \"neighbor_square_price\", \"neighbor10_dist\",\n",
    "                        \"has_basement\", \"floor_count\"\n",
    "\n",
    "                        ]\n",
    "# Таргет\n",
    "TARGET_COLUMNS = ['per_square_meter_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b49bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "train = train[train.price_type == 1].reset_index(drop=True)\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "dataset = pd.concat([train, test]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd6da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_index = MainDataset(\"dataset/train.csv\")\n",
    "test_dataset_index = MainDataset(\"dataset/test.csv\", need_index=False)\n",
    "neighborhoods = Neighborhoods(train_dataset_index.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a62bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"neighbor_dist\"] = -999\n",
    "dataset[\"neighbor_total_price\"] = -999\n",
    "dataset[\"neighbor_square_price\"] = -999\n",
    "dataset[\"neighbor10_dist\"] = -999\n",
    "for d in [test_dataset_index, train_dataset_index]:\n",
    "    for i, o in enumerate(d.all_objects):\n",
    "        if o.row[\"price_type\"] != 1:\n",
    "            continue\n",
    "        neighbor = neighborhoods.get_haversine_closest(o, 12)\n",
    "        neighbor1 = neighborhoods.get_haversine_closest(o, 2)\n",
    "        n = neighbor[0]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor_dist\"] = n[1]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor_total_price\"] = n[0].row[\"per_square_meter_price\"] * \\\n",
    "                                                                            n[0].row[\"total_square\"]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor_square_price\"] = n[0].row[\"per_square_meter_price\"]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor10_dist\"] = neighbor[10][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25239261",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset=preprocess_floor.preprocess(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c745feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0abeb9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>floor</th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>osm_amenity_points_in_0.001</th>\n",
       "      <th>osm_amenity_points_in_0.005</th>\n",
       "      <th>osm_amenity_points_in_0.0075</th>\n",
       "      <th>osm_amenity_points_in_0.01</th>\n",
       "      <th>osm_building_points_in_0.001</th>\n",
       "      <th>...</th>\n",
       "      <th>date</th>\n",
       "      <th>realty_type</th>\n",
       "      <th>price_type</th>\n",
       "      <th>is_train</th>\n",
       "      <th>neighbor_dist</th>\n",
       "      <th>neighbor_total_price</th>\n",
       "      <th>neighbor_square_price</th>\n",
       "      <th>neighbor10_dist</th>\n",
       "      <th>has_basement</th>\n",
       "      <th>floor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Красноярск</td>\n",
       "      <td>-999</td>\n",
       "      <td>COL_62</td>\n",
       "      <td>56.063615</td>\n",
       "      <td>92.958428</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334024</td>\n",
       "      <td>995000.0</td>\n",
       "      <td>41458.333333</td>\n",
       "      <td>0.451369</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Саратов</td>\n",
       "      <td>-999</td>\n",
       "      <td>COL_71</td>\n",
       "      <td>51.534581</td>\n",
       "      <td>46.020549</td>\n",
       "      <td>13</td>\n",
       "      <td>198</td>\n",
       "      <td>345</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086136</td>\n",
       "      <td>2985000.0</td>\n",
       "      <td>33166.666667</td>\n",
       "      <td>0.190652</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Красноярск</td>\n",
       "      <td>-999</td>\n",
       "      <td>COL_140</td>\n",
       "      <td>56.026884</td>\n",
       "      <td>92.818323</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027117</td>\n",
       "      <td>18308000.0</td>\n",
       "      <td>61026.666667</td>\n",
       "      <td>0.291762</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Иркутск</td>\n",
       "      <td>-999</td>\n",
       "      <td>COL_202</td>\n",
       "      <td>52.275528</td>\n",
       "      <td>104.251444</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220089</td>\n",
       "      <td>5870000.0</td>\n",
       "      <td>58700.000000</td>\n",
       "      <td>0.435699</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Белгород</td>\n",
       "      <td>-999</td>\n",
       "      <td>COL_207</td>\n",
       "      <td>50.576545</td>\n",
       "      <td>36.584197</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>73</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046677</td>\n",
       "      <td>4179000.0</td>\n",
       "      <td>59700.000000</td>\n",
       "      <td>0.147191</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         city floor       id        lat         lng  \\\n",
       "0  Красноярск  -999   COL_62  56.063615   92.958428   \n",
       "1     Саратов  -999   COL_71  51.534581   46.020549   \n",
       "2  Красноярск  -999  COL_140  56.026884   92.818323   \n",
       "3     Иркутск  -999  COL_202  52.275528  104.251444   \n",
       "4    Белгород  -999  COL_207  50.576545   36.584197   \n",
       "\n",
       "   osm_amenity_points_in_0.001  osm_amenity_points_in_0.005  \\\n",
       "0                            0                            7   \n",
       "1                           13                          198   \n",
       "2                            3                           15   \n",
       "3                            0                           10   \n",
       "4                            4                           48   \n",
       "\n",
       "   osm_amenity_points_in_0.0075  osm_amenity_points_in_0.01  \\\n",
       "0                            14                          26   \n",
       "1                           345                         462   \n",
       "2                            23                          33   \n",
       "3                            26                          40   \n",
       "4                            73                          92   \n",
       "\n",
       "   osm_building_points_in_0.001  ...        date  realty_type  price_type  \\\n",
       "0                             0  ...  2020-01-05          110           1   \n",
       "1                             0  ...  2020-01-05           10           1   \n",
       "2                             0  ...  2020-01-05           10           1   \n",
       "3                             0  ...  2020-01-05           10           1   \n",
       "4                             0  ...  2020-01-05           10           1   \n",
       "\n",
       "   is_train  neighbor_dist  neighbor_total_price  neighbor_square_price  \\\n",
       "0         1       0.334024              995000.0           41458.333333   \n",
       "1         1       0.086136             2985000.0           33166.666667   \n",
       "2         1       0.027117            18308000.0           61026.666667   \n",
       "3         1       0.220089             5870000.0           58700.000000   \n",
       "4         1       0.046677             4179000.0           59700.000000   \n",
       "\n",
       "   neighbor10_dist has_basement  floor_count  \n",
       "0         0.451369         -999         -999  \n",
       "1         0.190652         -999         -999  \n",
       "2         0.291762         -999         -999  \n",
       "3         0.435699         -999         -999  \n",
       "4         0.147191         -999         -999  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80bdfe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        dict_encoding = {key: val for val, key in enumerate(df[column].unique())}\n",
    "        df[column] = df[column].map(dict_encoding)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6773a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Квантильное преобразование данных\n",
    "def get_quantile_transform(_df, columns_for_quantilization, random_state=41, n_quantiles=100,\n",
    "                           output_distribution='normal'):\n",
    "    df = _df.copy()\n",
    "    for col in columns_for_quantilization:\n",
    "        qt = QuantileTransformer(random_state=random_state, n_quantiles=n_quantiles,\n",
    "                                 output_distribution=output_distribution)\n",
    "        df[col] = qt.fit_transform(df[[col]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "383f9ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# МинМакс преобразование данных\n",
    "def get_minmax_transform(_df, columns_for_quantilization, min_value=-1, max_value=1):\n",
    "    df = _df.copy()\n",
    "    for col in columns_for_quantilization:\n",
    "        scaler = MinMaxScaler(feature_range=(min_value, max_value))\n",
    "        df[col] = scaler.fit_transform(df[[col]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca33d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hotencoding для категориальных фичей\n",
    "data = encode_categorical_features(dataset, CATEGORICAL_FEATURES_COLUMNS)\n",
    "# Нормализация численных данных\n",
    "data = get_quantile_transform(data, NUM_FEATURES_COLUMNS)\n",
    "data = get_minmax_transform(data, NUM_FEATURES_COLUMNS)\n",
    "# Заполняем NaN значения\n",
    "data = data.fillna(data.mean())\n",
    "train = data[data.is_train == 1].reset_index(drop=True)\n",
    "test = data[data.is_train == 0].reset_index(drop=True)\n",
    "train = train.drop(columns=['is_train'])\n",
    "test = test.drop(columns=['is_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfaa49e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>floor</th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>osm_amenity_points_in_0.001</th>\n",
       "      <th>osm_amenity_points_in_0.005</th>\n",
       "      <th>osm_amenity_points_in_0.0075</th>\n",
       "      <th>osm_amenity_points_in_0.01</th>\n",
       "      <th>osm_building_points_in_0.001</th>\n",
       "      <th>...</th>\n",
       "      <th>date</th>\n",
       "      <th>realty_type</th>\n",
       "      <th>price_type</th>\n",
       "      <th>is_train</th>\n",
       "      <th>neighbor_dist</th>\n",
       "      <th>neighbor_total_price</th>\n",
       "      <th>neighbor_square_price</th>\n",
       "      <th>neighbor10_dist</th>\n",
       "      <th>has_basement</th>\n",
       "      <th>floor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COL_62</td>\n",
       "      <td>0.060226</td>\n",
       "      <td>0.223088</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.234768</td>\n",
       "      <td>-0.256798</td>\n",
       "      <td>-0.245381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.295130</td>\n",
       "      <td>-0.335815</td>\n",
       "      <td>-0.100331</td>\n",
       "      <td>0.117364</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>COL_71</td>\n",
       "      <td>-0.284322</td>\n",
       "      <td>-0.042332</td>\n",
       "      <td>0.298058</td>\n",
       "      <td>0.285412</td>\n",
       "      <td>0.284259</td>\n",
       "      <td>0.272468</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.125504</td>\n",
       "      <td>-0.153689</td>\n",
       "      <td>-0.153689</td>\n",
       "      <td>-0.153382</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COL_140</td>\n",
       "      <td>0.033880</td>\n",
       "      <td>0.146323</td>\n",
       "      <td>0.067077</td>\n",
       "      <td>-0.131259</td>\n",
       "      <td>-0.182216</td>\n",
       "      <td>-0.206562</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.370964</td>\n",
       "      <td>0.156685</td>\n",
       "      <td>0.014726</td>\n",
       "      <td>-0.012172</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>COL_202</td>\n",
       "      <td>-0.206973</td>\n",
       "      <td>0.271530</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.194000</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.178437</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175130</td>\n",
       "      <td>-0.024577</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.108546</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>COL_207</td>\n",
       "      <td>-0.335843</td>\n",
       "      <td>-0.118494</td>\n",
       "      <td>0.110487</td>\n",
       "      <td>0.077531</td>\n",
       "      <td>0.017066</td>\n",
       "      <td>-0.039228</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.260458</td>\n",
       "      <td>-0.093665</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>-0.236691</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   city  floor       id       lat       lng  osm_amenity_points_in_0.001  \\\n",
       "0     0      0   COL_62  0.060226  0.223088                    -1.000000   \n",
       "1     1      0   COL_71 -0.284322 -0.042332                     0.298058   \n",
       "2     0      0  COL_140  0.033880  0.146323                     0.067077   \n",
       "3     2      0  COL_202 -0.206973  0.271530                    -1.000000   \n",
       "4     3      0  COL_207 -0.335843 -0.118494                     0.110487   \n",
       "\n",
       "   osm_amenity_points_in_0.005  osm_amenity_points_in_0.0075  \\\n",
       "0                    -0.234768                     -0.256798   \n",
       "1                     0.285412                      0.284259   \n",
       "2                    -0.131259                     -0.182216   \n",
       "3                    -0.194000                     -0.167492   \n",
       "4                     0.077531                      0.017066   \n",
       "\n",
       "   osm_amenity_points_in_0.01  osm_building_points_in_0.001  ...        date  \\\n",
       "0                   -0.245381                          -1.0  ...  2020-01-05   \n",
       "1                    0.272468                          -1.0  ...  2020-01-05   \n",
       "2                   -0.206562                          -1.0  ...  2020-01-05   \n",
       "3                   -0.178437                          -1.0  ...  2020-01-05   \n",
       "4                   -0.039228                          -1.0  ...  2020-01-05   \n",
       "\n",
       "   realty_type  price_type  is_train  neighbor_dist  neighbor_total_price  \\\n",
       "0            0           1         1       0.295130             -0.335815   \n",
       "1            1           1         1      -0.125504             -0.153689   \n",
       "2            1           1         1      -0.370964              0.156685   \n",
       "3            1           1         1       0.175130             -0.024577   \n",
       "4            1           1         1      -0.260458             -0.093665   \n",
       "\n",
       "   neighbor_square_price  neighbor10_dist  has_basement  floor_count  \n",
       "0              -0.100331         0.117364          -1.0         -1.0  \n",
       "1              -0.153689        -0.153382          -1.0         -1.0  \n",
       "2               0.014726        -0.012172          -1.0         -1.0  \n",
       "3               0.001980         0.108546          -1.0         -1.0  \n",
       "4               0.007306        -0.236691          -1.0         -1.0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e50cf496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standart_split(data, n_splits=5, seed=41):\n",
    "    kf = KFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
    "    split_list = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        split_list += [(train_index, test_index)]\n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c28ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(arr_features, arr_target, arr_region, arr_city, arr_realty, batch_size):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            {\n",
    "                \"model_features_input\": arr_features,\n",
    "                \"model_region_input\": arr_region,\n",
    "                \"model_city_input\": arr_city,\n",
    "                \"model_realty_input\": arr_realty,\n",
    "            },\n",
    "            {\n",
    "                \"model_output\": arr_target,\n",
    "            },\n",
    "        )\n",
    "    ).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "343535f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_order(columns):\n",
    "    columns_order = sorted([x for x in columns if not x in (CATEGORICAL_FEATURES_COLUMNS + TARGET_COLUMNS)])\n",
    "    return columns_order + CATEGORICAL_FEATURES_COLUMNS + TARGET_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8706f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Коллбэк, для отслеживания целевой метрики\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, val_dataset, val_targets):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.val_targets = val_targets\n",
    "        self.val_dataset = val_dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        predicts = self.model.predict(self.val_dataset)[:, 0]\n",
    "        targets = self.val_targets[:, 0]\n",
    "        print(f\"Текущий реальный скор(валидационная часть): {np.round(deviation_metric(targets, predicts), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7408c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Dropout(x):\n",
    "    return keras.layers.Dropout(x)\n",
    "\n",
    "\n",
    "def Flatten():\n",
    "    return keras.layers.Flatten()\n",
    "\n",
    "\n",
    "def Concatenate():\n",
    "    return keras.layers.Concatenate()\n",
    "\n",
    "\n",
    "# Функция обучения модели\n",
    "def fit(model, epochs, train_dataset, val_dataset, val_targets, verbose=True):\n",
    "    if IS_GPU:\n",
    "        print(f\"Начинаю обучение модели (GPU) количество эпох = {epochs}\")\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            # Коллбэк для остановки, если модель перестала обучаться\n",
    "            early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=2.5e-6,\n",
    "                                                                       patience=100, restore_best_weights=True,\n",
    "                                                                       mode='min')\n",
    "            # Коллбэк для уменьшения скорости обучения\n",
    "            lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-9,\n",
    "                                                               mode='min')\n",
    "            # Кастомный коллбэк для отображения скора по целевой метрике\n",
    "            metric_callback = CustomCallback(val_dataset, val_targets)\n",
    "            history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, verbose=verbose,\n",
    "                                shuffle=True, callbacks=[early_stopping_callback, lr_callback, metric_callback],\n",
    "                                workers=-1)\n",
    "            return history\n",
    "    else:\n",
    "        print(f\"Начинаю обучение модели (СPU) количество эпох = {epochs}\")\n",
    "        # Коллбэк для остановки, если модель перестала обучаться\n",
    "        early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=2.5e-6, patience=100,\n",
    "                                                                   restore_best_weights=True, mode='min')\n",
    "        # Коллбэк для уменьшения скорости обучения\n",
    "        lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-9,\n",
    "                                                           mode='min')\n",
    "        # Кастомный коллбэк для отображения скора по целевой метрике\n",
    "        metric_callback = CustomCallback(val_dataset, val_targets)\n",
    "        history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, verbose=verbose, shuffle=True,\n",
    "                            callbacks=[early_stopping_callback, lr_callback, metric_callback], workers=-1)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f602e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Реализация кастомной функции потерь для обучения\n",
    "def tf_custom_loss(y_true, y_pred):\n",
    "    threshold = 0.6\n",
    "    error = tf.abs(y_true - y_pred) / y_true\n",
    "    is_small_error = error <= threshold\n",
    "    small_error_loss = tf.square(error / 0.15 - 1)\n",
    "    big_error_loss = 9.0 * tf.ones_like(small_error_loss) + tf.abs(error)\n",
    "    # big_error_loss = (3.0 * tf.ones_like(small_error_loss) + tf.abs(error)) ** 2\n",
    "    return tf.where(is_small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bd2234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Компиляция текущей модели\n",
    "def compile_model(train_dataset, val_dataset, num_features, max_realty, max_region, max_city, lr=5e-4):\n",
    "    reset_tensorflow_session()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    model_input_layer = tf.keras.Input(shape=(num_features), name=\"model_features_input\")\n",
    "    model_input_realty = tf.keras.Input(shape=(1), name=\"model_realty_input\")\n",
    "    model_input_region = tf.keras.Input(shape=(1), name=\"model_region_input\")\n",
    "    model_input_city = tf.keras.Input(shape=(1), name=\"model_city_input\")\n",
    "\n",
    "    model_embedding_layer_realty = keras.layers.Embedding(max_realty + 1, 4, input_length=1, dtype=tf.float64)(\n",
    "        model_input_realty)\n",
    "    model_embedding_layer_region = keras.layers.Embedding(max_region + 1, 32, input_length=1, dtype=tf.float64)(\n",
    "        model_input_region)\n",
    "    model_embedding_layer_city = keras.layers.Embedding(max_city + 1, 32, input_length=1, dtype=tf.float64)(\n",
    "        model_input_city)\n",
    "\n",
    "    concatenated_input_layer = Concatenate()(\n",
    "        [Flatten()(model_embedding_layer_realty), Flatten()(model_embedding_layer_region),\n",
    "         Flatten()(model_embedding_layer_city), Flatten()(model_input_layer)])\n",
    "\n",
    "    layer_0 = keras.layers.Dense(128, activation=\"relu\")(concatenated_input_layer)\n",
    "    layer_1 = keras.layers.Dense(64, activation=\"relu\")(layer_0)\n",
    "    layer_2 = keras.layers.Dense(32, activation=\"relu\")(layer_1)\n",
    "    model_output_layer = keras.layers.Dense(1, activation=\"relu\", name=\"model_output\")(layer_2)\n",
    "\n",
    "    cur_model = keras.Model(\n",
    "        inputs=[\n",
    "            model_input_layer,\n",
    "            model_input_realty,\n",
    "            model_input_region,\n",
    "            model_input_city,\n",
    "        ],\n",
    "        outputs=[\n",
    "            model_output_layer,\n",
    "        ])\n",
    "\n",
    "    print(f\"Модель: input_shape = {cur_model.input_shape} output_shape = {cur_model.output_shape}\")\n",
    "#     cur_model.compile(loss=tf_custom_loss, optimizer=optimizer)  # , run_eagerly=True)\n",
    "    cur_model.compile(loss=tf_custom_loss, optimizer=optimizer)  # , run_eagerly=True)\n",
    "\n",
    "    #\n",
    "    return cur_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf5bf10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фолд: 0\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 3.8335Текущий реальный скор(валидационная часть): 1.8458\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 3.8008 - val_loss: 1.9345 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 1.9735Текущий реальный скор(валидационная часть): 1.5845\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9656 - val_loss: 1.6764 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 1.6693Текущий реальный скор(валидационная часть): 1.5415\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6620 - val_loss: 1.6319 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.5058Текущий реальный скор(валидационная часть): 1.4474\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5058 - val_loss: 1.5399 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.4231Текущий реальный скор(валидационная часть): 1.3839\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4803 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 1.3501Текущий реальный скор(валидационная часть): 1.4077\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3482 - val_loss: 1.4944 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 1.2782Текущий реальный скор(валидационная часть): 1.4063\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2885 - val_loss: 1.5006 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 1.2348Текущий реальный скор(валидационная часть): 1.4005\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2344 - val_loss: 1.4983 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.1882Текущий реальный скор(валидационная часть): 1.3747\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1977 - val_loss: 1.4794 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 1.1500Текущий реальный скор(валидационная часть): 1.3538\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1530 - val_loss: 1.4538 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 1.1029Текущий реальный скор(валидационная часть): 1.3622\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1059 - val_loss: 1.4617 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 1.0499Текущий реальный скор(валидационная часть): 1.3505\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0650 - val_loss: 1.4550 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.0308Текущий реальный скор(валидационная часть): 1.3495\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0307 - val_loss: 1.4546 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 1.0067Текущий реальный скор(валидационная часть): 1.3448\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 1.4474 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.9912Текущий реальный скор(валидационная часть): 1.337\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9916 - val_loss: 1.4468 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.9590Текущий реальный скор(валидационная часть): 1.4381\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9755 - val_loss: 1.5462 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.9931Текущий реальный скор(валидационная часть): 1.4665\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.5731 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0350Текущий реальный скор(валидационная часть): 1.3879\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0350 - val_loss: 1.4699 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.9821Текущий реальный скор(валидационная часть): 1.4779\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9853 - val_loss: 1.5602 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.9243Текущий реальный скор(валидационная часть): 1.4032\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9270 - val_loss: 1.4960 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.8782Текущий реальный скор(валидационная часть): 1.3973\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8789 - val_loss: 1.4953 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.8423Текущий реальный скор(валидационная часть): 1.392\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8394 - val_loss: 1.4757 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8047Текущий реальный скор(валидационная часть): 1.3489\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8047 - val_loss: 1.4432 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7718Текущий реальный скор(валидационная часть): 1.3529\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7740 - val_loss: 1.4558 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.7622Текущий реальный скор(валидационная часть): 1.3505\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7631 - val_loss: 1.4510 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.7522Текущий реальный скор(валидационная часть): 1.3598\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7501 - val_loss: 1.4693 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.7950Текущий реальный скор(валидационная часть): 1.3558\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7963 - val_loss: 1.4550 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.8217Текущий реальный скор(валидационная часть): 1.3021\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8386 - val_loss: 1.4057 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.8040Текущий реальный скор(валидационная часть): 1.3355\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8048 - val_loss: 1.4615 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.7496Текущий реальный скор(валидационная часть): 1.2346\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7559 - val_loss: 1.3601 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.7804Текущий реальный скор(валидационная часть): 1.2467\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7816 - val_loss: 1.3522 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.7526Текущий реальный скор(валидационная часть): 1.3119\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7709 - val_loss: 1.4292 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.7645Текущий реальный скор(валидационная часть): 1.3869\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8287 - val_loss: 1.4933 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.8198Текущий реальный скор(валидационная часть): 1.3856\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8896 - val_loss: 1.5049 - lr: 5.0000e-04\n",
      "Epoch 35/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.9413Текущий реальный скор(валидационная часть): 1.7342\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 1.8204 - lr: 5.0000e-04\n",
      "Epoch 36/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.8841Текущий реальный скор(валидационная часть): 1.7392\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8865 - val_loss: 1.8523 - lr: 5.0000e-04\n",
      "Epoch 37/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.7555Текущий реальный скор(валидационная часть): 1.5792\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7927 - val_loss: 1.6912 - lr: 5.0000e-04\n",
      "Epoch 38/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.7434Текущий реальный скор(валидационная часть): 1.5287\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7447 - val_loss: 1.6290 - lr: 5.0000e-04\n",
      "Epoch 39/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.7242Текущий реальный скор(валидационная часть): 1.4347\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7449 - val_loss: 1.5272 - lr: 5.0000e-04\n",
      "Epoch 40/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.6915Текущий реальный скор(валидационная часть): 1.4039\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7090 - val_loss: 1.4918 - lr: 5.0000e-04\n",
      "Epoch 41/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.6941Текущий реальный скор(валидационная часть): 1.3511\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6964 - val_loss: 1.4391 - lr: 5.0000e-04\n",
      "Epoch 42/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.7113Текущий реальный скор(валидационная часть): 1.2162\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7137 - val_loss: 1.3320 - lr: 2.5000e-04\n",
      "Epoch 43/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.6387Текущий реальный скор(валидационная часть): 1.1697\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.6426 - val_loss: 1.2885 - lr: 2.5000e-04\n",
      "Epoch 44/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.5984Текущий реальный скор(валидационная часть): 1.1609\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5967 - val_loss: 1.2766 - lr: 2.5000e-04\n",
      "Epoch 45/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5601Текущий реальный скор(валидационная часть): 1.1545\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5678 - val_loss: 1.2693 - lr: 2.5000e-04\n",
      "Epoch 46/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5389Текущий реальный скор(валидационная часть): 1.1505\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5451 - val_loss: 1.2648 - lr: 2.5000e-04\n",
      "Epoch 47/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5264Текущий реальный скор(валидационная часть): 1.156\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 1.2688 - lr: 2.5000e-04\n",
      "Epoch 48/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5120Текущий реальный скор(валидационная часть): 1.1543\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 1.2686 - lr: 2.5000e-04\n",
      "Epoch 49/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4997Текущий реальный скор(валидационная часть): 1.1532\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5023 - val_loss: 1.2665 - lr: 2.5000e-04\n",
      "Epoch 50/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4899Текущий реальный скор(валидационная часть): 1.1556\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 1.2666 - lr: 2.5000e-04\n",
      "Epoch 51/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4810Текущий реальный скор(валидационная часть): 1.1554\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4831 - val_loss: 1.2661 - lr: 2.5000e-04\n",
      "Epoch 52/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4636Текущий реальный скор(валидационная часть): 1.1558\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 1.2683 - lr: 2.5000e-04\n",
      "Epoch 53/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4589Текущий реальный скор(валидационная часть): 1.1544\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 1.2641 - lr: 2.5000e-04\n",
      "Epoch 54/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4524Текущий реальный скор(валидационная часть): 1.1569\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 1.2660 - lr: 2.5000e-04\n",
      "Epoch 55/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4475Текущий реальный скор(валидационная часть): 1.1596\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 1.2682 - lr: 2.5000e-04\n",
      "Epoch 56/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4387Текущий реальный скор(валидационная часть): 1.1628\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4419 - val_loss: 1.2678 - lr: 2.5000e-04\n",
      "Epoch 57/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4364Текущий реальный скор(валидационная часть): 1.1637\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 1.2684 - lr: 2.5000e-04\n",
      "Epoch 58/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4270Текущий реальный скор(валидационная часть): 1.1755\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4301 - val_loss: 1.2802 - lr: 2.5000e-04\n",
      "Epoch 59/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4160Текущий реальный скор(валидационная часть): 1.1758\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4257 - val_loss: 1.2797 - lr: 2.5000e-04\n",
      "Epoch 60/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4175Текущий реальный скор(валидационная часть): 1.1797\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 1.2881 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4092Текущий реальный скор(валидационная часть): 1.182\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4151 - val_loss: 1.2907 - lr: 2.5000e-04\n",
      "Epoch 62/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4074Текущий реальный скор(валидационная часть): 1.1885\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 1.3006 - lr: 2.5000e-04\n",
      "Epoch 63/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4075Текущий реальный скор(валидационная часть): 1.1904\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 1.3045 - lr: 2.5000e-04\n",
      "Epoch 64/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4269Текущий реальный скор(валидационная часть): 1.2194\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 1.3259 - lr: 1.2500e-04\n",
      "Epoch 65/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4302Текущий реальный скор(валидационная часть): 1.2204\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 1.3225 - lr: 1.2500e-04\n",
      "Epoch 66/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4485Текущий реальный скор(валидационная часть): 1.2356\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 1.3360 - lr: 1.2500e-04\n",
      "Epoch 67/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4538Текущий реальный скор(валидационная часть): 1.2738\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 1.3719 - lr: 1.2500e-04\n",
      "Epoch 68/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4754Текущий реальный скор(валидационная часть): 1.3547\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 1.4426 - lr: 1.2500e-04\n",
      "Epoch 69/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5066Текущий реальный скор(валидационная часть): 1.3827\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5090 - val_loss: 1.4645 - lr: 1.2500e-04\n",
      "Epoch 70/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5083Текущий реальный скор(валидационная часть): 1.3288\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5102 - val_loss: 1.4179 - lr: 1.2500e-04\n",
      "Epoch 71/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4866Текущий реальный скор(валидационная часть): 1.2807\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 1.3817 - lr: 1.2500e-04\n",
      "Epoch 72/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4622Текущий реальный скор(валидационная часть): 1.2364\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 1.3361 - lr: 1.2500e-04\n",
      "Epoch 73/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4501Текущий реальный скор(валидационная часть): 1.2075\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4512 - val_loss: 1.3136 - lr: 1.2500e-04\n",
      "Epoch 74/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4164Текущий реальный скор(валидационная часть): 1.1736\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4228 - val_loss: 1.2832 - lr: 6.2500e-05\n",
      "Epoch 75/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4048Текущий реальный скор(валидационная часть): 1.1747\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4048 - val_loss: 1.2784 - lr: 6.2500e-05\n",
      "Epoch 76/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.3909Текущий реальный скор(валидационная часть): 1.1755\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3945 - val_loss: 1.2765 - lr: 6.2500e-05\n",
      "Epoch 77/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3842Текущий реальный скор(валидационная часть): 1.1763\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 1.2759 - lr: 6.2500e-05\n",
      "Epoch 78/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.3783Текущий реальный скор(валидационная часть): 1.1785\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 1.2775 - lr: 6.2500e-05\n",
      "Epoch 79/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3729Текущий реальный скор(валидационная часть): 1.179\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 1.2774 - lr: 6.2500e-05\n",
      "Epoch 80/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.3624Текущий реальный скор(валидационная часть): 1.1813\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 1.2790 - lr: 6.2500e-05\n",
      "Epoch 81/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3654Текущий реальный скор(валидационная часть): 1.1819\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 1.2792 - lr: 6.2500e-05\n",
      "Epoch 82/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3655Текущий реальный скор(валидационная часть): 1.1833\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3668 - val_loss: 1.2807 - lr: 6.2500e-05\n",
      "Epoch 83/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3606Текущий реальный скор(валидационная часть): 1.1832\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3640 - val_loss: 1.2806 - lr: 6.2500e-05\n",
      "Epoch 84/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.3569Текущий реальный скор(валидационная часть): 1.1884\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3627 - val_loss: 1.2835 - lr: 3.1250e-05\n",
      "Epoch 85/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3533Текущий реальный скор(валидационная часть): 1.1882\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3598 - val_loss: 1.2830 - lr: 3.1250e-05\n",
      "Epoch 86/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3526Текущий реальный скор(валидационная часть): 1.1886\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3579 - val_loss: 1.2860 - lr: 3.1250e-05\n",
      "Epoch 87/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3549Текущий реальный скор(валидационная часть): 1.1885\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3562 - val_loss: 1.2859 - lr: 3.1250e-05\n",
      "Epoch 88/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3502Текущий реальный скор(валидационная часть): 1.1891\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 1.2864 - lr: 3.1250e-05\n",
      "Epoch 89/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3533Текущий реальный скор(валидационная часть): 1.1886\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3533 - val_loss: 1.2861 - lr: 3.1250e-05\n",
      "Epoch 90/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3446Текущий реальный скор(валидационная часть): 1.1892\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3520 - val_loss: 1.2866 - lr: 3.1250e-05\n",
      "Epoch 91/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3482Текущий реальный скор(валидационная часть): 1.1897\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3507 - val_loss: 1.2873 - lr: 3.1250e-05\n",
      "Epoch 92/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3495Текущий реальный скор(валидационная часть): 1.1905\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3495 - val_loss: 1.2882 - lr: 3.1250e-05\n",
      "Epoch 93/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.3450Текущий реальный скор(валидационная часть): 1.1904\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3483 - val_loss: 1.2883 - lr: 3.1250e-05\n",
      "Epoch 94/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.3456Текущий реальный скор(валидационная часть): 1.1849\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3492 - val_loss: 1.2825 - lr: 1.5625e-05\n",
      "Epoch 95/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3467Текущий реальный скор(валидационная часть): 1.1844\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 1.2821 - lr: 1.5625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3460Текущий реальный скор(валидационная часть): 1.1843\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3473 - val_loss: 1.2820 - lr: 1.5625e-05\n",
      "Epoch 97/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3390Текущий реальный скор(валидационная часть): 1.1841\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 1.2819 - lr: 1.5625e-05\n",
      "Epoch 98/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3410Текущий реальный скор(валидационная часть): 1.1842\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3458 - val_loss: 1.2821 - lr: 1.5625e-05\n",
      "Epoch 99/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.3396Текущий реальный скор(валидационная часть): 1.1837\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3452 - val_loss: 1.2820 - lr: 1.5625e-05\n",
      "Epoch 100/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.3373Текущий реальный скор(валидационная часть): 1.1839\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 1.2824 - lr: 1.5625e-05\n",
      "Epoch 101/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3348Текущий реальный скор(валидационная часть): 1.1837\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3440 - val_loss: 1.2824 - lr: 1.5625e-05\n",
      "Epoch 102/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3397Текущий реальный скор(валидационная часть): 1.184\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3434 - val_loss: 1.2827 - lr: 1.5625e-05\n",
      "Epoch 103/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3336Текущий реальный скор(валидационная часть): 1.1837\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 1.2826 - lr: 1.5625e-05\n",
      "Epoch 104/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.3414Текущий реальный скор(валидационная часть): 1.1813\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 1.2813 - lr: 7.8125e-06\n",
      "Epoch 105/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3400Текущий реальный скор(валидационная часть): 1.1816\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3481 - val_loss: 1.2814 - lr: 7.8125e-06\n",
      "Epoch 106/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3430Текущий реальный скор(валидационная часть): 1.1818\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 1.2816 - lr: 7.8125e-06\n",
      "Epoch 107/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.3439Текущий реальный скор(валидационная часть): 1.1822\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 1.2819 - lr: 7.8125e-06\n",
      "Epoch 108/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3408Текущий реальный скор(валидационная часть): 1.1825\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3472 - val_loss: 1.2822 - lr: 7.8125e-06\n",
      "Epoch 109/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.3368Текущий реальный скор(валидационная часть): 1.1827\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3468 - val_loss: 1.2824 - lr: 7.8125e-06\n",
      "Epoch 110/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3418Текущий реальный скор(валидационная часть): 1.1831\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 1.2828 - lr: 7.8125e-06\n",
      "Epoch 111/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3462Текущий реальный скор(валидационная часть): 1.1833\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3462 - val_loss: 1.2829 - lr: 7.8125e-06\n",
      "Epoch 112/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3411Текущий реальный скор(валидационная часть): 1.1838\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3459 - val_loss: 1.2834 - lr: 7.8125e-06\n",
      "Epoch 113/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3443Текущий реальный скор(валидационная часть): 1.1839\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 1.2836 - lr: 7.8125e-06\n",
      "Epoch 114/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3462Текущий реальный скор(валидационная часть): 1.1933\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3507 - val_loss: 1.2901 - lr: 3.9063e-06\n",
      "Epoch 115/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.3409Текущий реальный скор(валидационная часть): 1.1938\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3476 - val_loss: 1.2905 - lr: 3.9063e-06\n",
      "Epoch 116/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3419Текущий реальный скор(валидационная часть): 1.1942\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3471 - val_loss: 1.2908 - lr: 3.9063e-06\n",
      "Epoch 117/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3415Текущий реальный скор(валидационная часть): 1.1945\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 1.2910 - lr: 3.9063e-06\n",
      "Epoch 118/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.3430Текущий реальный скор(валидационная часть): 1.1948\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3463 - val_loss: 1.2913 - lr: 3.9063e-06\n",
      "Epoch 119/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.3395Текущий реальный скор(валидационная часть): 1.195\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 1.2914 - lr: 3.9063e-06\n",
      "Epoch 120/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.3420Текущий реальный скор(валидационная часть): 1.1953\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 1.2917 - lr: 3.9063e-06\n",
      "Epoch 121/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3399Текущий реальный скор(валидационная часть): 1.1954\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 1.2918 - lr: 3.9063e-06\n",
      "Epoch 122/500\n",
      "105/134 [======================>.......] - ETA: 0s - loss: 0.3312Текущий реальный скор(валидационная часть): 1.1957\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3450 - val_loss: 1.2920 - lr: 3.9063e-06\n",
      "Epoch 123/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3383Текущий реальный скор(валидационная часть): 1.1958\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 1.2922 - lr: 3.9063e-06\n",
      "Epoch 124/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.3426Текущий реальный скор(валидационная часть): 1.2032\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3457 - val_loss: 1.2988 - lr: 1.9531e-06\n",
      "Epoch 125/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3377Текущий реальный скор(валидационная часть): 1.2045\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 1.2998 - lr: 1.9531e-06\n",
      "Epoch 126/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.3403Текущий реальный скор(валидационная часть): 1.2047\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3435 - val_loss: 1.3000 - lr: 1.9531e-06\n",
      "Epoch 127/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3369Текущий реальный скор(валидационная часть): 1.2047\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3433 - val_loss: 1.3000 - lr: 1.9531e-06\n",
      "Epoch 128/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.3350Текущий реальный скор(валидационная часть): 1.2048\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3431 - val_loss: 1.3000 - lr: 1.9531e-06\n",
      "Epoch 129/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.3356Текущий реальный скор(валидационная часть): 1.2048\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3430 - val_loss: 1.3000 - lr: 1.9531e-06\n",
      "Epoch 130/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3355Текущий реальный скор(валидационная часть): 1.2048\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 1.3000 - lr: 1.9531e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.3346Текущий реальный скор(валидационная часть): 1.2049\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3427 - val_loss: 1.3000 - lr: 1.9531e-06\n",
      "Epoch 132/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3352Текущий реальный скор(валидационная часть): 1.2049\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 1.3000 - lr: 1.9531e-06\n",
      "Epoch 133/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.3392Текущий реальный скор(валидационная часть): 1.205\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3424 - val_loss: 1.3001 - lr: 1.9531e-06\n",
      "Epoch 134/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3331Текущий реальный скор(валидационная часть): 1.2076\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3421 - val_loss: 1.3023 - lr: 9.7656e-07\n",
      "Epoch 135/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3372Текущий реальный скор(валидационная часть): 1.2087\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3416 - val_loss: 1.3033 - lr: 9.7656e-07\n",
      "Epoch 136/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3415Текущий реальный скор(валидационная часть): 1.2092\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3415 - val_loss: 1.3037 - lr: 9.7656e-07\n",
      "Epoch 137/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.3378Текущий реальный скор(валидационная часть): 1.2093\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3413 - val_loss: 1.3038 - lr: 9.7656e-07\n",
      "Epoch 138/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3413Текущий реальный скор(валидационная часть): 1.2094\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3413 - val_loss: 1.3039 - lr: 9.7656e-07\n",
      "Epoch 139/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3356Текущий реальный скор(валидационная часть): 1.2095\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 1.3039 - lr: 9.7656e-07\n",
      "Epoch 140/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3335Текущий реальный скор(валидационная часть): 1.2095\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3411 - val_loss: 1.3039 - lr: 9.7656e-07\n",
      "Epoch 141/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.3352Текущий реальный скор(валидационная часть): 1.2095\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3411 - val_loss: 1.3039 - lr: 9.7656e-07\n",
      "Epoch 142/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.3377Текущий реальный скор(валидационная часть): 1.2096\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 1.3039 - lr: 9.7656e-07\n",
      "Epoch 143/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3344Текущий реальный скор(валидационная часть): 1.2096\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3409 - val_loss: 1.3039 - lr: 9.7656e-07\n",
      "Epoch 144/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3392Текущий реальный скор(валидационная часть): 1.2103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 1.3046 - lr: 4.8828e-07\n",
      "Epoch 145/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3358Текущий реальный скор(валидационная часть): 1.2108\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 1.3050 - lr: 4.8828e-07\n",
      "Epoch 146/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3381Текущий реальный скор(валидационная часть): 1.2112\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 1.3053 - lr: 4.8828e-07\n",
      "Epoch 147/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3334Текущий реальный скор(валидационная часть): 1.2114\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 1.3055 - lr: 4.8828e-07\n",
      "Epoch 148/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.3370Текущий реальный скор(валидационная часть): 1.2115\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3403 - val_loss: 1.3056 - lr: 4.8828e-07\n",
      "Epoch 149/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.3367Текущий реальный скор(валидационная часть): 1.2116\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3403 - val_loss: 1.3057 - lr: 4.8828e-07\n",
      "Epoch 150/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.3324Текущий реальный скор(валидационная часть): 1.2116\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3402 - val_loss: 1.3057 - lr: 4.8828e-07\n",
      "Epoch 151/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3402Текущий реальный скор(валидационная часть): 1.2117\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3402 - val_loss: 1.3057 - lr: 4.8828e-07\n",
      "Epoch 152/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.3323Текущий реальный скор(валидационная часть): 1.2117\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3402 - val_loss: 1.3058 - lr: 4.8828e-07\n",
      "Epoch 153/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3353Текущий реальный скор(валидационная часть): 1.1544\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3401 - val_loss: 1.3058 - lr: 4.8828e-07\n",
      "Скор для фолда(0) : 1.1544 средний скор на префиксе = 1.1544 это заняло = 44 сек.\n",
      "Фолд: 1\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 4.0745Текущий реальный скор(валидационная часть): 2.2284\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.7938 - val_loss: 2.3054 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 1.9990Текущий реальный скор(валидационная часть): 1.8214\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9389 - val_loss: 1.8994 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 1.6562Текущий реальный скор(валидационная часть): 1.6645\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6442 - val_loss: 1.7563 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.4990Текущий реальный скор(валидационная часть): 1.6006\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4858 - val_loss: 1.6940 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 1.4333Текущий реальный скор(валидационная часть): 1.5912\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4147 - val_loss: 1.6814 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 1.3460Текущий реальный скор(валидационная часть): 1.5625\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.6548 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.2756Текущий реальный скор(валидационная часть): 1.5557\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2756 - val_loss: 1.6495 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.2357Текущий реальный скор(валидационная часть): 1.5403\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2262 - val_loss: 1.6401 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.1885Текущий реальный скор(валидационная часть): 1.5176\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1770 - val_loss: 1.6212 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 1.1346Текущий реальный скор(валидационная часть): 1.5129\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1305 - val_loss: 1.6180 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 1.0970Текущий реальный скор(валидационная часть): 1.525\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0906 - val_loss: 1.6250 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 1.0654Текущий реальный скор(валидационная часть): 1.5222\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0600 - val_loss: 1.6139 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0374Текущий реальный скор(валидационная часть): 1.5022\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0374 - val_loss: 1.5999 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 1.0184Текущий реальный скор(валидационная часть): 1.5336\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0164 - val_loss: 1.6376 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.9760Текущий реальный скор(валидационная часть): 1.5357\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9743 - val_loss: 1.6415 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.9528Текущий реальный скор(валидационная часть): 1.5157\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9486 - val_loss: 1.6168 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.9216Текущий реальный скор(валидационная часть): 1.549\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 1.6688 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.9349Текущий реальный скор(валидационная часть): 1.536\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 1.6436 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 1.0335Текущий реальный скор(валидационная часть): 1.4754\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0250 - val_loss: 1.5690 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.9929Текущий реальный скор(валидационная часть): 1.5173\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.6250 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.9864Текущий реальный скор(валидационная часть): 1.5642\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9768 - val_loss: 1.6641 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.9718Текущий реальный скор(валидационная часть): 1.5498\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9694 - val_loss: 1.6257 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.9387Текущий реальный скор(валидационная часть): 1.4758\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9559 - val_loss: 1.5762 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.9271Текущий реальный скор(валидационная часть): 1.5102\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 1.5978 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.9726Текущий реальный скор(валидационная часть): 1.6994\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9784 - val_loss: 1.7790 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0164Текущий реальный скор(валидационная часть): 1.8803\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0164 - val_loss: 1.9946 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.9874Текущий реальный скор(валидационная часть): 1.8046\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9840 - val_loss: 1.8953 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.9440Текущий реальный скор(валидационная часть): 1.71\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 1.7941 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.9057Текущий реальный скор(валидационная часть): 1.5258\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9152 - val_loss: 1.6207 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.7947Текущий реальный скор(валидационная часть): 1.3963\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7841 - val_loss: 1.4933 - lr: 2.5000e-04\n",
      "Epoch 31/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.7024Текущий реальный скор(валидационная часть): 1.4182\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7024 - val_loss: 1.5174 - lr: 2.5000e-04\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6641Текущий реальный скор(валидационная часть): 1.4168\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6641 - val_loss: 1.5174 - lr: 2.5000e-04\n",
      "Epoch 33/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.6376Текущий реальный скор(валидационная часть): 1.4279\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6360 - val_loss: 1.5287 - lr: 2.5000e-04\n",
      "Epoch 34/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.6149Текущий реальный скор(валидационная часть): 1.4454\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 1.5465 - lr: 2.5000e-04\n",
      "Epoch 35/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5914Текущий реальный скор(валидационная часть): 1.4622\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5908 - val_loss: 1.5677 - lr: 2.5000e-04\n",
      "Epoch 36/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5722Текущий реальный скор(валидационная часть): 1.475\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5730 - val_loss: 1.5775 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5578Текущий реальный скор(валидационная часть): 1.4915\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5579 - val_loss: 1.5960 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5411Текущий реальный скор(валидационная часть): 1.5041\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5439 - val_loss: 1.6055 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5329Текущий реальный скор(валидационная часть): 1.5332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5348 - val_loss: 1.6233 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5666Текущий реальный скор(валидационная часть): 1.5082\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5588 - val_loss: 1.6139 - lr: 2.5000e-04\n",
      "Epoch 41/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5259Текущий реальный скор(валидационная часть): 1.5637\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5215 - val_loss: 1.6734 - lr: 1.2500e-04\n",
      "Epoch 42/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5088Текущий реальный скор(валидационная часть): 1.5695\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5117 - val_loss: 1.6846 - lr: 1.2500e-04\n",
      "Epoch 43/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5029Текущий реальный скор(валидационная часть): 1.5758\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5039 - val_loss: 1.6897 - lr: 1.2500e-04\n",
      "Epoch 44/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5011Текущий реальный скор(валидационная часть): 1.5742\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4974 - val_loss: 1.6891 - lr: 1.2500e-04\n",
      "Epoch 45/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4927Текущий реальный скор(валидационная часть): 1.5774\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4918 - val_loss: 1.6928 - lr: 1.2500e-04\n",
      "Epoch 46/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4839Текущий реальный скор(валидационная часть): 1.5782\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4853 - val_loss: 1.6942 - lr: 1.2500e-04\n",
      "Epoch 47/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4764Текущий реальный скор(валидационная часть): 1.5775\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 1.6956 - lr: 1.2500e-04\n",
      "Epoch 48/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4723Текущий реальный скор(валидационная часть): 1.5828\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4742 - val_loss: 1.7036 - lr: 1.2500e-04\n",
      "Epoch 49/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4697Текущий реальный скор(валидационная часть): 1.5811\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4690 - val_loss: 1.7035 - lr: 1.2500e-04\n",
      "Epoch 50/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4649Текущий реальный скор(валидационная часть): 1.5845\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 1.7058 - lr: 1.2500e-04\n",
      "Epoch 51/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4777Текущий реальный скор(валидационная часть): 1.5099\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 1.6079 - lr: 6.2500e-05\n",
      "Epoch 52/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4742Текущий реальный скор(валидационная часть): 1.4918\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 1.5886 - lr: 6.2500e-05\n",
      "Epoch 53/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4668Текущий реальный скор(валидационная часть): 1.4859\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4735 - val_loss: 1.5817 - lr: 6.2500e-05\n",
      "Epoch 54/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4641Текущий реальный скор(валидационная часть): 1.48\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4695 - val_loss: 1.5749 - lr: 6.2500e-05\n",
      "Epoch 55/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4621Текущий реальный скор(валидационная часть): 1.478\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 1.5723 - lr: 6.2500e-05\n",
      "Epoch 56/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4562Текущий реальный скор(валидационная часть): 1.4757\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 1.5699 - lr: 6.2500e-05\n",
      "Epoch 57/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4586Текущий реальный скор(валидационная часть): 1.4759\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 1.5690 - lr: 6.2500e-05\n",
      "Epoch 58/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4550Текущий реальный скор(валидационная часть): 1.4744\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4550 - val_loss: 1.5678 - lr: 6.2500e-05\n",
      "Epoch 59/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4526Текущий реальный скор(валидационная часть): 1.4768\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4519 - val_loss: 1.5705 - lr: 6.2500e-05\n",
      "Epoch 60/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4452Текущий реальный скор(валидационная часть): 1.4766\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 1.5705 - lr: 6.2500e-05\n",
      "Epoch 61/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4606Текущий реальный скор(валидационная часть): 1.5085\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 1.6061 - lr: 3.1250e-05\n",
      "Epoch 62/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4508Текущий реальный скор(валидационная часть): 1.5134\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4534 - val_loss: 1.6103 - lr: 3.1250e-05\n",
      "Epoch 63/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4547Текущий реальный скор(валидационная часть): 1.5182\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4495 - val_loss: 1.6147 - lr: 3.1250e-05\n",
      "Epoch 64/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4453Текущий реальный скор(валидационная часть): 1.5208\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4463 - val_loss: 1.6200 - lr: 3.1250e-05\n",
      "Epoch 65/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4405Текущий реальный скор(валидационная часть): 1.523\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4435 - val_loss: 1.6220 - lr: 3.1250e-05\n",
      "Epoch 66/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4462Текущий реальный скор(валидационная часть): 1.5238\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 1.6230 - lr: 3.1250e-05\n",
      "Epoch 67/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4448Текущий реальный скор(валидационная часть): 1.5258\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 1.6249 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4408Текущий реальный скор(валидационная часть): 1.5253\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4368 - val_loss: 1.6247 - lr: 3.1250e-05\n",
      "Epoch 69/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4333Текущий реальный скор(валидационная часть): 1.5277\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 1.6270 - lr: 3.1250e-05\n",
      "Epoch 70/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4392Текущий реальный скор(валидационная часть): 1.5274\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4330 - val_loss: 1.6267 - lr: 3.1250e-05\n",
      "Epoch 71/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4369Текущий реальный скор(валидационная часть): 1.5339\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4380 - val_loss: 1.6337 - lr: 1.5625e-05\n",
      "Epoch 72/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4414Текущий реальный скор(валидационная часть): 1.5318\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 1.6323 - lr: 1.5625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4403Текущий реальный скор(валидационная часть): 1.5297\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4338 - val_loss: 1.6307 - lr: 1.5625e-05\n",
      "Epoch 74/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4354Текущий реальный скор(валидационная часть): 1.5283\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 1.6297 - lr: 1.5625e-05\n",
      "Epoch 75/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4340Текущий реальный скор(валидационная часть): 1.5279\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4312 - val_loss: 1.6297 - lr: 1.5625e-05\n",
      "Epoch 76/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4286Текущий реальный скор(валидационная часть): 1.5264\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4299 - val_loss: 1.6285 - lr: 1.5625e-05\n",
      "Epoch 77/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4315Текущий реальный скор(валидационная часть): 1.5255\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 1.6278 - lr: 1.5625e-05\n",
      "Epoch 78/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4314Текущий реальный скор(валидационная часть): 1.5251\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4278 - val_loss: 1.6276 - lr: 1.5625e-05\n",
      "Epoch 79/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4298Текущий реальный скор(валидационная часть): 1.5243\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 1.6272 - lr: 1.5625e-05\n",
      "Epoch 80/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4225Текущий реальный скор(валидационная часть): 1.5234\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4257 - val_loss: 1.6266 - lr: 1.5625e-05\n",
      "Epoch 81/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4323Текущий реальный скор(валидационная часть): 1.5232\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 1.6260 - lr: 7.8125e-06\n",
      "Epoch 82/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4345Текущий реальный скор(валидационная часть): 1.5237\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 1.6270 - lr: 7.8125e-06\n",
      "Epoch 83/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4293Текущий реальный скор(валидационная часть): 1.5236\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 1.6274 - lr: 7.8125e-06\n",
      "Epoch 84/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4303Текущий реальный скор(валидационная часть): 1.5237\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4249 - val_loss: 1.6278 - lr: 7.8125e-06\n",
      "Epoch 85/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4270Текущий реальный скор(валидационная часть): 1.5232\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 1.6276 - lr: 7.8125e-06\n",
      "Epoch 86/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4204Текущий реальный скор(валидационная часть): 1.5233\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4236 - val_loss: 1.6278 - lr: 7.8125e-06\n",
      "Epoch 87/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4219Текущий реальный скор(валидационная часть): 1.5229\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4230 - val_loss: 1.6278 - lr: 7.8125e-06\n",
      "Epoch 88/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4269Текущий реальный скор(валидационная часть): 1.5227\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4225 - val_loss: 1.6278 - lr: 7.8125e-06\n",
      "Epoch 89/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4293Текущий реальный скор(валидационная часть): 1.5225\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4219 - val_loss: 1.6277 - lr: 7.8125e-06\n",
      "Epoch 90/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4287Текущий реальный скор(валидационная часть): 1.5224\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4214 - val_loss: 1.6277 - lr: 7.8125e-06\n",
      "Epoch 91/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4194Текущий реальный скор(валидационная часть): 1.5348\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4223 - val_loss: 1.6414 - lr: 3.9063e-06\n",
      "Epoch 92/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4238Текущий реальный скор(валидационная часть): 1.5355\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 1.6448 - lr: 3.9063e-06\n",
      "Epoch 93/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4194Текущий реальный скор(валидационная часть): 1.5357\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4205 - val_loss: 1.6450 - lr: 3.9063e-06\n",
      "Epoch 94/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4249Текущий реальный скор(валидационная часть): 1.5357\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 1.6451 - lr: 3.9063e-06\n",
      "Epoch 95/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4187Текущий реальный скор(валидационная часть): 1.5358\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4198 - val_loss: 1.6452 - lr: 3.9063e-06\n",
      "Epoch 96/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4265Текущий реальный скор(валидационная часть): 1.5358\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 1.6452 - lr: 3.9063e-06\n",
      "Epoch 97/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4213Текущий реальный скор(валидационная часть): 1.5356\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4192 - val_loss: 1.6451 - lr: 3.9063e-06\n",
      "Epoch 98/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4161Текущий реальный скор(валидационная часть): 1.5357\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 1.6453 - lr: 3.9063e-06\n",
      "Epoch 99/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4226Текущий реальный скор(валидационная часть): 1.5355\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 1.6452 - lr: 3.9063e-06\n",
      "Epoch 100/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4155Текущий реальный скор(валидационная часть): 1.5355\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 1.6453 - lr: 3.9063e-06\n",
      "Epoch 101/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4221Текущий реальный скор(валидационная часть): 1.54\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4177 - val_loss: 1.6559 - lr: 1.9531e-06\n",
      "Epoch 102/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4154Текущий реальный скор(валидационная часть): 1.5407\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 1.6567 - lr: 1.9531e-06\n",
      "Epoch 103/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4230Текущий реальный скор(валидационная часть): 1.5409\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 1.6569 - lr: 1.9531e-06\n",
      "Epoch 104/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4229Текущий реальный скор(валидационная часть): 1.5408\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 1.6568 - lr: 1.9531e-06\n",
      "Epoch 105/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4207Текущий реальный скор(валидационная часть): 1.5408\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4164 - val_loss: 1.6568 - lr: 1.9531e-06\n",
      "Epoch 106/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4130Текущий реальный скор(валидационная часть): 1.5408\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4163 - val_loss: 1.6567 - lr: 1.9531e-06\n",
      "Epoch 107/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4150Текущий реальный скор(валидационная часть): 1.5407\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4161 - val_loss: 1.6567 - lr: 1.9531e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4182Текущий реальный скор(валидационная часть): 1.5407\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4160 - val_loss: 1.6566 - lr: 1.9531e-06\n",
      "Epoch 109/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4126Текущий реальный скор(валидационная часть): 1.5406\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 1.6565 - lr: 1.9531e-06\n",
      "Epoch 110/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4180Текущий реальный скор(валидационная часть): 1.5405\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 1.6565 - lr: 1.9531e-06\n",
      "Epoch 111/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4120Текущий реальный скор(валидационная часть): 1.5418\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4150 - val_loss: 1.6579 - lr: 9.7656e-07\n",
      "Epoch 112/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4169Текущий реальный скор(валидационная часть): 1.5423\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4148 - val_loss: 1.6584 - lr: 9.7656e-07\n",
      "Epoch 113/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4175Текущий реальный скор(валидационная часть): 1.5424\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 1.6586 - lr: 9.7656e-07\n",
      "Epoch 114/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4184Текущий реальный скор(валидационная часть): 1.5425\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 1.6587 - lr: 9.7656e-07\n",
      "Epoch 115/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4176Текущий реальный скор(валидационная часть): 1.5425\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 1.6587 - lr: 9.7656e-07\n",
      "Epoch 116/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4178Текущий реальный скор(валидационная часть): 1.5425\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 1.6586 - lr: 9.7656e-07\n",
      "Epoch 117/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4089Текущий реальный скор(валидационная часть): 1.5424\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4144 - val_loss: 1.6586 - lr: 9.7656e-07\n",
      "Epoch 118/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4132Текущий реальный скор(валидационная часть): 1.5424\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 1.6586 - lr: 9.7656e-07\n",
      "Epoch 119/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4181Текущий реальный скор(валидационная часть): 1.5424\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 1.6585 - lr: 9.7656e-07\n",
      "Epoch 120/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4127Текущий реальный скор(валидационная часть): 1.5424\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 1.6585 - lr: 9.7656e-07\n",
      "Epoch 121/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4175Текущий реальный скор(валидационная часть): 1.5427\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 1.6589 - lr: 4.8828e-07\n",
      "Epoch 122/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4104Текущий реальный скор(валидационная часть): 1.5429\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 1.6591 - lr: 4.8828e-07\n",
      "Epoch 123/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4173Текущий реальный скор(валидационная часть): 1.543\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4136 - val_loss: 1.6592 - lr: 4.8828e-07\n",
      "Epoch 124/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4119Текущий реальный скор(валидационная часть): 1.5431\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4136 - val_loss: 1.6593 - lr: 4.8828e-07\n",
      "Epoch 125/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4155Текущий реальный скор(валидационная часть): 1.5431\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4136 - val_loss: 1.6593 - lr: 4.8828e-07\n",
      "Epoch 126/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4105Текущий реальный скор(валидационная часть): 1.5431\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4135 - val_loss: 1.6594 - lr: 4.8828e-07\n",
      "Epoch 127/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4102Текущий реальный скор(валидационная часть): 1.5431\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4135 - val_loss: 1.6594 - lr: 4.8828e-07\n",
      "Epoch 128/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4193Текущий реальный скор(валидационная часть): 1.5431\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4135 - val_loss: 1.6594 - lr: 4.8828e-07\n",
      "Epoch 129/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4079Текущий реальный скор(валидационная часть): 1.5431\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4134 - val_loss: 1.6593 - lr: 4.8828e-07\n",
      "Epoch 130/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4153Текущий реальный скор(валидационная часть): 1.3963\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4134 - val_loss: 1.6593 - lr: 4.8828e-07\n",
      "Скор для фолда(1) : 1.3963 средний скор на префиксе = 1.2753 это заняло = 36 сек.\n",
      "Фолд: 2\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 3.9240Текущий реальный скор(валидационная часть): 2.1298\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8159 - val_loss: 2.1815 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.9724Текущий реальный скор(валидационная часть): 1.7099\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9536 - val_loss: 1.7855 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 1.6707Текущий реальный скор(валидационная часть): 1.535\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6546 - val_loss: 1.6242 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 1.5131Текущий реальный скор(валидационная часть): 1.4604\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5091 - val_loss: 1.5433 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.4259Текущий реальный скор(валидационная часть): 1.406\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4225 - val_loss: 1.4797 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 1.3514Текущий реальный скор(валидационная часть): 1.3851\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3600 - val_loss: 1.4698 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 1.2948Текущий реальный скор(валидационная часть): 1.355\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3013 - val_loss: 1.4462 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 1.2632Текущий реальный скор(валидационная часть): 1.3378\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2599 - val_loss: 1.4361 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 1.2219Текущий реальный скор(валидационная часть): 1.3168\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2272 - val_loss: 1.4168 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.1767Текущий реальный скор(валидационная часть): 1.3083\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1888 - val_loss: 1.4145 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.1317Текущий реальный скор(валидационная часть): 1.3138\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1480 - val_loss: 1.4220 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 1.0964Текущий реальный скор(валидационная часть): 1.3386\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1068 - val_loss: 1.4638 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.1208Текущий реальный скор(валидационная часть): 1.3756\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1205 - val_loss: 1.4955 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 1.0665Текущий реальный скор(валидационная часть): 1.3452\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0810 - val_loss: 1.4671 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.0453Текущий реальный скор(валидационная часть): 1.3177\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0453 - val_loss: 1.4140 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 1.0535Текущий реальный скор(валидационная часть): 1.4353\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0657 - val_loss: 1.5138 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 1.0580Текущий реальный скор(валидационная часть): 1.5347\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0542 - val_loss: 1.6285 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 1.0308Текущий реальный скор(валидационная часть): 1.3609\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0264 - val_loss: 1.4610 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0436Текущий реальный скор(валидационная часть): 1.2811\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0436 - val_loss: 1.3975 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.0299Текущий реальный скор(валидационная часть): 1.2749\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0238 - val_loss: 1.3865 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.9826Текущий реальный скор(валидационная часть): 1.2532\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9886 - val_loss: 1.3628 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.9679Текущий реальный скор(валидационная часть): 1.2916\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9652 - val_loss: 1.3810 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.8984Текущий реальный скор(валидационная часть): 1.5972\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9259 - val_loss: 1.6633 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.9127Текущий реальный скор(валидационная часть): 1.7634\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9132 - val_loss: 1.8286 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.8588Текущий реальный скор(валидационная часть): 1.8304\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8908 - val_loss: 1.8807 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.8534Текущий реальный скор(валидационная часть): 1.876\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8804 - val_loss: 1.9350 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.8281Текущий реальный скор(валидационная часть): 1.7491\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8376 - val_loss: 1.8429 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.8004Текущий реальный скор(валидационная часть): 1.5996\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7999 - val_loss: 1.6923 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.7667Текущий реальный скор(валидационная часть): 1.4912\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7687 - val_loss: 1.5895 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.7535Текущий реальный скор(валидационная часть): 1.2744\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7653 - val_loss: 1.3725 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.7780Текущий реальный скор(валидационная часть): 1.2874\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7787 - val_loss: 1.3698 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.7354Текущий реальный скор(валидационная часть): 1.1725\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7362 - val_loss: 1.2759 - lr: 2.5000e-04\n",
      "Epoch 33/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.6790Текущий реальный скор(валидационная часть): 1.1776\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6806 - val_loss: 1.2752 - lr: 2.5000e-04\n",
      "Epoch 34/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.6372Текущий реальный скор(валидационная часть): 1.1913\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6426 - val_loss: 1.2831 - lr: 2.5000e-04\n",
      "Epoch 35/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6182Текущий реальный скор(валидационная часть): 1.1767\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6203 - val_loss: 1.2685 - lr: 2.5000e-04\n",
      "Epoch 36/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.5998Текущий реальный скор(валидационная часть): 1.1908\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 1.2816 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5815Текущий реальный скор(валидационная часть): 1.1906\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5842 - val_loss: 1.2861 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5684Текущий реальный скор(валидационная часть): 1.1838\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5718 - val_loss: 1.2849 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5516Текущий реальный скор(валидационная часть): 1.1826\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5575 - val_loss: 1.2805 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5465Текущий реальный скор(валидационная часть): 1.1839\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5448 - val_loss: 1.2810 - lr: 2.5000e-04\n",
      "Epoch 41/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5330Текущий реальный скор(валидационная часть): 1.1869\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 1.2826 - lr: 2.5000e-04\n",
      "Epoch 42/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5254Текущий реальный скор(валидационная часть): 1.186\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 1.2855 - lr: 2.5000e-04\n",
      "Epoch 43/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5168Текущий реальный скор(валидационная часть): 1.1907\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5187 - val_loss: 1.2876 - lr: 2.5000e-04\n",
      "Epoch 44/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5100Текущий реальный скор(валидационная часть): 1.1992\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5109 - val_loss: 1.2962 - lr: 2.5000e-04\n",
      "Epoch 45/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5013Текущий реальный скор(валидационная часть): 1.1944\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5022 - val_loss: 1.2905 - lr: 2.5000e-04\n",
      "Epoch 46/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5369Текущий реальный скор(валидационная часть): 1.2056\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 1.3131 - lr: 1.2500e-04\n",
      "Epoch 47/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5356Текущий реальный скор(валидационная часть): 1.1821\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5365 - val_loss: 1.2807 - lr: 1.2500e-04\n",
      "Epoch 48/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5303Текущий реальный скор(валидационная часть): 1.1873\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5331 - val_loss: 1.2905 - lr: 1.2500e-04\n",
      "Epoch 49/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5223Текущий реальный скор(валидационная часть): 1.1863\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.2863 - lr: 1.2500e-04\n",
      "Epoch 50/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5266Текущий реальный скор(валидационная часть): 1.186\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5205 - val_loss: 1.2866 - lr: 1.2500e-04\n",
      "Epoch 51/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5102Текущий реальный скор(валидационная часть): 1.189\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5111 - val_loss: 1.2865 - lr: 1.2500e-04\n",
      "Epoch 52/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5090Текущий реальный скор(валидационная часть): 1.1903\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 1.2874 - lr: 1.2500e-04\n",
      "Epoch 53/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4980Текущий реальный скор(валидационная часть): 1.1907\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4980 - val_loss: 1.2864 - lr: 1.2500e-04\n",
      "Epoch 54/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4869Текущий реальный скор(валидационная часть): 1.1945\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4904 - val_loss: 1.2867 - lr: 1.2500e-04\n",
      "Epoch 55/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4815Текущий реальный скор(валидационная часть): 1.2001\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 1.2916 - lr: 1.2500e-04\n",
      "Epoch 56/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4956Текущий реальный скор(валидационная часть): 1.21\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 1.3020 - lr: 6.2500e-05\n",
      "Epoch 57/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4836Текущий реальный скор(валидационная часть): 1.21\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 1.3044 - lr: 6.2500e-05\n",
      "Epoch 58/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4719Текущий реальный скор(валидационная часть): 1.2124\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 1.3080 - lr: 6.2500e-05\n",
      "Epoch 59/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4582Текущий реальный скор(валидационная часть): 1.2147\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 1.3112 - lr: 6.2500e-05\n",
      "Epoch 60/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4507Текущий реальный скор(валидационная часть): 1.2171\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 1.3142 - lr: 6.2500e-05\n",
      "Epoch 61/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4490Текущий реальный скор(валидационная часть): 1.2199\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4490 - val_loss: 1.3167 - lr: 6.2500e-05\n",
      "Epoch 62/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4434Текущий реальный скор(валидационная часть): 1.2207\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4444 - val_loss: 1.3178 - lr: 6.2500e-05\n",
      "Epoch 63/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4391Текущий реальный скор(валидационная часть): 1.2237\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4399 - val_loss: 1.3206 - lr: 6.2500e-05\n",
      "Epoch 64/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4344Текущий реальный скор(валидационная часть): 1.2243\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 1.3218 - lr: 6.2500e-05\n",
      "Epoch 65/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4320Текущий реальный скор(валидационная часть): 1.2269\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4325 - val_loss: 1.3242 - lr: 6.2500e-05\n",
      "Epoch 66/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4317Текущий реальный скор(валидационная часть): 1.2837\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 1.3690 - lr: 3.1250e-05\n",
      "Epoch 67/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4327Текущий реальный скор(валидационная часть): 1.2845\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 1.3702 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4270Текущий реальный скор(валидационная часть): 1.2854\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4296 - val_loss: 1.3719 - lr: 3.1250e-05\n",
      "Epoch 69/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4243Текущий реальный скор(валидационная часть): 1.2852\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 1.3720 - lr: 3.1250e-05\n",
      "Epoch 70/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4179Текущий реальный скор(валидационная часть): 1.2862\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4239 - val_loss: 1.3737 - lr: 3.1250e-05\n",
      "Epoch 71/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4219Текущий реальный скор(валидационная часть): 1.2871\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4216 - val_loss: 1.3745 - lr: 3.1250e-05\n",
      "Epoch 72/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4149Текущий реальный скор(валидационная часть): 1.2875\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4194 - val_loss: 1.3757 - lr: 3.1250e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4174Текущий реальный скор(валидационная часть): 1.2875\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 1.3757 - lr: 3.1250e-05\n",
      "Epoch 74/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4093Текущий реальный скор(валидационная часть): 1.288\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 1.3767 - lr: 3.1250e-05\n",
      "Epoch 75/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4102Текущий реальный скор(валидационная часть): 1.2885\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4138 - val_loss: 1.3772 - lr: 3.1250e-05\n",
      "Epoch 76/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4148Текущий реальный скор(валидационная часть): 1.2904\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 1.3791 - lr: 1.5625e-05\n",
      "Epoch 77/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4072Текущий реальный скор(валидационная часть): 1.2895\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4129 - val_loss: 1.3785 - lr: 1.5625e-05\n",
      "Epoch 78/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4095Текущий реальный скор(валидационная часть): 1.2891\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4114 - val_loss: 1.3784 - lr: 1.5625e-05\n",
      "Epoch 79/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4086Текущий реальный скор(валидационная часть): 1.289\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4100 - val_loss: 1.3786 - lr: 1.5625e-05\n",
      "Epoch 80/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4069Текущий реальный скор(валидационная часть): 1.2888\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 1.3784 - lr: 1.5625e-05\n",
      "Epoch 81/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4020Текущий реальный скор(валидационная часть): 1.2888\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 1.3787 - lr: 1.5625e-05\n",
      "Epoch 82/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4014Текущий реальный скор(валидационная часть): 1.2893\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 1.3792 - lr: 1.5625e-05\n",
      "Epoch 83/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4031Текущий реальный скор(валидационная часть): 1.2889\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4054 - val_loss: 1.3790 - lr: 1.5625e-05\n",
      "Epoch 84/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4025Текущий реальный скор(валидационная часть): 1.2896\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 1.3797 - lr: 1.5625e-05\n",
      "Epoch 85/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4016Текущий реальный скор(валидационная часть): 1.2897\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4035 - val_loss: 1.3800 - lr: 1.5625e-05\n",
      "Epoch 86/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4003Текущий реальный скор(валидационная часть): 1.2679\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 1.3610 - lr: 7.8125e-06\n",
      "Epoch 87/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3950Текущий реальный скор(валидационная часть): 1.2687\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 1.3619 - lr: 7.8125e-06\n",
      "Epoch 88/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4008Текущий реальный скор(валидационная часть): 1.2694\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4014 - val_loss: 1.3626 - lr: 7.8125e-06\n",
      "Epoch 89/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3997Текущий реальный скор(валидационная часть): 1.2698\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4009 - val_loss: 1.3632 - lr: 7.8125e-06\n",
      "Epoch 90/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3945Текущий реальный скор(валидационная часть): 1.2706\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4003 - val_loss: 1.3639 - lr: 7.8125e-06\n",
      "Epoch 91/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3986Текущий реальный скор(валидационная часть): 1.2709\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 1.3644 - lr: 7.8125e-06\n",
      "Epoch 92/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3977Текущий реальный скор(валидационная часть): 1.2716\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3992 - val_loss: 1.3651 - lr: 7.8125e-06\n",
      "Epoch 93/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3969Текущий реальный скор(валидационная часть): 1.2719\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3988 - val_loss: 1.3654 - lr: 7.8125e-06\n",
      "Epoch 94/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3934Текущий реальный скор(валидационная часть): 1.2724\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3983 - val_loss: 1.3659 - lr: 7.8125e-06\n",
      "Epoch 95/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.3942Текущий реальный скор(валидационная часть): 1.2729\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3978 - val_loss: 1.3664 - lr: 7.8125e-06\n",
      "Epoch 96/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.3934Текущий реальный скор(валидационная часть): 1.2704\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 1.3639 - lr: 3.9063e-06\n",
      "Epoch 97/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.3932Текущий реальный скор(валидационная часть): 1.2708\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 1.3642 - lr: 3.9063e-06\n",
      "Epoch 98/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3945Текущий реальный скор(валидационная часть): 1.2711\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 1.3645 - lr: 3.9063e-06\n",
      "Epoch 99/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.3961Текущий реальный скор(валидационная часть): 1.2713\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 1.3647 - lr: 3.9063e-06\n",
      "Epoch 100/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3947Текущий реальный скор(валидационная часть): 1.2716\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3959 - val_loss: 1.3650 - lr: 3.9063e-06\n",
      "Epoch 101/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3981Текущий реальный скор(валидационная часть): 1.2719\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3957 - val_loss: 1.3654 - lr: 3.9063e-06\n",
      "Epoch 102/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.3936Текущий реальный скор(валидационная часть): 1.2721\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3954 - val_loss: 1.3656 - lr: 3.9063e-06\n",
      "Epoch 103/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3940Текущий реальный скор(валидационная часть): 1.2724\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3952 - val_loss: 1.3658 - lr: 3.9063e-06\n",
      "Epoch 104/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3950Текущий реальный скор(валидационная часть): 1.2727\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 1.3662 - lr: 3.9063e-06\n",
      "Epoch 105/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.3918Текущий реальный скор(валидационная часть): 1.2729\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3947 - val_loss: 1.3664 - lr: 3.9063e-06\n",
      "Epoch 106/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3869Текущий реальный скор(валидационная часть): 1.2759\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 1.3683 - lr: 1.9531e-06\n",
      "Epoch 107/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3934Текущий реальный скор(валидационная часть): 1.2762\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 1.3685 - lr: 1.9531e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3935Текущий реальный скор(валидационная часть): 1.2763\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3935 - val_loss: 1.3685 - lr: 1.9531e-06\n",
      "Epoch 109/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3934Текущий реальный скор(валидационная часть): 1.2764\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 1.3685 - lr: 1.9531e-06\n",
      "Epoch 110/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.3907Текущий реальный скор(валидационная часть): 1.2765\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 1.3686 - lr: 1.9531e-06\n",
      "Epoch 111/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3931Текущий реальный скор(валидационная часть): 1.2765\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 1.3686 - lr: 1.9531e-06\n",
      "Epoch 112/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3925Текущий реальный скор(валидационная часть): 1.2766\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3930 - val_loss: 1.3687 - lr: 1.9531e-06\n",
      "Epoch 113/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.3893Текущий реальный скор(валидационная часть): 1.2767\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 1.3688 - lr: 1.9531e-06\n",
      "Epoch 114/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3916Текущий реальный скор(валидационная часть): 1.2768\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 1.3689 - lr: 1.9531e-06\n",
      "Epoch 115/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3883Текущий реальный скор(валидационная часть): 1.2769\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 1.3690 - lr: 1.9531e-06\n",
      "Epoch 116/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.3919Текущий реальный скор(валидационная часть): 1.2783\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 1.3699 - lr: 9.7656e-07\n",
      "Epoch 117/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.3893Текущий реальный скор(валидационная часть): 1.2788\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 1.3702 - lr: 9.7656e-07\n",
      "Epoch 118/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.3917Текущий реальный скор(валидационная часть): 1.2789\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3919 - val_loss: 1.3703 - lr: 9.7656e-07\n",
      "Epoch 119/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3912Текущий реальный скор(валидационная часть): 1.279\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3918 - val_loss: 1.3704 - lr: 9.7656e-07\n",
      "Epoch 120/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3906Текущий реальный скор(валидационная часть): 1.2791\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3918 - val_loss: 1.3704 - lr: 9.7656e-07\n",
      "Epoch 121/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3905Текущий реальный скор(валидационная часть): 1.2791\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 1.3704 - lr: 9.7656e-07\n",
      "Epoch 122/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3896Текущий реальный скор(валидационная часть): 1.2792\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 1.3705 - lr: 9.7656e-07\n",
      "Epoch 123/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.3886Текущий реальный скор(валидационная часть): 1.2792\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 1.3705 - lr: 9.7656e-07\n",
      "Epoch 124/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3940Текущий реальный скор(валидационная часть): 1.2793\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 1.3705 - lr: 9.7656e-07\n",
      "Epoch 125/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.3879Текущий реальный скор(валидационная часть): 1.2793\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 1.3706 - lr: 9.7656e-07\n",
      "Epoch 126/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3900Текущий реальный скор(валидационная часть): 1.2797\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 1.3709 - lr: 4.8828e-07\n",
      "Epoch 127/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.3875Текущий реальный скор(валидационная часть): 1.28\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3911 - val_loss: 1.3710 - lr: 4.8828e-07\n",
      "Epoch 128/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.3884Текущий реальный скор(валидационная часть): 1.2801\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3911 - val_loss: 1.3711 - lr: 4.8828e-07\n",
      "Epoch 129/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3890Текущий реальный скор(валидационная часть): 1.2802\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3910 - val_loss: 1.3712 - lr: 4.8828e-07\n",
      "Epoch 130/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3898Текущий реальный скор(валидационная часть): 1.2802\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3910 - val_loss: 1.3712 - lr: 4.8828e-07\n",
      "Epoch 131/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3889Текущий реальный скор(валидационная часть): 1.2803\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3910 - val_loss: 1.3713 - lr: 4.8828e-07\n",
      "Epoch 132/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3910Текущий реальный скор(валидационная часть): 1.2803\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3910 - val_loss: 1.3713 - lr: 4.8828e-07\n",
      "Epoch 133/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3909Текущий реальный скор(валидационная часть): 1.2804\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3909 - val_loss: 1.3713 - lr: 4.8828e-07\n",
      "Epoch 134/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3889Текущий реальный скор(валидационная часть): 1.2804\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3909 - val_loss: 1.3713 - lr: 4.8828e-07\n",
      "Epoch 135/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3864Текущий реальный скор(валидационная часть): 1.1767\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3909 - val_loss: 1.3714 - lr: 4.8828e-07\n",
      "Скор для фолда(2) : 1.1767 средний скор на префиксе = 1.2425 это заняло = 38 сек.\n",
      "Фолд: 3\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 4.1700Текущий реальный скор(валидационная часть): 2.4161\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8062 - val_loss: 2.4914 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 2.0000Текущий реальный скор(валидационная часть): 1.7585\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9441 - val_loss: 1.8273 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.6608Текущий реальный скор(валидационная часть): 1.5535\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6458 - val_loss: 1.6366 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.5025Текущий реальный скор(валидационная часть): 1.5121\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5001 - val_loss: 1.5812 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4184Текущий реальный скор(валидационная часть): 1.497\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4184 - val_loss: 1.5645 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.3506Текущий реальный скор(валидационная часть): 1.5134\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3515 - val_loss: 1.5799 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 1.2903Текущий реальный скор(валидационная часть): 1.5266\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2924 - val_loss: 1.5957 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.2395Текущий реальный скор(валидационная часть): 1.5231\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2391 - val_loss: 1.5915 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1917Текущий реальный скор(валидационная часть): 1.5396\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1917 - val_loss: 1.5958 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 1.1487Текущий реальный скор(валидационная часть): 1.5726\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1520 - val_loss: 1.6271 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.1101Текущий реальный скор(валидационная часть): 1.565\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1136 - val_loss: 1.6198 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.0770Текущий реальный скор(валидационная часть): 1.5427\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0768 - val_loss: 1.5941 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 1.0360Текущий реальный скор(валидационная часть): 1.5417\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0361 - val_loss: 1.5992 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 1.0041Текущий реальный скор(валидационная часть): 1.5342\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0104 - val_loss: 1.6016 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.9725Текущий реальный скор(валидационная часть): 1.4961\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9697 - val_loss: 1.5621 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.9380Текущий реальный скор(валидационная часть): 1.5203\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9479 - val_loss: 1.5967 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.9140Текущий реальный скор(валидационная часть): 1.5512\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9284 - val_loss: 1.6343 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.8859Текущий реальный скор(валидационная часть): 1.5689\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9090 - val_loss: 1.6489 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.8962Текущий реальный скор(валидационная часть): 1.5823\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8963 - val_loss: 1.6811 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.8716Текущий реальный скор(валидационная часть): 1.4677\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8828 - val_loss: 1.5686 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.8851Текущий реальный скор(валидационная часть): 1.4783\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8853 - val_loss: 1.5799 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.9140Текущий реальный скор(валидационная часть): 1.4401\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9131 - val_loss: 1.5312 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.9140Текущий реальный скор(валидационная часть): 1.527\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9125 - val_loss: 1.6259 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.8617Текущий реальный скор(валидационная часть): 1.4964\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8621 - val_loss: 1.6075 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.8140Текущий реальный скор(валидационная часть): 1.6472\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8237 - val_loss: 1.7490 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.8138Текущий реальный скор(валидационная часть): 1.6457\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8143 - val_loss: 1.7481 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.8230Текущий реальный скор(валидационная часть): 1.5649\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8295 - val_loss: 1.6643 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.8039Текущий реальный скор(валидационная часть): 1.5461\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8008 - val_loss: 1.6570 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.7816Текущий реальный скор(валидационная часть): 1.585\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8088 - val_loss: 1.7004 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.8273Текущий реальный скор(валидационная часть): 1.5628\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8276 - val_loss: 1.6712 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.8114Текущий реальный скор(валидационная часть): 1.7887\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8129 - val_loss: 1.8669 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.7867Текущий реальный скор(валидационная часть): 2.0805\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7867 - val_loss: 2.1560 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8158Текущий реальный скор(валидационная часть): 1.6766\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8158 - val_loss: 1.7651 - lr: 2.5000e-04\n",
      "Epoch 34/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.7127Текущий реальный скор(валидационная часть): 1.6371\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7251 - val_loss: 1.7345 - lr: 2.5000e-04\n",
      "Epoch 35/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/134 [===========================>..] - ETA: 0s - loss: 0.6757Текущий реальный скор(валидационная часть): 1.6264\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6783 - val_loss: 1.7351 - lr: 2.5000e-04\n",
      "Epoch 36/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.6171Текущий реальный скор(валидационная часть): 1.6339\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6378 - val_loss: 1.7426 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.6101Текущий реальный скор(валидационная часть): 1.6408\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6128 - val_loss: 1.7497 - lr: 2.5000e-04\n",
      "Epoch 38/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5766Текущий реальный скор(валидационная часть): 1.6467\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5937 - val_loss: 1.7561 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5763Текущий реальный скор(валидационная часть): 1.6568\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5776 - val_loss: 1.7671 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5451Текущий реальный скор(валидационная часть): 1.6608\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5636 - val_loss: 1.7672 - lr: 2.5000e-04\n",
      "Epoch 41/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5494Текущий реальный скор(валидационная часть): 1.6717\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5521 - val_loss: 1.7814 - lr: 2.5000e-04\n",
      "Epoch 42/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5385Текущий реальный скор(валидационная часть): 1.6733\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 1.7803 - lr: 2.5000e-04\n",
      "Epoch 43/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5328Текущий реальный скор(валидационная часть): 1.6662\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5548 - val_loss: 1.7378 - lr: 1.2500e-04\n",
      "Epoch 44/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5441Текущий реальный скор(валидационная часть): 1.6725\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5599 - val_loss: 1.7431 - lr: 1.2500e-04\n",
      "Epoch 45/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5341Текущий реальный скор(валидационная часть): 1.6734\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5476 - val_loss: 1.7455 - lr: 1.2500e-04\n",
      "Epoch 46/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5388Текущий реальный скор(валидационная часть): 1.6732\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 1.7456 - lr: 1.2500e-04\n",
      "Epoch 47/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.5299Текущий реальный скор(валидационная часть): 1.6769\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 1.7492 - lr: 1.2500e-04\n",
      "Epoch 48/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5222Текущий реальный скор(валидационная часть): 1.6769\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.7491 - lr: 1.2500e-04\n",
      "Epoch 49/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.5094Текущий реальный скор(валидационная часть): 1.6789\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5167 - val_loss: 1.7537 - lr: 1.2500e-04\n",
      "Epoch 50/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5017Текущий реальный скор(валидационная часть): 1.6751\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5109 - val_loss: 1.7529 - lr: 1.2500e-04\n",
      "Epoch 51/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4956Текущий реальный скор(валидационная часть): 1.6722\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5049 - val_loss: 1.7542 - lr: 1.2500e-04\n",
      "Epoch 52/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4982Текущий реальный скор(валидационная часть): 1.664\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4991 - val_loss: 1.7477 - lr: 1.2500e-04\n",
      "Epoch 53/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.5205Текущий реальный скор(валидационная часть): 1.6439\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.7280 - lr: 6.2500e-05\n",
      "Epoch 54/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5033Текущий реальный скор(валидационная часть): 1.6365\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5090 - val_loss: 1.7232 - lr: 6.2500e-05\n",
      "Epoch 55/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4983Текущий реальный скор(валидационная часть): 1.6358\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4992 - val_loss: 1.7233 - lr: 6.2500e-05\n",
      "Epoch 56/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4815Текущий реальный скор(валидационная часть): 1.6329\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 1.7212 - lr: 6.2500e-05\n",
      "Epoch 57/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4847Текущий реальный скор(валидационная часть): 1.6331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4860 - val_loss: 1.7212 - lr: 6.2500e-05\n",
      "Epoch 58/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4791Текущий реальный скор(валидационная часть): 1.6341\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 1.7218 - lr: 6.2500e-05\n",
      "Epoch 59/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4608Текущий реальный скор(валидационная часть): 1.6325\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 1.7196 - lr: 6.2500e-05\n",
      "Epoch 60/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4620Текущий реальный скор(валидационная часть): 1.6322\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 1.7185 - lr: 6.2500e-05\n",
      "Epoch 61/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4639Текущий реальный скор(валидационная часть): 1.6334\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4675 - val_loss: 1.7192 - lr: 6.2500e-05\n",
      "Epoch 62/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4638Текущий реальный скор(валидационная часть): 1.6328\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 1.7189 - lr: 6.2500e-05\n",
      "Epoch 63/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4550Текущий реальный скор(валидационная часть): 1.63\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4688 - val_loss: 1.7328 - lr: 3.1250e-05\n",
      "Epoch 64/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4523Текущий реальный скор(валидационная часть): 1.6333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 1.7370 - lr: 3.1250e-05\n",
      "Epoch 65/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4463Текущий реальный скор(валидационная часть): 1.6344\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 1.7384 - lr: 3.1250e-05\n",
      "Epoch 66/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4550Текущий реальный скор(валидационная часть): 1.6361\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 1.7407 - lr: 3.1250e-05\n",
      "Epoch 67/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4500Текущий реальный скор(валидационная часть): 1.637\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 1.7418 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4455Текущий реальный скор(валидационная часть): 1.6382\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 1.7433 - lr: 3.1250e-05\n",
      "Epoch 69/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4389Текущий реальный скор(валидационная часть): 1.6389\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 1.7440 - lr: 3.1250e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4334Текущий реальный скор(валидационная часть): 1.6403\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4462 - val_loss: 1.7455 - lr: 3.1250e-05\n",
      "Epoch 71/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4335Текущий реальный скор(валидационная часть): 1.6409\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4442 - val_loss: 1.7462 - lr: 3.1250e-05\n",
      "Epoch 72/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4327Текущий реальный скор(валидационная часть): 1.6423\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 1.7476 - lr: 3.1250e-05\n",
      "Epoch 73/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4426Текущий реальный скор(валидационная часть): 1.6466\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4437 - val_loss: 1.7556 - lr: 1.5625e-05\n",
      "Epoch 74/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4405Текущий реальный скор(валидационная часть): 1.6466\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 1.7561 - lr: 1.5625e-05\n",
      "Epoch 75/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4375Текущий реальный скор(валидационная часть): 1.647\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 1.7569 - lr: 1.5625e-05\n",
      "Epoch 76/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4283Текущий реальный скор(валидационная часть): 1.647\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4370 - val_loss: 1.7571 - lr: 1.5625e-05\n",
      "Epoch 77/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4354Текущий реальный скор(валидационная часть): 1.6469\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 1.7572 - lr: 1.5625e-05\n",
      "Epoch 78/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4341Текущий реальный скор(валидационная часть): 1.6469\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4342 - val_loss: 1.7574 - lr: 1.5625e-05\n",
      "Epoch 79/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4316Текущий реальный скор(валидационная часть): 1.6471\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4330 - val_loss: 1.7576 - lr: 1.5625e-05\n",
      "Epoch 80/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4219Текущий реальный скор(валидационная часть): 1.6477\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4318 - val_loss: 1.7582 - lr: 1.5625e-05\n",
      "Epoch 81/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4297Текущий реальный скор(валидационная часть): 1.6476\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 1.7582 - lr: 1.5625e-05\n",
      "Epoch 82/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4279Текущий реальный скор(валидационная часть): 1.6481\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4297 - val_loss: 1.7589 - lr: 1.5625e-05\n",
      "Epoch 83/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4252Текущий реальный скор(валидационная часть): 1.6493\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 1.7597 - lr: 7.8125e-06\n",
      "Epoch 84/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4240Текущий реальный скор(валидационная часть): 1.6499\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 1.7604 - lr: 7.8125e-06\n",
      "Epoch 85/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4219Текущий реальный скор(валидационная часть): 1.6499\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4274 - val_loss: 1.7605 - lr: 7.8125e-06\n",
      "Epoch 86/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4252Текущий реальный скор(валидационная часть): 1.6502\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 1.7609 - lr: 7.8125e-06\n",
      "Epoch 87/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4218Текущий реальный скор(валидационная часть): 1.6502\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4262 - val_loss: 1.7610 - lr: 7.8125e-06\n",
      "Epoch 88/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4246Текущий реальный скор(валидационная часть): 1.6505\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4257 - val_loss: 1.7614 - lr: 7.8125e-06\n",
      "Epoch 89/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4211Текущий реальный скор(валидационная часть): 1.6508\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4252 - val_loss: 1.7617 - lr: 7.8125e-06\n",
      "Epoch 90/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4114Текущий реальный скор(валидационная часть): 1.6508\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4246 - val_loss: 1.7618 - lr: 7.8125e-06\n",
      "Epoch 91/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4177Текущий реальный скор(валидационная часть): 1.6511\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4241 - val_loss: 1.7621 - lr: 7.8125e-06\n",
      "Epoch 92/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4150Текущий реальный скор(валидационная часть): 1.6513\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 1.7624 - lr: 7.8125e-06\n",
      "Epoch 93/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4231Текущий реальный скор(валидационная часть): 1.6537\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4231 - val_loss: 1.7659 - lr: 3.9063e-06\n",
      "Epoch 94/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4177Текущий реальный скор(валидационная часть): 1.654\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4223 - val_loss: 1.7663 - lr: 3.9063e-06\n",
      "Epoch 95/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4087Текущий реальный скор(валидационная часть): 1.6542\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4220 - val_loss: 1.7665 - lr: 3.9063e-06\n",
      "Epoch 96/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4138Текущий реальный скор(валидационная часть): 1.6545\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4217 - val_loss: 1.7668 - lr: 3.9063e-06\n",
      "Epoch 97/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4137Текущий реальный скор(валидационная часть): 1.6546\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4214 - val_loss: 1.7670 - lr: 3.9063e-06\n",
      "Epoch 98/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4121Текущий реальный скор(валидационная часть): 1.6548\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4211 - val_loss: 1.7671 - lr: 3.9063e-06\n",
      "Epoch 99/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4207Текущий реальный скор(валидационная часть): 1.6549\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 1.7672 - lr: 3.9063e-06\n",
      "Epoch 100/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4204Текущий реальный скор(валидационная часть): 1.6551\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4206 - val_loss: 1.7674 - lr: 3.9063e-06\n",
      "Epoch 101/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4105Текущий реальный скор(валидационная часть): 1.6553\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 1.7676 - lr: 3.9063e-06\n",
      "Epoch 102/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4199Текущий реальный скор(валидационная часть): 1.6553\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 1.7677 - lr: 3.9063e-06\n",
      "Epoch 103/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4144Текущий реальный скор(валидационная часть): 1.657\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4193 - val_loss: 1.7702 - lr: 1.9531e-06\n",
      "Epoch 104/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4174Текущий реальный скор(валидационная часть): 1.6575\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 1.7707 - lr: 1.9531e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4135Текущий реальный скор(валидационная часть): 1.6577\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4187 - val_loss: 1.7709 - lr: 1.9531e-06\n",
      "Epoch 106/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4185Текущий реальный скор(валидационная часть): 1.6578\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 1.7710 - lr: 1.9531e-06\n",
      "Epoch 107/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4132Текущий реальный скор(валидационная часть): 1.6579\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4184 - val_loss: 1.7711 - lr: 1.9531e-06\n",
      "Epoch 108/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4171Текущий реальный скор(валидационная часть): 1.658\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 1.7712 - lr: 1.9531e-06\n",
      "Epoch 109/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4140Текущий реальный скор(валидационная часть): 1.6581\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4181 - val_loss: 1.7712 - lr: 1.9531e-06\n",
      "Epoch 110/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4042Текущий реальный скор(валидационная часть): 1.6582\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4180 - val_loss: 1.7713 - lr: 1.9531e-06\n",
      "Epoch 111/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4098Текущий реальный скор(валидационная часть): 1.6582\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4179 - val_loss: 1.7714 - lr: 1.9531e-06\n",
      "Epoch 112/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4066Текущий реальный скор(валидационная часть): 1.6583\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 1.7714 - lr: 1.9531e-06\n",
      "Epoch 113/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4160Текущий реальный скор(валидационная часть): 1.6589\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4172 - val_loss: 1.7722 - lr: 9.7656e-07\n",
      "Epoch 114/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4170Текущий реальный скор(валидационная часть): 1.6592\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4170 - val_loss: 1.7725 - lr: 9.7656e-07\n",
      "Epoch 115/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4084Текущий реальный скор(валидационная часть): 1.6593\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 1.7727 - lr: 9.7656e-07\n",
      "Epoch 116/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4096Текущий реальный скор(валидационная часть): 1.6594\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 1.7728 - lr: 9.7656e-07\n",
      "Epoch 117/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4153Текущий реальный скор(валидационная часть): 1.6595\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4168 - val_loss: 1.7729 - lr: 9.7656e-07\n",
      "Epoch 118/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4125Текущий реальный скор(валидационная часть): 1.6595\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 1.7729 - lr: 9.7656e-07\n",
      "Epoch 119/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4113Текущий реальный скор(валидационная часть): 1.6596\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 1.7729 - lr: 9.7656e-07\n",
      "Epoch 120/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4026Текущий реальный скор(валидационная часть): 1.6596\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 1.7729 - lr: 9.7656e-07\n",
      "Epoch 121/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4154Текущий реальный скор(валидационная часть): 1.6597\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4165 - val_loss: 1.7730 - lr: 9.7656e-07\n",
      "Epoch 122/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4161Текущий реальный скор(валидационная часть): 1.4401\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4165 - val_loss: 1.7730 - lr: 9.7656e-07\n",
      "Скор для фолда(3) : 1.4401 средний скор на префиксе = 1.2919 это заняло = 34 сек.\n",
      "Фолд: 4\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 4.1632Текущий реальный скор(валидационная часть): 2.3608\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8140 - val_loss: 2.4088 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.9316Текущий реальный скор(валидационная часть): 1.7916\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9316 - val_loss: 1.8780 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 1.6485Текущий реальный скор(валидационная часть): 1.715\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6382 - val_loss: 1.8081 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.4899Текущий реальный скор(валидационная часть): 1.6521\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4868 - val_loss: 1.7457 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 1.4169Текущий реальный скор(валидационная часть): 1.6275\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4041 - val_loss: 1.7213 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.3267Текущий реальный скор(валидационная часть): 1.567\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3316 - val_loss: 1.6564 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 1.2712Текущий реальный скор(валидационная часть): 1.6151\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2697 - val_loss: 1.7022 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 1.2189Текущий реальный скор(валидационная часть): 1.5372\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2215 - val_loss: 1.6289 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.1838Текущий реальный скор(валидационная часть): 1.4479\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1838 - val_loss: 1.5483 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 1.1410Текущий реальный скор(валидационная часть): 1.4644\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1463 - val_loss: 1.5614 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 1.0807Текущий реальный скор(валидационная часть): 1.4686\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0905 - val_loss: 1.5604 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 1.0465Текущий реальный скор(валидационная часть): 1.515\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0500 - val_loss: 1.6005 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.0088Текущий реальный скор(валидационная часть): 1.5261\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0085 - val_loss: 1.6126 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.9738Текущий реальный скор(валидационная часть): 1.5286\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9727 - val_loss: 1.6228 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.9358Текущий реальный скор(валидационная часть): 1.5176\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9560 - val_loss: 1.6132 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.9282Текущий реальный скор(валидационная часть): 1.5807\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 1.6674 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.9341Текущий реальный скор(валидационная часть): 1.8711\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9478 - val_loss: 1.9710 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.9516Текущий реальный скор(валидационная часть): 1.9327\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9516 - val_loss: 2.0166 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 1.0176Текущий реальный скор(валидационная часть): 1.7118\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0164 - val_loss: 1.8081 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.9552Текущий реальный скор(валидационная часть): 1.6965\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9529 - val_loss: 1.7914 - lr: 2.5000e-04\n",
      "Epoch 21/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.8716Текущий реальный скор(валидационная часть): 1.7613\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8651 - val_loss: 1.8566 - lr: 2.5000e-04\n",
      "Epoch 22/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.8247Текущий реальный скор(валидационная часть): 1.8027\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8324 - val_loss: 1.9006 - lr: 2.5000e-04\n",
      "Epoch 23/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.8015Текущий реальный скор(валидационная часть): 1.8189\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8066 - val_loss: 1.9066 - lr: 2.5000e-04\n",
      "Epoch 24/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.7710Текущий реальный скор(валидационная часть): 1.8316\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7821 - val_loss: 1.9319 - lr: 2.5000e-04\n",
      "Epoch 25/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.7631Текущий реальный скор(валидационная часть): 1.8384\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7609 - val_loss: 1.9438 - lr: 2.5000e-04\n",
      "Epoch 26/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.7276Текущий реальный скор(валидационная часть): 1.8582\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7422 - val_loss: 1.9618 - lr: 2.5000e-04\n",
      "Epoch 27/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.7143Текущий реальный скор(валидационная часть): 1.8759\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7242 - val_loss: 1.9781 - lr: 2.5000e-04\n",
      "Epoch 28/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.6951Текущий реальный скор(валидационная часть): 1.8903\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7077 - val_loss: 1.9982 - lr: 2.5000e-04\n",
      "Epoch 29/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.6948Текущий реальный скор(валидационная часть): 1.9184\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6953 - val_loss: 2.0251 - lr: 2.5000e-04\n",
      "Epoch 30/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.7227Текущий реальный скор(валидационная часть): 1.7717\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7184 - val_loss: 1.8576 - lr: 1.2500e-04\n",
      "Epoch 31/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.6906Текущий реальный скор(валидационная часть): 1.8455\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6958 - val_loss: 1.9388 - lr: 1.2500e-04\n",
      "Epoch 32/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.6676Текущий реальный скор(валидационная часть): 1.8393\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6686 - val_loss: 1.9318 - lr: 1.2500e-04\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6538Текущий реальный скор(валидационная часть): 1.8447\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6538 - val_loss: 1.9418 - lr: 1.2500e-04\n",
      "Epoch 34/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.6393Текущий реальный скор(валидационная часть): 1.8325\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6409 - val_loss: 1.9323 - lr: 1.2500e-04\n",
      "Epoch 35/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.6243Текущий реальный скор(валидационная часть): 1.8391\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 1.9384 - lr: 1.2500e-04\n",
      "Epoch 36/500\n",
      "105/134 [======================>.......] - ETA: 0s - loss: 0.6126Текущий реальный скор(валидационная часть): 1.838\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6204 - val_loss: 1.9378 - lr: 1.2500e-04\n",
      "Epoch 37/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.6006Текущий реальный скор(валидационная часть): 1.8391\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 1.9415 - lr: 1.2500e-04\n",
      "Epoch 38/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6040Текущий реальный скор(валидационная часть): 1.838\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 1.9410 - lr: 1.2500e-04\n",
      "Epoch 39/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5961Текущий реальный скор(валидационная часть): 1.8388\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5966 - val_loss: 1.9405 - lr: 1.2500e-04\n",
      "Epoch 40/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.6019Текущий реальный скор(валидационная часть): 1.7181\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 1.8098 - lr: 6.2500e-05\n",
      "Epoch 41/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.6151Текущий реальный скор(валидационная часть): 1.6823\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 1.7863 - lr: 6.2500e-05\n",
      "Epoch 42/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.6097Текущий реальный скор(валидационная часть): 1.6666\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 1.7714 - lr: 6.2500e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.6069Текущий реальный скор(валидационная часть): 1.6543\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 1.7628 - lr: 6.2500e-05\n",
      "Epoch 44/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5901Текущий реальный скор(валидационная часть): 1.6475\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 1.7613 - lr: 6.2500e-05\n",
      "Epoch 45/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.5906Текущий реальный скор(валидационная часть): 1.6416\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5951 - val_loss: 1.7573 - lr: 6.2500e-05\n",
      "Epoch 46/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5898Текущий реальный скор(валидационная часть): 1.6365\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 1.7542 - lr: 6.2500e-05\n",
      "Epoch 47/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5864Текущий реальный скор(валидационная часть): 1.6338\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5864 - val_loss: 1.7525 - lr: 6.2500e-05\n",
      "Epoch 48/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5814Текущий реальный скор(валидационная часть): 1.631\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5823 - val_loss: 1.7507 - lr: 6.2500e-05\n",
      "Epoch 49/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5619Текущий реальный скор(валидационная часть): 1.6293\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5783 - val_loss: 1.7496 - lr: 6.2500e-05\n",
      "Epoch 50/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5912Текущий реальный скор(валидационная часть): 1.6411\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5912 - val_loss: 1.7549 - lr: 3.1250e-05\n",
      "Epoch 51/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5707Текущий реальный скор(валидационная часть): 1.649\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5806 - val_loss: 1.7609 - lr: 3.1250e-05\n",
      "Epoch 52/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5645Текущий реальный скор(валидационная часть): 1.6544\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5741 - val_loss: 1.7631 - lr: 3.1250e-05\n",
      "Epoch 53/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5603Текущий реальный скор(валидационная часть): 1.6584\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5686 - val_loss: 1.7670 - lr: 3.1250e-05\n",
      "Epoch 54/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5670Текущий реальный скор(валидационная часть): 1.6641\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5643 - val_loss: 1.7724 - lr: 3.1250e-05\n",
      "Epoch 55/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5496Текущий реальный скор(валидационная часть): 1.6684\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5605 - val_loss: 1.7768 - lr: 3.1250e-05\n",
      "Epoch 56/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.5546Текущий реальный скор(валидационная часть): 1.6697\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5572 - val_loss: 1.7811 - lr: 3.1250e-05\n",
      "Epoch 57/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5405Текущий реальный скор(валидационная часть): 1.6725\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5540 - val_loss: 1.7845 - lr: 3.1250e-05\n",
      "Epoch 58/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.5566Текущий реальный скор(валидационная часть): 1.6742\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5510 - val_loss: 1.7866 - lr: 3.1250e-05\n",
      "Epoch 59/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5507Текущий реальный скор(валидационная часть): 1.6769\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5483 - val_loss: 1.7896 - lr: 3.1250e-05\n",
      "Epoch 60/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5441Текущий реальный скор(валидационная часть): 1.7185\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 1.8245 - lr: 1.5625e-05\n",
      "Epoch 61/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5430Текущий реальный скор(валидационная часть): 1.7165\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5430 - val_loss: 1.8233 - lr: 1.5625e-05\n",
      "Epoch 62/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5394Текущий реальный скор(валидационная часть): 1.7162\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5411 - val_loss: 1.8236 - lr: 1.5625e-05\n",
      "Epoch 63/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.5381Текущий реальный скор(валидационная часть): 1.716\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 1.8238 - lr: 1.5625e-05\n",
      "Epoch 64/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5330Текущий реальный скор(валидационная часть): 1.7163\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5380 - val_loss: 1.8244 - lr: 1.5625e-05\n",
      "Epoch 65/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5357Текущий реальный скор(валидационная часть): 1.7162\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 1.8246 - lr: 1.5625e-05\n",
      "Epoch 66/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5299Текущий реальный скор(валидационная часть): 1.717\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 1.8284 - lr: 1.5625e-05\n",
      "Epoch 67/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5319Текущий реальный скор(валидационная часть): 1.7176\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5339 - val_loss: 1.8292 - lr: 1.5625e-05\n",
      "Epoch 68/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5334Текущий реальный скор(валидационная часть): 1.718\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5327 - val_loss: 1.8300 - lr: 1.5625e-05\n",
      "Epoch 69/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5237Текущий реальный скор(валидационная часть): 1.7186\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5315 - val_loss: 1.8308 - lr: 1.5625e-05\n",
      "Epoch 70/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5271Текущий реальный скор(валидационная часть): 1.7034\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 1.8185 - lr: 7.8125e-06\n",
      "Epoch 71/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5204Текущий реальный скор(валидационная часть): 1.705\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 1.8203 - lr: 7.8125e-06\n",
      "Epoch 72/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5287Текущий реальный скор(валидационная часть): 1.706\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.8216 - lr: 7.8125e-06\n",
      "Epoch 73/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5204Текущий реальный скор(валидационная часть): 1.7067\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.8224 - lr: 7.8125e-06\n",
      "Epoch 74/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.5215Текущий реальный скор(валидационная часть): 1.7071\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.8229 - lr: 7.8125e-06\n",
      "Epoch 75/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5177Текущий реальный скор(валидационная часть): 1.7078\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.8238 - lr: 7.8125e-06\n",
      "Epoch 76/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5231Текущий реальный скор(валидационная часть): 1.7083\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.8244 - lr: 7.8125e-06\n",
      "Epoch 77/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5213Текущий реальный скор(валидационная часть): 1.7087\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.8249 - lr: 7.8125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5230Текущий реальный скор(валидационная часть): 1.7092\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.8256 - lr: 7.8125e-06\n",
      "Epoch 79/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5224Текущий реальный скор(валидационная часть): 1.7098\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 1.8263 - lr: 7.8125e-06\n",
      "Epoch 80/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5097Текущий реальный скор(валидационная часть): 1.7085\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5204 - val_loss: 1.8253 - lr: 3.9063e-06\n",
      "Epoch 81/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5147Текущий реальный скор(валидационная часть): 1.7093\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5202 - val_loss: 1.8261 - lr: 3.9063e-06\n",
      "Epoch 82/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5144Текущий реальный скор(валидационная часть): 1.7099\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 1.8267 - lr: 3.9063e-06\n",
      "Epoch 83/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.5191Текущий реальный скор(валидационная часть): 1.7103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5195 - val_loss: 1.8271 - lr: 3.9063e-06\n",
      "Epoch 84/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5084Текущий реальный скор(валидационная часть): 1.7108\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5192 - val_loss: 1.8277 - lr: 3.9063e-06\n",
      "Epoch 85/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5189Текущий реальный скор(валидационная часть): 1.7112\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5189 - val_loss: 1.8282 - lr: 3.9063e-06\n",
      "Epoch 86/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5111Текущий реальный скор(валидационная часть): 1.7113\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5186 - val_loss: 1.8284 - lr: 3.9063e-06\n",
      "Epoch 87/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5173Текущий реальный скор(валидационная часть): 1.7118\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5184 - val_loss: 1.8290 - lr: 3.9063e-06\n",
      "Epoch 88/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5120Текущий реальный скор(валидационная часть): 1.712\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5181 - val_loss: 1.8293 - lr: 3.9063e-06\n",
      "Epoch 89/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5151Текущий реальный скор(валидационная часть): 1.7125\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 1.8298 - lr: 3.9063e-06\n",
      "Epoch 90/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5157Текущий реальный скор(валидационная часть): 1.7182\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5166 - val_loss: 1.8322 - lr: 1.9531e-06\n",
      "Epoch 91/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5051Текущий реальный скор(валидационная часть): 1.719\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5163 - val_loss: 1.8329 - lr: 1.9531e-06\n",
      "Epoch 92/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.5134Текущий реальный скор(валидационная часть): 1.7192\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5161 - val_loss: 1.8332 - lr: 1.9531e-06\n",
      "Epoch 93/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5102Текущий реальный скор(валидационная часть): 1.7194\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5159 - val_loss: 1.8334 - lr: 1.9531e-06\n",
      "Epoch 94/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5186Текущий реальный скор(валидационная часть): 1.7196\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5158 - val_loss: 1.8337 - lr: 1.9531e-06\n",
      "Epoch 95/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5146Текущий реальный скор(валидационная часть): 1.7198\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5156 - val_loss: 1.8339 - lr: 1.9531e-06\n",
      "Epoch 96/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5146Текущий реальный скор(валидационная часть): 1.72\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5155 - val_loss: 1.8341 - lr: 1.9531e-06\n",
      "Epoch 97/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5123Текущий реальный скор(валидационная часть): 1.7201\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5153 - val_loss: 1.8343 - lr: 1.9531e-06\n",
      "Epoch 98/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5089Текущий реальный скор(валидационная часть): 1.7202\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5152 - val_loss: 1.8345 - lr: 1.9531e-06\n",
      "Epoch 99/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5087Текущий реальный скор(валидационная часть): 1.7204\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5151 - val_loss: 1.8347 - lr: 1.9531e-06\n",
      "Epoch 100/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.5095Текущий реальный скор(валидационная часть): 1.7232\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5143 - val_loss: 1.8371 - lr: 9.7656e-07\n",
      "Epoch 101/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5084Текущий реальный скор(валидационная часть): 1.7242\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5142 - val_loss: 1.8380 - lr: 9.7656e-07\n",
      "Epoch 102/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5061Текущий реальный скор(валидационная часть): 1.7246\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5141 - val_loss: 1.8383 - lr: 9.7656e-07\n",
      "Epoch 103/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.5189Текущий реальный скор(валидационная часть): 1.7248\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5140 - val_loss: 1.8386 - lr: 9.7656e-07\n",
      "Epoch 104/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.5090Текущий реальный скор(валидационная часть): 1.7249\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5140 - val_loss: 1.8387 - lr: 9.7656e-07\n",
      "Epoch 105/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5130Текущий реальный скор(валидационная часть): 1.725\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5139 - val_loss: 1.8388 - lr: 9.7656e-07\n",
      "Epoch 106/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5058Текущий реальный скор(валидационная часть): 1.7251\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5138 - val_loss: 1.8389 - lr: 9.7656e-07\n",
      "Epoch 107/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5156Текущий реальный скор(валидационная часть): 1.7252\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5138 - val_loss: 1.8390 - lr: 9.7656e-07\n",
      "Epoch 108/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5072Текущий реальный скор(валидационная часть): 1.7252\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 1.8391 - lr: 9.7656e-07\n",
      "Epoch 109/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5126Текущий реальный скор(валидационная часть): 1.4479\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5136 - val_loss: 1.8393 - lr: 9.7656e-07\n",
      "Скор для фолда(4) : 1.4479 средний скор на префиксе = 1.3231 это заняло = 30 сек.\n",
      "Фолд: 5\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 3.8206Текущий реальный скор(валидационная часть): 2.468\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.7898 - val_loss: 2.5751 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.9231Текущий реальный скор(валидационная часть): 2.007\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9231 - val_loss: 2.1244 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 1.6259Текущий реальный скор(валидационная часть): 1.9014\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6178 - val_loss: 2.0194 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 1.4945Текущий реальный скор(валидационная часть): 1.8686\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4801 - val_loss: 1.9770 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 1.3921Текущий реальный скор(валидационная часть): 1.8287\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3859 - val_loss: 1.9392 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 1.3204Текущий реальный скор(валидационная часть): 1.8187\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3168 - val_loss: 1.9267 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.2675Текущий реальный скор(валидационная часть): 1.7988\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2640 - val_loss: 1.9004 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.2076Текущий реальный скор(валидационная часть): 1.802\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2067 - val_loss: 1.9032 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.1560Текущий реальный скор(валидационная часть): 1.8132\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1589 - val_loss: 1.9165 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.1195Текущий реальный скор(валидационная часть): 1.8182\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1184 - val_loss: 1.9064 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.0829Текущий реальный скор(валидационная часть): 1.7786\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0801 - val_loss: 1.8695 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.0234Текущий реальный скор(валидационная часть): 1.7839\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0231 - val_loss: 1.8645 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.9808Текущий реальный скор(валидационная часть): 1.8047\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9847 - val_loss: 1.8820 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.9472Текущий реальный скор(валидационная часть): 1.7808\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9536 - val_loss: 1.8588 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.9377Текущий реальный скор(валидационная часть): 1.7986\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9397 - val_loss: 1.8737 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.9259Текущий реальный скор(валидационная часть): 1.8169\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 1.8899 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.9067Текущий реальный скор(валидационная часть): 1.8305\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9063 - val_loss: 1.9115 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8925Текущий реальный скор(валидационная часть): 1.8353\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8925 - val_loss: 1.9050 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.8865Текущий реальный скор(валидационная часть): 1.8796\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8858 - val_loss: 1.9513 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8372Текущий реальный скор(валидационная часть): 1.8596\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8372 - val_loss: 1.9455 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.8178Текущий реальный скор(валидационная часть): 1.8153\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8242 - val_loss: 1.8912 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.7931Текущий реальный скор(валидационная часть): 1.856\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8122 - val_loss: 1.9455 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.7919Текущий реальный скор(валидационная часть): 1.7314\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8152 - val_loss: 1.8208 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.8146Текущий реальный скор(валидационная часть): 1.6886\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8119 - val_loss: 1.7853 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.7859Текущий реальный скор(валидационная часть): 1.6864\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7864 - val_loss: 1.7840 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.8173Текущий реальный скор(валидационная часть): 1.8291\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8171 - val_loss: 1.9061 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.9615Текущий реальный скор(валидационная часть): 1.6841\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9616 - val_loss: 1.7819 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.9669Текущий реальный скор(валидационная часть): 1.6129\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9951 - val_loss: 1.7146 - lr: 5.0000e-04\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/134 [=======================>......] - ETA: 0s - loss: 0.9306Текущий реальный скор(валидационная часть): 1.7586\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9610 - val_loss: 1.8508 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.8350Текущий реальный скор(валидационная часть): 1.867\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8474 - val_loss: 1.9597 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.7292Текущий реальный скор(валидационная часть): 1.9073\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7405 - val_loss: 1.9923 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.6855Текущий реальный скор(валидационная часть): 1.9609\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6840 - val_loss: 2.0601 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.6424Текущий реальный скор(валидационная часть): 1.8925\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6505 - val_loss: 1.9909 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6833Текущий реальный скор(валидационная часть): 1.9461\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6833 - val_loss: 2.0414 - lr: 5.0000e-04\n",
      "Epoch 35/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6523Текущий реальный скор(валидационная часть): 1.9159\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6523 - val_loss: 2.0117 - lr: 5.0000e-04\n",
      "Epoch 36/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.6484Текущий реальный скор(валидационная часть): 1.9071\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6469 - val_loss: 2.0036 - lr: 5.0000e-04\n",
      "Epoch 37/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.6707Текущий реальный скор(валидационная часть): 1.87\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6710 - val_loss: 1.9745 - lr: 5.0000e-04\n",
      "Epoch 38/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.7181Текущий реальный скор(валидационная часть): 1.7248\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7120 - val_loss: 1.8245 - lr: 5.0000e-04\n",
      "Epoch 39/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.7040Текущий реальный скор(валидационная часть): 1.7466\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7045 - val_loss: 1.8338 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.6277Текущий реальный скор(валидационная часть): 1.688\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 1.7789 - lr: 2.5000e-04\n",
      "Epoch 41/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5819Текущий реальный скор(валидационная часть): 1.6852\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5826 - val_loss: 1.7729 - lr: 2.5000e-04\n",
      "Epoch 42/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.5558Текущий реальный скор(валидационная часть): 1.694\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5574 - val_loss: 1.7849 - lr: 2.5000e-04\n",
      "Epoch 43/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5310Текущий реальный скор(валидационная часть): 1.6914\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 1.7801 - lr: 2.5000e-04\n",
      "Epoch 44/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5059Текущий реальный скор(валидационная часть): 1.6817\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5126 - val_loss: 1.7658 - lr: 2.5000e-04\n",
      "Epoch 45/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4909Текущий реальный скор(валидационная часть): 1.6746\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4982 - val_loss: 1.7585 - lr: 2.5000e-04\n",
      "Epoch 46/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4790Текущий реальный скор(валидационная часть): 1.6766\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 1.7616 - lr: 2.5000e-04\n",
      "Epoch 47/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4665Текущий реальный скор(валидационная часть): 1.6733\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 1.7573 - lr: 2.5000e-04\n",
      "Epoch 48/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4601Текущий реальный скор(валидационная часть): 1.6729\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 1.7586 - lr: 2.5000e-04\n",
      "Epoch 49/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4665Текущий реальный скор(валидационная часть): 1.6402\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 1.7237 - lr: 1.2500e-04\n",
      "Epoch 50/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4634Текущий реальный скор(валидационная часть): 1.6428\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 1.7252 - lr: 1.2500e-04\n",
      "Epoch 51/500\n",
      "105/134 [======================>.......] - ETA: 0s - loss: 0.4463Текущий реальный скор(валидационная часть): 1.6493\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 1.7313 - lr: 1.2500e-04\n",
      "Epoch 52/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4490Текущий реальный скор(валидационная часть): 1.6527\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4490 - val_loss: 1.7352 - lr: 1.2500e-04\n",
      "Epoch 53/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4331Текущий реальный скор(валидационная часть): 1.6584\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 1.7400 - lr: 1.2500e-04\n",
      "Epoch 54/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4352Текущий реальный скор(валидационная часть): 1.658\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 1.7394 - lr: 1.2500e-04\n",
      "Epoch 55/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4232Текущий реальный скор(валидационная часть): 1.6625\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4309 - val_loss: 1.7485 - lr: 1.2500e-04\n",
      "Epoch 56/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4183Текущий реальный скор(валидационная часть): 1.6624\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4260 - val_loss: 1.7489 - lr: 1.2500e-04\n",
      "Epoch 57/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4197Текущий реальный скор(валидационная часть): 1.6649\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 1.7535 - lr: 1.2500e-04\n",
      "Epoch 58/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4096Текущий реальный скор(валидационная часть): 1.6659\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4165 - val_loss: 1.7538 - lr: 1.2500e-04\n",
      "Epoch 59/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4374Текущий реальный скор(валидационная часть): 1.6504\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4425 - val_loss: 1.7365 - lr: 6.2500e-05\n",
      "Epoch 60/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4317Текущий реальный скор(валидационная часть): 1.6425\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4325 - val_loss: 1.7248 - lr: 6.2500e-05\n",
      "Epoch 61/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4236Текущий реальный скор(валидационная часть): 1.6377\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 1.7190 - lr: 6.2500e-05\n",
      "Epoch 62/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4148Текущий реальный скор(валидационная часть): 1.6369\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 1.7175 - lr: 6.2500e-05\n",
      "Epoch 63/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4098Текущий реальный скор(валидационная часть): 1.6389\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 1.7188 - lr: 6.2500e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4027Текущий реальный скор(валидационная часть): 1.6403\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4096 - val_loss: 1.7197 - lr: 6.2500e-05\n",
      "Epoch 65/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4009Текущий реальный скор(валидационная часть): 1.6419\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 1.7205 - lr: 6.2500e-05\n",
      "Epoch 66/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3920Текущий реальный скор(валидационная часть): 1.6448\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 1.7229 - lr: 6.2500e-05\n",
      "Epoch 67/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3928Текущий реальный скор(валидационная часть): 1.6472\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3980 - val_loss: 1.7245 - lr: 6.2500e-05\n",
      "Epoch 68/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.3914Текущий реальный скор(валидационная часть): 1.6493\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 1.7232 - lr: 6.2500e-05\n",
      "Epoch 69/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3979Текущий реальный скор(валидационная часть): 1.6784\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4046 - val_loss: 1.7438 - lr: 3.1250e-05\n",
      "Epoch 70/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3984Текущий реальный скор(валидационная часть): 1.6807\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 1.7458 - lr: 3.1250e-05\n",
      "Epoch 71/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3894Текущий реальный скор(валидационная часть): 1.6842\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3954 - val_loss: 1.7490 - lr: 3.1250e-05\n",
      "Epoch 72/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.3885Текущий реальный скор(валидационная часть): 1.6867\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 1.7513 - lr: 3.1250e-05\n",
      "Epoch 73/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.3831Текущий реальный скор(валидационная часть): 1.6888\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 1.7532 - lr: 3.1250e-05\n",
      "Epoch 74/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3816Текущий реальный скор(валидационная часть): 1.69\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 1.7544 - lr: 3.1250e-05\n",
      "Epoch 75/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3758Текущий реальный скор(валидационная часть): 1.6918\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 1.7563 - lr: 3.1250e-05\n",
      "Epoch 76/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.3781Текущий реальный скор(валидационная часть): 1.6926\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 1.7570 - lr: 3.1250e-05\n",
      "Epoch 77/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3754Текущий реальный скор(валидационная часть): 1.6931\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 1.7571 - lr: 3.1250e-05\n",
      "Epoch 78/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.3717Текущий реальный скор(валидационная часть): 1.6945\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 1.7613 - lr: 3.1250e-05\n",
      "Epoch 79/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.3801Текущий реальный скор(валидационная часть): 1.6904\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 1.7594 - lr: 1.5625e-05\n",
      "Epoch 80/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3800Текущий реальный скор(валидационная часть): 1.6903\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 1.7596 - lr: 1.5625e-05\n",
      "Epoch 81/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.3787Текущий реальный скор(валидационная часть): 1.6902\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3787 - val_loss: 1.7599 - lr: 1.5625e-05\n",
      "Epoch 82/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3687Текущий реальный скор(валидационная часть): 1.69\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 1.7600 - lr: 1.5625e-05\n",
      "Epoch 83/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3764Текущий реальный скор(валидационная часть): 1.6899\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 1.7602 - lr: 1.5625e-05\n",
      "Epoch 84/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.3685Текущий реальный скор(валидационная часть): 1.6903\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 1.7609 - lr: 1.5625e-05\n",
      "Epoch 85/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.3727Текущий реальный скор(валидационная часть): 1.6897\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 1.7604 - lr: 1.5625e-05\n",
      "Epoch 86/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.3717Текущий реальный скор(валидационная часть): 1.6905\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 1.7614 - lr: 1.5625e-05\n",
      "Epoch 87/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3657Текущий реальный скор(валидационная часть): 1.6906\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 1.7616 - lr: 1.5625e-05\n",
      "Epoch 88/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3703Текущий реальный скор(валидационная часть): 1.6908\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 1.7618 - lr: 1.5625e-05\n",
      "Epoch 89/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3711Текущий реальный скор(валидационная часть): 1.6833\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 1.7552 - lr: 7.8125e-06\n",
      "Epoch 90/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.3727Текущий реальный скор(валидационная часть): 1.6849\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 1.7568 - lr: 7.8125e-06\n",
      "Epoch 91/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3698Текущий реальный скор(валидационная часть): 1.6862\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 1.7581 - lr: 7.8125e-06\n",
      "Epoch 92/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3713Текущий реальный скор(валидационная часть): 1.6872\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 1.7591 - lr: 7.8125e-06\n",
      "Epoch 93/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.3702Текущий реальный скор(валидационная часть): 1.688\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 1.7599 - lr: 7.8125e-06\n",
      "Epoch 94/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.3699Текущий реальный скор(валидационная часть): 1.6891\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 1.7609 - lr: 7.8125e-06\n",
      "Epoch 95/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3678Текущий реальный скор(валидационная часть): 1.6901\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3729 - val_loss: 1.7619 - lr: 7.8125e-06\n",
      "Epoch 96/500\n",
      "105/134 [======================>.......] - ETA: 0s - loss: 0.3623Текущий реальный скор(валидационная часть): 1.6908\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 1.7626 - lr: 7.8125e-06\n",
      "Epoch 97/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3705Текущий реальный скор(валидационная часть): 1.6918\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 1.7636 - lr: 7.8125e-06\n",
      "Epoch 98/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3712Текущий реальный скор(валидационная часть): 1.6926\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 1.7643 - lr: 7.8125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.3684Текущий реальный скор(валидационная часть): 1.7003\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 1.7723 - lr: 3.9063e-06\n",
      "Epoch 100/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3620Текущий реальный скор(валидационная часть): 1.7011\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 1.7730 - lr: 3.9063e-06\n",
      "Epoch 101/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3670Текущий реальный скор(валидационная часть): 1.7015\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 1.7733 - lr: 3.9063e-06\n",
      "Epoch 102/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3648Текущий реальный скор(валидационная часть): 1.7019\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 1.7737 - lr: 3.9063e-06\n",
      "Epoch 103/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3686Текущий реальный скор(валидационная часть): 1.7023\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 1.7740 - lr: 3.9063e-06\n",
      "Epoch 104/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.3657Текущий реальный скор(валидационная часть): 1.7027\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 1.7744 - lr: 3.9063e-06\n",
      "Epoch 105/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3647Текущий реальный скор(валидационная часть): 1.703\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 1.7747 - lr: 3.9063e-06\n",
      "Epoch 106/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.3650Текущий реальный скор(валидационная часть): 1.7033\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 1.7750 - lr: 3.9063e-06\n",
      "Epoch 107/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3660Текущий реальный скор(валидационная часть): 1.7035\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 1.7752 - lr: 3.9063e-06\n",
      "Epoch 108/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.3648Текущий реальный скор(валидационная часть): 1.7039\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 1.7755 - lr: 3.9063e-06\n",
      "Epoch 109/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3621Текущий реальный скор(валидационная часть): 1.7091\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3680 - val_loss: 1.7795 - lr: 1.9531e-06\n",
      "Epoch 110/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3655Текущий реальный скор(валидационная часть): 1.7104\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 1.7806 - lr: 1.9531e-06\n",
      "Epoch 111/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3602Текущий реальный скор(валидационная часть): 1.7109\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 1.7810 - lr: 1.9531e-06\n",
      "Epoch 112/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.3600Текущий реальный скор(валидационная часть): 1.7111\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3662 - val_loss: 1.7812 - lr: 1.9531e-06\n",
      "Epoch 113/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.3604Текущий реальный скор(валидационная часть): 1.7113\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3660 - val_loss: 1.7813 - lr: 1.9531e-06\n",
      "Epoch 114/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3596Текущий реальный скор(валидационная часть): 1.7116\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 1.7816 - lr: 1.9531e-06\n",
      "Epoch 115/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.3617Текущий реальный скор(валидационная часть): 1.7118\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3657 - val_loss: 1.7817 - lr: 1.9531e-06\n",
      "Epoch 116/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.3599Текущий реальный скор(валидационная часть): 1.712\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 1.7819 - lr: 1.9531e-06\n",
      "Epoch 117/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.3583Текущий реальный скор(валидационная часть): 1.7122\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3654 - val_loss: 1.7821 - lr: 1.9531e-06\n",
      "Epoch 118/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3618Текущий реальный скор(валидационная часть): 1.7124\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 1.7823 - lr: 1.9531e-06\n",
      "Epoch 119/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.3573Текущий реальный скор(валидационная часть): 1.7143\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3646 - val_loss: 1.7839 - lr: 9.7656e-07\n",
      "Epoch 120/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.3583Текущий реальный скор(валидационная часть): 1.7153\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3643 - val_loss: 1.7847 - lr: 9.7656e-07\n",
      "Epoch 121/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.3559Текущий реальный скор(валидационная часть): 1.7158\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3641 - val_loss: 1.7851 - lr: 9.7656e-07\n",
      "Epoch 122/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.3602Текущий реальный скор(валидационная часть): 1.716\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3640 - val_loss: 1.7854 - lr: 9.7656e-07\n",
      "Epoch 123/500\n",
      "105/134 [======================>.......] - ETA: 0s - loss: 0.3525Текущий реальный скор(валидационная часть): 1.7163\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3639 - val_loss: 1.7855 - lr: 9.7656e-07\n",
      "Epoch 124/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3534Текущий реальный скор(валидационная часть): 1.7164\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3638 - val_loss: 1.7857 - lr: 9.7656e-07\n",
      "Epoch 125/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.3554Текущий реальный скор(валидационная часть): 1.7165\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3638 - val_loss: 1.7858 - lr: 9.7656e-07\n",
      "Epoch 126/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3637Текущий реальный скор(валидационная часть): 1.7167\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 1.7859 - lr: 9.7656e-07\n",
      "Epoch 127/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.3601Текущий реальный скор(валидационная часть): 1.7168\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3636 - val_loss: 1.7860 - lr: 9.7656e-07\n",
      "Epoch 128/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3594Текущий реальный скор(валидационная часть): 1.6129\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3636 - val_loss: 1.7861 - lr: 9.7656e-07\n",
      "Скор для фолда(5) : 1.6129 средний скор на префиксе = 1.3714 это заняло = 35 сек.\n",
      "Фолд: 6\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 4.1045Текущий реальный скор(валидационная часть): 2.0119\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8013 - val_loss: 2.0912 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 2.0291Текущий реальный скор(валидационная часть): 1.4918\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9699 - val_loss: 1.5625 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.6594Текущий реальный скор(валидационная часть): 1.3408\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6586 - val_loss: 1.4201 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.5145Текущий реальный скор(валидационная часть): 1.2806\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5078 - val_loss: 1.3782 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.4263Текущий реальный скор(валидационная часть): 1.221\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.3259 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.3572Текущий реальный скор(валидационная часть): 1.1951\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3569 - val_loss: 1.2994 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.3004Текущий реальный скор(валидационная часть): 1.1753\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2997 - val_loss: 1.2827 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 1.2413Текущий реальный скор(валидационная часть): 1.1494\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2468 - val_loss: 1.2534 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 1.1956Текущий реальный скор(валидационная часть): 1.1354\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1941 - val_loss: 1.2421 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.1449Текущий реальный скор(валидационная часть): 1.1358\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1483 - val_loss: 1.2472 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1104Текущий реальный скор(валидационная часть): 1.1189\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1104 - val_loss: 1.2184 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 1.1096Текущий реальный скор(валидационная часть): 1.1452\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1023 - val_loss: 1.2222 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 1.0600Текущий реальный скор(валидационная часть): 1.3021\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0751 - val_loss: 1.3663 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 1.0630Текущий реальный скор(валидационная часть): 1.1422\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0625 - val_loss: 1.2431 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 1.0423Текущий реальный скор(валидационная часть): 1.1726\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0476 - val_loss: 1.2779 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "105/134 [======================>.......] - ETA: 0s - loss: 0.9974Текущий реальный скор(валидационная часть): 1.1229\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0142 - val_loss: 1.2313 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.9942Текущий реальный скор(валидационная часть): 1.0971\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 1.1880 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.9476Текущий реальный скор(валидационная часть): 1.2125\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9528 - val_loss: 1.2839 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.9355Текущий реальный скор(валидационная часть): 1.2808\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9353 - val_loss: 1.3454 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.9346Текущий реальный скор(валидационная часть): 1.2701\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9346 - val_loss: 1.3433 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.9407Текущий реальный скор(валидационная часть): 1.289\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9383 - val_loss: 1.3605 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.9574Текущий реальный скор(валидационная часть): 1.3954\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9525 - val_loss: 1.4544 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.0751Текущий реальный скор(валидационная часть): 1.2529\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0751 - val_loss: 1.3473 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.0492Текущий реальный скор(валидационная часть): 1.2998\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0237 - val_loss: 1.3839 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.9018Текущий реальный скор(валидационная часть): 1.2882\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9011 - val_loss: 1.3739 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.8513Текущий реальный скор(валидационная часть): 1.2987\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8370 - val_loss: 1.3762 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.8060Текущий реальный скор(валидационная часть): 1.3176\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7949 - val_loss: 1.3885 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.7634Текущий реальный скор(валидационная часть): 1.3646\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7638 - val_loss: 1.4389 - lr: 2.5000e-04\n",
      "Epoch 29/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.7433Текущий реальный скор(валидационная часть): 1.2543\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7328 - val_loss: 1.3316 - lr: 2.5000e-04\n",
      "Epoch 30/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.7062Текущий реальный скор(валидационная часть): 1.2495\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6951 - val_loss: 1.3270 - lr: 2.5000e-04\n",
      "Epoch 31/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.6704Текущий реальный скор(валидационная часть): 1.2577\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6656 - val_loss: 1.3348 - lr: 2.5000e-04\n",
      "Epoch 32/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/134 [============================>.] - ETA: 0s - loss: 0.6398Текущий реальный скор(валидационная часть): 1.2481\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6423 - val_loss: 1.3287 - lr: 2.5000e-04\n",
      "Epoch 33/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.6233Текущий реальный скор(валидационная часть): 1.1998\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 1.2863 - lr: 2.5000e-04\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6483Текущий реальный скор(валидационная часть): 1.2092\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6483 - val_loss: 1.2969 - lr: 2.5000e-04\n",
      "Epoch 35/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.6047Текущий реальный скор(валидационная часть): 1.2106\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 1.2945 - lr: 2.5000e-04\n",
      "Epoch 36/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5877Текущий реальный скор(валидационная часть): 1.1931\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5885 - val_loss: 1.2788 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.5737Текущий реальный скор(валидационная часть): 1.2042\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5772 - val_loss: 1.2928 - lr: 2.5000e-04\n",
      "Epoch 38/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.6135Текущий реальный скор(валидационная часть): 1.2626\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6139 - val_loss: 1.3409 - lr: 1.2500e-04\n",
      "Epoch 39/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5846Текущий реальный скор(валидационная часть): 1.255\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5847 - val_loss: 1.3358 - lr: 1.2500e-04\n",
      "Epoch 40/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5612Текущий реальный скор(валидационная часть): 1.2422\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5657 - val_loss: 1.3213 - lr: 1.2500e-04\n",
      "Epoch 41/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.5492Текущий реальный скор(валидационная часть): 1.2327\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5529 - val_loss: 1.3128 - lr: 1.2500e-04\n",
      "Epoch 42/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5379Текущий реальный скор(валидационная часть): 1.2248\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5436 - val_loss: 1.3063 - lr: 1.2500e-04\n",
      "Epoch 43/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5347Текущий реальный скор(валидационная часть): 1.2233\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 1.3063 - lr: 1.2500e-04\n",
      "Epoch 44/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5234Текущий реальный скор(валидационная часть): 1.2187\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.3038 - lr: 1.2500e-04\n",
      "Epoch 45/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.5172Текущий реальный скор(валидационная часть): 1.2153\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5194 - val_loss: 1.3026 - lr: 1.2500e-04\n",
      "Epoch 46/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5120Текущий реальный скор(валидационная часть): 1.2099\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5129 - val_loss: 1.2991 - lr: 1.2500e-04\n",
      "Epoch 47/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5016Текущий реальный скор(валидационная часть): 1.2062\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5068 - val_loss: 1.2970 - lr: 1.2500e-04\n",
      "Epoch 48/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5093Текущий реальный скор(валидационная часть): 1.1121\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 1.2081 - lr: 6.2500e-05\n",
      "Epoch 49/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5075Текущий реальный скор(валидационная часть): 1.104\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5171 - val_loss: 1.1984 - lr: 6.2500e-05\n",
      "Epoch 50/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5077Текущий реальный скор(валидационная часть): 1.0997\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5091 - val_loss: 1.1944 - lr: 6.2500e-05\n",
      "Epoch 51/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4949Текущий реальный скор(валидационная часть): 1.0981\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5028 - val_loss: 1.1926 - lr: 6.2500e-05\n",
      "Epoch 52/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4963Текущий реальный скор(валидационная часть): 1.0963\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4976 - val_loss: 1.1913 - lr: 6.2500e-05\n",
      "Epoch 53/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4874Текущий реальный скор(валидационная часть): 1.0976\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4930 - val_loss: 1.1949 - lr: 6.2500e-05\n",
      "Epoch 54/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4843Текущий реальный скор(валидационная часть): 1.0973\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 1.1950 - lr: 6.2500e-05\n",
      "Epoch 55/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4736Текущий реальный скор(валидационная часть): 1.0964\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 1.1953 - lr: 6.2500e-05\n",
      "Epoch 56/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4691Текущий реальный скор(валидационная часть): 1.0967\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 1.1965 - lr: 6.2500e-05\n",
      "Epoch 57/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4745Текущий реальный скор(валидационная часть): 1.0974\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 1.1974 - lr: 6.2500e-05\n",
      "Epoch 58/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4713Текущий реальный скор(валидационная часть): 1.1006\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4795 - val_loss: 1.2008 - lr: 3.1250e-05\n",
      "Epoch 59/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4723Текущий реальный скор(валидационная часть): 1.1032\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 1.2063 - lr: 3.1250e-05\n",
      "Epoch 60/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4689Текущий реальный скор(валидационная часть): 1.1036\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 1.2042 - lr: 3.1250e-05\n",
      "Epoch 61/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4637Текущий реальный скор(валидационная часть): 1.1041\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 1.2046 - lr: 3.1250e-05\n",
      "Epoch 62/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4566Текущий реальный скор(валидационная часть): 1.1042\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 1.2076 - lr: 3.1250e-05\n",
      "Epoch 63/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4495Текущий реальный скор(валидационная часть): 1.1043\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 1.2077 - lr: 3.1250e-05\n",
      "Epoch 64/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4459Текущий реальный скор(валидационная часть): 1.1043\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 1.2075 - lr: 3.1250e-05\n",
      "Epoch 65/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4494Текущий реальный скор(валидационная часть): 1.1045\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 1.2078 - lr: 3.1250e-05\n",
      "Epoch 66/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4516Текущий реальный скор(валидационная часть): 1.105\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 1.2082 - lr: 3.1250e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4404Текущий реальный скор(валидационная часть): 1.1056\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 1.2087 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4475Текущий реальный скор(валидационная часть): 1.1123\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 1.2161 - lr: 1.5625e-05\n",
      "Epoch 69/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4376Текущий реальный скор(валидационная часть): 1.1114\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4477 - val_loss: 1.2152 - lr: 1.5625e-05\n",
      "Epoch 70/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4452Текущий реальный скор(валидационная часть): 1.111\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4463 - val_loss: 1.2150 - lr: 1.5625e-05\n",
      "Epoch 71/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4357Текущий реальный скор(валидационная часть): 1.1105\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4451 - val_loss: 1.2145 - lr: 1.5625e-05\n",
      "Epoch 72/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4410Текущий реальный скор(валидационная часть): 1.1099\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4440 - val_loss: 1.2139 - lr: 1.5625e-05\n",
      "Epoch 73/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4368Текущий реальный скор(валидационная часть): 1.1096\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4431 - val_loss: 1.2135 - lr: 1.5625e-05\n",
      "Epoch 74/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4410Текущий реальный скор(валидационная часть): 1.1095\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4420 - val_loss: 1.2132 - lr: 1.5625e-05\n",
      "Epoch 75/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4298Текущий реальный скор(валидационная часть): 1.1092\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 1.2129 - lr: 1.5625e-05\n",
      "Epoch 76/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4302Текущий реальный скор(валидационная часть): 1.1094\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 1.2131 - lr: 1.5625e-05\n",
      "Epoch 77/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4381Текущий реальный скор(валидационная часть): 1.1091\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 1.2128 - lr: 1.5625e-05\n",
      "Epoch 78/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4306Текущий реальный скор(валидационная часть): 1.1031\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4399 - val_loss: 1.2069 - lr: 7.8125e-06\n",
      "Epoch 79/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4295Текущий реальный скор(валидационная часть): 1.1032\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4391 - val_loss: 1.2070 - lr: 7.8125e-06\n",
      "Epoch 80/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4278Текущий реальный скор(валидационная часть): 1.1033\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 1.2070 - lr: 7.8125e-06\n",
      "Epoch 81/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4369Текущий реальный скор(валидационная часть): 1.1036\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 1.2073 - lr: 7.8125e-06\n",
      "Epoch 82/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4276Текущий реальный скор(валидационная часть): 1.1037\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 1.2076 - lr: 7.8125e-06\n",
      "Epoch 83/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4270Текущий реальный скор(валидационная часть): 1.104\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4368 - val_loss: 1.2078 - lr: 7.8125e-06\n",
      "Epoch 84/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4265Текущий реальный скор(валидационная часть): 1.1043\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 1.2081 - lr: 7.8125e-06\n",
      "Epoch 85/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4262Текущий реальный скор(валидационная часть): 1.1043\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 1.2081 - lr: 7.8125e-06\n",
      "Epoch 86/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4257Текущий реальный скор(валидационная часть): 1.1044\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 1.2082 - lr: 7.8125e-06\n",
      "Epoch 87/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4326Текущий реальный скор(валидационная часть): 1.1046\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 1.2083 - lr: 7.8125e-06\n",
      "Epoch 88/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4310Текущий реальный скор(валидационная часть): 1.1137\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 1.2174 - lr: 3.9063e-06\n",
      "Epoch 89/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4256Текущий реальный скор(валидационная часть): 1.1141\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4351 - val_loss: 1.2176 - lr: 3.9063e-06\n",
      "Epoch 90/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4303Текущий реальный скор(валидационная часть): 1.1143\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 1.2177 - lr: 3.9063e-06\n",
      "Epoch 91/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4183Текущий реальный скор(валидационная часть): 1.1145\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4344 - val_loss: 1.2179 - lr: 3.9063e-06\n",
      "Epoch 92/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4341Текущий реальный скор(валидационная часть): 1.1146\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 1.2180 - lr: 3.9063e-06\n",
      "Epoch 93/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4302Текущий реальный скор(валидационная часть): 1.1148\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4338 - val_loss: 1.2182 - lr: 3.9063e-06\n",
      "Epoch 94/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4324Текущий реальный скор(валидационная часть): 1.1149\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4335 - val_loss: 1.2182 - lr: 3.9063e-06\n",
      "Epoch 95/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4229Текущий реальный скор(валидационная часть): 1.115\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4332 - val_loss: 1.2183 - lr: 3.9063e-06\n",
      "Epoch 96/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4329Текущий реальный скор(валидационная часть): 1.1151\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4329 - val_loss: 1.2184 - lr: 3.9063e-06\n",
      "Epoch 97/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4291Текущий реальный скор(валидационная часть): 1.1153\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4327 - val_loss: 1.2186 - lr: 3.9063e-06\n",
      "Epoch 98/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4226Текущий реальный скор(валидационная часть): 1.1251\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 1.2245 - lr: 1.9531e-06\n",
      "Epoch 99/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4261Текущий реальный скор(валидационная часть): 1.1262\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4317 - val_loss: 1.2253 - lr: 1.9531e-06\n",
      "Epoch 100/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4258Текущий реальный скор(валидационная часть): 1.1264\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4315 - val_loss: 1.2254 - lr: 1.9531e-06\n",
      "Epoch 101/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4256Текущий реальный скор(валидационная часть): 1.1264\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4313 - val_loss: 1.2255 - lr: 1.9531e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4186Текущий реальный скор(валидационная часть): 1.1265\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4312 - val_loss: 1.2255 - lr: 1.9531e-06\n",
      "Epoch 103/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4201Текущий реальный скор(валидационная часть): 1.1266\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 1.2256 - lr: 1.9531e-06\n",
      "Epoch 104/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4183Текущий реальный скор(валидационная часть): 1.1266\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4309 - val_loss: 1.2256 - lr: 1.9531e-06\n",
      "Epoch 105/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4296Текущий реальный скор(валидационная часть): 1.1266\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 1.2256 - lr: 1.9531e-06\n",
      "Epoch 106/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4286Текущий реальный скор(валидационная часть): 1.1266\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 1.2256 - lr: 1.9531e-06\n",
      "Epoch 107/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4135Текущий реальный скор(валидационная часть): 1.1267\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4305 - val_loss: 1.2257 - lr: 1.9531e-06\n",
      "Epoch 108/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4192Текущий реальный скор(валидационная часть): 1.1305\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4302 - val_loss: 1.2282 - lr: 9.7656e-07\n",
      "Epoch 109/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4215Текущий реальный скор(валидационная часть): 1.1318\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4298 - val_loss: 1.2291 - lr: 9.7656e-07\n",
      "Epoch 110/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4285Текущий реальный скор(валидационная часть): 1.1322\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4296 - val_loss: 1.2295 - lr: 9.7656e-07\n",
      "Epoch 111/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4182Текущий реальный скор(валидационная часть): 1.1324\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4296 - val_loss: 1.2296 - lr: 9.7656e-07\n",
      "Epoch 112/500\n",
      "105/134 [======================>.......] - ETA: 0s - loss: 0.4099Текущий реальный скор(валидационная часть): 1.1325\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 1.2296 - lr: 9.7656e-07\n",
      "Epoch 113/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4172Текущий реальный скор(валидационная часть): 1.1325\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4294 - val_loss: 1.2296 - lr: 9.7656e-07\n",
      "Epoch 114/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4263Текущий реальный скор(валидационная часть): 1.1325\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 1.2296 - lr: 9.7656e-07\n",
      "Epoch 115/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4164Текущий реальный скор(валидационная часть): 1.1326\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 1.2296 - lr: 9.7656e-07\n",
      "Epoch 116/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4208Текущий реальный скор(валидационная часть): 1.1326\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4292 - val_loss: 1.2296 - lr: 9.7656e-07\n",
      "Epoch 117/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4234Текущий реальный скор(валидационная часть): 1.0971\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4292 - val_loss: 1.2296 - lr: 9.7656e-07\n",
      "Скор для фолда(6) : 1.0971 средний скор на префиксе = 1.3322 это заняло = 32 сек.\n",
      "Фолд: 7\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 4.0946Текущий реальный скор(валидационная часть): 2.5468\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8153 - val_loss: 2.6279 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 2.0264Текущий реальный скор(валидационная часть): 1.6849\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9571 - val_loss: 1.7718 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 1.6782Текущий реальный скор(валидационная часть): 1.5681\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6594 - val_loss: 1.6419 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 1.5020Текущий реальный скор(валидационная часть): 1.472\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5003 - val_loss: 1.5569 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 1.4211Текущий реальный скор(валидационная часть): 1.4276\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 1.5119 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.3462Текущий реальный скор(валидационная часть): 1.4471\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3462 - val_loss: 1.5427 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.2754Текущий реальный скор(валидационная часть): 1.4513\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2801 - val_loss: 1.5415 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 1.2249Текущий реальный скор(валидационная часть): 1.5048\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2361 - val_loss: 1.5897 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.1844Текущий реальный скор(валидационная часть): 1.5491\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1844 - val_loss: 1.6386 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 1.1409Текущий реальный скор(валидационная часть): 1.5415\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1507 - val_loss: 1.6235 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.1274Текущий реальный скор(валидационная часть): 1.4397\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1300 - val_loss: 1.5100 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 1.1005Текущий реальный скор(валидационная часть): 1.4494\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1006 - val_loss: 1.5445 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.0827Текущий реальный скор(валидационная часть): 1.4496\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0813 - val_loss: 1.5380 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.0204Текущий реальный скор(валидационная часть): 1.4601\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0199 - val_loss: 1.5353 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.9753Текущий реальный скор(валидационная часть): 1.4693\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9746 - val_loss: 1.5308 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.9404Текущий реальный скор(валидационная часть): 1.4076\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9579 - val_loss: 1.4847 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.9218Текущий реальный скор(валидационная часть): 1.4197\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 1.5119 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.9152Текущий реальный скор(валидационная часть): 1.3954\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9152 - val_loss: 1.4890 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.9010Текущий реальный скор(валидационная часть): 1.4233\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9010 - val_loss: 1.5016 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.9207Текущий реальный скор(валидационная часть): 1.7512\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9283 - val_loss: 1.8201 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.9596Текущий реальный скор(валидационная часть): 1.8275\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9595 - val_loss: 1.9200 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.0092Текущий реальный скор(валидационная часть): 1.5844\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0091 - val_loss: 1.6804 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.9300Текущий реальный скор(валидационная часть): 1.5132\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9156 - val_loss: 1.6035 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.8119Текущий реальный скор(валидационная часть): 1.5312\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8122 - val_loss: 1.6285 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.7860Текущий реальный скор(валидационная часть): 1.5731\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7876 - val_loss: 1.6726 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.7521Текущий реальный скор(валидационная часть): 1.5057\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7545 - val_loss: 1.5866 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.8944Текущий реальный скор(валидационная часть): 1.6486\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8945 - val_loss: 1.7448 - lr: 2.5000e-04\n",
      "Epoch 28/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.8160Текущий реальный скор(валидационная часть): 1.612\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8098 - val_loss: 1.6990 - lr: 2.5000e-04\n",
      "Epoch 29/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.7607Текущий реальный скор(валидационная часть): 1.5805\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7611 - val_loss: 1.6802 - lr: 2.5000e-04\n",
      "Epoch 30/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.7191Текущий реальный скор(валидационная часть): 1.5658\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7269 - val_loss: 1.6723 - lr: 2.5000e-04\n",
      "Epoch 31/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.7048Текущий реальный скор(валидационная часть): 1.5406\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7048 - val_loss: 1.6471 - lr: 2.5000e-04\n",
      "Epoch 32/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.6748Текущий реальный скор(валидационная часть): 1.5202\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 1.6270 - lr: 2.5000e-04\n",
      "Epoch 33/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.6604Текущий реальный скор(валидационная часть): 1.4885\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6589 - val_loss: 1.5910 - lr: 2.5000e-04\n",
      "Epoch 34/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.6369Текущий реальный скор(валидационная часть): 1.4638\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6417 - val_loss: 1.5636 - lr: 2.5000e-04\n",
      "Epoch 35/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.6235Текущий реальный скор(валидационная часть): 1.4472\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6261 - val_loss: 1.5432 - lr: 2.5000e-04\n",
      "Epoch 36/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.6150Текущий реальный скор(валидационная часть): 1.4128\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6182 - val_loss: 1.5089 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.6357Текущий реальный скор(валидационная часть): 1.3867\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 1.4901 - lr: 1.2500e-04\n",
      "Epoch 38/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5936Текущий реальный скор(валидационная часть): 1.3918\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5894 - val_loss: 1.4957 - lr: 1.2500e-04\n",
      "Epoch 39/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5677Текущий реальный скор(валидационная часть): 1.4027\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5706 - val_loss: 1.5075 - lr: 1.2500e-04\n",
      "Epoch 40/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.5531Текущий реальный скор(валидационная часть): 1.4127\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5569 - val_loss: 1.5200 - lr: 1.2500e-04\n",
      "Epoch 41/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5397Текущий реальный скор(валидационная часть): 1.4175\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5452 - val_loss: 1.5247 - lr: 1.2500e-04\n",
      "Epoch 42/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5324Текущий реальный скор(валидационная часть): 1.4209\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 1.5281 - lr: 1.2500e-04\n",
      "Epoch 43/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5191Текущий реальный скор(валидационная часть): 1.4255\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 1.5324 - lr: 1.2500e-04\n",
      "Epoch 44/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5106Текущий реальный скор(валидационная часть): 1.4297\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5200 - val_loss: 1.5368 - lr: 1.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "105/134 [======================>.......] - ETA: 0s - loss: 0.4966Текущий реальный скор(валидационная часть): 1.433\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5130 - val_loss: 1.5400 - lr: 1.2500e-04\n",
      "Epoch 46/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4965Текущий реальный скор(валидационная часть): 1.4374\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5068 - val_loss: 1.5439 - lr: 1.2500e-04\n",
      "Epoch 47/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4990Текущий реальный скор(валидационная часть): 1.394\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5202 - val_loss: 1.4900 - lr: 6.2500e-05\n",
      "Epoch 48/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4992Текущий реальный скор(валидационная часть): 1.3892\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 1.4801 - lr: 6.2500e-05\n",
      "Epoch 49/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4952Текущий реальный скор(валидационная часть): 1.3856\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5066 - val_loss: 1.4733 - lr: 6.2500e-05\n",
      "Epoch 50/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4846Текущий реальный скор(валидационная часть): 1.3823\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4999 - val_loss: 1.4698 - lr: 6.2500e-05\n",
      "Epoch 51/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4930Текущий реальный скор(валидационная часть): 1.3779\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4940 - val_loss: 1.4632 - lr: 6.2500e-05\n",
      "Epoch 52/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4742Текущий реальный скор(валидационная часть): 1.377\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 1.4622 - lr: 6.2500e-05\n",
      "Epoch 53/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4836Текущий реальный скор(валидационная часть): 1.3772\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 1.4624 - lr: 6.2500e-05\n",
      "Epoch 54/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4788Текущий реальный скор(валидационная часть): 1.3787\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 1.4636 - lr: 6.2500e-05\n",
      "Epoch 55/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4639Текущий реальный скор(валидационная часть): 1.3784\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 1.4630 - lr: 6.2500e-05\n",
      "Epoch 56/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4684Текущий реальный скор(валидационная часть): 1.379\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4721 - val_loss: 1.4639 - lr: 6.2500e-05\n",
      "Epoch 57/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4649Текущий реальный скор(валидационная часть): 1.3799\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4686 - val_loss: 1.4647 - lr: 6.2500e-05\n",
      "Epoch 58/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4613Текущий реальный скор(валидационная часть): 1.3805\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 1.4652 - lr: 6.2500e-05\n",
      "Epoch 59/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4490Текущий реальный скор(валидационная часть): 1.3812\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 1.4657 - lr: 6.2500e-05\n",
      "Epoch 60/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4568Текущий реальный скор(валидационная часть): 1.3807\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 1.4655 - lr: 6.2500e-05\n",
      "Epoch 61/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4479Текущий реальный скор(валидационная часть): 1.3814\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4566 - val_loss: 1.4655 - lr: 6.2500e-05\n",
      "Epoch 62/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4501Текущий реальный скор(валидационная часть): 1.3812\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 1.4657 - lr: 6.2500e-05\n",
      "Epoch 63/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4538Текущий реальный скор(валидационная часть): 1.3824\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 1.4651 - lr: 3.1250e-05\n",
      "Epoch 64/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4453Текущий реальный скор(валидационная часть): 1.3878\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 1.4698 - lr: 3.1250e-05\n",
      "Epoch 65/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4519Текущий реальный скор(валидационная часть): 1.3915\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 1.4728 - lr: 3.1250e-05\n",
      "Epoch 66/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4438Текущий реальный скор(валидационная часть): 1.3948\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4518 - val_loss: 1.4786 - lr: 3.1250e-05\n",
      "Epoch 67/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4359Текущий реальный скор(валидационная часть): 1.3967\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4496 - val_loss: 1.4806 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4416Текущий реальный скор(валидационная часть): 1.3979\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 1.4816 - lr: 3.1250e-05\n",
      "Epoch 69/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4358Текущий реальный скор(валидационная часть): 1.4001\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4457 - val_loss: 1.4839 - lr: 3.1250e-05\n",
      "Epoch 70/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4375Текущий реальный скор(валидационная часть): 1.4016\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4440 - val_loss: 1.4851 - lr: 3.1250e-05\n",
      "Epoch 71/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4388Текущий реальный скор(валидационная часть): 1.4031\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4423 - val_loss: 1.4867 - lr: 3.1250e-05\n",
      "Epoch 72/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4317Текущий реальный скор(валидационная часть): 1.404\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4406 - val_loss: 1.4877 - lr: 3.1250e-05\n",
      "Epoch 73/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4367Текущий реальный скор(валидационная часть): 1.4316\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4444 - val_loss: 1.5194 - lr: 1.5625e-05\n",
      "Epoch 74/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4454Текущий реальный скор(валидационная часть): 1.4288\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4426 - val_loss: 1.5170 - lr: 1.5625e-05\n",
      "Epoch 75/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4334Текущий реальный скор(валидационная часть): 1.4271\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 1.5155 - lr: 1.5625e-05\n",
      "Epoch 76/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4364Текущий реальный скор(валидационная часть): 1.4261\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 1.5144 - lr: 1.5625e-05\n",
      "Epoch 77/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4346Текущий реальный скор(валидационная часть): 1.425\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4389 - val_loss: 1.5135 - lr: 1.5625e-05\n",
      "Epoch 78/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4336Текущий реальный скор(валидационная часть): 1.424\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 1.5124 - lr: 1.5625e-05\n",
      "Epoch 79/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4281Текущий реальный скор(валидационная часть): 1.4237\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4368 - val_loss: 1.5122 - lr: 1.5625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4268Текущий реальный скор(валидационная часть): 1.4228\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 1.5114 - lr: 1.5625e-05\n",
      "Epoch 81/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4258Текущий реальный скор(валидационная часть): 1.4223\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 1.5111 - lr: 1.5625e-05\n",
      "Epoch 82/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4229Текущий реальный скор(валидационная часть): 1.422\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 1.5106 - lr: 1.5625e-05\n",
      "Epoch 83/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4352Текущий реальный скор(валидационная часть): 1.4079\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 1.4936 - lr: 7.8125e-06\n",
      "Epoch 84/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4348Текущий реальный скор(валидационная часть): 1.4075\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 1.4930 - lr: 7.8125e-06\n",
      "Epoch 85/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4293Текущий реальный скор(валидационная часть): 1.4077\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 1.4933 - lr: 7.8125e-06\n",
      "Epoch 86/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4313Текущий реальный скор(валидационная часть): 1.4083\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 1.4937 - lr: 7.8125e-06\n",
      "Epoch 87/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4328Текущий реальный скор(валидационная часть): 1.4088\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4364 - val_loss: 1.4942 - lr: 7.8125e-06\n",
      "Epoch 88/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4277Текущий реальный скор(валидационная часть): 1.4094\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 1.4948 - lr: 7.8125e-06\n",
      "Epoch 89/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4345Текущий реальный скор(валидационная часть): 1.4096\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 1.4951 - lr: 7.8125e-06\n",
      "Epoch 90/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4283Текущий реальный скор(валидационная часть): 1.4101\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 1.4955 - lr: 7.8125e-06\n",
      "Epoch 91/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4325Текущий реальный скор(валидационная часть): 1.4104\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4342 - val_loss: 1.4959 - lr: 7.8125e-06\n",
      "Epoch 92/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4273Текущий реальный скор(валидационная часть): 1.4108\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4337 - val_loss: 1.4963 - lr: 7.8125e-06\n",
      "Epoch 93/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4335Текущий реальный скор(валидационная часть): 1.423\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 1.5101 - lr: 3.9063e-06\n",
      "Epoch 94/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4303Текущий реальный скор(валидационная часть): 1.4241\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4356 - val_loss: 1.5114 - lr: 3.9063e-06\n",
      "Epoch 95/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4356Текущий реальный скор(валидационная часть): 1.4249\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4351 - val_loss: 1.5149 - lr: 3.9063e-06\n",
      "Epoch 96/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.4330Текущий реальный скор(валидационная часть): 1.4255\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 1.5156 - lr: 3.9063e-06\n",
      "Epoch 97/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4283Текущий реальный скор(валидационная часть): 1.4261\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 1.5163 - lr: 3.9063e-06\n",
      "Epoch 98/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4328Текущий реальный скор(валидационная часть): 1.4266\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4339 - val_loss: 1.5169 - lr: 3.9063e-06\n",
      "Epoch 99/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4336Текущий реальный скор(валидационная часть): 1.4271\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4336 - val_loss: 1.5174 - lr: 3.9063e-06\n",
      "Epoch 100/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4298Текущий реальный скор(валидационная часть): 1.4275\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 1.5178 - lr: 3.9063e-06\n",
      "Epoch 101/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4267Текущий реальный скор(валидационная часть): 1.4281\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4329 - val_loss: 1.5185 - lr: 3.9063e-06\n",
      "Epoch 102/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4261Текущий реальный скор(валидационная часть): 1.4283\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 1.5188 - lr: 3.9063e-06\n",
      "Epoch 103/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4262Текущий реальный скор(валидационная часть): 1.4387\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 1.5295 - lr: 1.9531e-06\n",
      "Epoch 104/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.4273Текущий реальный скор(валидационная часть): 1.4404\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4314 - val_loss: 1.5312 - lr: 1.9531e-06\n",
      "Epoch 105/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4277Текущий реальный скор(валидационная часть): 1.4408\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4312 - val_loss: 1.5317 - lr: 1.9531e-06\n",
      "Epoch 106/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4219Текущий реальный скор(валидационная часть): 1.4411\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 1.5320 - lr: 1.9531e-06\n",
      "Epoch 107/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4272Текущий реальный скор(валидационная часть): 1.4413\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 1.5323 - lr: 1.9531e-06\n",
      "Epoch 108/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4230Текущий реальный скор(валидационная часть): 1.4415\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 1.5325 - lr: 1.9531e-06\n",
      "Epoch 109/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4269Текущий реальный скор(валидационная часть): 1.4418\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4305 - val_loss: 1.5328 - lr: 1.9531e-06\n",
      "Epoch 110/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4292Текущий реальный скор(валидационная часть): 1.442\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 1.5329 - lr: 1.9531e-06\n",
      "Epoch 111/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.4266Текущий реальный скор(валидационная часть): 1.4422\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4301 - val_loss: 1.5331 - lr: 1.9531e-06\n",
      "Epoch 112/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4242Текущий реальный скор(валидационная часть): 1.4424\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4300 - val_loss: 1.5333 - lr: 1.9531e-06\n",
      "Epoch 113/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4240Текущий реальный скор(валидационная часть): 1.4459\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 1.5394 - lr: 9.7656e-07\n",
      "Epoch 114/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4214Текущий реальный скор(валидационная часть): 1.4472\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4289 - val_loss: 1.5407 - lr: 9.7656e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4188Текущий реальный скор(валидационная часть): 1.4477\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 1.5413 - lr: 9.7656e-07\n",
      "Epoch 116/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4251Текущий реальный скор(валидационная часть): 1.448\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 1.5416 - lr: 9.7656e-07\n",
      "Epoch 117/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4230Текущий реальный скор(валидационная часть): 1.4482\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4286 - val_loss: 1.5418 - lr: 9.7656e-07\n",
      "Epoch 118/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4275Текущий реальный скор(валидационная часть): 1.4484\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4285 - val_loss: 1.5420 - lr: 9.7656e-07\n",
      "Epoch 119/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4209Текущий реальный скор(валидационная часть): 1.4485\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 1.5421 - lr: 9.7656e-07\n",
      "Epoch 120/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4248Текущий реальный скор(валидационная часть): 1.4486\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 1.5422 - lr: 9.7656e-07\n",
      "Epoch 121/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4247Текущий реальный скор(валидационная часть): 1.4487\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4283 - val_loss: 1.5423 - lr: 9.7656e-07\n",
      "Epoch 122/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4271Текущий реальный скор(валидационная часть): 1.4488\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4282 - val_loss: 1.5425 - lr: 9.7656e-07\n",
      "Epoch 123/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4266Текущий реальный скор(валидационная часть): 1.4497\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4277 - val_loss: 1.5433 - lr: 4.8828e-07\n",
      "Epoch 124/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4198Текущий реальный скор(валидационная часть): 1.4503\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4276 - val_loss: 1.5439 - lr: 4.8828e-07\n",
      "Epoch 125/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4239Текущий реальный скор(валидационная часть): 1.4507\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 1.5443 - lr: 4.8828e-07\n",
      "Epoch 126/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4197Текущий реальный скор(валидационная часть): 1.451\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 1.5445 - lr: 4.8828e-07\n",
      "Epoch 127/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4238Текущий реальный скор(валидационная часть): 1.4512\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4274 - val_loss: 1.5447 - lr: 4.8828e-07\n",
      "Epoch 128/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4195Текущий реальный скор(валидационная часть): 1.4513\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4274 - val_loss: 1.5449 - lr: 4.8828e-07\n",
      "Epoch 129/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4275Текущий реальный скор(валидационная часть): 1.4514\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4274 - val_loss: 1.5450 - lr: 4.8828e-07\n",
      "Epoch 130/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4262Текущий реальный скор(валидационная часть): 1.4515\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4273 - val_loss: 1.5450 - lr: 4.8828e-07\n",
      "Epoch 131/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4194Текущий реальный скор(валидационная часть): 1.4516\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4273 - val_loss: 1.5451 - lr: 4.8828e-07\n",
      "Epoch 132/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4190Текущий реальный скор(валидационная часть): 1.4516\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4273 - val_loss: 1.5452 - lr: 4.8828e-07\n",
      "Epoch 133/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4269Текущий реальный скор(валидационная часть): 1.4519\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 1.5455 - lr: 2.4414e-07\n",
      "Epoch 134/500\n",
      "106/134 [======================>.......] - ETA: 0s - loss: 0.4157Текущий реальный скор(валидационная часть): 1.4521\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 1.5457 - lr: 2.4414e-07\n",
      "Epoch 135/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4187Текущий реальный скор(валидационная часть): 1.4523\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 1.5458 - lr: 2.4414e-07\n",
      "Epoch 136/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.4258Текущий реальный скор(валидационная часть): 1.4524\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 1.5460 - lr: 2.4414e-07\n",
      "Epoch 137/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4257Текущий реальный скор(валидационная часть): 1.4525\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 1.5461 - lr: 2.4414e-07\n",
      "Epoch 138/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4232Текущий реальный скор(валидационная часть): 1.4526\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 1.5462 - lr: 2.4414e-07\n",
      "Epoch 139/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4210Текущий реальный скор(валидационная часть): 1.4527\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 1.5462 - lr: 2.4414e-07\n",
      "Epoch 140/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4268Текущий реальный скор(валидационная часть): 1.4527\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 1.5463 - lr: 2.4414e-07\n",
      "Epoch 141/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4269Текущий реальный скор(валидационная часть): 1.4528\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 1.5464 - lr: 2.4414e-07\n",
      "Epoch 142/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4165Текущий реальный скор(валидационная часть): 1.4529\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 1.5464 - lr: 2.4414e-07\n",
      "Epoch 143/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4255Текущий реальный скор(валидационная часть): 1.4529\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 1.5465 - lr: 1.2207e-07\n",
      "Epoch 144/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4182Текущий реальный скор(валидационная часть): 1.453\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 1.5466 - lr: 1.2207e-07\n",
      "Epoch 145/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4267Текущий реальный скор(валидационная часть): 1.4531\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 1.5466 - lr: 1.2207e-07\n",
      "Epoch 146/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4229Текущий реальный скор(валидационная часть): 1.4531\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 1.5467 - lr: 1.2207e-07\n",
      "Epoch 147/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4266Текущий реальный скор(валидационная часть): 1.4532\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 1.5468 - lr: 1.2207e-07\n",
      "Epoch 148/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4206Текущий реальный скор(валидационная часть): 1.4532\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 1.5468 - lr: 1.2207e-07\n",
      "Epoch 149/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.4182Текущий реальный скор(валидационная часть): 1.4533\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 1.5469 - lr: 1.2207e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4186Текущий реальный скор(валидационная часть): 1.4533\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 1.5469 - lr: 1.2207e-07\n",
      "Epoch 151/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4206Текущий реальный скор(валидационная часть): 1.4534\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 1.5469 - lr: 1.2207e-07\n",
      "Epoch 152/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.4229Текущий реальный скор(валидационная часть): 1.377\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 1.5470 - lr: 1.2207e-07\n",
      "Скор для фолда(7) : 1.377 средний скор на префиксе = 1.3378 это заняло = 42 сек.\n",
      "Фолд: 8\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 4.1724Текущий реальный скор(валидационная часть): 1.8665\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8272 - val_loss: 1.9216 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 2.0507Текущий реальный скор(валидационная часть): 1.3998\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9889 - val_loss: 1.4744 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.6754Текущий реальный скор(валидационная часть): 1.2545\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6754 - val_loss: 1.3361 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.5187Текущий реальный скор(валидационная часть): 1.2003\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5161 - val_loss: 1.2789 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 1.4512Текущий реальный скор(валидационная часть): 1.1589\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4497 - val_loss: 1.2485 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 1.3750Текущий реальный скор(валидационная часть): 1.1286\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3855 - val_loss: 1.2194 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 1.3199Текущий реальный скор(валидационная часть): 1.1276\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3184 - val_loss: 1.2193 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 1.2548Текущий реальный скор(валидационная часть): 1.1507\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2608 - val_loss: 1.2409 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.2118Текущий реальный скор(валидационная часть): 1.1268\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2114 - val_loss: 1.2178 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 1.1540Текущий реальный скор(валидационная часть): 1.1345\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1590 - val_loss: 1.2337 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 1.1225Текущий реальный скор(валидационная часть): 1.1529\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1188 - val_loss: 1.2484 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.0698Текущий реальный скор(валидационная часть): 1.1953\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0699 - val_loss: 1.2876 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.0293Текущий реальный скор(валидационная часть): 1.2094\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0294 - val_loss: 1.3127 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 1.0018Текущий реальный скор(валидационная часть): 1.1932\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0021 - val_loss: 1.3022 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.9598Текущий реальный скор(валидационная часть): 1.2356\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9715 - val_loss: 1.3380 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.9536Текущий реальный скор(валидационная часть): 1.2149\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9537 - val_loss: 1.3258 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.9354Текущий реальный скор(валидационная часть): 1.2001\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 1.3147 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.9558Текущий реальный скор(валидационная часть): 1.2946\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9626 - val_loss: 1.4072 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.9404Текущий реальный скор(валидационная часть): 1.3872\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 1.4940 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.9531Текущий реальный скор(валидационная часть): 1.3536\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 1.4670 - lr: 2.5000e-04\n",
      "Epoch 21/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.9082Текущий реальный скор(валидационная часть): 1.3452\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9083 - val_loss: 1.4588 - lr: 2.5000e-04\n",
      "Epoch 22/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.8743Текущий реальный скор(валидационная часть): 1.3548\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8745 - val_loss: 1.4781 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.8476Текущий реальный скор(валидационная часть): 1.3598\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8479 - val_loss: 1.4846 - lr: 2.5000e-04\n",
      "Epoch 24/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.8182Текущий реальный скор(валидационная часть): 1.3896\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8211 - val_loss: 1.5081 - lr: 2.5000e-04\n",
      "Epoch 25/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.8076Текущий реальный скор(валидационная часть): 1.411\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8079 - val_loss: 1.5357 - lr: 2.5000e-04\n",
      "Epoch 26/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.7822Текущий реальный скор(валидационная часть): 1.3869\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7848 - val_loss: 1.5089 - lr: 2.5000e-04\n",
      "Epoch 27/500\n",
      "105/134 [======================>.......] - ETA: 0s - loss: 0.7604Текущий реальный скор(валидационная часть): 1.4001\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7752 - val_loss: 1.5337 - lr: 2.5000e-04\n",
      "Epoch 28/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.7732Текущий реальный скор(валидационная часть): 1.3792\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7781 - val_loss: 1.4974 - lr: 2.5000e-04\n",
      "Epoch 29/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.7442Текущий реальный скор(валидационная часть): 1.3979\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7515 - val_loss: 1.5186 - lr: 2.5000e-04\n",
      "Epoch 30/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.7578Текущий реальный скор(валидационная часть): 1.2419\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7628 - val_loss: 1.3720 - lr: 1.2500e-04\n",
      "Epoch 31/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.7167Текущий реальный скор(валидационная часть): 1.2335\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7172 - val_loss: 1.3728 - lr: 1.2500e-04\n",
      "Epoch 32/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.6876Текущий реальный скор(валидационная часть): 1.2354\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6881 - val_loss: 1.3655 - lr: 1.2500e-04\n",
      "Epoch 33/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.6581Текущий реальный скор(валидационная часть): 1.2445\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6667 - val_loss: 1.3748 - lr: 1.2500e-04\n",
      "Epoch 34/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.6470Текущий реальный скор(валидационная часть): 1.2509\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6497 - val_loss: 1.3791 - lr: 1.2500e-04\n",
      "Epoch 35/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.6307Текущий реальный скор(валидационная часть): 1.256\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6383 - val_loss: 1.3828 - lr: 1.2500e-04\n",
      "Epoch 36/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.6232Текущий реальный скор(валидационная часть): 1.2604\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6273 - val_loss: 1.3869 - lr: 1.2500e-04\n",
      "Epoch 37/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.6086Текущий реальный скор(валидационная часть): 1.2617\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 1.3874 - lr: 1.2500e-04\n",
      "Epoch 38/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.6003Текущий реальный скор(валидационная часть): 1.2653\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 1.3894 - lr: 1.2500e-04\n",
      "Epoch 39/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5911Текущий реальный скор(валидационная часть): 1.2681\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 1.3943 - lr: 1.2500e-04\n",
      "Epoch 40/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6057Текущий реальный скор(валидационная часть): 1.2618\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 1.3890 - lr: 6.2500e-05\n",
      "Epoch 41/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.5987Текущий реальный скор(валидационная часть): 1.2641\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 1.3924 - lr: 6.2500e-05\n",
      "Epoch 42/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5895Текущий реальный скор(валидационная часть): 1.2623\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 1.3902 - lr: 6.2500e-05\n",
      "Epoch 43/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5858Текущий реальный скор(валидационная часть): 1.2636\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5949 - val_loss: 1.3921 - lr: 6.2500e-05\n",
      "Epoch 44/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5814Текущий реальный скор(валидационная часть): 1.2623\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5909 - val_loss: 1.3924 - lr: 6.2500e-05\n",
      "Epoch 45/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.5824Текущий реальный скор(валидационная часть): 1.2634\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5870 - val_loss: 1.3943 - lr: 6.2500e-05\n",
      "Epoch 46/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5724Текущий реальный скор(валидационная часть): 1.2652\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5836 - val_loss: 1.3962 - lr: 6.2500e-05\n",
      "Epoch 47/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.5757Текущий реальный скор(валидационная часть): 1.2661\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5803 - val_loss: 1.3970 - lr: 6.2500e-05\n",
      "Epoch 48/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5760Текущий реальный скор(валидационная часть): 1.2677\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5767 - val_loss: 1.4011 - lr: 6.2500e-05\n",
      "Epoch 49/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5703Текущий реальный скор(валидационная часть): 1.2686\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5731 - val_loss: 1.4018 - lr: 6.2500e-05\n",
      "Epoch 50/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5900Текущий реальный скор(валидационная часть): 1.2385\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5900 - val_loss: 1.3768 - lr: 3.1250e-05\n",
      "Epoch 51/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5859Текущий реальный скор(валидационная часть): 1.2398\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5867 - val_loss: 1.3757 - lr: 3.1250e-05\n",
      "Epoch 52/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5782Текущий реальный скор(валидационная часть): 1.2428\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5808 - val_loss: 1.3786 - lr: 3.1250e-05\n",
      "Epoch 53/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5650Текущий реальный скор(валидационная часть): 1.2459\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5762 - val_loss: 1.3813 - lr: 3.1250e-05\n",
      "Epoch 54/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5694Текущий реальный скор(валидационная часть): 1.2476\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5723 - val_loss: 1.3855 - lr: 3.1250e-05\n",
      "Epoch 55/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5577Текущий реальный скор(валидационная часть): 1.2498\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5687 - val_loss: 1.3873 - lr: 3.1250e-05\n",
      "Epoch 56/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5654Текущий реальный скор(валидационная часть): 1.2516\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5654 - val_loss: 1.3890 - lr: 3.1250e-05\n",
      "Epoch 57/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5528Текущий реальный скор(валидационная часть): 1.2532\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5625 - val_loss: 1.3907 - lr: 3.1250e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.5567Текущий реальный скор(валидационная часть): 1.2553\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5597 - val_loss: 1.3928 - lr: 3.1250e-05\n",
      "Epoch 59/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5473Текущий реальный скор(валидационная часть): 1.2568\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5570 - val_loss: 1.3944 - lr: 3.1250e-05\n",
      "Epoch 60/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5475Текущий реальный скор(валидационная часть): 1.2673\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5564 - val_loss: 1.4067 - lr: 1.5625e-05\n",
      "Epoch 61/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5437Текущий реальный скор(валидационная часть): 1.2681\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5530 - val_loss: 1.4072 - lr: 1.5625e-05\n",
      "Epoch 62/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5436Текущий реальный скор(валидационная часть): 1.2685\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5511 - val_loss: 1.4074 - lr: 1.5625e-05\n",
      "Epoch 63/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5468Текущий реальный скор(валидационная часть): 1.2687\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5495 - val_loss: 1.4075 - lr: 1.5625e-05\n",
      "Epoch 64/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5350Текущий реальный скор(валидационная часть): 1.2691\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5481 - val_loss: 1.4078 - lr: 1.5625e-05\n",
      "Epoch 65/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5393Текущий реальный скор(валидационная часть): 1.2694\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5467 - val_loss: 1.4080 - lr: 1.5625e-05\n",
      "Epoch 66/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5372Текущий реальный скор(валидационная часть): 1.27\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5453 - val_loss: 1.4084 - lr: 1.5625e-05\n",
      "Epoch 67/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.5397Текущий реальный скор(валидационная часть): 1.2703\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5440 - val_loss: 1.4086 - lr: 1.5625e-05\n",
      "Epoch 68/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5318Текущий реальный скор(валидационная часть): 1.2711\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5423 - val_loss: 1.4094 - lr: 1.5625e-05\n",
      "Epoch 69/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5407Текущий реальный скор(валидационная часть): 1.2713\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5407 - val_loss: 1.4097 - lr: 1.5625e-05\n",
      "Epoch 70/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5290Текущий реальный скор(валидационная часть): 1.2656\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5402 - val_loss: 1.4033 - lr: 7.8125e-06\n",
      "Epoch 71/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5286Текущий реальный скор(валидационная часть): 1.2661\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5398 - val_loss: 1.4038 - lr: 7.8125e-06\n",
      "Epoch 72/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5276Текущий реальный скор(валидационная часть): 1.2666\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 1.4042 - lr: 7.8125e-06\n",
      "Epoch 73/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5274Текущий реальный скор(валидационная часть): 1.2671\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5380 - val_loss: 1.4047 - lr: 7.8125e-06\n",
      "Epoch 74/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5280Текущий реальный скор(валидационная часть): 1.2673\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5373 - val_loss: 1.4049 - lr: 7.8125e-06\n",
      "Epoch 75/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5221Текущий реальный скор(валидационная часть): 1.2676\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5365 - val_loss: 1.4052 - lr: 7.8125e-06\n",
      "Epoch 76/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5213Текущий реальный скор(валидационная часть): 1.2678\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5358 - val_loss: 1.4054 - lr: 7.8125e-06\n",
      "Epoch 77/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5257Текущий реальный скор(валидационная часть): 1.2682\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 1.4058 - lr: 7.8125e-06\n",
      "Epoch 78/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.5295Текущий реальный скор(валидационная часть): 1.2686\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5345 - val_loss: 1.4062 - lr: 7.8125e-06\n",
      "Epoch 79/500\n",
      "107/134 [======================>.......] - ETA: 0s - loss: 0.5227Текущий реальный скор(валидационная часть): 1.2688\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5339 - val_loss: 1.4064 - lr: 7.8125e-06\n",
      "Epoch 80/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5253Текущий реальный скор(валидационная часть): 1.2693\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 1.4066 - lr: 3.9063e-06\n",
      "Epoch 81/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5257Текущий реальный скор(валидационная часть): 1.2698\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5339 - val_loss: 1.4070 - lr: 3.9063e-06\n",
      "Epoch 82/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5230Текущий реальный скор(валидационная часть): 1.2699\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5335 - val_loss: 1.4072 - lr: 3.9063e-06\n",
      "Epoch 83/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5238Текущий реальный скор(валидационная часть): 1.2702\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5331 - val_loss: 1.4075 - lr: 3.9063e-06\n",
      "Epoch 84/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5243Текущий реальный скор(валидационная часть): 1.2704\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5327 - val_loss: 1.4078 - lr: 3.9063e-06\n",
      "Epoch 85/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5309Текущий реальный скор(валидационная часть): 1.2706\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5323 - val_loss: 1.4081 - lr: 3.9063e-06\n",
      "Epoch 86/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5293Текущий реальный скор(валидационная часть): 1.2707\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 1.4083 - lr: 3.9063e-06\n",
      "Epoch 87/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5234Текущий реальный скор(валидационная часть): 1.271\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5316 - val_loss: 1.4086 - lr: 3.9063e-06\n",
      "Epoch 88/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.5321Текущий реальный скор(валидационная часть): 1.2711\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 1.4088 - lr: 3.9063e-06\n",
      "Epoch 89/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5294Текущий реальный скор(валидационная часть): 1.2713\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5309 - val_loss: 1.4091 - lr: 3.9063e-06\n",
      "Epoch 90/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5245Текущий реальный скор(валидационная часть): 1.2747\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 1.4121 - lr: 1.9531e-06\n",
      "Epoch 91/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5203Текущий реальный скор(валидационная часть): 1.2754\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5296 - val_loss: 1.4128 - lr: 1.9531e-06\n",
      "Epoch 92/500\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.5245Текущий реальный скор(валидационная часть): 1.2756\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 1.4131 - lr: 1.9531e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5204Текущий реальный скор(валидационная часть): 1.2758\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 1.4133 - lr: 1.9531e-06\n",
      "Epoch 94/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.5300Текущий реальный скор(валидационная часть): 1.2759\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 1.4135 - lr: 1.9531e-06\n",
      "Epoch 95/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5237Текущий реальный скор(валидационная часть): 1.2761\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 1.4137 - lr: 1.9531e-06\n",
      "Epoch 96/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.5240Текущий реальный скор(валидационная часть): 1.2762\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5286 - val_loss: 1.4138 - lr: 1.9531e-06\n",
      "Epoch 97/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5260Текущий реальный скор(валидационная часть): 1.2763\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5284 - val_loss: 1.4140 - lr: 1.9531e-06\n",
      "Epoch 98/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5194Текущий реальный скор(валидационная часть): 1.2764\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5283 - val_loss: 1.4141 - lr: 1.9531e-06\n",
      "Epoch 99/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5281Текущий реальный скор(валидационная часть): 1.2765\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 1.4143 - lr: 1.9531e-06\n",
      "Epoch 100/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5179Текущий реальный скор(валидационная часть): 1.2782\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 1.4158 - lr: 9.7656e-07\n",
      "Epoch 101/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5248Текущий реальный скор(валидационная часть): 1.2789\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 1.4164 - lr: 9.7656e-07\n",
      "Epoch 102/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5123Текущий реальный скор(валидационная часть): 1.2792\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 1.4167 - lr: 9.7656e-07\n",
      "Epoch 103/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.5223Текущий реальный скор(валидационная часть): 1.2793\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 1.4168 - lr: 9.7656e-07\n",
      "Epoch 104/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5174Текущий реальный скор(валидационная часть): 1.2794\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 1.4169 - lr: 9.7656e-07\n",
      "Epoch 105/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5120Текущий реальный скор(валидационная часть): 1.2795\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.4170 - lr: 9.7656e-07\n",
      "Epoch 106/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.5220Текущий реальный скор(валидационная часть): 1.2796\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 1.4170 - lr: 9.7656e-07\n",
      "Epoch 107/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5168Текущий реальный скор(валидационная часть): 1.2796\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.4171 - lr: 9.7656e-07\n",
      "Epoch 108/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5240Текущий реальный скор(валидационная часть): 1.2797\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.4172 - lr: 9.7656e-07\n",
      "Epoch 109/500\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.5236Текущий реальный скор(валидационная часть): 1.1268\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.4172 - lr: 9.7656e-07\n",
      "Скор для фолда(8) : 1.1268 средний скор на префиксе = 1.3144 это заняло = 30 сек.\n",
      "Фолд: 9\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 4.0513Текущий реальный скор(валидационная часть): 2.0486\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.7945 - val_loss: 2.1368 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.9476Текущий реальный скор(валидационная часть): 1.7028\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.9477 - val_loss: 1.8068 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 1.6697Текущий реальный скор(валидационная часть): 1.5757\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6505 - val_loss: 1.6853 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 1.5099Текущий реальный скор(валидационная часть): 1.5503\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5008 - val_loss: 1.6626 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 1.4197Текущий реальный скор(валидационная часть): 1.5152\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4146 - val_loss: 1.6359 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 1.3459Текущий реальный скор(валидационная часть): 1.4873\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3422 - val_loss: 1.6055 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 1.2909Текущий реальный скор(валидационная часть): 1.4798\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2851 - val_loss: 1.5932 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.2348Текущий реальный скор(валидационная часть): 1.4622\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2265 - val_loss: 1.5759 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.1874Текущий реальный скор(валидационная часть): 1.4663\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1790 - val_loss: 1.5745 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 1.1435Текущий реальный скор(валидационная часть): 1.4885\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1417 - val_loss: 1.5994 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.1097Текущий реальный скор(валидационная часть): 1.4747\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1048 - val_loss: 1.5884 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 1.0592Текущий реальный скор(валидационная часть): 1.4625\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0679 - val_loss: 1.5823 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.0279Текущий реальный скор(валидационная часть): 1.432\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0304 - val_loss: 1.5429 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.9908Текущий реальный скор(валидационная часть): 1.4419\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 1.5444 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.9639Текущий реальный скор(валидационная часть): 1.4218\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9677 - val_loss: 1.5302 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.9450Текущий реальный скор(валидационная часть): 1.5139\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 1.6151 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.9158Текущий реальный скор(валидационная часть): 1.4661\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9169 - val_loss: 1.5917 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.9124Текущий реальный скор(валидационная часть): 1.4541\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9155 - val_loss: 1.5539 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.8957Текущий реальный скор(валидационная часть): 1.4266\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8992 - val_loss: 1.5062 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.8650Текущий реальный скор(валидационная часть): 1.3868\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8711 - val_loss: 1.4800 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.8355Текущий реальный скор(валидационная часть): 1.3678\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8426 - val_loss: 1.4551 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.8272Текущий реальный скор(валидационная часть): 1.5925\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8301 - val_loss: 1.6751 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.8561Текущий реальный скор(валидационная часть): 1.6352\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8576 - val_loss: 1.7133 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.8200Текущий реальный скор(валидационная часть): 1.4542\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8193 - val_loss: 1.5466 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.8238Текущий реальный скор(валидационная часть): 1.4304\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8239 - val_loss: 1.5184 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.8691Текущий реальный скор(валидационная часть): 1.4574\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8666 - val_loss: 1.5430 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8027Текущий реальный скор(валидационная часть): 1.4504\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8013 - val_loss: 1.5394 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.7634Текущий реальный скор(валидационная часть): 1.4958\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7603 - val_loss: 1.5780 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.7528Текущий реальный скор(валидационная часть): 1.4111\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7485 - val_loss: 1.4953 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.7562Текущий реальный скор(валидационная часть): 1.4368\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7580 - val_loss: 1.5318 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7274Текущий реальный скор(валидационная часть): 1.437\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7383 - val_loss: 1.5465 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.7421Текущий реальный скор(валидационная часть): 1.6242\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7537 - val_loss: 1.6876 - lr: 2.5000e-04\n",
      "Epoch 33/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.7284Текущий реальный скор(валидационная часть): 1.4936\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7386 - val_loss: 1.5537 - lr: 2.5000e-04\n",
      "Epoch 34/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6702Текущий реальный скор(валидационная часть): 1.428\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6735 - val_loss: 1.5008 - lr: 2.5000e-04\n",
      "Epoch 35/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.6324Текущий реальный скор(валидационная часть): 1.404\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6446 - val_loss: 1.4833 - lr: 2.5000e-04\n",
      "Epoch 36/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.6114Текущий реальный скор(валидационная часть): 1.3953\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 1.4788 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5887Текущий реальный скор(валидационная часть): 1.3971\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5981 - val_loss: 1.4797 - lr: 2.5000e-04\n",
      "Epoch 38/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5789Текущий реальный скор(валидационная часть): 1.4016\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5825 - val_loss: 1.4828 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5565Текущий реальный скор(валидационная часть): 1.4014\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5701 - val_loss: 1.4853 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5465Текущий реальный скор(валидационная часть): 1.4053\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5565 - val_loss: 1.4861 - lr: 2.5000e-04\n",
      "Epoch 41/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5389Текущий реальный скор(валидационная часть): 1.412\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5429 - val_loss: 1.4960 - lr: 2.5000e-04\n",
      "Epoch 42/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5465Текущий реальный скор(валидационная часть): 1.3666\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5540 - val_loss: 1.4626 - lr: 1.2500e-04\n",
      "Epoch 43/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5185Текущий реальный скор(валидационная часть): 1.3871\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5284 - val_loss: 1.4827 - lr: 1.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5023Текущий реальный скор(валидационная часть): 1.3992\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5090 - val_loss: 1.4944 - lr: 1.2500e-04\n",
      "Epoch 45/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4958Текущий реальный скор(валидационная часть): 1.4032\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4959 - val_loss: 1.4965 - lr: 1.2500e-04\n",
      "Epoch 46/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4748Текущий реальный скор(валидационная часть): 1.4076\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 1.4995 - lr: 1.2500e-04\n",
      "Epoch 47/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4711Текущий реальный скор(валидационная часть): 1.4117\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 1.5021 - lr: 1.2500e-04\n",
      "Epoch 48/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4618Текущий реальный скор(валидационная часть): 1.4142\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 1.5040 - lr: 1.2500e-04\n",
      "Epoch 49/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4630Текущий реальный скор(валидационная часть): 1.4171\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 1.5061 - lr: 1.2500e-04\n",
      "Epoch 50/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4482Текущий реальный скор(валидационная часть): 1.4201\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 1.5080 - lr: 1.2500e-04\n",
      "Epoch 51/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4475Текущий реальный скор(валидационная часть): 1.4221\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 1.5094 - lr: 1.2500e-04\n",
      "Epoch 52/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4517Текущий реальный скор(валидационная часть): 1.4067\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 1.4915 - lr: 6.2500e-05\n",
      "Epoch 53/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4523Текущий реальный скор(валидационная часть): 1.4016\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 1.4861 - lr: 6.2500e-05\n",
      "Epoch 54/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4451Текущий реальный скор(валидационная часть): 1.4004\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 1.4851 - lr: 6.2500e-05\n",
      "Epoch 55/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4428Текущий реальный скор(валидационная часть): 1.3878\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4495 - val_loss: 1.4775 - lr: 6.2500e-05\n",
      "Epoch 56/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4424Текущий реальный скор(валидационная часть): 1.4007\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4502 - val_loss: 1.4850 - lr: 6.2500e-05\n",
      "Epoch 57/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4397Текущий реальный скор(валидационная часть): 1.3983\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 1.4828 - lr: 6.2500e-05\n",
      "Epoch 58/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4356Текущий реальный скор(валидационная часть): 1.3959\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4435 - val_loss: 1.4810 - lr: 6.2500e-05\n",
      "Epoch 59/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4322Текущий реальный скор(валидационная часть): 1.3931\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 1.4789 - lr: 6.2500e-05\n",
      "Epoch 60/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4308Текущий реальный скор(валидационная часть): 1.3944\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 1.4791 - lr: 6.2500e-05\n",
      "Epoch 61/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4326Текущий реальный скор(валидационная часть): 1.3927\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4361 - val_loss: 1.4782 - lr: 6.2500e-05\n",
      "Epoch 62/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4428Текущий реальный скор(валидационная часть): 1.3781\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 1.4661 - lr: 3.1250e-05\n",
      "Epoch 63/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4373Текущий реальный скор(валидационная часть): 1.3825\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 1.4682 - lr: 3.1250e-05\n",
      "Epoch 64/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4365Текущий реальный скор(валидационная часть): 1.3863\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4421 - val_loss: 1.4711 - lr: 3.1250e-05\n",
      "Epoch 65/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4356Текущий реальный скор(валидационная часть): 1.3901\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 1.4741 - lr: 3.1250e-05\n",
      "Epoch 66/500\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4345Текущий реальный скор(валидационная часть): 1.3923\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4357 - val_loss: 1.4763 - lr: 3.1250e-05\n",
      "Epoch 67/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4272Текущий реальный скор(валидационная часть): 1.3942\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 1.4780 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4242Текущий реальный скор(валидационная часть): 1.3963\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 1.4798 - lr: 3.1250e-05\n",
      "Epoch 69/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4260Текущий реальный скор(валидационная часть): 1.398\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 1.4817 - lr: 3.1250e-05\n",
      "Epoch 70/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4169Текущий реальный скор(валидационная часть): 1.399\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 1.4823 - lr: 3.1250e-05\n",
      "Epoch 71/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4175Текущий реальный скор(валидационная часть): 1.3998\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4249 - val_loss: 1.4832 - lr: 3.1250e-05\n",
      "Epoch 72/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4219Текущий реальный скор(валидационная часть): 1.4112\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4273 - val_loss: 1.4919 - lr: 1.5625e-05\n",
      "Epoch 73/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4223Текущий реальный скор(валидационная часть): 1.407\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4249 - val_loss: 1.4887 - lr: 1.5625e-05\n",
      "Epoch 74/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4177Текущий реальный скор(валидационная часть): 1.4047\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4234 - val_loss: 1.4870 - lr: 1.5625e-05\n",
      "Epoch 75/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4163Текущий реальный скор(валидационная часть): 1.4028\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4221 - val_loss: 1.4855 - lr: 1.5625e-05\n",
      "Epoch 76/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4138Текущий реальный скор(валидационная часть): 1.4017\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 1.4846 - lr: 1.5625e-05\n",
      "Epoch 77/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4166Текущий реальный скор(валидационная часть): 1.4007\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4199 - val_loss: 1.4839 - lr: 1.5625e-05\n",
      "Epoch 78/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4126Текущий реальный скор(валидационная часть): 1.4004\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4188 - val_loss: 1.4838 - lr: 1.5625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4151Текущий реальный скор(валидационная часть): 1.3992\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 1.4829 - lr: 1.5625e-05\n",
      "Epoch 80/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4106Текущий реальный скор(валидационная часть): 1.399\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 1.4827 - lr: 1.5625e-05\n",
      "Epoch 81/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4100Текущий реальный скор(валидационная часть): 1.3985\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4160 - val_loss: 1.4825 - lr: 1.5625e-05\n",
      "Epoch 82/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4054Текущий реальный скор(валидационная часть): 1.382\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4168 - val_loss: 1.4718 - lr: 7.8125e-06\n",
      "Epoch 83/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4100Текущий реальный скор(валидационная часть): 1.3812\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 1.4710 - lr: 7.8125e-06\n",
      "Epoch 84/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4096Текущий реальный скор(валидационная часть): 1.3808\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 1.4706 - lr: 7.8125e-06\n",
      "Epoch 85/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4120Текущий реальный скор(валидационная часть): 1.3805\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4153 - val_loss: 1.4703 - lr: 7.8125e-06\n",
      "Epoch 86/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4083Текущий реальный скор(валидационная часть): 1.3804\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 1.4702 - lr: 7.8125e-06\n",
      "Epoch 87/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4083Текущий реальный скор(валидационная часть): 1.3804\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 1.4702 - lr: 7.8125e-06\n",
      "Epoch 88/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.4088Текущий реальный скор(валидационная часть): 1.38\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 1.4699 - lr: 7.8125e-06\n",
      "Epoch 89/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4104Текущий реальный скор(валидационная часть): 1.3803\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 1.4702 - lr: 7.8125e-06\n",
      "Epoch 90/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4061Текущий реальный скор(валидационная часть): 1.3801\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4127 - val_loss: 1.4701 - lr: 7.8125e-06\n",
      "Epoch 91/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4061Текущий реальный скор(валидационная часть): 1.3801\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 1.4702 - lr: 7.8125e-06\n",
      "Epoch 92/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4069Текущий реальный скор(валидационная часть): 1.3839\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 1.4730 - lr: 3.9063e-06\n",
      "Epoch 93/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4092Текущий реальный скор(валидационная часть): 1.3839\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 1.4730 - lr: 3.9063e-06\n",
      "Epoch 94/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4026Текущий реальный скор(валидационная часть): 1.3838\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4116 - val_loss: 1.4730 - lr: 3.9063e-06\n",
      "Epoch 95/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4015Текущий реальный скор(валидационная часть): 1.3838\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 1.4730 - lr: 3.9063e-06\n",
      "Epoch 96/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4045Текущий реальный скор(валидационная часть): 1.3837\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4109 - val_loss: 1.4729 - lr: 3.9063e-06\n",
      "Epoch 97/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4046Текущий реальный скор(валидационная часть): 1.3838\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4106 - val_loss: 1.4730 - lr: 3.9063e-06\n",
      "Epoch 98/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3987Текущий реальный скор(валидационная часть): 1.3836\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4103 - val_loss: 1.4728 - lr: 3.9063e-06\n",
      "Epoch 99/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4040Текущий реальный скор(валидационная часть): 1.3837\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4101 - val_loss: 1.4729 - lr: 3.9063e-06\n",
      "Epoch 100/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4035Текущий реальный скор(валидационная часть): 1.3837\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 1.4728 - lr: 3.9063e-06\n",
      "Epoch 101/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4067Текущий реальный скор(валидационная часть): 1.3837\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 1.4729 - lr: 3.9063e-06\n",
      "Epoch 102/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3974Текущий реальный скор(валидационная часть): 1.39\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 1.4773 - lr: 1.9531e-06\n",
      "Epoch 103/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4049Текущий реальный скор(валидационная часть): 1.3908\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 1.4779 - lr: 1.9531e-06\n",
      "Epoch 104/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4014Текущий реальный скор(валидационная часть): 1.3908\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4081 - val_loss: 1.4780 - lr: 1.9531e-06\n",
      "Epoch 105/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3980Текущий реальный скор(валидационная часть): 1.3908\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4079 - val_loss: 1.4780 - lr: 1.9531e-06\n",
      "Epoch 106/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4011Текущий реальный скор(валидационная часть): 1.3907\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4078 - val_loss: 1.4779 - lr: 1.9531e-06\n",
      "Epoch 107/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4015Текущий реальный скор(валидационная часть): 1.3906\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 1.4779 - lr: 1.9531e-06\n",
      "Epoch 108/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4075Текущий реальный скор(валидационная часть): 1.3906\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 1.4779 - lr: 1.9531e-06\n",
      "Epoch 109/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3975Текущий реальный скор(валидационная часть): 1.3906\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 1.4779 - lr: 1.9531e-06\n",
      "Epoch 110/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3977Текущий реальный скор(валидационная часть): 1.3906\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4073 - val_loss: 1.4779 - lr: 1.9531e-06\n",
      "Epoch 111/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4037Текущий реальный скор(валидационная часть): 1.3906\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 1.4779 - lr: 1.9531e-06\n",
      "Epoch 112/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3995Текущий реальный скор(валидационная часть): 1.393\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4064 - val_loss: 1.4795 - lr: 9.7656e-07\n",
      "Epoch 113/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3961Текущий реальный скор(валидационная часть): 1.3939\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 1.4828 - lr: 9.7656e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3962Текущий реальный скор(валидационная часть): 1.3942\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4060 - val_loss: 1.4829 - lr: 9.7656e-07\n",
      "Epoch 115/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4024Текущий реальный скор(валидационная часть): 1.3943\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 1.4830 - lr: 9.7656e-07\n",
      "Epoch 116/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3962Текущий реальный скор(валидационная часть): 1.3943\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 1.4830 - lr: 9.7656e-07\n",
      "Epoch 117/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3995Текущий реальный скор(валидационная часть): 1.3943\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 1.4831 - lr: 9.7656e-07\n",
      "Epoch 118/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.3997Текущий реальный скор(валидационная часть): 1.3943\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 1.4830 - lr: 9.7656e-07\n",
      "Epoch 119/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3956Текущий реальный скор(валидационная часть): 1.3942\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 1.4830 - lr: 9.7656e-07\n",
      "Epoch 120/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3993Текущий реальный скор(валидационная часть): 1.3942\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 1.4830 - lr: 9.7656e-07\n",
      "Epoch 121/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4025Текущий реальный скор(валидационная часть): 1.3678\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4055 - val_loss: 1.4830 - lr: 9.7656e-07\n",
      "Скор для фолда(9) : 1.3678 средний скор на префиксе = 1.3197 это заняло = 31 сек.\n",
      "Фолд: 10\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 4.0529Текущий реальный скор(валидационная часть): 2.4191\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8110 - val_loss: 2.6298 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.9696Текущий реальный скор(валидационная часть): 1.6503\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9468 - val_loss: 1.8274 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 1.6511Текущий реальный скор(валидационная часть): 1.6258\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6404 - val_loss: 1.8124 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.5112Текущий реальный скор(валидационная часть): 1.6333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4988 - val_loss: 1.8397 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 1.4221Текущий реальный скор(валидационная часть): 1.6267\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4129 - val_loss: 1.8484 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 1.3574Текущий реальный скор(валидационная часть): 1.5199\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3478 - val_loss: 1.7399 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.2912Текущий реальный скор(валидационная часть): 1.5294\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2763 - val_loss: 1.7610 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.2270Текущий реальный скор(валидационная часть): 1.4929\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2152 - val_loss: 1.7405 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.1784Текущий реальный скор(валидационная часть): 1.4664\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1637 - val_loss: 1.7079 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.1274Текущий реальный скор(валидационная часть): 1.48\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1172 - val_loss: 1.7238 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.0952Текущий реальный скор(валидационная часть): 1.5072\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0838 - val_loss: 1.7591 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.0737Текущий реальный скор(валидационная часть): 1.7694\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0629 - val_loss: 2.0429 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.0941Текущий реальный скор(валидационная часть): 1.6215\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0753 - val_loss: 1.9032 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 1.0085Текущий реальный скор(валидационная часть): 1.5332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.7966 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.9774Текущий реальный скор(валидационная часть): 1.4801\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9661 - val_loss: 1.7332 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.9640Текущий реальный скор(валидационная часть): 1.4408\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9548 - val_loss: 1.7051 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.9533Текущий реальный скор(валидационная часть): 1.5464\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9378 - val_loss: 1.8153 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.9377Текущий реальный скор(валидационная часть): 1.5824\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9281 - val_loss: 1.8500 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.9210Текущий реальный скор(валидационная часть): 1.4934\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9049 - val_loss: 1.7528 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.9086Текущий реальный скор(валидационная часть): 1.6203\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9033 - val_loss: 1.8639 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.8767Текущий реальный скор(валидационная часть): 1.5682\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8665 - val_loss: 1.8173 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.8673Текущий реальный скор(валидационная часть): 1.5642\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8611 - val_loss: 1.8254 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.8422Текущий реальный скор(валидационная часть): 1.3904\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8458 - val_loss: 1.6340 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.8466Текущий реальный скор(валидационная часть): 1.473\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8426 - val_loss: 1.7278 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.8740Текущий реальный скор(валидационная часть): 1.4995\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8660 - val_loss: 1.7443 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.8649Текущий реальный скор(валидационная часть): 1.5134\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8585 - val_loss: 1.7308 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.8353Текущий реальный скор(валидационная часть): 1.5082\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8179 - val_loss: 1.7336 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.8615Текущий реальный скор(валидационная часть): 1.5611\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8452 - val_loss: 1.7961 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.8755Текущий реальный скор(валидационная часть): 1.4778\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8583 - val_loss: 1.7156 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.8407Текущий реальный скор(валидационная часть): 1.5639\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8391 - val_loss: 1.7770 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.7987Текущий реальный скор(валидационная часть): 1.8235\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8340 - val_loss: 2.0492 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.8126Текущий реальный скор(валидационная часть): 2.1319\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8173 - val_loss: 2.3820 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7774Текущий реальный скор(валидационная часть): 2.0622\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7704 - val_loss: 2.3355 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7209Текущий реальный скор(валидационная часть): 1.7441\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7183 - val_loss: 1.9914 - lr: 2.5000e-04\n",
      "Epoch 35/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.6637Текущий реальный скор(валидационная часть): 1.7049\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6614 - val_loss: 1.9399 - lr: 2.5000e-04\n",
      "Epoch 36/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.6145Текущий реальный скор(валидационная часть): 1.7083\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 1.9379 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5919Текущий реальный скор(валидационная часть): 1.7115\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5922 - val_loss: 1.9343 - lr: 2.5000e-04\n",
      "Epoch 38/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5711Текущий реальный скор(валидационная часть): 1.7101\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5717 - val_loss: 1.9304 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5569Текущий реальный скор(валидационная часть): 1.7091\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5573 - val_loss: 1.9281 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5407Текущий реальный скор(валидационная часть): 1.7022\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5435 - val_loss: 1.9242 - lr: 2.5000e-04\n",
      "Epoch 41/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5260Текущий реальный скор(валидационная часть): 1.7081\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 1.9309 - lr: 2.5000e-04\n",
      "Epoch 42/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5207Текущий реальный скор(валидационная часть): 1.7039\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 1.9258 - lr: 2.5000e-04\n",
      "Epoch 43/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5078Текущий реальный скор(валидационная часть): 1.6963\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 1.9181 - lr: 2.5000e-04\n",
      "Epoch 44/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5269Текущий реальный скор(валидационная часть): 1.5264\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 1.7230 - lr: 1.2500e-04\n",
      "Epoch 45/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5386Текущий реальный скор(валидационная часть): 1.5117\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 1.7096 - lr: 1.2500e-04\n",
      "Epoch 46/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5348Текущий реальный скор(валидационная часть): 1.4994\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5315 - val_loss: 1.7027 - lr: 1.2500e-04\n",
      "Epoch 47/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5211Текущий реальный скор(валидационная часть): 1.4948\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.6953 - lr: 1.2500e-04\n",
      "Epoch 48/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5181Текущий реальный скор(валидационная часть): 1.4904\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5176 - val_loss: 1.6929 - lr: 1.2500e-04\n",
      "Epoch 49/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5153Текущий реальный скор(валидационная часть): 1.4886\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5126 - val_loss: 1.6945 - lr: 1.2500e-04\n",
      "Epoch 50/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5079Текущий реальный скор(валидационная часть): 1.4909\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5066 - val_loss: 1.6993 - lr: 1.2500e-04\n",
      "Epoch 51/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5038Текущий реальный скор(валидационная часть): 1.4989\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5005 - val_loss: 1.7102 - lr: 1.2500e-04\n",
      "Epoch 52/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4983Текущий реальный скор(валидационная часть): 1.5042\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4951 - val_loss: 1.7147 - lr: 1.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4922Текущий реальный скор(валидационная часть): 1.5085\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 1.7216 - lr: 1.2500e-04\n",
      "Epoch 54/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5359Текущий реальный скор(валидационная часть): 1.4876\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 1.6907 - lr: 6.2500e-05\n",
      "Epoch 55/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5189Текущий реальный скор(валидационная часть): 1.4894\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5123 - val_loss: 1.6909 - lr: 6.2500e-05\n",
      "Epoch 56/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5057Текущий реальный скор(валидационная часть): 1.4914\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5010 - val_loss: 1.6920 - lr: 6.2500e-05\n",
      "Epoch 57/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4924Текущий реальный скор(валидационная часть): 1.4965\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 1.6970 - lr: 6.2500e-05\n",
      "Epoch 58/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4822Текущий реальный скор(валидационная часть): 1.501\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 1.7012 - lr: 6.2500e-05\n",
      "Epoch 59/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4740Текущий реальный скор(валидационная часть): 1.5051\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 1.7047 - lr: 6.2500e-05\n",
      "Epoch 60/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4672Текущий реальный скор(валидационная часть): 1.5091\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 1.7113 - lr: 6.2500e-05\n",
      "Epoch 61/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4601Текущий реальный скор(валидационная часть): 1.5126\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 1.7144 - lr: 6.2500e-05\n",
      "Epoch 62/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4543Текущий реальный скор(валидационная часть): 1.5147\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4535 - val_loss: 1.7165 - lr: 6.2500e-05\n",
      "Epoch 63/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4504- ETA: 0s - loss: 0.41Текущий реальный скор(валидационная часть): 1.5175\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 1.7221 - lr: 6.2500e-05\n",
      "Epoch 64/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4490Текущий реальный скор(валидационная часть): 1.5602\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 1.7704 - lr: 3.1250e-05\n",
      "Epoch 65/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4419Текущий реальный скор(валидационная часть): 1.5623\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 1.7757 - lr: 3.1250e-05\n",
      "Epoch 66/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4359Текущий реальный скор(валидационная часть): 1.5631\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 1.7760 - lr: 3.1250e-05\n",
      "Epoch 67/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4337Текущий реальный скор(валидационная часть): 1.5629\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 1.7765 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4311Текущий реальный скор(валидационная часть): 1.5632\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4299 - val_loss: 1.7767 - lr: 3.1250e-05\n",
      "Epoch 69/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4296Текущий реальный скор(валидационная часть): 1.5627\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4272 - val_loss: 1.7763 - lr: 3.1250e-05\n",
      "Epoch 70/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4242Текущий реальный скор(валидационная часть): 1.563\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4246 - val_loss: 1.7768 - lr: 3.1250e-05\n",
      "Epoch 71/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4229Текущий реальный скор(валидационная часть): 1.5618\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4223 - val_loss: 1.7753 - lr: 3.1250e-05\n",
      "Epoch 72/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4211Текущий реальный скор(валидационная часть): 1.5614\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4200 - val_loss: 1.7753 - lr: 3.1250e-05\n",
      "Epoch 73/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4192Текущий реальный скор(валидационная часть): 1.5609\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4180 - val_loss: 1.7750 - lr: 3.1250e-05\n",
      "Epoch 74/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4176Текущий реальный скор(валидационная часть): 1.5528\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4203 - val_loss: 1.7623 - lr: 1.5625e-05\n",
      "Epoch 75/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4164Текущий реальный скор(валидационная часть): 1.5522\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 1.7617 - lr: 1.5625e-05\n",
      "Epoch 76/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4155Текущий реальный скор(валидационная часть): 1.5511\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4161 - val_loss: 1.7603 - lr: 1.5625e-05\n",
      "Epoch 77/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4138Текущий реальный скор(валидационная часть): 1.5504\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4149 - val_loss: 1.7597 - lr: 1.5625e-05\n",
      "Epoch 78/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4145Текущий реальный скор(валидационная часть): 1.5498\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 1.7592 - lr: 1.5625e-05\n",
      "Epoch 79/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4140Текущий реальный скор(валидационная часть): 1.5489\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4126 - val_loss: 1.7580 - lr: 1.5625e-05\n",
      "Epoch 80/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4106Текущий реальный скор(валидационная часть): 1.5488\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4116 - val_loss: 1.7580 - lr: 1.5625e-05\n",
      "Epoch 81/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4093Текущий реальный скор(валидационная часть): 1.5483\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4106 - val_loss: 1.7576 - lr: 1.5625e-05\n",
      "Epoch 82/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4102Текущий реальный скор(валидационная часть): 1.5478\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4096 - val_loss: 1.7570 - lr: 1.5625e-05\n",
      "Epoch 83/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4098Текущий реальный скор(валидационная часть): 1.5473\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4086 - val_loss: 1.7591 - lr: 1.5625e-05\n",
      "Epoch 84/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4103Текущий реальный скор(валидационная часть): 1.5292\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4114 - val_loss: 1.7366 - lr: 7.8125e-06\n",
      "Epoch 85/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4079Текущий реальный скор(валидационная часть): 1.5304\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4117 - val_loss: 1.7378 - lr: 7.8125e-06\n",
      "Epoch 86/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4100Текущий реальный скор(валидационная часть): 1.5308\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4110 - val_loss: 1.7379 - lr: 7.8125e-06\n",
      "Epoch 87/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4127Текущий реальный скор(валидационная часть): 1.5311\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 1.7379 - lr: 7.8125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4063Текущий реальный скор(валидационная часть): 1.5312\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 1.7379 - lr: 7.8125e-06\n",
      "Epoch 89/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4103Текущий реальный скор(валидационная часть): 1.5314\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 1.7382 - lr: 7.8125e-06\n",
      "Epoch 90/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4075Текущий реальный скор(валидационная часть): 1.5315\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 1.7383 - lr: 7.8125e-06\n",
      "Epoch 91/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4089Текущий реальный скор(валидационная часть): 1.5317\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4081 - val_loss: 1.7383 - lr: 7.8125e-06\n",
      "Epoch 92/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.4073Текущий реальный скор(валидационная часть): 1.5317\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 1.7383 - lr: 7.8125e-06\n",
      "Epoch 93/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4055Текущий реальный скор(валидационная часть): 1.5318\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4070 - val_loss: 1.7384 - lr: 7.8125e-06\n",
      "Epoch 94/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4082Текущий реальный скор(валидационная часть): 1.5391\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4089 - val_loss: 1.7494 - lr: 3.9063e-06\n",
      "Epoch 95/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4060Текущий реальный скор(валидационная часть): 1.5396\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 1.7498 - lr: 3.9063e-06\n",
      "Epoch 96/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4082Текущий реальный скор(валидационная часть): 1.5398\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 1.7499 - lr: 3.9063e-06\n",
      "Epoch 97/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4055Текущий реальный скор(валидационная часть): 1.5399\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 1.7500 - lr: 3.9063e-06\n",
      "Epoch 98/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4029Текущий реальный скор(валидационная часть): 1.54\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 1.7500 - lr: 3.9063e-06\n",
      "Epoch 99/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4081Текущий реальный скор(валидационная часть): 1.5401\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 1.7500 - lr: 3.9063e-06\n",
      "Epoch 100/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4043Текущий реальный скор(валидационная часть): 1.54\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4054 - val_loss: 1.7499 - lr: 3.9063e-06\n",
      "Epoch 101/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4036Текущий реальный скор(валидационная часть): 1.5399\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4051 - val_loss: 1.7498 - lr: 3.9063e-06\n",
      "Epoch 102/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4055Текущий реальный скор(валидационная часть): 1.5399\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 1.7497 - lr: 3.9063e-06\n",
      "Epoch 103/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4056Текущий реальный скор(валидационная часть): 1.5399\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 1.7497 - lr: 3.9063e-06\n",
      "Epoch 104/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.4050Текущий реальный скор(валидационная часть): 1.5472\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 1.7581 - lr: 1.9531e-06\n",
      "Epoch 105/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4029Текущий реальный скор(валидационная часть): 1.5485\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4031 - val_loss: 1.7596 - lr: 1.9531e-06\n",
      "Epoch 106/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3986Текущий реальный скор(валидационная часть): 1.5487\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4028 - val_loss: 1.7598 - lr: 1.9531e-06\n",
      "Epoch 107/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4036Текущий реальный скор(валидационная часть): 1.5488\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4026 - val_loss: 1.7598 - lr: 1.9531e-06\n",
      "Epoch 108/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4012Текущий реальный скор(валидационная часть): 1.5487\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4024 - val_loss: 1.7598 - lr: 1.9531e-06\n",
      "Epoch 109/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4029Текущий реальный скор(валидационная часть): 1.5486\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4023 - val_loss: 1.7597 - lr: 1.9531e-06\n",
      "Epoch 110/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4027Текущий реальный скор(валидационная часть): 1.5486\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4021 - val_loss: 1.7596 - lr: 1.9531e-06\n",
      "Epoch 111/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4041Текущий реальный скор(валидационная часть): 1.5485\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 1.7596 - lr: 1.9531e-06\n",
      "Epoch 112/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4021Текущий реальный скор(валидационная часть): 1.5485\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 1.7594 - lr: 1.9531e-06\n",
      "Epoch 113/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3974Текущий реальный скор(валидационная часть): 1.5485\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4017 - val_loss: 1.7595 - lr: 1.9531e-06\n",
      "Epoch 114/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3999Текущий реальный скор(валидационная часть): 1.5514\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4012 - val_loss: 1.7628 - lr: 9.7656e-07\n",
      "Epoch 115/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4016Текущий реальный скор(валидационная часть): 1.5526\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 1.7641 - lr: 9.7656e-07\n",
      "Epoch 116/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3985Текущий реальный скор(валидационная часть): 1.5531\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4006 - val_loss: 1.7646 - lr: 9.7656e-07\n",
      "Epoch 117/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4024Текущий реальный скор(валидационная часть): 1.5532\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4005 - val_loss: 1.7648 - lr: 9.7656e-07\n",
      "Epoch 118/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3986Текущий реальный скор(валидационная часть): 1.5533\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4004 - val_loss: 1.7648 - lr: 9.7656e-07\n",
      "Epoch 119/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4009Текущий реальный скор(валидационная часть): 1.5533\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4003 - val_loss: 1.7648 - lr: 9.7656e-07\n",
      "Epoch 120/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3984Текущий реальный скор(валидационная часть): 1.5533\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4002 - val_loss: 1.7648 - lr: 9.7656e-07\n",
      "Epoch 121/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4000Текущий реальный скор(валидационная часть): 1.5533\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 1.7648 - lr: 9.7656e-07\n",
      "Epoch 122/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.3995Текущий реальный скор(валидационная часть): 1.5532\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 1.7647 - lr: 9.7656e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4006Текущий реальный скор(валидационная часть): 1.3904\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4000 - val_loss: 1.7647 - lr: 9.7656e-07\n",
      "Скор для фолда(10) : 1.3904 средний скор на префиксе = 1.3261 это заняло = 31 сек.\n",
      "Фолд: 11\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 4.0043Текущий реальный скор(валидационная часть): 2.5777\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.7981 - val_loss: 2.6425 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.9439Текущий реальный скор(валидационная часть): 2.0137\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9245 - val_loss: 2.0874 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 1.6209Текущий реальный скор(валидационная часть): 1.8754\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6106 - val_loss: 1.9630 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 1.4696Текущий реальный скор(валидационная часть): 1.8478\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4719 - val_loss: 1.9380 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 1.3762Текущий реальный скор(валидационная часть): 1.7632\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3813 - val_loss: 1.8522 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.3163Текущий реальный скор(валидационная часть): 1.6921\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3189 - val_loss: 1.7753 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.2579Текущий реальный скор(валидационная часть): 1.656\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2581 - val_loss: 1.7471 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.2001Текущий реальный скор(валидационная часть): 1.6868\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2010 - val_loss: 1.7724 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.1485Текущий реальный скор(валидационная часть): 1.6986\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1515 - val_loss: 1.7805 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 1.1080Текущий реальный скор(валидационная часть): 1.6665\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1135 - val_loss: 1.7604 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.0858Текущий реальный скор(валидационная часть): 1.6398\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0830 - val_loss: 1.7480 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 1.0422Текущий реальный скор(валидационная часть): 1.6481\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0457 - val_loss: 1.7607 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.0129Текущий реальный скор(валидационная часть): 1.6627\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0124 - val_loss: 1.7720 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.9828Текущий реальный скор(валидационная часть): 1.6469\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9838 - val_loss: 1.7508 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.9632Текущий реальный скор(валидационная часть): 1.6738\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9615 - val_loss: 1.7655 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.9469Текущий реальный скор(валидационная часть): 1.7189\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 1.8056 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.9342Текущий реальный скор(валидационная часть): 1.823\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 1.8819 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.9793Текущий реальный скор(валидационная часть): 1.68\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9793 - val_loss: 1.7678 - lr: 2.5000e-04\n",
      "Epoch 19/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.9258Текущий реальный скор(валидационная часть): 1.7192\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 1.7964 - lr: 2.5000e-04\n",
      "Epoch 20/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.8898Текущий реальный скор(валидационная часть): 1.79\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8885 - val_loss: 1.8504 - lr: 2.5000e-04\n",
      "Epoch 21/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.8577Текущий реальный скор(валидационная часть): 1.8465\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8589 - val_loss: 1.9007 - lr: 2.5000e-04\n",
      "Epoch 22/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8403Текущий реальный скор(валидационная часть): 1.9012\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8405 - val_loss: 1.9561 - lr: 2.5000e-04\n",
      "Epoch 23/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8256Текущий реальный скор(валидационная часть): 1.9371\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8252 - val_loss: 2.0034 - lr: 2.5000e-04\n",
      "Epoch 24/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8122Текущий реальный скор(валидационная часть): 1.9546\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8111 - val_loss: 2.0054 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.7890Текущий реальный скор(валидационная часть): 2.0204\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7941 - val_loss: 2.0825 - lr: 2.5000e-04\n",
      "Epoch 26/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.7791Текущий реальный скор(валидационная часть): 2.0212\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7742 - val_loss: 2.0850 - lr: 2.5000e-04\n",
      "Epoch 27/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.7475Текущий реальный скор(валидационная часть): 2.045\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7518 - val_loss: 2.1070 - lr: 2.5000e-04\n",
      "Epoch 28/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.7433Текущий реальный скор(валидационная часть): 1.785\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7460 - val_loss: 1.8628 - lr: 1.2500e-04\n",
      "Epoch 29/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.6968Текущий реальный скор(валидационная часть): 1.8083\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6988 - val_loss: 1.8786 - lr: 1.2500e-04\n",
      "Epoch 30/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.6730Текущий реальный скор(валидационная часть): 1.8206\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6735 - val_loss: 1.8916 - lr: 1.2500e-04\n",
      "Epoch 31/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.6535Текущий реальный скор(валидационная часть): 1.8263\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6557 - val_loss: 1.8962 - lr: 1.2500e-04\n",
      "Epoch 32/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.6385Текущий реальный скор(валидационная часть): 1.832\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6422 - val_loss: 1.9034 - lr: 1.2500e-04\n",
      "Epoch 33/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6333Текущий реальный скор(валидационная часть): 1.8002\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 1.8618 - lr: 1.2500e-04\n",
      "Epoch 34/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.6275Текущий реальный скор(валидационная часть): 1.8311\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6267 - val_loss: 1.9037 - lr: 1.2500e-04\n",
      "Epoch 35/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.6101Текущий реальный скор(валидационная часть): 1.8338\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 1.9026 - lr: 1.2500e-04\n",
      "Epoch 36/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.6011Текущий реальный скор(валидационная часть): 1.8381\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 1.9053 - lr: 1.2500e-04\n",
      "Epoch 37/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5942Текущий реальный скор(валидационная часть): 1.8433\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5975 - val_loss: 1.9087 - lr: 1.2500e-04\n",
      "Epoch 38/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5929Текущий реальный скор(валидационная часть): 1.7878\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5946 - val_loss: 1.8624 - lr: 6.2500e-05\n",
      "Epoch 39/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5867Текущий реальный скор(валидационная часть): 1.7821\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5921 - val_loss: 1.8576 - lr: 6.2500e-05\n",
      "Epoch 40/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5807Текущий реальный скор(валидационная часть): 1.7808\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5874 - val_loss: 1.8558 - lr: 6.2500e-05\n",
      "Epoch 41/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5766Текущий реальный скор(валидационная часть): 1.7793\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5831 - val_loss: 1.8546 - lr: 6.2500e-05\n",
      "Epoch 42/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5770Текущий реальный скор(валидационная часть): 1.7762\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5792 - val_loss: 1.8535 - lr: 6.2500e-05\n",
      "Epoch 43/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5665Текущий реальный скор(валидационная часть): 1.7736\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5744 - val_loss: 1.8476 - lr: 6.2500e-05\n",
      "Epoch 44/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5637Текущий реальный скор(валидационная часть): 1.7744\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5704 - val_loss: 1.8483 - lr: 6.2500e-05\n",
      "Epoch 45/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5619Текущий реальный скор(валидационная часть): 1.774\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5663 - val_loss: 1.8477 - lr: 6.2500e-05\n",
      "Epoch 46/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5609Текущий реальный скор(валидационная часть): 1.7736\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5628 - val_loss: 1.8466 - lr: 6.2500e-05\n",
      "Epoch 47/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5525Текущий реальный скор(валидационная часть): 1.7731\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5593 - val_loss: 1.8462 - lr: 6.2500e-05\n",
      "Epoch 48/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5548Текущий реальный скор(валидационная часть): 1.7326\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5613 - val_loss: 1.8119 - lr: 3.1250e-05\n",
      "Epoch 49/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5544Текущий реальный скор(валидационная часть): 1.7338\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5605 - val_loss: 1.8122 - lr: 3.1250e-05\n",
      "Epoch 50/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5537Текущий реальный скор(валидационная часть): 1.7343\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5573 - val_loss: 1.8121 - lr: 3.1250e-05\n",
      "Epoch 51/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5485Текущий реальный скор(валидационная часть): 1.7341\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5544 - val_loss: 1.8137 - lr: 3.1250e-05\n",
      "Epoch 52/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5461Текущий реальный скор(валидационная часть): 1.7338\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 1.8124 - lr: 3.1250e-05\n",
      "Epoch 53/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5439Текущий реальный скор(валидационная часть): 1.7337\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5496 - val_loss: 1.8117 - lr: 3.1250e-05\n",
      "Epoch 54/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5417Текущий реальный скор(валидационная часть): 1.7335\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5474 - val_loss: 1.8107 - lr: 3.1250e-05\n",
      "Epoch 55/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5397Текущий реальный скор(валидационная часть): 1.7335\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5454 - val_loss: 1.8104 - lr: 3.1250e-05\n",
      "Epoch 56/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5414Текущий реальный скор(валидационная часть): 1.7329\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5433 - val_loss: 1.8094 - lr: 3.1250e-05\n",
      "Epoch 57/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5354Текущий реальный скор(валидационная часть): 1.7334\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5412 - val_loss: 1.8094 - lr: 3.1250e-05\n",
      "Epoch 58/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5389Текущий реальный скор(валидационная часть): 1.7388\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5403 - val_loss: 1.8115 - lr: 1.5625e-05\n",
      "Epoch 59/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5378Текущий реальный скор(валидационная часть): 1.738\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 1.8105 - lr: 1.5625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5348Текущий реальный скор(валидационная часть): 1.7373\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 1.8095 - lr: 1.5625e-05\n",
      "Epoch 61/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5357Текущий реальный скор(валидационная часть): 1.7363\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5353 - val_loss: 1.8084 - lr: 1.5625e-05\n",
      "Epoch 62/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5289Текущий реальный скор(валидационная часть): 1.7361\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5341 - val_loss: 1.8079 - lr: 1.5625e-05\n",
      "Epoch 63/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5331Текущий реальный скор(валидационная часть): 1.7354\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5329 - val_loss: 1.8070 - lr: 1.5625e-05\n",
      "Epoch 64/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5296Текущий реальный скор(валидационная часть): 1.7349\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 1.8064 - lr: 1.5625e-05\n",
      "Epoch 65/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5257Текущий реальный скор(валидационная часть): 1.7346\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 1.8058 - lr: 1.5625e-05\n",
      "Epoch 66/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5247Текущий реальный скор(валидационная часть): 1.7338\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 1.8050 - lr: 1.5625e-05\n",
      "Epoch 67/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5269Текущий реальный скор(валидационная часть): 1.7338\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5287 - val_loss: 1.8048 - lr: 1.5625e-05\n",
      "Epoch 68/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5282Текущий реальный скор(валидационная часть): 1.7313\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5300 - val_loss: 1.8005 - lr: 7.8125e-06\n",
      "Epoch 69/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5267Текущий реальный скор(валидационная часть): 1.7307\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 1.8000 - lr: 7.8125e-06\n",
      "Epoch 70/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5223Текущий реальный скор(валидационная часть): 1.7304\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 1.7998 - lr: 7.8125e-06\n",
      "Epoch 71/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5263Текущий реальный скор(валидационная часть): 1.7301\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 1.7997 - lr: 7.8125e-06\n",
      "Epoch 72/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5242Текущий реальный скор(валидационная часть): 1.73\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 1.7997 - lr: 7.8125e-06\n",
      "Epoch 73/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5217Текущий реальный скор(валидационная часть): 1.7299\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.7997 - lr: 7.8125e-06\n",
      "Epoch 74/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5231Текущий реальный скор(валидационная часть): 1.7298\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.7997 - lr: 7.8125e-06\n",
      "Epoch 75/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5229Текущий реальный скор(валидационная часть): 1.7296\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.7997 - lr: 7.8125e-06\n",
      "Epoch 76/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5219Текущий реальный скор(валидационная часть): 1.7296\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.7997 - lr: 7.8125e-06\n",
      "Epoch 77/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.5227Текущий реальный скор(валидационная часть): 1.7295\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.7997 - lr: 7.8125e-06\n",
      "Epoch 78/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5205Текущий реальный скор(валидационная часть): 1.7393\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.8062 - lr: 3.9063e-06\n",
      "Epoch 79/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5193Текущий реальный скор(валидационная часть): 1.7397\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.8066 - lr: 3.9063e-06\n",
      "Epoch 80/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5188Текущий реальный скор(валидационная часть): 1.7399\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.8069 - lr: 3.9063e-06\n",
      "Epoch 81/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5209Текущий реальный скор(валидационная часть): 1.74\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.8070 - lr: 3.9063e-06\n",
      "Epoch 82/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5208Текущий реальный скор(валидационная часть): 1.7402\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.8073 - lr: 3.9063e-06\n",
      "Epoch 83/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5173Текущий реальный скор(валидационная часть): 1.7401\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5226 - val_loss: 1.8074 - lr: 3.9063e-06\n",
      "Epoch 84/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5201Текущий реальный скор(валидационная часть): 1.7403\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 1.8076 - lr: 3.9063e-06\n",
      "Epoch 85/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5173Текущий реальный скор(валидационная часть): 1.7403\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5220 - val_loss: 1.8077 - lr: 3.9063e-06\n",
      "Epoch 86/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5169Текущий реальный скор(валидационная часть): 1.7403\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5217 - val_loss: 1.8077 - lr: 3.9063e-06\n",
      "Epoch 87/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5167Текущий реальный скор(валидационная часть): 1.7401\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5214 - val_loss: 1.8077 - lr: 3.9063e-06\n",
      "Epoch 88/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5195Текущий реальный скор(валидационная часть): 1.7513\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 1.8168 - lr: 1.9531e-06\n",
      "Epoch 89/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5169Текущий реальный скор(валидационная часть): 1.7526\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5206 - val_loss: 1.8180 - lr: 1.9531e-06\n",
      "Epoch 90/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5181Текущий реальный скор(валидационная часть): 1.7528\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 1.8181 - lr: 1.9531e-06\n",
      "Epoch 91/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5196Текущий реальный скор(валидационная часть): 1.7529\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5201 - val_loss: 1.8182 - lr: 1.9531e-06\n",
      "Epoch 92/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5143Текущий реальный скор(валидационная часть): 1.7528\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5199 - val_loss: 1.8209 - lr: 1.9531e-06\n",
      "Epoch 93/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5172Текущий реальный скор(валидационная часть): 1.7528\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 1.8209 - lr: 1.9531e-06\n",
      "Epoch 94/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5140Текущий реальный скор(валидационная часть): 1.7528\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5196 - val_loss: 1.8208 - lr: 1.9531e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5169Текущий реальный скор(валидационная часть): 1.7528\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5195 - val_loss: 1.8209 - lr: 1.9531e-06\n",
      "Epoch 96/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5167Текущий реальный скор(валидационная часть): 1.7527\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5193 - val_loss: 1.8208 - lr: 1.9531e-06\n",
      "Epoch 97/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5166Текущий реальный скор(валидационная часть): 1.7526\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5192 - val_loss: 1.8208 - lr: 1.9531e-06\n",
      "Epoch 98/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5151Текущий реальный скор(валидационная часть): 1.7565\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5188 - val_loss: 1.8241 - lr: 9.7656e-07\n",
      "Epoch 99/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5186Текущий реальный скор(валидационная часть): 1.7578\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5184 - val_loss: 1.8252 - lr: 9.7656e-07\n",
      "Epoch 100/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5160Текущий реальный скор(валидационная часть): 1.7582\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5183 - val_loss: 1.8255 - lr: 9.7656e-07\n",
      "Epoch 101/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5183Текущий реальный скор(валидационная часть): 1.7583\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5182 - val_loss: 1.8256 - lr: 9.7656e-07\n",
      "Epoch 102/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 0.5193Текущий реальный скор(валидационная часть): 1.7583\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5181 - val_loss: 1.8256 - lr: 9.7656e-07\n",
      "Epoch 103/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5131Текущий реальный скор(валидационная часть): 1.7583\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5180 - val_loss: 1.8256 - lr: 9.7656e-07\n",
      "Epoch 104/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5121Текущий реальный скор(валидационная часть): 1.7583\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5179 - val_loss: 1.8256 - lr: 9.7656e-07\n",
      "Epoch 105/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5172Текущий реальный скор(валидационная часть): 1.7582\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5179 - val_loss: 1.8255 - lr: 9.7656e-07\n",
      "Epoch 106/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5119Текущий реальный скор(валидационная часть): 1.7582\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 1.8255 - lr: 9.7656e-07\n",
      "Epoch 107/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5150Текущий реальный скор(валидационная часть): 1.656\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5177 - val_loss: 1.8255 - lr: 9.7656e-07\n",
      "Скор для фолда(11) : 1.656 средний скор на префиксе = 1.3536 это заняло = 27 сек.\n",
      "Фолд: 12\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 4.0351Текущий реальный скор(валидационная часть): 2.1459\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8235 - val_loss: 2.2433 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.9777Текущий реальный скор(валидационная часть): 1.6335\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9577 - val_loss: 1.7375 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.6746Текущий реальный скор(валидационная часть): 1.5637\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6568 - val_loss: 1.6890 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.5041Текущий реальный скор(валидационная часть): 1.4983\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4974 - val_loss: 1.6279 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.4069Текущий реальный скор(валидационная часть): 1.4749\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3969 - val_loss: 1.6054 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.3428Текущий реальный скор(валидационная часть): 1.5098\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3283 - val_loss: 1.6312 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 1.2743Текущий реальный скор(валидационная часть): 1.522\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2618 - val_loss: 1.6391 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.2092Текущий реальный скор(валидационная часть): 1.5235\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2072 - val_loss: 1.6314 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.1851Текущий реальный скор(валидационная часть): 1.5365\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1678 - val_loss: 1.6440 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.1271Текущий реальный скор(валидационная часть): 1.5449\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1202 - val_loss: 1.6491 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.0818Текущий реальный скор(валидационная часть): 1.5274\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0771 - val_loss: 1.6326 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.0458Текущий реальный скор(валидационная часть): 1.5295\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0452 - val_loss: 1.6425 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.0142Текущий реальный скор(валидационная часть): 1.5347\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0130 - val_loss: 1.6514 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 1.0120Текущий реальный скор(валидационная часть): 1.5783\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0040 - val_loss: 1.6908 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.9868Текущий реальный скор(валидационная часть): 1.6952\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9897 - val_loss: 1.7930 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.9846Текущий реальный скор(валидационная часть): 1.5525\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9822 - val_loss: 1.6589 - lr: 2.5000e-04\n",
      "Epoch 17/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.9286Текущий реальный скор(валидационная часть): 1.5686\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9248 - val_loss: 1.6865 - lr: 2.5000e-04\n",
      "Epoch 18/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.8914Текущий реальный скор(валидационная часть): 1.5817\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8931 - val_loss: 1.6844 - lr: 2.5000e-04\n",
      "Epoch 19/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.8720Текущий реальный скор(валидационная часть): 1.5969\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8616 - val_loss: 1.6955 - lr: 2.5000e-04\n",
      "Epoch 20/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.8406Текущий реальный скор(валидационная часть): 1.6144\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8372 - val_loss: 1.7129 - lr: 2.5000e-04\n",
      "Epoch 21/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.8202Текущий реальный скор(валидационная часть): 1.6356\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8174 - val_loss: 1.7347 - lr: 2.5000e-04\n",
      "Epoch 22/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.8006Текущий реальный скор(валидационная часть): 1.5939\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8005 - val_loss: 1.6996 - lr: 2.5000e-04\n",
      "Epoch 23/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.7858Текущий реальный скор(валидационная часть): 1.6186\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7831 - val_loss: 1.7170 - lr: 2.5000e-04\n",
      "Epoch 24/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.7640Текущий реальный скор(валидационная часть): 1.6582\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7656 - val_loss: 1.7499 - lr: 2.5000e-04\n",
      "Epoch 25/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.7524Текущий реальный скор(валидационная часть): 1.6825\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7501 - val_loss: 1.7701 - lr: 2.5000e-04\n",
      "Epoch 26/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.7799Текущий реальный скор(валидационная часть): 1.6291\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8016 - val_loss: 1.7306 - lr: 1.2500e-04\n",
      "Epoch 27/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.7624Текущий реальный скор(валидационная часть): 1.5891\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7719 - val_loss: 1.6920 - lr: 1.2500e-04\n",
      "Epoch 28/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.7265Текущий реальный скор(валидационная часть): 1.5765\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7378 - val_loss: 1.6801 - lr: 1.2500e-04\n",
      "Epoch 29/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.7098Текущий реальный скор(валидационная часть): 1.5517\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7184 - val_loss: 1.6581 - lr: 1.2500e-04\n",
      "Epoch 30/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.6940Текущий реальный скор(валидационная часть): 1.5497\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7030 - val_loss: 1.6579 - lr: 1.2500e-04\n",
      "Epoch 31/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.6794Текущий реальный скор(валидационная часть): 1.544\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6888 - val_loss: 1.6524 - lr: 1.2500e-04\n",
      "Epoch 32/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.6669Текущий реальный скор(валидационная часть): 1.5424\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6768 - val_loss: 1.6500 - lr: 1.2500e-04\n",
      "Epoch 33/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.6605Текущий реальный скор(валидационная часть): 1.54\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6661 - val_loss: 1.6494 - lr: 1.2500e-04\n",
      "Epoch 34/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.6558Текущий реальный скор(валидационная часть): 1.5412\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6560 - val_loss: 1.6562 - lr: 1.2500e-04\n",
      "Epoch 35/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.6474Текущий реальный скор(валидационная часть): 1.5423\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6472 - val_loss: 1.6553 - lr: 1.2500e-04\n",
      "Epoch 36/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6414Текущий реальный скор(валидационная часть): 1.4755\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6487 - val_loss: 1.6008 - lr: 6.2500e-05\n",
      "Epoch 37/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.6503Текущий реальный скор(валидационная часть): 1.4788\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6518 - val_loss: 1.6034 - lr: 6.2500e-05\n",
      "Epoch 38/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.6414Текущий реальный скор(валидационная часть): 1.4809\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6427 - val_loss: 1.6058 - lr: 6.2500e-05\n",
      "Epoch 39/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.6343Текущий реальный скор(валидационная часть): 1.4839\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6355 - val_loss: 1.6093 - lr: 6.2500e-05\n",
      "Epoch 40/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.6267Текущий реальный скор(валидационная часть): 1.4847\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 1.6094 - lr: 6.2500e-05\n",
      "Epoch 41/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.6266Текущий реальный скор(валидационная часть): 1.4866\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6240 - val_loss: 1.6105 - lr: 6.2500e-05\n",
      "Epoch 42/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6157Текущий реальный скор(валидационная часть): 1.4887\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 1.6118 - lr: 6.2500e-05\n",
      "Epoch 43/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.6114Текущий реальный скор(валидационная часть): 1.4902\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6142 - val_loss: 1.6125 - lr: 6.2500e-05\n",
      "Epoch 44/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6071Текущий реальный скор(валидационная часть): 1.4921\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 1.6138 - lr: 6.2500e-05\n",
      "Epoch 45/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.6033Текущий реальный скор(валидационная часть): 1.4935\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 1.6143 - lr: 6.2500e-05\n",
      "Epoch 46/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5994Текущий реальный скор(валидационная часть): 1.4947\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 1.6148 - lr: 6.2500e-05\n",
      "Epoch 47/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.6108Текущий реальный скор(валидационная часть): 1.5049\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 1.6213 - lr: 3.1250e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.6047Текущий реальный скор(валидационная часть): 1.5084\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 1.6256 - lr: 3.1250e-05\n",
      "Epoch 49/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5995Текущий реальный скор(валидационная часть): 1.5119\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5981 - val_loss: 1.6293 - lr: 3.1250e-05\n",
      "Epoch 50/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.6002Текущий реальный скор(валидационная часть): 1.5139\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5943 - val_loss: 1.6318 - lr: 3.1250e-05\n",
      "Epoch 51/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5940Текущий реальный скор(валидационная часть): 1.5164\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5907 - val_loss: 1.6341 - lr: 3.1250e-05\n",
      "Epoch 52/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5913Текущий реальный скор(валидационная часть): 1.5186\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5873 - val_loss: 1.6365 - lr: 3.1250e-05\n",
      "Epoch 53/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5851Текущий реальный скор(валидационная часть): 1.5225\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5836 - val_loss: 1.6403 - lr: 3.1250e-05\n",
      "Epoch 54/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5842Текущий реальный скор(валидационная часть): 1.5247\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5801 - val_loss: 1.6429 - lr: 3.1250e-05\n",
      "Epoch 55/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5802Текущий реальный скор(валидационная часть): 1.5257\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5771 - val_loss: 1.6470 - lr: 3.1250e-05\n",
      "Epoch 56/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5792Текущий реальный скор(валидационная часть): 1.5272\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5745 - val_loss: 1.6487 - lr: 3.1250e-05\n",
      "Epoch 57/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5767Текущий реальный скор(валидационная часть): 1.558\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5753 - val_loss: 1.6769 - lr: 1.5625e-05\n",
      "Epoch 58/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5766Текущий реальный скор(валидационная часть): 1.5571\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5719 - val_loss: 1.6767 - lr: 1.5625e-05\n",
      "Epoch 59/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5731Текущий реальный скор(валидационная часть): 1.5565\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5700 - val_loss: 1.6767 - lr: 1.5625e-05\n",
      "Epoch 60/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5764Текущий реальный скор(валидационная часть): 1.5561\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5683 - val_loss: 1.6766 - lr: 1.5625e-05\n",
      "Epoch 61/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5684Текущий реальный скор(валидационная часть): 1.5555\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5667 - val_loss: 1.6764 - lr: 1.5625e-05\n",
      "Epoch 62/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5687Текущий реальный скор(валидационная часть): 1.5552\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5653 - val_loss: 1.6764 - lr: 1.5625e-05\n",
      "Epoch 63/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5656Текущий реальный скор(валидационная часть): 1.5551\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5639 - val_loss: 1.6766 - lr: 1.5625e-05\n",
      "Epoch 64/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5677Текущий реальный скор(валидационная часть): 1.5547\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5625 - val_loss: 1.6764 - lr: 1.5625e-05\n",
      "Epoch 65/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5649Текущий реальный скор(валидационная часть): 1.5541\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5612 - val_loss: 1.6761 - lr: 1.5625e-05\n",
      "Epoch 66/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5619Текущий реальный скор(валидационная часть): 1.5543\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5599 - val_loss: 1.6764 - lr: 1.5625e-05\n",
      "Epoch 67/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5609Текущий реальный скор(валидационная часть): 1.5637\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5579 - val_loss: 1.6851 - lr: 7.8125e-06\n",
      "Epoch 68/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5622Текущий реальный скор(валидационная часть): 1.5632\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5559 - val_loss: 1.6848 - lr: 7.8125e-06\n",
      "Epoch 69/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5594Текущий реальный скор(валидационная часть): 1.5625\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5551 - val_loss: 1.6842 - lr: 7.8125e-06\n",
      "Epoch 70/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5605Текущий реальный скор(валидационная часть): 1.5619\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5544 - val_loss: 1.6837 - lr: 7.8125e-06\n",
      "Epoch 71/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5576Текущий реальный скор(валидационная часть): 1.5616\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5537 - val_loss: 1.6834 - lr: 7.8125e-06\n",
      "Epoch 72/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5592Текущий реальный скор(валидационная часть): 1.5611\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5530 - val_loss: 1.6830 - lr: 7.8125e-06\n",
      "Epoch 73/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5547Текущий реальный скор(валидационная часть): 1.5608\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5524 - val_loss: 1.6827 - lr: 7.8125e-06\n",
      "Epoch 74/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5570Текущий реальный скор(валидационная часть): 1.5605\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5518 - val_loss: 1.6826 - lr: 7.8125e-06\n",
      "Epoch 75/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5536Текущий реальный скор(валидационная часть): 1.5604\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5511 - val_loss: 1.6825 - lr: 7.8125e-06\n",
      "Epoch 76/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5573Текущий реальный скор(валидационная часть): 1.5602\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5505 - val_loss: 1.6824 - lr: 7.8125e-06\n",
      "Epoch 77/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5518Текущий реальный скор(валидационная часть): 1.5619\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5487 - val_loss: 1.6849 - lr: 3.9063e-06\n",
      "Epoch 78/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5545Текущий реальный скор(валидационная часть): 1.5626\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5480 - val_loss: 1.6856 - lr: 3.9063e-06\n",
      "Epoch 79/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5501Текущий реальный скор(валидационная часть): 1.5626\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5477 - val_loss: 1.6857 - lr: 3.9063e-06\n",
      "Epoch 80/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5538Текущий реальный скор(валидационная часть): 1.5625\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5473 - val_loss: 1.6857 - lr: 3.9063e-06\n",
      "Epoch 81/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5501Текущий реальный скор(валидационная часть): 1.5624\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5470 - val_loss: 1.6856 - lr: 3.9063e-06\n",
      "Epoch 82/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5559Текущий реальный скор(валидационная часть): 1.5624\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5467 - val_loss: 1.6856 - lr: 3.9063e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5489Текущий реальный скор(валидационная часть): 1.5623\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5464 - val_loss: 1.6856 - lr: 3.9063e-06\n",
      "Epoch 84/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5506Текущий реальный скор(валидационная часть): 1.5622\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5461 - val_loss: 1.6855 - lr: 3.9063e-06\n",
      "Epoch 85/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5519Текущий реальный скор(валидационная часть): 1.5619\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 1.6853 - lr: 3.9063e-06\n",
      "Epoch 86/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5476Текущий реальный скор(валидационная часть): 1.5619\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5451 - val_loss: 1.6854 - lr: 3.9063e-06\n",
      "Epoch 87/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5462Текущий реальный скор(валидационная часть): 1.5647\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 1.6875 - lr: 1.9531e-06\n",
      "Epoch 88/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5458Текущий реальный скор(валидационная часть): 1.5655\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5434 - val_loss: 1.6882 - lr: 1.9531e-06\n",
      "Epoch 89/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5496Текущий реальный скор(валидационная часть): 1.5659\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5430 - val_loss: 1.6886 - lr: 1.9531e-06\n",
      "Epoch 90/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5452Текущий реальный скор(валидационная часть): 1.566\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 1.6888 - lr: 1.9531e-06\n",
      "Epoch 91/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5457Текущий реальный скор(валидационная часть): 1.5661\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 1.6889 - lr: 1.9531e-06\n",
      "Epoch 92/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5448Текущий реальный скор(валидационная часть): 1.5662\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5424 - val_loss: 1.6890 - lr: 1.9531e-06\n",
      "Epoch 93/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5519Текущий реальный скор(валидационная часть): 1.5663\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5422 - val_loss: 1.6890 - lr: 1.9531e-06\n",
      "Epoch 94/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5445- ETA: 0s - loss: 0.542Текущий реальный скор(валидационная часть): 1.5663\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5420 - val_loss: 1.6890 - lr: 1.9531e-06\n",
      "Epoch 95/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5515Текущий реальный скор(валидационная часть): 1.5663\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 1.6891 - lr: 1.9531e-06\n",
      "Epoch 96/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5460Текущий реальный скор(валидационная часть): 1.5663\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 1.6891 - lr: 1.9531e-06\n",
      "Epoch 97/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5506Текущий реальный скор(валидационная часть): 1.5675\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 1.6900 - lr: 9.7656e-07\n",
      "Epoch 98/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5439Текущий реальный скор(валидационная часть): 1.568\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5408 - val_loss: 1.6903 - lr: 9.7656e-07\n",
      "Epoch 99/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5472Текущий реальный скор(валидационная часть): 1.5682\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5407 - val_loss: 1.6905 - lr: 9.7656e-07\n",
      "Epoch 100/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5468Текущий реальный скор(валидационная часть): 1.5683\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5406 - val_loss: 1.6906 - lr: 9.7656e-07\n",
      "Epoch 101/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5466Текущий реальный скор(валидационная часть): 1.5683\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 1.6907 - lr: 9.7656e-07\n",
      "Epoch 102/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5435Текущий реальный скор(валидационная часть): 1.5684\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5404 - val_loss: 1.6907 - lr: 9.7656e-07\n",
      "Epoch 103/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5464Текущий реальный скор(валидационная часть): 1.5684\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5404 - val_loss: 1.6907 - lr: 9.7656e-07\n",
      "Epoch 104/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5433Текущий реальный скор(валидационная часть): 1.5684\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5403 - val_loss: 1.6907 - lr: 9.7656e-07\n",
      "Epoch 105/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5497Текущий реальный скор(валидационная часть): 1.5684\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5402 - val_loss: 1.6907 - lr: 9.7656e-07\n",
      "Epoch 106/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5485Текущий реальный скор(валидационная часть): 1.5684\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5401 - val_loss: 1.6907 - lr: 9.7656e-07\n",
      "Epoch 107/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5500Текущий реальный скор(валидационная часть): 1.5687\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 1.6910 - lr: 4.8828e-07\n",
      "Epoch 108/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5419Текущий реальный скор(валидационная часть): 1.569\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 1.6912 - lr: 4.8828e-07\n",
      "Epoch 109/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5460Текущий реальный скор(валидационная часть): 1.5691\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5396 - val_loss: 1.6913 - lr: 4.8828e-07\n",
      "Epoch 110/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5426Текущий реальный скор(валидационная часть): 1.5692\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5396 - val_loss: 1.6914 - lr: 4.8828e-07\n",
      "Epoch 111/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5490Текущий реальный скор(валидационная часть): 1.5692\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 1.6914 - lr: 4.8828e-07\n",
      "Epoch 112/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5481Текущий реальный скор(валидационная часть): 1.5693\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 1.6915 - lr: 4.8828e-07\n",
      "Epoch 113/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5478Текущий реальный скор(валидационная часть): 1.5693\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 1.6915 - lr: 4.8828e-07\n",
      "Epoch 114/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5417Текущий реальный скор(валидационная часть): 1.5693\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 1.6915 - lr: 4.8828e-07\n",
      "Epoch 115/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5489Текущий реальный скор(валидационная часть): 1.5694\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5393 - val_loss: 1.6915 - lr: 4.8828e-07\n",
      "Epoch 116/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5435Текущий реальный скор(валидационная часть): 1.5694\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5393 - val_loss: 1.6916 - lr: 4.8828e-07\n",
      "Epoch 117/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5453Текущий реальный скор(валидационная часть): 1.5695\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 1.6917 - lr: 2.4414e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5413Текущий реальный скор(валидационная часть): 1.5696\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 1.6917 - lr: 2.4414e-07\n",
      "Epoch 119/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5413Текущий реальный скор(валидационная часть): 1.5697\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 1.6918 - lr: 2.4414e-07\n",
      "Epoch 120/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5420Текущий реальный скор(валидационная часть): 1.5697\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5390 - val_loss: 1.6918 - lr: 2.4414e-07\n",
      "Epoch 121/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5450Текущий реальный скор(валидационная часть): 1.5698\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5390 - val_loss: 1.6919 - lr: 2.4414e-07\n",
      "Epoch 122/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5412Текущий реальный скор(валидационная часть): 1.5698\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5390 - val_loss: 1.6919 - lr: 2.4414e-07\n",
      "Epoch 123/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5474Текущий реальный скор(валидационная часть): 1.5698\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5390 - val_loss: 1.6919 - lr: 2.4414e-07\n",
      "Epoch 124/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5412Текущий реальный скор(валидационная часть): 1.5699\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5390 - val_loss: 1.6920 - lr: 2.4414e-07\n",
      "Epoch 125/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5451Текущий реальный скор(валидационная часть): 1.5699\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 1.6920 - lr: 2.4414e-07\n",
      "Epoch 126/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5413Текущий реальный скор(валидационная часть): 1.5699\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 1.6920 - lr: 2.4414e-07\n",
      "Epoch 127/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5430Текущий реальный скор(валидационная часть): 1.57\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 1.6920 - lr: 1.2207e-07\n",
      "Epoch 128/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5427Текущий реальный скор(валидационная часть): 1.57\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 1.6921 - lr: 1.2207e-07\n",
      "Epoch 129/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5452Текущий реальный скор(валидационная часть): 1.57\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 1.6921 - lr: 1.2207e-07\n",
      "Epoch 130/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5447Текущий реальный скор(валидационная часть): 1.5701\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 1.6921 - lr: 1.2207e-07\n",
      "Epoch 131/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5483Текущий реальный скор(валидационная часть): 1.5701\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 1.6921 - lr: 1.2207e-07\n",
      "Epoch 132/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5418Текущий реальный скор(валидационная часть): 1.5701\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 1.6922 - lr: 1.2207e-07\n",
      "Epoch 133/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5482Текущий реальный скор(валидационная часть): 1.5701\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5387 - val_loss: 1.6922 - lr: 1.2207e-07\n",
      "Epoch 134/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5426Текущий реальный скор(валидационная часть): 1.5701\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5387 - val_loss: 1.6922 - lr: 1.2207e-07\n",
      "Epoch 135/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5482Текущий реальный скор(валидационная часть): 1.5702\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5387 - val_loss: 1.6922 - lr: 1.2207e-07\n",
      "Epoch 136/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5426Текущий реальный скор(валидационная часть): 1.4755\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5387 - val_loss: 1.6922 - lr: 1.2207e-07\n",
      "Скор для фолда(12) : 1.4755 средний скор на префиксе = 1.363 это заняло = 33 сек.\n",
      "Фолд: 13\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 3.9920Текущий реальный скор(валидационная часть): 2.5952\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.7700 - val_loss: 2.7119 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.9541Текущий реальный скор(валидационная часть): 2.0853\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9348 - val_loss: 2.1806 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 1.6541Текущий реальный скор(валидационная часть): 1.8646\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6472 - val_loss: 1.9604 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.4962Текущий реальный скор(валидационная часть): 1.8388\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4964 - val_loss: 1.9291 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 1.4066Текущий реальный скор(валидационная часть): 1.7772\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4064 - val_loss: 1.8718 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.3408Текущий реальный скор(валидационная часть): 1.7815\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3421 - val_loss: 1.8731 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.2780Текущий реальный скор(валидационная часть): 1.739\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2802 - val_loss: 1.8311 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.2306Текущий реальный скор(валидационная часть): 1.7244\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2322 - val_loss: 1.8081 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 1.1791Текущий реальный скор(валидационная часть): 1.724\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1843 - val_loss: 1.8129 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.1305Текущий реальный скор(валидационная часть): 1.7234\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1340 - val_loss: 1.8147 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.0802Текущий реальный скор(валидационная часть): 1.7106\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0871 - val_loss: 1.8010 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 1.0476Текущий реальный скор(валидационная часть): 1.7516\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0570 - val_loss: 1.8401 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.0186Текущий реальный скор(валидационная часть): 1.7667\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0166 - val_loss: 1.8524 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.9739Текущий реальный скор(валидационная часть): 1.7523\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9770 - val_loss: 1.8351 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.9499Текущий реальный скор(валидационная часть): 1.7438\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9551 - val_loss: 1.8257 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.9139Текущий реальный скор(валидационная часть): 1.7317\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9223 - val_loss: 1.8015 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.8883Текущий реальный скор(валидационная часть): 1.7141\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8975 - val_loss: 1.7918 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8468Текущий реальный скор(валидационная часть): 1.7542\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8568 - val_loss: 1.8235 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.8530Текущий реальный скор(валидационная часть): 1.7741\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8582 - val_loss: 1.8480 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.8270Текущий реальный скор(валидационная часть): 1.7512\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8327 - val_loss: 1.8107 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.8258Текущий реальный скор(валидационная часть): 1.7957\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8338 - val_loss: 1.8613 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8753Текущий реальный скор(валидационная часть): 1.6615\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8853 - val_loss: 1.7462 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.8853Текущий реальный скор(валидационная часть): 1.5915\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8821 - val_loss: 1.6768 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.8783Текущий реальный скор(валидационная часть): 1.5815\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8761 - val_loss: 1.6726 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.8361Текущий реальный скор(валидационная часть): 1.5829\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8391 - val_loss: 1.6738 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.8324Текущий реальный скор(валидационная часть): 1.6117\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8386 - val_loss: 1.6694 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.8224Текущий реальный скор(валидационная часть): 1.6348\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8237 - val_loss: 1.6997 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7905Текущий реальный скор(валидационная часть): 1.6564\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7921 - val_loss: 1.7338 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.7200Текущий реальный скор(валидационная часть): 1.6225\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7227 - val_loss: 1.7141 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6918Текущий реальный скор(валидационная часть): 1.6345\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6925 - val_loss: 1.7227 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.6691Текущий реальный скор(валидационная часть): 1.6541\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6749 - val_loss: 1.7611 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.6486Текущий реальный скор(валидационная часть): 1.6763\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6523 - val_loss: 1.7568 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.6419Текущий реальный скор(валидационная часть): 1.8255\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6496 - val_loss: 1.9341 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.7407Текущий реальный скор(валидационная часть): 1.7071\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7535 - val_loss: 1.7903 - lr: 5.0000e-04\n",
      "Epoch 35/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.7233Текущий реальный скор(валидационная часть): 1.7241\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7271 - val_loss: 1.8026 - lr: 5.0000e-04\n",
      "Epoch 36/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.7261Текущий реальный скор(валидационная часть): 1.819\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7552 - val_loss: 1.8926 - lr: 5.0000e-04\n",
      "Epoch 37/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7724Текущий реальный скор(валидационная часть): 1.8203\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7829 - val_loss: 1.8819 - lr: 2.5000e-04\n",
      "Epoch 38/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.6397Текущий реальный скор(валидационная часть): 1.7274\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6622 - val_loss: 1.7855 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5920Текущий реальный скор(валидационная часть): 1.6819\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6139 - val_loss: 1.7361 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5590Текущий реальный скор(валидационная часть): 1.6459\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5780 - val_loss: 1.6986 - lr: 2.5000e-04\n",
      "Epoch 41/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5440Текущий реальный скор(валидационная часть): 1.6476\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5536 - val_loss: 1.6977 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5177Текущий реальный скор(валидационная часть): 1.6322\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 1.6804 - lr: 2.5000e-04\n",
      "Epoch 43/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5048Текущий реальный скор(валидационная часть): 1.6276\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5204 - val_loss: 1.6771 - lr: 2.5000e-04\n",
      "Epoch 44/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4911Текущий реальный скор(валидационная часть): 1.6205\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 1.6716 - lr: 2.5000e-04\n",
      "Epoch 45/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4883Текущий реальный скор(валидационная часть): 1.6246\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4969 - val_loss: 1.6759 - lr: 2.5000e-04\n",
      "Epoch 46/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4691Текущий реальный скор(валидационная часть): 1.6296\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4853 - val_loss: 1.6847 - lr: 2.5000e-04\n",
      "Epoch 47/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4951Текущий реальный скор(валидационная часть): 1.5953\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5051 - val_loss: 1.6723 - lr: 1.2500e-04\n",
      "Epoch 48/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4964Текущий реальный скор(валидационная часть): 1.615\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5035 - val_loss: 1.6904 - lr: 1.2500e-04\n",
      "Epoch 49/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4916Текущий реальный скор(валидационная часть): 1.6364\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4961 - val_loss: 1.7076 - lr: 1.2500e-04\n",
      "Epoch 50/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4747Текущий реальный скор(валидационная часть): 1.645\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 1.7132 - lr: 1.2500e-04\n",
      "Epoch 51/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4660Текущий реальный скор(валидационная часть): 1.6608\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 1.7253 - lr: 1.2500e-04\n",
      "Epoch 52/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4626Текущий реальный скор(валидационная часть): 1.6774\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 1.7406 - lr: 1.2500e-04\n",
      "Epoch 53/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4551Текущий реальный скор(валидационная часть): 1.6884\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 1.7499 - lr: 1.2500e-04\n",
      "Epoch 54/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4510Текущий реальный скор(валидационная часть): 1.6999\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 1.7602 - lr: 1.2500e-04\n",
      "Epoch 55/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4494Текущий реальный скор(валидационная часть): 1.707\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 1.7720 - lr: 1.2500e-04\n",
      "Epoch 56/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4418Текущий реальный скор(валидационная часть): 1.7208\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4494 - val_loss: 1.7842 - lr: 1.2500e-04\n",
      "Epoch 57/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4673Текущий реальный скор(валидационная часть): 1.6676\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 1.7242 - lr: 6.2500e-05\n",
      "Epoch 58/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4505Текущий реальный скор(валидационная часть): 1.6423\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 1.7002 - lr: 6.2500e-05\n",
      "Epoch 59/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4406Текущий реальный скор(валидационная часть): 1.6335\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4481 - val_loss: 1.6925 - lr: 6.2500e-05\n",
      "Epoch 60/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4301Текущий реальный скор(валидационная часть): 1.6281\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4402 - val_loss: 1.6877 - lr: 6.2500e-05\n",
      "Epoch 61/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4226Текущий реальный скор(валидационная часть): 1.6251\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4338 - val_loss: 1.6852 - lr: 6.2500e-05\n",
      "Epoch 62/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4186Текущий реальный скор(валидационная часть): 1.6245\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 1.6851 - lr: 6.2500e-05\n",
      "Epoch 63/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4126Текущий реальный скор(валидационная часть): 1.6225\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 1.6838 - lr: 6.2500e-05\n",
      "Epoch 64/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4094Текущий реальный скор(валидационная часть): 1.6228\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4197 - val_loss: 1.6836 - lr: 6.2500e-05\n",
      "Epoch 65/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4047Текущий реальный скор(валидационная часть): 1.6212\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4158 - val_loss: 1.6825 - lr: 6.2500e-05\n",
      "Epoch 66/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4020Текущий реальный скор(валидационная часть): 1.6232\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 1.6838 - lr: 6.2500e-05\n",
      "Epoch 67/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4051Текущий реальный скор(валидационная часть): 1.632\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 1.6952 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3994Текущий реальный скор(валидационная часть): 1.636\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 1.6989 - lr: 3.1250e-05\n",
      "Epoch 69/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3995Текущий реальный скор(валидационная часть): 1.6371\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4062 - val_loss: 1.7001 - lr: 3.1250e-05\n",
      "Epoch 70/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3940Текущий реальный скор(валидационная часть): 1.6392\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4034 - val_loss: 1.7020 - lr: 3.1250e-05\n",
      "Epoch 71/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.3933Текущий реальный скор(валидационная часть): 1.6401\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4009 - val_loss: 1.7024 - lr: 3.1250e-05\n",
      "Epoch 72/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3890Текущий реальный скор(валидационная часть): 1.6408\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3987 - val_loss: 1.7031 - lr: 3.1250e-05\n",
      "Epoch 73/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3899Текущий реальный скор(валидационная часть): 1.6411\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3968 - val_loss: 1.7033 - lr: 3.1250e-05\n",
      "Epoch 74/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3852Текущий реальный скор(валидационная часть): 1.6412\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3949 - val_loss: 1.7031 - lr: 3.1250e-05\n",
      "Epoch 75/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3881Текущий реальный скор(валидационная часть): 1.642\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 1.7041 - lr: 3.1250e-05\n",
      "Epoch 76/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.3825Текущий реальный скор(валидационная часть): 1.6425\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 1.7044 - lr: 3.1250e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3810Текущий реальный скор(валидационная часть): 1.6479\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3905 - val_loss: 1.7090 - lr: 1.5625e-05\n",
      "Epoch 78/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3795Текущий реальный скор(валидационная часть): 1.6469\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3890 - val_loss: 1.7107 - lr: 1.5625e-05\n",
      "Epoch 79/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.3799Текущий реальный скор(валидационная часть): 1.6465\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3879 - val_loss: 1.7102 - lr: 1.5625e-05\n",
      "Epoch 80/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3775Текущий реальный скор(валидационная часть): 1.6458\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 1.7096 - lr: 1.5625e-05\n",
      "Epoch 81/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3756Текущий реальный скор(валидационная часть): 1.6451\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 1.7088 - lr: 1.5625e-05\n",
      "Epoch 82/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3779Текущий реальный скор(валидационная часть): 1.6448\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3852 - val_loss: 1.7086 - lr: 1.5625e-05\n",
      "Epoch 83/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3788Текущий реальный скор(валидационная часть): 1.6442\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 1.7081 - lr: 1.5625e-05\n",
      "Epoch 84/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.3746Текущий реальный скор(валидационная часть): 1.644\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 1.7078 - lr: 1.5625e-05\n",
      "Epoch 85/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3720Текущий реальный скор(валидационная часть): 1.6439\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 1.7080 - lr: 1.5625e-05\n",
      "Epoch 86/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3761Текущий реальный скор(валидационная часть): 1.6434\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 1.7075 - lr: 1.5625e-05\n",
      "Epoch 87/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.3802Текущий реальный скор(валидационная часть): 1.6313\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 1.6975 - lr: 7.8125e-06\n",
      "Epoch 88/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3733Текущий реальный скор(валидационная часть): 1.6311\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 1.6971 - lr: 7.8125e-06\n",
      "Epoch 89/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.3747Текущий реальный скор(валидационная часть): 1.6312\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 1.6971 - lr: 7.8125e-06\n",
      "Epoch 90/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3715Текущий реальный скор(валидационная часть): 1.6316\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 1.6974 - lr: 7.8125e-06\n",
      "Epoch 91/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.3735Текущий реальный скор(валидационная часть): 1.6317\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3816 - val_loss: 1.6975 - lr: 7.8125e-06\n",
      "Epoch 92/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3756Текущий реальный скор(валидационная часть): 1.6319\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3811 - val_loss: 1.6976 - lr: 7.8125e-06\n",
      "Epoch 93/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.3726Текущий реальный скор(валидационная часть): 1.6321\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3807 - val_loss: 1.6978 - lr: 7.8125e-06\n",
      "Epoch 94/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3748Текущий реальный скор(валидационная часть): 1.6325\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 1.6981 - lr: 7.8125e-06\n",
      "Epoch 95/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3743Текущий реальный скор(валидационная часть): 1.6329\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3798 - val_loss: 1.6985 - lr: 7.8125e-06\n",
      "Epoch 96/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3690Текущий реальный скор(валидационная часть): 1.6332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3794 - val_loss: 1.6988 - lr: 7.8125e-06\n",
      "Epoch 97/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3749Текущий реальный скор(валидационная часть): 1.6433\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 1.7064 - lr: 3.9063e-06\n",
      "Epoch 98/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3752Текущий реальный скор(валидационная часть): 1.6438\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 1.7067 - lr: 3.9063e-06\n",
      "Epoch 99/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3706Текущий реальный скор(валидационная часть): 1.6443\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 1.7071 - lr: 3.9063e-06\n",
      "Epoch 100/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.3715Текущий реальный скор(валидационная часть): 1.6449\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3798 - val_loss: 1.7075 - lr: 3.9063e-06\n",
      "Epoch 101/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3701Текущий реальный скор(валидационная часть): 1.6455\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 1.7081 - lr: 3.9063e-06\n",
      "Epoch 102/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.3767Текущий реальный скор(валидационная часть): 1.646\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3792 - val_loss: 1.7085 - lr: 3.9063e-06\n",
      "Epoch 103/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3694Текущий реальный скор(валидационная часть): 1.6464\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 1.7088 - lr: 3.9063e-06\n",
      "Epoch 104/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3734Текущий реальный скор(валидационная часть): 1.6467\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3787 - val_loss: 1.7091 - lr: 3.9063e-06\n",
      "Epoch 105/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.3701Текущий реальный скор(валидационная часть): 1.6471\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3784 - val_loss: 1.7094 - lr: 3.9063e-06\n",
      "Epoch 106/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3729Текущий реальный скор(валидационная часть): 1.6475\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 1.7097 - lr: 3.9063e-06\n",
      "Epoch 107/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3684Текущий реальный скор(валидационная часть): 1.6587\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 1.7190 - lr: 1.9531e-06\n",
      "Epoch 108/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3720Текущий реальный скор(валидационная часть): 1.6602\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 1.7202 - lr: 1.9531e-06\n",
      "Epoch 109/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3718Текущий реальный скор(валидационная часть): 1.6605\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3772 - val_loss: 1.7205 - lr: 1.9531e-06\n",
      "Epoch 110/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3716Текущий реальный скор(валидационная часть): 1.6607\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 1.7207 - lr: 1.9531e-06\n",
      "Epoch 111/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3671Текущий реальный скор(валидационная часть): 1.6609\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 1.7208 - lr: 1.9531e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3713Текущий реальный скор(валидационная часть): 1.661\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 1.7209 - lr: 1.9531e-06\n",
      "Epoch 113/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.3681Текущий реальный скор(валидационная часть): 1.6612\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 1.7210 - lr: 1.9531e-06\n",
      "Epoch 114/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3711Текущий реальный скор(валидационная часть): 1.6612\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 1.7211 - lr: 1.9531e-06\n",
      "Epoch 115/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.3685Текущий реальный скор(валидационная часть): 1.6614\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 1.7212 - lr: 1.9531e-06\n",
      "Epoch 116/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3691Текущий реальный скор(валидационная часть): 1.6615\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 1.7213 - lr: 1.9531e-06\n",
      "Epoch 117/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.3673Текущий реальный скор(валидационная часть): 1.6656\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 1.7245 - lr: 9.7656e-07\n",
      "Epoch 118/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3684Текущий реальный скор(валидационная часть): 1.6672\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 1.7258 - lr: 9.7656e-07\n",
      "Epoch 119/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3655Текущий реальный скор(валидационная часть): 1.6678\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 1.7262 - lr: 9.7656e-07\n",
      "Epoch 120/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3604Текущий реальный скор(валидационная часть): 1.668\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 1.7264 - lr: 9.7656e-07\n",
      "Epoch 121/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3653Текущий реальный скор(валидационная часть): 1.6681\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 1.7265 - lr: 9.7656e-07\n",
      "Epoch 122/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3697Текущий реальный скор(валидационная часть): 1.6682\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 1.7265 - lr: 9.7656e-07\n",
      "Epoch 123/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3651Текущий реальный скор(валидационная часть): 1.6683\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 1.7266 - lr: 9.7656e-07\n",
      "Epoch 124/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.3671Текущий реальный скор(валидационная часть): 1.6683\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 1.7266 - lr: 9.7656e-07\n",
      "Epoch 125/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3650Текущий реальный скор(валидационная часть): 1.6684\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 1.7267 - lr: 9.7656e-07\n",
      "Epoch 126/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3647- ETA: 0s - loss: 0.2Текущий реальный скор(валидационная часть): 1.6117\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3749 - val_loss: 1.7267 - lr: 9.7656e-07\n",
      "Скор для фолда(13) : 1.6117 средний скор на префиксе = 1.3808 это заняло = 31 сек.\n",
      "Фолд: 14\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 4.0417Текущий реальный скор(валидационная часть): 2.0356\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8276 - val_loss: 2.1013 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.9543Текущий реальный скор(валидационная часть): 1.5484\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9412 - val_loss: 1.6116 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.6528Текущий реальный скор(валидационная часть): 1.4869\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6419 - val_loss: 1.5484 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.5141Текущий реальный скор(валидационная часть): 1.4529\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5130 - val_loss: 1.5308 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 1.4181Текущий реальный скор(валидационная часть): 1.4359\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4174 - val_loss: 1.5286 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 1.3299Текущий реальный скор(валидационная часть): 1.4335\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3380 - val_loss: 1.5282 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 1.2721Текущий реальный скор(валидационная часть): 1.4614\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2764 - val_loss: 1.5470 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.2295Текущий реальный скор(валидационная часть): 1.4455\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2310 - val_loss: 1.5463 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.1871Текущий реальный скор(валидационная часть): 1.4768\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1870 - val_loss: 1.5692 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.1364Текущий реальный скор(валидационная часть): 1.4652\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1388 - val_loss: 1.5602 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.1048Текущий реальный скор(валидационная часть): 1.4928\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1037 - val_loss: 1.5940 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.0578Текущий реальный скор(валидационная часть): 1.5085\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0653 - val_loss: 1.6093 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.0630Текущий реальный скор(валидационная часть): 1.4936\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0635 - val_loss: 1.5901 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 1.0081Текущий реальный скор(валидационная часть): 1.5462\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0129 - val_loss: 1.6435 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.9617Текущий реальный скор(валидационная часть): 1.5762\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9699 - val_loss: 1.6594 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.9485Текущий реальный скор(валидационная часть): 1.5633\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9576 - val_loss: 1.6576 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 1.0205Текущий реальный скор(валидационная часть): 1.4506\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0166 - val_loss: 1.5440 - lr: 2.5000e-04\n",
      "Epoch 18/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.9460Текущий реальный скор(валидационная часть): 1.4839\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9436 - val_loss: 1.5704 - lr: 2.5000e-04\n",
      "Epoch 19/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.9085Текущий реальный скор(валидационная часть): 1.4915\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9136 - val_loss: 1.5787 - lr: 2.5000e-04\n",
      "Epoch 20/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8814Текущий реальный скор(валидационная часть): 1.5077\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8851 - val_loss: 1.5945 - lr: 2.5000e-04\n",
      "Epoch 21/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.8616Текущий реальный скор(валидационная часть): 1.5487\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8628 - val_loss: 1.6341 - lr: 2.5000e-04\n",
      "Epoch 22/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.8437Текущий реальный скор(валидационная часть): 1.5635\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8435 - val_loss: 1.6516 - lr: 2.5000e-04\n",
      "Epoch 23/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.8207Текущий реальный скор(валидационная часть): 1.6\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8260 - val_loss: 1.6894 - lr: 2.5000e-04\n",
      "Epoch 24/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.8198Текущий реальный скор(валидационная часть): 1.6225\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8160 - val_loss: 1.7088 - lr: 2.5000e-04\n",
      "Epoch 25/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.7974Текущий реальный скор(валидационная часть): 1.644\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8016 - val_loss: 1.7310 - lr: 2.5000e-04\n",
      "Epoch 26/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7934Текущий реальный скор(валидационная часть): 1.6416\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7923 - val_loss: 1.7229 - lr: 2.5000e-04\n",
      "Epoch 27/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.7784Текущий реальный скор(валидационная часть): 1.4884\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7861 - val_loss: 1.5728 - lr: 1.2500e-04\n",
      "Epoch 28/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.7409Текущий реальный скор(валидационная часть): 1.4822\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7462 - val_loss: 1.5671 - lr: 1.2500e-04\n",
      "Epoch 29/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.7160Текущий реальный скор(валидационная часть): 1.4788\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7211 - val_loss: 1.5641 - lr: 1.2500e-04\n",
      "Epoch 30/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.6966Текущий реальный скор(валидационная часть): 1.4754\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7020 - val_loss: 1.5623 - lr: 1.2500e-04\n",
      "Epoch 31/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.6818Текущий реальный скор(валидационная часть): 1.4742\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6847 - val_loss: 1.5612 - lr: 1.2500e-04\n",
      "Epoch 32/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.6719Текущий реальный скор(валидационная часть): 1.4744\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6769 - val_loss: 1.5652 - lr: 1.2500e-04\n",
      "Epoch 33/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.6611Текущий реальный скор(валидационная часть): 1.4724\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6664 - val_loss: 1.5604 - lr: 1.2500e-04\n",
      "Epoch 34/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.6535Текущий реальный скор(валидационная часть): 1.4714\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6567 - val_loss: 1.5586 - lr: 1.2500e-04\n",
      "Epoch 35/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.6407Текущий реальный скор(валидационная часть): 1.4677\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6474 - val_loss: 1.5550 - lr: 1.2500e-04\n",
      "Epoch 36/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.6329Текущий реальный скор(валидационная часть): 1.4701\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6391 - val_loss: 1.5565 - lr: 1.2500e-04\n",
      "Epoch 37/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.6377Текущий реальный скор(валидационная часть): 1.4478\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6439 - val_loss: 1.5410 - lr: 6.2500e-05\n",
      "Epoch 38/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.6395Текущий реальный скор(валидационная часть): 1.4463\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6419 - val_loss: 1.5404 - lr: 6.2500e-05\n",
      "Epoch 39/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.6332Текущий реальный скор(валидационная часть): 1.4438\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6375 - val_loss: 1.5398 - lr: 6.2500e-05\n",
      "Epoch 40/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.6276Текущий реальный скор(валидационная часть): 1.4417\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6335 - val_loss: 1.5393 - lr: 6.2500e-05\n",
      "Epoch 41/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.6255Текущий реальный скор(валидационная часть): 1.4586\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 1.5531 - lr: 6.2500e-05\n",
      "Epoch 42/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.6287Текущий реальный скор(валидационная часть): 1.4356\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 1.5338 - lr: 6.2500e-05\n",
      "Epoch 43/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.6242Текущий реальный скор(валидационная часть): 1.433\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6257 - val_loss: 1.5319 - lr: 6.2500e-05\n",
      "Epoch 44/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.6182Текущий реальный скор(валидационная часть): 1.4308\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6208 - val_loss: 1.5285 - lr: 6.2500e-05\n",
      "Epoch 45/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.6189Текущий реальный скор(валидационная часть): 1.4292\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 1.5273 - lr: 6.2500e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.6106Текущий реальный скор(валидационная часть): 1.4272\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6121 - val_loss: 1.5260 - lr: 6.2500e-05\n",
      "Epoch 47/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6058Текущий реальный скор(валидационная часть): 1.4238\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 1.5223 - lr: 6.2500e-05\n",
      "Epoch 48/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6014Текущий реальный скор(валидационная часть): 1.4224\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 1.5213 - lr: 6.2500e-05\n",
      "Epoch 49/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5970Текущий реальный скор(валидационная часть): 1.4219\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5983 - val_loss: 1.5205 - lr: 6.2500e-05\n",
      "Epoch 50/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5920Текущий реальный скор(валидационная часть): 1.4211\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5944 - val_loss: 1.5204 - lr: 6.2500e-05\n",
      "Epoch 51/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5894Текущий реальный скор(валидационная часть): 1.4197\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 1.5192 - lr: 6.2500e-05\n",
      "Epoch 52/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5860Текущий реальный скор(валидационная часть): 1.4193\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5870 - val_loss: 1.5187 - lr: 6.2500e-05\n",
      "Epoch 53/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5826Текущий реальный скор(валидационная часть): 1.4178\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5835 - val_loss: 1.5173 - lr: 6.2500e-05\n",
      "Epoch 54/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5780Текущий реальный скор(валидационная часть): 1.4174\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5802 - val_loss: 1.5171 - lr: 6.2500e-05\n",
      "Epoch 55/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5756Текущий реальный скор(валидационная часть): 1.4184\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5768 - val_loss: 1.5178 - lr: 6.2500e-05\n",
      "Epoch 56/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5693Текущий реальный скор(валидационная часть): 1.4168\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5735 - val_loss: 1.5167 - lr: 6.2500e-05\n",
      "Epoch 57/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5716Текущий реальный скор(валидационная часть): 1.416\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5707 - val_loss: 1.5149 - lr: 6.2500e-05\n",
      "Epoch 58/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5652Текущий реальный скор(валидационная часть): 1.417\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5671 - val_loss: 1.5157 - lr: 6.2500e-05\n",
      "Epoch 59/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5592Текущий реальный скор(валидационная часть): 1.4164\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5640 - val_loss: 1.5146 - lr: 6.2500e-05\n",
      "Epoch 60/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5587Текущий реальный скор(валидационная часть): 1.4157\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5607 - val_loss: 1.5133 - lr: 6.2500e-05\n",
      "Epoch 61/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5583Текущий реальный скор(валидационная часть): 1.4159\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5575 - val_loss: 1.5133 - lr: 6.2500e-05\n",
      "Epoch 62/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5488Текущий реальный скор(валидационная часть): 1.4144\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5545 - val_loss: 1.5117 - lr: 6.2500e-05\n",
      "Epoch 63/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5523Текущий реальный скор(валидационная часть): 1.4153\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5515 - val_loss: 1.5120 - lr: 6.2500e-05\n",
      "Epoch 64/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5441Текущий реальный скор(валидационная часть): 1.4154\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5485 - val_loss: 1.5118 - lr: 6.2500e-05\n",
      "Epoch 65/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5450Текущий реальный скор(валидационная часть): 1.416\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 1.5119 - lr: 6.2500e-05\n",
      "Epoch 66/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5405Текущий реальный скор(валидационная часть): 1.4173\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 1.5128 - lr: 6.2500e-05\n",
      "Epoch 67/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5396Текущий реальный скор(валидационная часть): 1.4162\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5403 - val_loss: 1.5111 - lr: 6.2500e-05\n",
      "Epoch 68/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5350Текущий реальный скор(валидационная часть): 1.4168\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5374 - val_loss: 1.5118 - lr: 6.2500e-05\n",
      "Epoch 69/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5357Текущий реальный скор(валидационная часть): 1.4162\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5349 - val_loss: 1.5134 - lr: 6.2500e-05\n",
      "Epoch 70/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5295Текущий реальный скор(валидационная часть): 1.4157\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5320 - val_loss: 1.5127 - lr: 6.2500e-05\n",
      "Epoch 71/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5280Текущий реальный скор(валидационная часть): 1.4159\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 1.5124 - lr: 6.2500e-05\n",
      "Epoch 72/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5234Текущий реальный скор(валидационная часть): 1.4151\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.5119 - lr: 6.2500e-05\n",
      "Epoch 73/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5171Текущий реальный скор(валидационная часть): 1.4155\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.5125 - lr: 6.2500e-05\n",
      "Epoch 74/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5181Текущий реальный скор(валидационная часть): 1.4153\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5205 - val_loss: 1.5122 - lr: 6.2500e-05\n",
      "Epoch 75/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5169Текущий реальный скор(валидационная часть): 1.4145\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5181 - val_loss: 1.5109 - lr: 6.2500e-05\n",
      "Epoch 76/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5055Текущий реальный скор(валидационная часть): 1.4153\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5156 - val_loss: 1.5117 - lr: 6.2500e-05\n",
      "Epoch 77/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5124Текущий реальный скор(валидационная часть): 1.417\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 1.5123 - lr: 6.2500e-05\n",
      "Epoch 78/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5007Текущий реальный скор(валидационная часть): 1.4173\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5108 - val_loss: 1.5135 - lr: 6.2500e-05\n",
      "Epoch 79/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5083Текущий реальный скор(валидационная часть): 1.4203\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5089 - val_loss: 1.5150 - lr: 6.2500e-05\n",
      "Epoch 80/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5032Текущий реальный скор(валидационная часть): 1.418\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5062 - val_loss: 1.5136 - lr: 6.2500e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5033Текущий реальный скор(валидационная часть): 1.4214\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5044 - val_loss: 1.5159 - lr: 6.2500e-05\n",
      "Epoch 82/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4956Текущий реальный скор(валидационная часть): 1.4243\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5018 - val_loss: 1.5202 - lr: 6.2500e-05\n",
      "Epoch 83/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4981Текущий реальный скор(валидационная часть): 1.4232\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4979 - val_loss: 1.5189 - lr: 6.2500e-05\n",
      "Epoch 84/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4895Текущий реальный скор(валидационная часть): 1.4229\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4958 - val_loss: 1.5181 - lr: 6.2500e-05\n",
      "Epoch 85/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4908Текущий реальный скор(валидационная часть): 1.4225\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 1.5182 - lr: 6.2500e-05\n",
      "Epoch 86/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5026Текущий реальный скор(валидационная часть): 1.4177\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5074 - val_loss: 1.5062 - lr: 3.1250e-05\n",
      "Epoch 87/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.5151Текущий реальный скор(валидационная часть): 1.419\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5124 - val_loss: 1.5053 - lr: 3.1250e-05\n",
      "Epoch 88/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5067Текущий реальный скор(валидационная часть): 1.4211\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5127 - val_loss: 1.5074 - lr: 3.1250e-05\n",
      "Epoch 89/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5035Текущий реальный скор(валидационная часть): 1.4233\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5117 - val_loss: 1.5121 - lr: 3.1250e-05\n",
      "Epoch 90/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5046Текущий реальный скор(валидационная часть): 1.421\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5102 - val_loss: 1.5100 - lr: 3.1250e-05\n",
      "Epoch 91/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5043Текущий реальный скор(валидационная часть): 1.4199\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 1.5089 - lr: 3.1250e-05\n",
      "Epoch 92/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4962Текущий реальный скор(валидационная часть): 1.4203\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 1.5096 - lr: 3.1250e-05\n",
      "Epoch 93/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4960Текущий реальный скор(валидационная часть): 1.4208\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5007 - val_loss: 1.5106 - lr: 3.1250e-05\n",
      "Epoch 94/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4911Текущий реальный скор(валидационная часть): 1.4212\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4980 - val_loss: 1.5139 - lr: 3.1250e-05\n",
      "Epoch 95/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4875Текущий реальный скор(валидационная часть): 1.4213\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4956 - val_loss: 1.5148 - lr: 3.1250e-05\n",
      "Epoch 96/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4891Текущий реальный скор(валидационная часть): 1.4214\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4933 - val_loss: 1.5148 - lr: 3.1250e-05\n",
      "Epoch 97/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4887Текущий реальный скор(валидационная часть): 1.4218\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 1.5179 - lr: 3.1250e-05\n",
      "Epoch 98/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4896Текущий реальный скор(валидационная часть): 1.4235\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 1.5203 - lr: 1.5625e-05\n",
      "Epoch 99/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4912Текущий реальный скор(валидационная часть): 1.4247\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4907 - val_loss: 1.5222 - lr: 1.5625e-05\n",
      "Epoch 100/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4842Текущий реальный скор(валидационная часть): 1.4256\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 1.5235 - lr: 1.5625e-05\n",
      "Epoch 101/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4831Текущий реальный скор(валидационная часть): 1.4263\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 1.5244 - lr: 1.5625e-05\n",
      "Epoch 102/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4842Текущий реальный скор(валидационная часть): 1.4267\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 1.5251 - lr: 1.5625e-05\n",
      "Epoch 103/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4836Текущий реальный скор(валидационная часть): 1.4274\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 1.5258 - lr: 1.5625e-05\n",
      "Epoch 104/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4817Текущий реальный скор(валидационная часть): 1.4277\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 1.5263 - lr: 1.5625e-05\n",
      "Epoch 105/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4819Текущий реальный скор(валидационная часть): 1.4283\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 1.5269 - lr: 1.5625e-05\n",
      "Epoch 106/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4794Текущий реальный скор(валидационная часть): 1.4289\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 1.5276 - lr: 1.5625e-05\n",
      "Epoch 107/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4720Текущий реальный скор(валидационная часть): 1.4293\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 1.5280 - lr: 1.5625e-05\n",
      "Epoch 108/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4805Текущий реальный скор(валидационная часть): 1.4294\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 1.5307 - lr: 7.8125e-06\n",
      "Epoch 109/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4789Текущий реальный скор(валидационная часть): 1.4292\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 1.5309 - lr: 7.8125e-06\n",
      "Epoch 110/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4760Текущий реальный скор(валидационная часть): 1.4293\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4790 - val_loss: 1.5312 - lr: 7.8125e-06\n",
      "Epoch 111/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4750Текущий реальный скор(валидационная часть): 1.4294\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 1.5314 - lr: 7.8125e-06\n",
      "Epoch 112/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4746Текущий реальный скор(валидационная часть): 1.4296\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 1.5316 - lr: 7.8125e-06\n",
      "Epoch 113/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4739Текущий реальный скор(валидационная часть): 1.4296\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 1.5318 - lr: 7.8125e-06\n",
      "Epoch 114/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4733Текущий реальный скор(валидационная часть): 1.4296\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 1.5319 - lr: 7.8125e-06\n",
      "Epoch 115/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4724Текущий реальный скор(валидационная часть): 1.4298\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 1.5322 - lr: 7.8125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4661Текущий реальный скор(валидационная часть): 1.43\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 1.5323 - lr: 7.8125e-06\n",
      "Epoch 117/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4750Текущий реальный скор(валидационная часть): 1.4299\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 1.5323 - lr: 7.8125e-06\n",
      "Epoch 118/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4661Текущий реальный скор(валидационная часть): 1.4311\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 1.5348 - lr: 3.9063e-06\n",
      "Epoch 119/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4659Текущий реальный скор(валидационная часть): 1.4314\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 1.5351 - lr: 3.9063e-06\n",
      "Epoch 120/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4712Текущий реальный скор(валидационная часть): 1.4313\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 1.5351 - lr: 3.9063e-06\n",
      "Epoch 121/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4729Текущий реальный скор(валидационная часть): 1.4314\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4737 - val_loss: 1.5352 - lr: 3.9063e-06\n",
      "Epoch 122/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4693Текущий реальный скор(валидационная часть): 1.4315\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 1.5352 - lr: 3.9063e-06\n",
      "Epoch 123/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4732Текущий реальный скор(валидационная часть): 1.4316\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 1.5353 - lr: 3.9063e-06\n",
      "Epoch 124/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4718Текущий реальный скор(валидационная часть): 1.4317\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 1.5353 - lr: 3.9063e-06\n",
      "Epoch 125/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4637Текущий реальный скор(валидационная часть): 1.4317\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4724 - val_loss: 1.5353 - lr: 3.9063e-06\n",
      "Epoch 126/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4711Текущий реальный скор(валидационная часть): 1.4317\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4721 - val_loss: 1.5353 - lr: 3.9063e-06\n",
      "Epoch 127/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4709Текущий реальный скор(валидационная часть): 1.4318\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 1.5354 - lr: 3.9063e-06\n",
      "Epoch 128/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4701Текущий реальный скор(валидационная часть): 1.4322\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 1.5339 - lr: 1.9531e-06\n",
      "Epoch 129/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4701Текущий реальный скор(валидационная часть): 1.4325\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 1.5340 - lr: 1.9531e-06\n",
      "Epoch 130/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4713Текущий реальный скор(валидационная часть): 1.4326\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 1.5341 - lr: 1.9531e-06\n",
      "Epoch 131/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4665Текущий реальный скор(валидационная часть): 1.4327\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4702 - val_loss: 1.5343 - lr: 1.9531e-06\n",
      "Epoch 132/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4701Текущий реальный скор(валидационная часть): 1.4328\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 1.5370 - lr: 1.9531e-06\n",
      "Epoch 133/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4702Текущий реальный скор(валидационная часть): 1.4328\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4699 - val_loss: 1.5370 - lr: 1.9531e-06\n",
      "Epoch 134/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4729Текущий реальный скор(валидационная часть): 1.4328\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4698 - val_loss: 1.5370 - lr: 1.9531e-06\n",
      "Epoch 135/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4659Текущий реальный скор(валидационная часть): 1.4329\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4696 - val_loss: 1.5371 - lr: 1.9531e-06\n",
      "Epoch 136/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4658Текущий реальный скор(валидационная часть): 1.4329\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4695 - val_loss: 1.5371 - lr: 1.9531e-06\n",
      "Epoch 137/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4683Текущий реальный скор(валидационная часть): 1.4329\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4694 - val_loss: 1.5371 - lr: 1.9531e-06\n",
      "Epoch 138/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4694Текущий реальный скор(валидационная часть): 1.4328\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4687 - val_loss: 1.5360 - lr: 9.7656e-07\n",
      "Epoch 139/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4669Текущий реальный скор(валидационная часть): 1.4329\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 1.5357 - lr: 9.7656e-07\n",
      "Epoch 140/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4670Текущий реальный скор(валидационная часть): 1.4329\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 1.5356 - lr: 9.7656e-07\n",
      "Epoch 141/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4595Текущий реальный скор(валидационная часть): 1.4329\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 1.5356 - lr: 9.7656e-07\n",
      "Epoch 142/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4675Текущий реальный скор(валидационная часть): 1.433\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4681 - val_loss: 1.5356 - lr: 9.7656e-07\n",
      "Epoch 143/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4666Текущий реальный скор(валидационная часть): 1.433\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4681 - val_loss: 1.5356 - lr: 9.7656e-07\n",
      "Epoch 144/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4678Текущий реальный скор(валидационная часть): 1.433\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 1.5356 - lr: 9.7656e-07\n",
      "Epoch 145/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4587Текущий реальный скор(валидационная часть): 1.433\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 1.5356 - lr: 9.7656e-07\n",
      "Epoch 146/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4677Текущий реальный скор(валидационная часть): 1.4331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 1.5356 - lr: 9.7656e-07\n",
      "Epoch 147/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.4631Текущий реальный скор(валидационная часть): 1.4331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 1.5357 - lr: 9.7656e-07\n",
      "Epoch 148/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4671Текущий реальный скор(валидационная часть): 1.4331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 1.5353 - lr: 4.8828e-07\n",
      "Epoch 149/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4655Текущий реальный скор(валидационная часть): 1.4331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4672 - val_loss: 1.5351 - lr: 4.8828e-07\n",
      "Epoch 150/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4664Текущий реальный скор(валидационная часть): 1.4331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4672 - val_loss: 1.5350 - lr: 4.8828e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4655Текущий реальный скор(валидационная часть): 1.4331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 1.5350 - lr: 4.8828e-07\n",
      "Epoch 152/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4678Текущий реальный скор(валидационная часть): 1.4331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 1.5350 - lr: 4.8828e-07\n",
      "Epoch 153/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4657Текущий реальный скор(валидационная часть): 1.4331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 1.5349 - lr: 4.8828e-07\n",
      "Epoch 154/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4668Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4670 - val_loss: 1.5349 - lr: 4.8828e-07\n",
      "Epoch 155/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4654Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4670 - val_loss: 1.5349 - lr: 4.8828e-07\n",
      "Epoch 156/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4667Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4670 - val_loss: 1.5349 - lr: 4.8828e-07\n",
      "Epoch 157/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4653Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4669 - val_loss: 1.5349 - lr: 4.8828e-07\n",
      "Epoch 158/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4664Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 1.5348 - lr: 2.4414e-07\n",
      "Epoch 159/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4650Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 1.5348 - lr: 2.4414e-07\n",
      "Epoch 160/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4673Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 1.5347 - lr: 2.4414e-07\n",
      "Epoch 161/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4617Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 1.5347 - lr: 2.4414e-07\n",
      "Epoch 162/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4658Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 1.5347 - lr: 2.4414e-07\n",
      "Epoch 163/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4616Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 1.5347 - lr: 2.4414e-07\n",
      "Epoch 164/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4658Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 1.5347 - lr: 2.4414e-07\n",
      "Epoch 165/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4657Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 1.5346 - lr: 2.4414e-07\n",
      "Epoch 166/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4651Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 1.5346 - lr: 2.4414e-07\n",
      "Epoch 167/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4627Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 1.5346 - lr: 2.4414e-07\n",
      "Epoch 168/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4661Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 1.5346 - lr: 1.2207e-07\n",
      "Epoch 169/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4625Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 1.5346 - lr: 1.2207e-07\n",
      "Epoch 170/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4655Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 1.5346 - lr: 1.2207e-07\n",
      "Epoch 171/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4625Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 1.5346 - lr: 1.2207e-07\n",
      "Epoch 172/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4669Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 1.5345 - lr: 1.2207e-07\n",
      "Epoch 173/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4645Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 1.5345 - lr: 1.2207e-07\n",
      "Epoch 174/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4655Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 1.5345 - lr: 1.2207e-07\n",
      "Epoch 175/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4649Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 1.5345 - lr: 1.2207e-07\n",
      "Epoch 176/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4669Текущий реальный скор(валидационная часть): 1.4332\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 1.5345 - lr: 1.2207e-07\n",
      "Epoch 177/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4644Текущий реальный скор(валидационная часть): 1.4333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 1.5345 - lr: 1.2207e-07\n",
      "Epoch 178/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4654Текущий реальный скор(валидационная часть): 1.4333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 1.5345 - lr: 6.1035e-08\n",
      "Epoch 179/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4643Текущий реальный скор(валидационная часть): 1.4333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 1.5345 - lr: 6.1035e-08\n",
      "Epoch 180/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4654Текущий реальный скор(валидационная часть): 1.4333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 1.5345 - lr: 6.1035e-08\n",
      "Epoch 181/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4643Текущий реальный скор(валидационная часть): 1.4333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 1.5345 - lr: 6.1035e-08\n",
      "Epoch 182/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4621Текущий реальный скор(валидационная часть): 1.4333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 1.5345 - lr: 6.1035e-08\n",
      "Epoch 183/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4612Текущий реальный скор(валидационная часть): 1.4333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 1.5345 - lr: 6.1035e-08\n",
      "Epoch 184/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4654Текущий реальный скор(валидационная часть): 1.4333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 1.5345 - lr: 6.1035e-08\n",
      "Epoch 185/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4646Текущий реальный скор(валидационная часть): 1.4333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 1.5345 - lr: 6.1035e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4660Текущий реальный скор(валидационная часть): 1.4333\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 1.5344 - lr: 6.1035e-08\n",
      "Epoch 187/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4659Текущий реальный скор(валидационная часть): 1.419\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 1.5344 - lr: 6.1035e-08\n",
      "Скор для фолда(14) : 1.419 средний скор на префиксе = 1.3833 это заняло = 46 сек.\n",
      "Фолд: 15\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 3.9784Текущий реальный скор(валидационная часть): 1.9004\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8178 - val_loss: 1.9870 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 2.0001Текущий реальный скор(валидационная часть): 1.7435\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9645 - val_loss: 1.8240 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 1.6428Текущий реальный скор(валидационная часть): 1.6237\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6294 - val_loss: 1.7084 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 1.4979Текущий реальный скор(валидационная часть): 1.5298\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4880 - val_loss: 1.6070 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.3964Текущий реальный скор(валидационная часть): 1.5109\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3924 - val_loss: 1.6054 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.3454Текущий реальный скор(валидационная часть): 1.5074\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3307 - val_loss: 1.5997 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 1.2780Текущий реальный скор(валидационная часть): 1.4774\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2702 - val_loss: 1.5758 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.2329Текущий реальный скор(валидационная часть): 1.4689\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2215 - val_loss: 1.5705 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.1775Текущий реальный скор(валидационная часть): 1.4575\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1759 - val_loss: 1.5555 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 1.1362Текущий реальный скор(валидационная часть): 1.4705\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1328 - val_loss: 1.5679 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.0910Текущий реальный скор(валидационная часть): 1.4367\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0949 - val_loss: 1.5362 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.0559Текущий реальный скор(валидационная часть): 1.454\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0595 - val_loss: 1.5529 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.0236Текущий реальный скор(валидационная часть): 1.4532\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0246 - val_loss: 1.5517 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.9986Текущий реальный скор(валидационная часть): 1.413\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 1.5149 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.0099Текущий реальный скор(валидационная часть): 1.5598\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0133 - val_loss: 1.6426 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.9940Текущий реальный скор(валидационная часть): 1.558\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 1.6412 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.9281Текущий реальный скор(валидационная часть): 1.4818\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9268 - val_loss: 1.5784 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.8986Текущий реальный скор(валидационная часть): 1.397\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8939 - val_loss: 1.4966 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.8642Текущий реальный скор(валидационная часть): 1.3381\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8653 - val_loss: 1.4331 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.8430Текущий реальный скор(валидационная часть): 1.392\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8565 - val_loss: 1.4949 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.8522Текущий реальный скор(валидационная часть): 1.3859\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8677 - val_loss: 1.5017 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.8903Текущий реальный скор(валидационная часть): 1.4197\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9050 - val_loss: 1.5592 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.9025Текущий реальный скор(валидационная часть): 1.3227\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 1.4495 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.8641Текущий реальный скор(валидационная часть): 1.5621\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8808 - val_loss: 1.6365 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.8761Текущий реальный скор(валидационная часть): 1.8422\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8729 - val_loss: 1.8821 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.8610Текущий реальный скор(валидационная часть): 1.8549\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8512 - val_loss: 1.9132 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.8672Текущий реальный скор(валидационная часть): 1.5615\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8610 - val_loss: 1.6304 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.8942Текущий реальный скор(валидационная часть): 1.5722\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8808 - val_loss: 1.6124 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8827Текущий реальный скор(валидационная часть): 1.798\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8813 - val_loss: 1.8339 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.8111Текущий реальный скор(валидационная часть): 1.6998\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8172 - val_loss: 1.7542 - lr: 2.5000e-04\n",
      "Epoch 31/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.7427Текущий реальный скор(валидационная часть): 1.6427\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7514 - val_loss: 1.7122 - lr: 2.5000e-04\n",
      "Epoch 32/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.6824Текущий реальный скор(валидационная часть): 1.608\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6913 - val_loss: 1.6866 - lr: 2.5000e-04\n",
      "Epoch 33/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.6462Текущий реальный скор(валидационная часть): 1.593\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6534 - val_loss: 1.6734 - lr: 2.5000e-04\n",
      "Epoch 34/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.6202Текущий реальный скор(валидационная часть): 1.6535\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6243 - val_loss: 1.7279 - lr: 2.5000e-04\n",
      "Epoch 35/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5954Текущий реальный скор(валидационная часть): 1.5903\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 1.6694 - lr: 2.5000e-04\n",
      "Epoch 36/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5803Текущий реальный скор(валидационная часть): 1.593\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5911 - val_loss: 1.6747 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5617Текущий реальный скор(валидационная часть): 1.5838\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5742 - val_loss: 1.6649 - lr: 2.5000e-04\n",
      "Epoch 38/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5480Текущий реальный скор(валидационная часть): 1.5926\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5612 - val_loss: 1.6740 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5431Текущий реальный скор(валидационная часть): 1.5866\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5501 - val_loss: 1.6694 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5370Текущий реальный скор(валидационная часть): 1.3538\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5571 - val_loss: 1.4671 - lr: 1.2500e-04\n",
      "Epoch 41/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5503Текущий реальный скор(валидационная часть): 1.3529\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5649 - val_loss: 1.4683 - lr: 1.2500e-04\n",
      "Epoch 42/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5479Текущий реальный скор(валидационная часть): 1.3573\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5560 - val_loss: 1.4730 - lr: 1.2500e-04\n",
      "Epoch 43/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5383Текущий реальный скор(валидационная часть): 1.3667\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5477 - val_loss: 1.4821 - lr: 1.2500e-04\n",
      "Epoch 44/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5312Текущий реальный скор(валидационная часть): 1.3693\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 1.4844 - lr: 1.2500e-04\n",
      "Epoch 45/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5261Текущий реальный скор(валидационная часть): 1.3747\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5320 - val_loss: 1.4922 - lr: 1.2500e-04\n",
      "Epoch 46/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5194Текущий реальный скор(валидационная часть): 1.3732\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.4908 - lr: 1.2500e-04\n",
      "Epoch 47/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5138Текущий реальный скор(валидационная часть): 1.3622\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 1.4831 - lr: 1.2500e-04\n",
      "Epoch 48/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5242Текущий реальный скор(валидационная часть): 1.3678\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 1.4874 - lr: 1.2500e-04\n",
      "Epoch 49/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5134Текущий реальный скор(валидационная часть): 1.3727\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5171 - val_loss: 1.4902 - lr: 1.2500e-04\n",
      "Epoch 50/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5563Текущий реальный скор(валидационная часть): 1.338\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5598 - val_loss: 1.4591 - lr: 6.2500e-05\n",
      "Epoch 51/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5485Текущий реальный скор(валидационная часть): 1.3438\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5486 - val_loss: 1.4608 - lr: 6.2500e-05\n",
      "Epoch 52/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5341Текущий реальный скор(валидационная часть): 1.3469\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5349 - val_loss: 1.4637 - lr: 6.2500e-05\n",
      "Epoch 53/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5225Текущий реальный скор(валидационная часть): 1.3526\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 1.4675 - lr: 6.2500e-05\n",
      "Epoch 54/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5134Текущий реальный скор(валидационная часть): 1.3582\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5134 - val_loss: 1.4710 - lr: 6.2500e-05\n",
      "Epoch 55/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5064Текущий реальный скор(валидационная часть): 1.3631\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5053 - val_loss: 1.4741 - lr: 6.2500e-05\n",
      "Epoch 56/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4965Текущий реальный скор(валидационная часть): 1.368\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4982 - val_loss: 1.4775 - lr: 6.2500e-05\n",
      "Epoch 57/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4884Текущий реальный скор(валидационная часть): 1.3748\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 1.4830 - lr: 6.2500e-05\n",
      "Epoch 58/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4837Текущий реальный скор(валидационная часть): 1.3833\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 1.4902 - lr: 6.2500e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4771Текущий реальный скор(валидационная часть): 1.3898\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4794 - val_loss: 1.4956 - lr: 6.2500e-05\n",
      "Epoch 60/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4796Текущий реальный скор(валидационная часть): 1.4305\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 1.5341 - lr: 3.1250e-05\n",
      "Epoch 61/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4721Текущий реальный скор(валидационная часть): 1.4309\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4731 - val_loss: 1.5351 - lr: 3.1250e-05\n",
      "Epoch 62/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4661Текущий реальный скор(валидационная часть): 1.4317\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4685 - val_loss: 1.5353 - lr: 3.1250e-05\n",
      "Epoch 63/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4638Текущий реальный скор(валидационная часть): 1.4347\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4646 - val_loss: 1.5382 - lr: 3.1250e-05\n",
      "Epoch 64/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4601Текущий реальный скор(валидационная часть): 1.4357\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 1.5384 - lr: 3.1250e-05\n",
      "Epoch 65/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4570Текущий реальный скор(валидационная часть): 1.4374\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 1.5398 - lr: 3.1250e-05\n",
      "Epoch 66/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4535Текущий реальный скор(валидационная часть): 1.439\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 1.5411 - lr: 3.1250e-05\n",
      "Epoch 67/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4481Текущий реальный скор(валидационная часть): 1.4414\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 1.5428 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4442Текущий реальный скор(валидационная часть): 1.4423\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4503 - val_loss: 1.5436 - lr: 3.1250e-05\n",
      "Epoch 69/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4431Текущий реальный скор(валидационная часть): 1.4453\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 1.5463 - lr: 3.1250e-05\n",
      "Epoch 70/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4431Текущий реальный скор(валидационная часть): 1.4276\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4491 - val_loss: 1.5300 - lr: 1.5625e-05\n",
      "Epoch 71/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4419Текущий реальный скор(валидационная часть): 1.4274\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 1.5299 - lr: 1.5625e-05\n",
      "Epoch 72/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4431Текущий реальный скор(валидационная часть): 1.4277\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 1.5303 - lr: 1.5625e-05\n",
      "Epoch 73/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4443Текущий реальный скор(валидационная часть): 1.4282\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4438 - val_loss: 1.5309 - lr: 1.5625e-05\n",
      "Epoch 74/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4395Текущий реальный скор(валидационная часть): 1.4289\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4425 - val_loss: 1.5317 - lr: 1.5625e-05\n",
      "Epoch 75/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.4393Текущий реальный скор(валидационная часть): 1.4298\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 1.5327 - lr: 1.5625e-05\n",
      "Epoch 76/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4336Текущий реальный скор(валидационная часть): 1.4305\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 1.5335 - lr: 1.5625e-05\n",
      "Epoch 77/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4337Текущий реальный скор(валидационная часть): 1.4315\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 1.5345 - lr: 1.5625e-05\n",
      "Epoch 78/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4355Текущий реальный скор(валидационная часть): 1.432\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 1.5350 - lr: 1.5625e-05\n",
      "Epoch 79/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4333Текущий реальный скор(валидационная часть): 1.4335\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 1.5363 - lr: 1.5625e-05\n",
      "Epoch 80/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4354Текущий реальный скор(валидационная часть): 1.4233\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 1.5314 - lr: 7.8125e-06\n",
      "Epoch 81/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4384Текущий реальный скор(валидационная часть): 1.4248\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4397 - val_loss: 1.5326 - lr: 7.8125e-06\n",
      "Epoch 82/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4370Текущий реальный скор(валидационная часть): 1.4255\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 1.5333 - lr: 7.8125e-06\n",
      "Epoch 83/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4340Текущий реальный скор(валидационная часть): 1.4264\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 1.5341 - lr: 7.8125e-06\n",
      "Epoch 84/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4355Текущий реальный скор(валидационная часть): 1.427\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 1.5319 - lr: 7.8125e-06\n",
      "Epoch 85/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4354Текущий реальный скор(валидационная часть): 1.4273\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4367 - val_loss: 1.5323 - lr: 7.8125e-06\n",
      "Epoch 86/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4345Текущий реальный скор(валидационная часть): 1.4279\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4361 - val_loss: 1.5328 - lr: 7.8125e-06\n",
      "Epoch 87/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4325Текущий реальный скор(валидационная часть): 1.428\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4354 - val_loss: 1.5329 - lr: 7.8125e-06\n",
      "Epoch 88/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4329Текущий реальный скор(валидационная часть): 1.4286\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 1.5335 - lr: 7.8125e-06\n",
      "Epoch 89/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4296Текущий реальный скор(валидационная часть): 1.4286\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4342 - val_loss: 1.5335 - lr: 7.8125e-06\n",
      "Epoch 90/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4348Текущий реальный скор(валидационная часть): 1.4364\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4362 - val_loss: 1.5392 - lr: 3.9063e-06\n",
      "Epoch 91/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4328Текущий реальный скор(валидационная часть): 1.4366\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4342 - val_loss: 1.5394 - lr: 3.9063e-06\n",
      "Epoch 92/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4340Текущий реальный скор(валидационная часть): 1.4367\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4336 - val_loss: 1.5396 - lr: 3.9063e-06\n",
      "Epoch 93/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4318Текущий реальный скор(валидационная часть): 1.4367\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4332 - val_loss: 1.5396 - lr: 3.9063e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4299Текущий реальный скор(валидационная часть): 1.4368\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 1.5397 - lr: 3.9063e-06\n",
      "Epoch 95/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4280Текущий реальный скор(валидационная часть): 1.4368\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 1.5397 - lr: 3.9063e-06\n",
      "Epoch 96/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4321Текущий реальный скор(валидационная часть): 1.4362\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4318 - val_loss: 1.5394 - lr: 3.9063e-06\n",
      "Epoch 97/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4300Текущий реальный скор(валидационная часть): 1.4359\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4314 - val_loss: 1.5391 - lr: 3.9063e-06\n",
      "Epoch 98/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4272Текущий реальный скор(валидационная часть): 1.4359\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 1.5392 - lr: 3.9063e-06\n",
      "Epoch 99/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4290Текущий реальный скор(валидационная часть): 1.436\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 1.5392 - lr: 3.9063e-06\n",
      "Epoch 100/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4309Текущий реальный скор(валидационная часть): 1.4426\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 1.5439 - lr: 1.9531e-06\n",
      "Epoch 101/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4243Текущий реальный скор(валидационная часть): 1.444\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 1.5449 - lr: 1.9531e-06\n",
      "Epoch 102/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4222Текущий реальный скор(валидационная часть): 1.4442\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4286 - val_loss: 1.5450 - lr: 1.9531e-06\n",
      "Epoch 103/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4265Текущий реальный скор(валидационная часть): 1.4443\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 1.5451 - lr: 1.9531e-06\n",
      "Epoch 104/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4265- ETA: 0s - loss: 0.405 - ETA: 0s - loss: 0.418Текущий реальный скор(валидационная часть): 1.4442\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4282 - val_loss: 1.5451 - lr: 1.9531e-06\n",
      "Epoch 105/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4258Текущий реальный скор(валидационная часть): 1.4443\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 1.5451 - lr: 1.9531e-06\n",
      "Epoch 106/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4246Текущий реальный скор(валидационная часть): 1.4442\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4278 - val_loss: 1.5450 - lr: 1.9531e-06\n",
      "Epoch 107/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4260Текущий реальный скор(валидационная часть): 1.4443\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4277 - val_loss: 1.5451 - lr: 1.9531e-06\n",
      "Epoch 108/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4258Текущий реальный скор(валидационная часть): 1.4442\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 1.5451 - lr: 1.9531e-06\n",
      "Epoch 109/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4250Текущий реальный скор(валидационная часть): 1.4443\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4273 - val_loss: 1.5451 - lr: 1.9531e-06\n",
      "Epoch 110/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4233Текущий реальный скор(валидационная часть): 1.4467\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 1.5468 - lr: 9.7656e-07\n",
      "Epoch 111/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4232Текущий реальный скор(валидационная часть): 1.448\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 1.5477 - lr: 9.7656e-07\n",
      "Epoch 112/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4221Текущий реальный скор(валидационная часть): 1.4485\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4261 - val_loss: 1.5481 - lr: 9.7656e-07\n",
      "Epoch 113/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4242Текущий реальный скор(валидационная часть): 1.4488\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4260 - val_loss: 1.5483 - lr: 9.7656e-07\n",
      "Epoch 114/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4258Текущий реальный скор(валидационная часть): 1.4489\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 1.5484 - lr: 9.7656e-07\n",
      "Epoch 115/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4240Текущий реальный скор(валидационная часть): 1.449\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4258 - val_loss: 1.5484 - lr: 9.7656e-07\n",
      "Epoch 116/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4201Текущий реальный скор(валидационная часть): 1.449\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4257 - val_loss: 1.5485 - lr: 9.7656e-07\n",
      "Epoch 117/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4238Текущий реальный скор(валидационная часть): 1.449\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 1.5485 - lr: 9.7656e-07\n",
      "Epoch 118/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4199Текущий реальный скор(валидационная часть): 1.4491\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4255 - val_loss: 1.5485 - lr: 9.7656e-07\n",
      "Epoch 119/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4256Текущий реальный скор(валидационная часть): 1.3381\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4254 - val_loss: 1.5485 - lr: 9.7656e-07\n",
      "Скор для фолда(15) : 1.3381 средний скор на префиксе = 1.3805 это заняло = 29 сек.\n",
      "Фолд: 16\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 4.0694Текущий реальный скор(валидационная часть): 2.3692\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8272 - val_loss: 2.5014 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.9690Текущий реальный скор(валидационная часть): 1.8719\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9440 - val_loss: 2.0033 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.6391Текущий реальный скор(валидационная часть): 1.7237\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6322 - val_loss: 1.8441 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.4851Текущий реальный скор(валидационная часть): 1.6863\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4766 - val_loss: 1.8020 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.3923Текущий реальный скор(валидационная часть): 1.6762\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3869 - val_loss: 1.7977 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.3220Текущий реальный скор(валидационная часть): 1.5901\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3247 - val_loss: 1.7228 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.2606Текущий реальный скор(валидационная часть): 1.5671\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2630 - val_loss: 1.7067 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 1.2050Текущий реальный скор(валидационная часть): 1.558\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2082 - val_loss: 1.7019 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 1.1503Текущий реальный скор(валидационная часть): 1.5513\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1558 - val_loss: 1.6998 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 1.1187Текущий реальный скор(валидационная часть): 1.5589\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1200 - val_loss: 1.7030 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.0729Текущий реальный скор(валидационная часть): 1.5406\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0742 - val_loss: 1.6837 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 1.0465Текущий реальный скор(валидационная часть): 1.5594\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0494 - val_loss: 1.7031 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.0123Текущий реальный скор(валидационная часть): 1.6058\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0153 - val_loss: 1.7365 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.9829Текущий реальный скор(валидационная часть): 1.7122\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9866 - val_loss: 1.8513 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.9865Текущий реальный скор(валидационная часть): 1.8005\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9872 - val_loss: 1.9347 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.0219Текущий реальный скор(валидационная часть): 1.6104\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0199 - val_loss: 1.7530 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 1.0687Текущий реальный скор(валидационная часть): 1.4847\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0696 - val_loss: 1.6122 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.1332Текущий реальный скор(валидационная часть): 1.4496\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1248 - val_loss: 1.5752 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.9814Текущий реальный скор(валидационная часть): 1.4983\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9825 - val_loss: 1.6244 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.9322Текущий реальный скор(валидационная часть): 1.6021\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9253 - val_loss: 1.7336 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8933Текущий реальный скор(валидационная часть): 1.6094\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8954 - val_loss: 1.7440 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.8670Текущий реальный скор(валидационная часть): 1.6366\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8630 - val_loss: 1.7747 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.8782Текущий реальный скор(валидационная часть): 1.5923\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8779 - val_loss: 1.7439 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.9001Текущий реальный скор(валидационная часть): 1.4482\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8918 - val_loss: 1.5662 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.8920Текущий реальный скор(валидационная часть): 1.4512\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8911 - val_loss: 1.5557 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.9116Текущий реальный скор(валидационная часть): 1.5044\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9118 - val_loss: 1.6249 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.9447Текущий реальный скор(валидационная часть): 1.5735\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9631 - val_loss: 1.7095 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.9836Текущий реальный скор(валидационная часть): 1.8258\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9810 - val_loss: 1.9499 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.9162Текущий реальный скор(валидационная часть): 1.7255\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 1.8571 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.8682Текущий реальный скор(валидационная часть): 1.6757\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8675 - val_loss: 1.8213 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.8315Текущий реальный скор(валидационная часть): 1.6384\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8434 - val_loss: 1.7783 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8075Текущий реальный скор(валидационная часть): 1.6741\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8235 - val_loss: 1.8075 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.8001Текущий реальный скор(валидационная часть): 1.5727\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8112 - val_loss: 1.6990 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.8212Текущий реальный скор(валидационная часть): 1.4629\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8312 - val_loss: 1.5757 - lr: 5.0000e-04\n",
      "Epoch 35/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/134 [=========================>....] - ETA: 0s - loss: 0.7965Текущий реальный скор(валидационная часть): 1.5129\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7976 - val_loss: 1.6180 - lr: 5.0000e-04\n",
      "Epoch 36/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.7322Текущий реальный скор(валидационная часть): 1.476\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7348 - val_loss: 1.5784 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.6555Текущий реальный скор(валидационная часть): 1.4612\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 1.5544 - lr: 2.5000e-04\n",
      "Epoch 38/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6144Текущий реальный скор(валидационная часть): 1.4578\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6176 - val_loss: 1.5521 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5844Текущий реальный скор(валидационная часть): 1.4421\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5894 - val_loss: 1.5403 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.5652Текущий реальный скор(валидационная часть): 1.4531\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5660 - val_loss: 1.5559 - lr: 2.5000e-04\n",
      "Epoch 41/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5393Текущий реальный скор(валидационная часть): 1.4461\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 1.5472 - lr: 2.5000e-04\n",
      "Epoch 42/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5301Текущий реальный скор(валидационная часть): 1.4492\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5344 - val_loss: 1.5524 - lr: 2.5000e-04\n",
      "Epoch 43/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5153Текущий реальный скор(валидационная часть): 1.4453\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5213 - val_loss: 1.5481 - lr: 2.5000e-04\n",
      "Epoch 44/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5065Текущий реальный скор(валидационная часть): 1.4491\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5111 - val_loss: 1.5521 - lr: 2.5000e-04\n",
      "Epoch 45/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.4942Текущий реальный скор(валидационная часть): 1.4523\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5013 - val_loss: 1.5551 - lr: 2.5000e-04\n",
      "Epoch 46/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4879Текущий реальный скор(валидационная часть): 1.4452\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4922 - val_loss: 1.5467 - lr: 2.5000e-04\n",
      "Epoch 47/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4802Текущий реальный скор(валидационная часть): 1.4431\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 1.5452 - lr: 2.5000e-04\n",
      "Epoch 48/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4710Текущий реальный скор(валидационная часть): 1.4408\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 1.5472 - lr: 2.5000e-04\n",
      "Epoch 49/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.4636Текущий реальный скор(валидационная часть): 1.4343\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 1.5397 - lr: 2.5000e-04\n",
      "Epoch 50/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4575Текущий реальный скор(валидационная часть): 1.4474\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 1.5548 - lr: 2.5000e-04\n",
      "Epoch 51/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.4516Текущий реальный скор(валидационная часть): 1.4369\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 1.5452 - lr: 2.5000e-04\n",
      "Epoch 52/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4435Текущий реальный скор(валидационная часть): 1.4513\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 1.5655 - lr: 2.5000e-04\n",
      "Epoch 53/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4370Текущий реальный скор(валидационная часть): 1.443\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4432 - val_loss: 1.5576 - lr: 2.5000e-04\n",
      "Epoch 54/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4346Текущий реальный скор(валидационная часть): 1.4559\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 1.5663 - lr: 2.5000e-04\n",
      "Epoch 55/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4288Текущий реальный скор(валидационная часть): 1.4605\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 1.5752 - lr: 2.5000e-04\n",
      "Epoch 56/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4213Текущий реальный скор(валидационная часть): 1.4586\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4264 - val_loss: 1.5706 - lr: 2.5000e-04\n",
      "Epoch 57/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4192Текущий реальный скор(валидационная часть): 1.4588\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4252 - val_loss: 1.5726 - lr: 2.5000e-04\n",
      "Epoch 58/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.4156Текущий реальный скор(валидационная часть): 1.4566\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 1.5708 - lr: 2.5000e-04\n",
      "Epoch 59/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.4057Текущий реальный скор(валидационная часть): 1.4477\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 1.5550 - lr: 2.5000e-04\n",
      "Epoch 60/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4060Текущий реальный скор(валидационная часть): 1.4671\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4121 - val_loss: 1.5807 - lr: 1.2500e-04\n",
      "Epoch 61/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.4026Текущий реальный скор(валидационная часть): 1.4671\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4079 - val_loss: 1.5774 - lr: 1.2500e-04\n",
      "Epoch 62/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.3991- ETA: 0s - loss: 0.3Текущий реальный скор(валидационная часть): 1.4678\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4051 - val_loss: 1.5795 - lr: 1.2500e-04\n",
      "Epoch 63/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3992Текущий реальный скор(валидационная часть): 1.4641\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4039 - val_loss: 1.5745 - lr: 1.2500e-04\n",
      "Epoch 64/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3967Текущий реальный скор(валидационная часть): 1.4685\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4022 - val_loss: 1.5783 - lr: 1.2500e-04\n",
      "Epoch 65/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3956Текущий реальный скор(валидационная часть): 1.4701\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4006 - val_loss: 1.5812 - lr: 1.2500e-04\n",
      "Epoch 66/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3895Текущий реальный скор(валидационная часть): 1.4706\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3984 - val_loss: 1.5810 - lr: 1.2500e-04\n",
      "Epoch 67/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3902Текущий реальный скор(валидационная часть): 1.4753\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 1.5835 - lr: 1.2500e-04\n",
      "Epoch 68/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3879Текущий реальный скор(валидационная часть): 1.4834\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 1.5917 - lr: 1.2500e-04\n",
      "Epoch 69/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.3819Текущий реальный скор(валидационная часть): 1.4844\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3903 - val_loss: 1.5932 - lr: 1.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4008Текущий реальный скор(валидационная часть): 1.5415\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4093 - val_loss: 1.6548 - lr: 6.2500e-05\n",
      "Epoch 71/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3972Текущий реальный скор(валидационная часть): 1.5382\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4043 - val_loss: 1.6512 - lr: 6.2500e-05\n",
      "Epoch 72/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3933Текущий реальный скор(валидационная часть): 1.5383\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4002 - val_loss: 1.6511 - lr: 6.2500e-05\n",
      "Epoch 73/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3918Текущий реальный скор(валидационная часть): 1.5366\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 1.6491 - lr: 6.2500e-05\n",
      "Epoch 74/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3891Текущий реальный скор(валидационная часть): 1.5372\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3952 - val_loss: 1.6499 - lr: 6.2500e-05\n",
      "Epoch 75/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3868Текущий реальный скор(валидационная часть): 1.5379\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 1.6513 - lr: 6.2500e-05\n",
      "Epoch 76/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3836Текущий реальный скор(валидационная часть): 1.5407\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3907 - val_loss: 1.6543 - lr: 6.2500e-05\n",
      "Epoch 77/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3838Текущий реальный скор(валидационная часть): 1.5389\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3885 - val_loss: 1.6530 - lr: 6.2500e-05\n",
      "Epoch 78/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3743Текущий реальный скор(валидационная часть): 1.5378\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 1.6517 - lr: 6.2500e-05\n",
      "Epoch 79/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3792Текущий реальный скор(валидационная часть): 1.539\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 1.6533 - lr: 6.2500e-05\n",
      "Epoch 80/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.3943Текущий реальный скор(валидационная часть): 1.5126\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4053 - val_loss: 1.6308 - lr: 3.1250e-05\n",
      "Epoch 81/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3897Текущий реальный скор(валидационная часть): 1.5084\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3979 - val_loss: 1.6264 - lr: 3.1250e-05\n",
      "Epoch 82/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3817Текущий реальный скор(валидационная часть): 1.5056\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 1.6236 - lr: 3.1250e-05\n",
      "Epoch 83/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3790Текущий реальный скор(валидационная часть): 1.5039\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 1.6222 - lr: 3.1250e-05\n",
      "Epoch 84/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3705Текущий реальный скор(валидационная часть): 1.5023\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 1.6201 - lr: 3.1250e-05\n",
      "Epoch 85/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3734Текущий реальный скор(валидационная часть): 1.5011\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3799 - val_loss: 1.6183 - lr: 3.1250e-05\n",
      "Epoch 86/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3679Текущий реальный скор(валидационная часть): 1.5012\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 1.6183 - lr: 3.1250e-05\n",
      "Epoch 87/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3681Текущий реальный скор(валидационная часть): 1.4999\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 1.6169 - lr: 3.1250e-05\n",
      "Epoch 88/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3669Текущий реальный скор(валидационная часть): 1.4999\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 1.6171 - lr: 3.1250e-05\n",
      "Epoch 89/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3635Текущий реальный скор(валидационная часть): 1.501\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 1.6176 - lr: 3.1250e-05\n",
      "Epoch 90/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3623Текущий реальный скор(валидационная часть): 1.5048\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 1.6195 - lr: 1.5625e-05\n",
      "Epoch 91/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3611Текущий реальный скор(валидационная часть): 1.5038\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3672 - val_loss: 1.6188 - lr: 1.5625e-05\n",
      "Epoch 92/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3624Текущий реальный скор(валидационная часть): 1.5027\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 1.6176 - lr: 1.5625e-05\n",
      "Epoch 93/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3591Текущий реальный скор(валидационная часть): 1.5026\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3642 - val_loss: 1.6175 - lr: 1.5625e-05\n",
      "Epoch 94/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3597Текущий реальный скор(валидационная часть): 1.5024\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3630 - val_loss: 1.6174 - lr: 1.5625e-05\n",
      "Epoch 95/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3556Текущий реальный скор(валидационная часть): 1.5022\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3619 - val_loss: 1.6172 - lr: 1.5625e-05\n",
      "Epoch 96/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3574Текущий реальный скор(валидационная часть): 1.5021\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3609 - val_loss: 1.6171 - lr: 1.5625e-05\n",
      "Epoch 97/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3536Текущий реальный скор(валидационная часть): 1.5022\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3600 - val_loss: 1.6174 - lr: 1.5625e-05\n",
      "Epoch 98/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3509Текущий реальный скор(валидационная часть): 1.5021\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3591 - val_loss: 1.6172 - lr: 1.5625e-05\n",
      "Epoch 99/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.3546Текущий реальный скор(валидационная часть): 1.502\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3582 - val_loss: 1.6173 - lr: 1.5625e-05\n",
      "Epoch 100/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3509Текущий реальный скор(валидационная часть): 1.505\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3593 - val_loss: 1.6189 - lr: 7.8125e-06\n",
      "Epoch 101/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3528Текущий реальный скор(валидационная часть): 1.5049\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 1.6186 - lr: 7.8125e-06\n",
      "Epoch 102/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3550Текущий реальный скор(валидационная часть): 1.5052\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3582 - val_loss: 1.6187 - lr: 7.8125e-06\n",
      "Epoch 103/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3515Текущий реальный скор(валидационная часть): 1.5053\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3576 - val_loss: 1.6186 - lr: 7.8125e-06\n",
      "Epoch 104/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3518Текущий реальный скор(валидационная часть): 1.5056\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3570 - val_loss: 1.6186 - lr: 7.8125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3503Текущий реальный скор(валидационная часть): 1.5057\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3565 - val_loss: 1.6185 - lr: 7.8125e-06\n",
      "Epoch 106/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3498Текущий реальный скор(валидационная часть): 1.5059\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3561 - val_loss: 1.6185 - lr: 7.8125e-06\n",
      "Epoch 107/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.3521Текущий реальный скор(валидационная часть): 1.506\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3556 - val_loss: 1.6185 - lr: 7.8125e-06\n",
      "Epoch 108/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3496Текущий реальный скор(валидационная часть): 1.5062\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3551 - val_loss: 1.6185 - lr: 7.8125e-06\n",
      "Epoch 109/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3486Текущий реальный скор(валидационная часть): 1.5064\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 1.6186 - lr: 7.8125e-06\n",
      "Epoch 110/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3514Текущий реальный скор(валидационная часть): 1.5061\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3554 - val_loss: 1.6182 - lr: 3.9063e-06\n",
      "Epoch 111/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3478Текущий реальный скор(валидационная часть): 1.506\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3543 - val_loss: 1.6180 - lr: 3.9063e-06\n",
      "Epoch 112/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3504Текущий реальный скор(валидационная часть): 1.506\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3540 - val_loss: 1.6178 - lr: 3.9063e-06\n",
      "Epoch 113/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.3499Текущий реальный скор(валидационная часть): 1.5059\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 1.6177 - lr: 3.9063e-06\n",
      "Epoch 114/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3472Текущий реальный скор(валидационная часть): 1.506\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 1.6177 - lr: 3.9063e-06\n",
      "Epoch 115/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3466Текущий реальный скор(валидационная часть): 1.5061\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 1.6176 - lr: 3.9063e-06\n",
      "Epoch 116/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3469Текущий реальный скор(валидационная часть): 1.5062\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3529 - val_loss: 1.6176 - lr: 3.9063e-06\n",
      "Epoch 117/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3461Текущий реальный скор(валидационная часть): 1.5064\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3526 - val_loss: 1.6177 - lr: 3.9063e-06\n",
      "Epoch 118/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3457Текущий реальный скор(валидационная часть): 1.5064\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3524 - val_loss: 1.6176 - lr: 3.9063e-06\n",
      "Epoch 119/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3455Текущий реальный скор(валидационная часть): 1.5066\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3522 - val_loss: 1.6178 - lr: 3.9063e-06\n",
      "Epoch 120/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3425Текущий реальный скор(валидационная часть): 1.5072\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3515 - val_loss: 1.6185 - lr: 1.9531e-06\n",
      "Epoch 121/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3440- ETA: 0s - loss: 0.333Текущий реальный скор(валидационная часть): 1.5074\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3508 - val_loss: 1.6187 - lr: 1.9531e-06\n",
      "Epoch 122/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3449Текущий реальный скор(валидационная часть): 1.5076\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3506 - val_loss: 1.6188 - lr: 1.9531e-06\n",
      "Epoch 123/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3448Текущий реальный скор(валидационная часть): 1.5077\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3505 - val_loss: 1.6188 - lr: 1.9531e-06\n",
      "Epoch 124/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3437Текущий реальный скор(валидационная часть): 1.5079\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3504 - val_loss: 1.6189 - lr: 1.9531e-06\n",
      "Epoch 125/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3411Текущий реальный скор(валидационная часть): 1.5079\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3502 - val_loss: 1.6189 - lr: 1.9531e-06\n",
      "Epoch 126/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3433Текущий реальный скор(валидационная часть): 1.508\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3501 - val_loss: 1.6189 - lr: 1.9531e-06\n",
      "Epoch 127/500\n",
      "109/134 [=======================>......] - ETA: 0s - loss: 0.3411Текущий реальный скор(валидационная часть): 1.5081\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3500 - val_loss: 1.6189 - lr: 1.9531e-06\n",
      "Epoch 128/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3442Текущий реальный скор(валидационная часть): 1.5081\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 1.6189 - lr: 1.9531e-06\n",
      "Epoch 129/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3450Текущий реальный скор(валидационная часть): 1.5082\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 1.6190 - lr: 1.9531e-06\n",
      "Epoch 130/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3422Текущий реальный скор(валидационная часть): 1.5085\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3491 - val_loss: 1.6191 - lr: 9.7656e-07\n",
      "Epoch 131/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3440Текущий реальный скор(валидационная часть): 1.5086\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 1.6192 - lr: 9.7656e-07\n",
      "Epoch 132/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.3428Текущий реальный скор(валидационная часть): 1.5087\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 1.6192 - lr: 9.7656e-07\n",
      "Epoch 133/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3445Текущий реальный скор(валидационная часть): 1.5087\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 1.6192 - lr: 9.7656e-07\n",
      "Epoch 134/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3417Текущий реальный скор(валидационная часть): 1.5088\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 1.6192 - lr: 9.7656e-07\n",
      "Epoch 135/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.3422Текущий реальный скор(валидационная часть): 1.5088\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 1.6192 - lr: 9.7656e-07\n",
      "Epoch 136/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3418Текущий реальный скор(валидационная часть): 1.5088\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 1.6192 - lr: 9.7656e-07\n",
      "Epoch 137/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3442Текущий реальный скор(валидационная часть): 1.5089\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 1.6192 - lr: 9.7656e-07\n",
      "Epoch 138/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3415Текущий реальный скор(валидационная часть): 1.5089\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3485 - val_loss: 1.6192 - lr: 9.7656e-07\n",
      "Epoch 139/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3434Текущий реальный скор(валидационная часть): 1.509\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3485 - val_loss: 1.6193 - lr: 9.7656e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3412Текущий реальный скор(валидационная часть): 1.509\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 1.6193 - lr: 4.8828e-07\n",
      "Epoch 141/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3411Текущий реальный скор(валидационная часть): 1.5091\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 1.6193 - lr: 4.8828e-07\n",
      "Epoch 142/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3409Текущий реальный скор(валидационная часть): 1.5092\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 1.6194 - lr: 4.8828e-07\n",
      "Epoch 143/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3428Текущий реальный скор(валидационная часть): 1.5092\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3479 - val_loss: 1.6194 - lr: 4.8828e-07\n",
      "Epoch 144/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3420Текущий реальный скор(валидационная часть): 1.5092\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3479 - val_loss: 1.6194 - lr: 4.8828e-07\n",
      "Epoch 145/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3411Текущий реальный скор(валидационная часть): 1.5093\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3479 - val_loss: 1.6194 - lr: 4.8828e-07\n",
      "Epoch 146/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3420Текущий реальный скор(валидационная часть): 1.5093\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 1.6194 - lr: 4.8828e-07\n",
      "Epoch 147/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.3374Текущий реальный скор(валидационная часть): 1.5093\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 1.6194 - lr: 4.8828e-07\n",
      "Epoch 148/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3419Текущий реальный скор(валидационная часть): 1.5093\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 1.6194 - lr: 4.8828e-07\n",
      "Epoch 149/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3371Текущий реальный скор(валидационная часть): 1.4343\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 1.6194 - lr: 4.8828e-07\n",
      "Скор для фолда(16) : 1.4343 средний скор на префиксе = 1.3836 это заняло = 37 сек.\n",
      "Фолд: 17\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 4.0111Текущий реальный скор(валидационная часть): 1.9542\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.7904 - val_loss: 2.0487 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.9783Текущий реальный скор(валидационная часть): 1.4963\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9638 - val_loss: 1.6223 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 1.6644Текущий реальный скор(валидационная часть): 1.4141\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6499 - val_loss: 1.5333 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 1.4998Текущий реальный скор(валидационная часть): 1.3331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4959 - val_loss: 1.4573 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.4104Текущий реальный скор(валидационная часть): 1.2885\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4090 - val_loss: 1.4177 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.3495Текущий реальный скор(валидационная часть): 1.2581\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3405 - val_loss: 1.3865 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.2898Текущий реальный скор(валидационная часть): 1.2241\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2870 - val_loss: 1.3524 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.2532Текущий реальный скор(валидационная часть): 1.2327\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2461 - val_loss: 1.3706 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 1.2119Текущий реальный скор(валидационная часть): 1.2563\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2044 - val_loss: 1.3953 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.1798Текущий реальный скор(валидационная часть): 1.2184\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1741 - val_loss: 1.3437 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 1.1392Текущий реальный скор(валидационная часть): 1.2191\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1308 - val_loss: 1.3457 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 1.1072Текущий реальный скор(валидационная часть): 1.2485\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1012 - val_loss: 1.3787 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 1.0709Текущий реальный скор(валидационная часть): 1.2326\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0656 - val_loss: 1.3619 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 1.0300Текущий реальный скор(валидационная часть): 1.2478\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0419 - val_loss: 1.3734 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.0178Текущий реальный скор(валидационная часть): 1.3374\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0218 - val_loss: 1.4459 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 1.0244Текущий реальный скор(валидационная часть): 1.4113\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0274 - val_loss: 1.5140 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.0367Текущий реальный скор(валидационная часть): 1.3452\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0380 - val_loss: 1.4556 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 1.0475Текущий реальный скор(валидационная часть): 1.3103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0382 - val_loss: 1.4526 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 1.1104Текущий реальный скор(валидационная часть): 1.3286\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1073 - val_loss: 1.4486 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.0666Текущий реальный скор(валидационная часть): 1.2798\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0719 - val_loss: 1.4029 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.9368Текущий реальный скор(валидационная часть): 1.3641\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9471 - val_loss: 1.4959 - lr: 2.5000e-04\n",
      "Epoch 22/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.8677Текущий реальный скор(валидационная часть): 1.3719\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8784 - val_loss: 1.5016 - lr: 2.5000e-04\n",
      "Epoch 23/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8166Текущий реальный скор(валидационная часть): 1.3792\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8287 - val_loss: 1.5040 - lr: 2.5000e-04\n",
      "Epoch 24/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.7859Текущий реальный скор(валидационная часть): 1.3775\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7961 - val_loss: 1.5001 - lr: 2.5000e-04\n",
      "Epoch 25/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.7618Текущий реальный скор(валидационная часть): 1.3842\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7693 - val_loss: 1.5025 - lr: 2.5000e-04\n",
      "Epoch 26/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.7381Текущий реальный скор(валидационная часть): 1.391\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7483 - val_loss: 1.5079 - lr: 2.5000e-04\n",
      "Epoch 27/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.7229Текущий реальный скор(валидационная часть): 1.3947\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7253 - val_loss: 1.5053 - lr: 2.5000e-04\n",
      "Epoch 28/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.6935Текущий реальный скор(валидационная часть): 1.4115\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7008 - val_loss: 1.5269 - lr: 2.5000e-04\n",
      "Epoch 29/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6770Текущий реальный скор(валидационная часть): 1.4203\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6846 - val_loss: 1.5344 - lr: 2.5000e-04\n",
      "Epoch 30/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.6601Текущий реальный скор(валидационная часть): 1.4331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6687 - val_loss: 1.5453 - lr: 2.5000e-04\n",
      "Epoch 31/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.6533Текущий реальный скор(валидационная часть): 1.4145\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6598 - val_loss: 1.5280 - lr: 1.2500e-04\n",
      "Epoch 32/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.6422Текущий реальный скор(валидационная часть): 1.4185\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6543 - val_loss: 1.5340 - lr: 1.2500e-04\n",
      "Epoch 33/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.6395Текущий реальный скор(валидационная часть): 1.4234\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6427 - val_loss: 1.5363 - lr: 1.2500e-04\n",
      "Epoch 34/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.6216Текущий реальный скор(валидационная часть): 1.43\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6341 - val_loss: 1.5402 - lr: 1.2500e-04\n",
      "Epoch 35/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6157Текущий реальный скор(валидационная часть): 1.4343\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6262 - val_loss: 1.5425 - lr: 1.2500e-04\n",
      "Epoch 36/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.6059Текущий реальный скор(валидационная часть): 1.442\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6186 - val_loss: 1.5479 - lr: 1.2500e-04\n",
      "Epoch 37/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6002Текущий реальный скор(валидационная часть): 1.4446\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 1.5495 - lr: 1.2500e-04\n",
      "Epoch 38/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5882Текущий реальный скор(валидационная часть): 1.4555\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 1.5541 - lr: 1.2500e-04\n",
      "Epoch 39/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5847Текущий реальный скор(валидационная часть): 1.4563\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5980 - val_loss: 1.5540 - lr: 1.2500e-04\n",
      "Epoch 40/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5728Текущий реальный скор(валидационная часть): 1.4592\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5911 - val_loss: 1.5566 - lr: 1.2500e-04\n",
      "Epoch 41/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5936Текущий реальный скор(валидационная часть): 1.5031\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 1.5995 - lr: 6.2500e-05\n",
      "Epoch 42/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5971Текущий реальный скор(валидационная часть): 1.5068\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 1.6050 - lr: 6.2500e-05\n",
      "Epoch 43/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5970Текущий реальный скор(валидационная часть): 1.4978\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 1.5970 - lr: 6.2500e-05\n",
      "Epoch 44/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5933Текущий реальный скор(валидационная часть): 1.4986\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 1.5990 - lr: 6.2500e-05\n",
      "Epoch 45/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5908Текущий реальный скор(валидационная часть): 1.4992\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 1.6004 - lr: 6.2500e-05\n",
      "Epoch 46/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5880Текущий реальный скор(валидационная часть): 1.4992\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5987 - val_loss: 1.6014 - lr: 6.2500e-05\n",
      "Epoch 47/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5819Текущий реальный скор(валидационная часть): 1.5004\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5951 - val_loss: 1.6028 - lr: 6.2500e-05\n",
      "Epoch 48/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5792Текущий реальный скор(валидационная часть): 1.5006\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5907 - val_loss: 1.6040 - lr: 6.2500e-05\n",
      "Epoch 49/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5814Текущий реальный скор(валидационная часть): 1.4952\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5869 - val_loss: 1.5977 - lr: 6.2500e-05\n",
      "Epoch 50/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5696Текущий реальный скор(валидационная часть): 1.4961\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5824 - val_loss: 1.5991 - lr: 6.2500e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5879Текущий реальный скор(валидационная часть): 1.4533\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5916 - val_loss: 1.5508 - lr: 3.1250e-05\n",
      "Epoch 52/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5666Текущий реальный скор(валидационная часть): 1.4512\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5796 - val_loss: 1.5490 - lr: 3.1250e-05\n",
      "Epoch 53/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5703Текущий реальный скор(валидационная часть): 1.4512\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5741 - val_loss: 1.5490 - lr: 3.1250e-05\n",
      "Epoch 54/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5525Текущий реальный скор(валидационная часть): 1.4536\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5693 - val_loss: 1.5508 - lr: 3.1250e-05\n",
      "Epoch 55/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5614Текущий реальный скор(валидационная часть): 1.4545\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5652 - val_loss: 1.5512 - lr: 3.1250e-05\n",
      "Epoch 56/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5479Текущий реальный скор(валидационная часть): 1.4561\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5616 - val_loss: 1.5522 - lr: 3.1250e-05\n",
      "Epoch 57/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5508Текущий реальный скор(валидационная часть): 1.4571\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5583 - val_loss: 1.5529 - lr: 3.1250e-05\n",
      "Epoch 58/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5407Текущий реальный скор(валидационная часть): 1.4586\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5551 - val_loss: 1.5540 - lr: 3.1250e-05\n",
      "Epoch 59/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5447Текущий реальный скор(валидационная часть): 1.4594\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5522 - val_loss: 1.5546 - lr: 3.1250e-05\n",
      "Epoch 60/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5385Текущий реальный скор(валидационная часть): 1.4607\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5495 - val_loss: 1.5581 - lr: 3.1250e-05\n",
      "Epoch 61/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5460Текущий реальный скор(валидационная часть): 1.4583\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5525 - val_loss: 1.5576 - lr: 1.5625e-05\n",
      "Epoch 62/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5454Текущий реальный скор(валидационная часть): 1.4596\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5489 - val_loss: 1.5587 - lr: 1.5625e-05\n",
      "Epoch 63/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5402Текущий реальный скор(валидационная часть): 1.4604\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5469 - val_loss: 1.5592 - lr: 1.5625e-05\n",
      "Epoch 64/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5379Текущий реальный скор(валидационная часть): 1.4613\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5451 - val_loss: 1.5599 - lr: 1.5625e-05\n",
      "Epoch 65/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5398Текущий реальный скор(валидационная часть): 1.4619\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5434 - val_loss: 1.5602 - lr: 1.5625e-05\n",
      "Epoch 66/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5350Текущий реальный скор(валидационная часть): 1.4627\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 1.5610 - lr: 1.5625e-05\n",
      "Epoch 67/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5277Текущий реальный скор(валидационная часть): 1.4634\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5404 - val_loss: 1.5614 - lr: 1.5625e-05\n",
      "Epoch 68/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5321Текущий реальный скор(валидационная часть): 1.4634\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 1.5621 - lr: 1.5625e-05\n",
      "Epoch 69/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5286Текущий реальный скор(валидационная часть): 1.4637\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5374 - val_loss: 1.5623 - lr: 1.5625e-05\n",
      "Epoch 70/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5255Текущий реальный скор(валидационная часть): 1.4643\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5361 - val_loss: 1.5627 - lr: 1.5625e-05\n",
      "Epoch 71/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5233Текущий реальный скор(валидационная часть): 1.4666\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 1.5662 - lr: 7.8125e-06\n",
      "Epoch 72/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5311Текущий реальный скор(валидационная часть): 1.4671\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5345 - val_loss: 1.5666 - lr: 7.8125e-06\n",
      "Epoch 73/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5208Текущий реальный скор(валидационная часть): 1.4676\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5337 - val_loss: 1.5669 - lr: 7.8125e-06\n",
      "Epoch 74/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.5319Текущий реальный скор(валидационная часть): 1.4681\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5328 - val_loss: 1.5672 - lr: 7.8125e-06\n",
      "Epoch 75/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5236Текущий реальный скор(валидационная часть): 1.4686\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5320 - val_loss: 1.5674 - lr: 7.8125e-06\n",
      "Epoch 76/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5277Текущий реальный скор(валидационная часть): 1.4689\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 1.5677 - lr: 7.8125e-06\n",
      "Epoch 77/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5192Текущий реальный скор(валидационная часть): 1.4693\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5305 - val_loss: 1.5679 - lr: 7.8125e-06\n",
      "Epoch 78/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5229Текущий реальный скор(валидационная часть): 1.4697\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 1.5682 - lr: 7.8125e-06\n",
      "Epoch 79/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5183Текущий реальный скор(валидационная часть): 1.47\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 1.5685 - lr: 7.8125e-06\n",
      "Epoch 80/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5201Текущий реальный скор(валидационная часть): 1.4705\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5284 - val_loss: 1.5688 - lr: 7.8125e-06\n",
      "Epoch 81/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5158Текущий реальный скор(валидационная часть): 1.4695\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 1.5692 - lr: 3.9063e-06\n",
      "Epoch 82/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5228Текущий реальный скор(валидационная часть): 1.4696\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.5693 - lr: 3.9063e-06\n",
      "Epoch 83/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5127Текущий реальный скор(валидационная часть): 1.4698\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 1.5694 - lr: 3.9063e-06\n",
      "Epoch 84/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5193Текущий реальный скор(валидационная часть): 1.47\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.5696 - lr: 3.9063e-06\n",
      "Epoch 85/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5117Текущий реальный скор(валидационная часть): 1.4701\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.5697 - lr: 3.9063e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5212Текущий реальный скор(валидационная часть): 1.4703\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.5698 - lr: 3.9063e-06\n",
      "Epoch 87/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5151Текущий реальный скор(валидационная часть): 1.4705\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.5700 - lr: 3.9063e-06\n",
      "Epoch 88/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5173Текущий реальный скор(валидационная часть): 1.4707\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.5702 - lr: 3.9063e-06\n",
      "Epoch 89/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5169Текущий реальный скор(валидационная часть): 1.471\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.5704 - lr: 3.9063e-06\n",
      "Epoch 90/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5132Текущий реальный скор(валидационная часть): 1.4712\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.5705 - lr: 3.9063e-06\n",
      "Epoch 91/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5128Текущий реальный скор(валидационная часть): 1.4696\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 1.5656 - lr: 1.9531e-06\n",
      "Epoch 92/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5113Текущий реальный скор(валидационная часть): 1.4694\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 1.5653 - lr: 1.9531e-06\n",
      "Epoch 93/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5099Текущий реальный скор(валидационная часть): 1.4695\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5216 - val_loss: 1.5653 - lr: 1.9531e-06\n",
      "Epoch 94/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5175Текущий реальный скор(валидационная часть): 1.4696\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5214 - val_loss: 1.5654 - lr: 1.9531e-06\n",
      "Epoch 95/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5124Текущий реальный скор(валидационная часть): 1.4696\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5213 - val_loss: 1.5655 - lr: 1.9531e-06\n",
      "Epoch 96/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5139Текущий реальный скор(валидационная часть): 1.4698\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 1.5656 - lr: 1.9531e-06\n",
      "Epoch 97/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5103Текущий реальный скор(валидационная часть): 1.4698\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5209 - val_loss: 1.5656 - lr: 1.9531e-06\n",
      "Epoch 98/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5142Текущий реальный скор(валидационная часть): 1.4699\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 1.5657 - lr: 1.9531e-06\n",
      "Epoch 99/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5106Текущий реальный скор(валидационная часть): 1.47\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5206 - val_loss: 1.5657 - lr: 1.9531e-06\n",
      "Epoch 100/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5165Текущий реальный скор(валидационная часть): 1.4701\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5204 - val_loss: 1.5658 - lr: 1.9531e-06\n",
      "Epoch 101/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5052Текущий реальный скор(валидационная часть): 1.4696\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5197 - val_loss: 1.5652 - lr: 9.7656e-07\n",
      "Epoch 102/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5096Текущий реальный скор(валидационная часть): 1.4695\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5194 - val_loss: 1.5650 - lr: 9.7656e-07\n",
      "Epoch 103/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5086Текущий реальный скор(валидационная часть): 1.4694\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5193 - val_loss: 1.5649 - lr: 9.7656e-07\n",
      "Epoch 104/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5151Текущий реальный скор(валидационная часть): 1.4695\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5192 - val_loss: 1.5649 - lr: 9.7656e-07\n",
      "Epoch 105/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5071Текущий реальный скор(валидационная часть): 1.4695\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5191 - val_loss: 1.5649 - lr: 9.7656e-07\n",
      "Epoch 106/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5150Текущий реальный скор(валидационная часть): 1.4695\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5190 - val_loss: 1.5649 - lr: 9.7656e-07\n",
      "Epoch 107/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5044Текущий реальный скор(валидационная часть): 1.4696\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5189 - val_loss: 1.5650 - lr: 9.7656e-07\n",
      "Epoch 108/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.5175Текущий реальный скор(валидационная часть): 1.4696\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5188 - val_loss: 1.5650 - lr: 9.7656e-07\n",
      "Epoch 109/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5085Текущий реальный скор(валидационная часть): 1.4696\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5188 - val_loss: 1.5650 - lr: 9.7656e-07\n",
      "Epoch 110/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5055Текущий реальный скор(валидационная часть): 1.2184\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5187 - val_loss: 1.5651 - lr: 9.7656e-07\n",
      "Скор для фолда(17) : 1.2184 средний скор на префиксе = 1.3745 это заняло = 27 сек.\n",
      "Фолд: 18\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/134 [========================>.....] - ETA: 0s - loss: 4.0597Текущий реальный скор(валидационная часть): 2.2032\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.8283 - val_loss: 2.2839 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.9615Текущий реальный скор(валидационная часть): 1.5211\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9455 - val_loss: 1.6107 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 1.6677Текущий реальный скор(валидационная часть): 1.3239\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6518 - val_loss: 1.3984 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.4965Текущий реальный скор(валидационная часть): 1.2918\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4953 - val_loss: 1.3829 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.4089Текущий реальный скор(валидационная часть): 1.2704\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4029 - val_loss: 1.3650 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.3214Текущий реальный скор(валидационная часть): 1.2607\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3257 - val_loss: 1.3544 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.2782Текущий реальный скор(валидационная часть): 1.2611\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2732 - val_loss: 1.3551 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 1.2193Текущий реальный скор(валидационная часть): 1.2701\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2216 - val_loss: 1.3737 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 1.1740Текущий реальный скор(валидационная часть): 1.2563\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1791 - val_loss: 1.3554 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 1.1330Текущий реальный скор(валидационная часть): 1.2616\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1386 - val_loss: 1.3707 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 1.1105Текущий реальный скор(валидационная часть): 1.2605\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1106 - val_loss: 1.3650 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 1.0757Текущий реальный скор(валидационная часть): 1.2916\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0785 - val_loss: 1.3859 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.0401Текущий реальный скор(валидационная часть): 1.2713\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0470 - val_loss: 1.3670 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 1.0277Текущий реальный скор(валидационная часть): 1.2795\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0298 - val_loss: 1.3655 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 1.0117Текущий реальный скор(валидационная часть): 1.2597\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0081 - val_loss: 1.3572 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.0106Текущий реальный скор(валидационная часть): 1.3617\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0138 - val_loss: 1.4501 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 1.0142Текущий реальный скор(валидационная часть): 1.353\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0127 - val_loss: 1.4486 - lr: 2.5000e-04\n",
      "Epoch 18/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.9349Текущий реальный скор(валидационная часть): 1.3816\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 1.4721 - lr: 2.5000e-04\n",
      "Epoch 19/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.9048Текущий реальный скор(валидационная часть): 1.3967\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9092 - val_loss: 1.4923 - lr: 2.5000e-04\n",
      "Epoch 20/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.8842Текущий реальный скор(валидационная часть): 1.4128\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8917 - val_loss: 1.5150 - lr: 2.5000e-04\n",
      "Epoch 21/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.8695Текущий реальный скор(валидационная часть): 1.4077\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8710 - val_loss: 1.5116 - lr: 2.5000e-04\n",
      "Epoch 22/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.8442Текущий реальный скор(валидационная часть): 1.3998\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8459 - val_loss: 1.5234 - lr: 2.5000e-04\n",
      "Epoch 23/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.8152Текущий реальный скор(валидационная часть): 1.4098\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8213 - val_loss: 1.5391 - lr: 2.5000e-04\n",
      "Epoch 24/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7996Текущий реальный скор(валидационная часть): 1.4181\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8054 - val_loss: 1.5488 - lr: 2.5000e-04\n",
      "Epoch 25/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.7755Текущий реальный скор(валидационная часть): 1.4394\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7850 - val_loss: 1.5689 - lr: 2.5000e-04\n",
      "Epoch 26/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.7766Текущий реальный скор(валидационная часть): 1.458\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7810 - val_loss: 1.5829 - lr: 2.5000e-04\n",
      "Epoch 27/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.7670Текущий реальный скор(валидационная часть): 1.3509\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7714 - val_loss: 1.4523 - lr: 1.2500e-04\n",
      "Epoch 28/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.7198Текущий реальный скор(валидационная часть): 1.3483\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7227 - val_loss: 1.4508 - lr: 1.2500e-04\n",
      "Epoch 29/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.6916Текущий реальный скор(валидационная часть): 1.3486\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6958 - val_loss: 1.4553 - lr: 1.2500e-04\n",
      "Epoch 30/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6759Текущий реальный скор(валидационная часть): 1.3502\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6781 - val_loss: 1.4584 - lr: 1.2500e-04\n",
      "Epoch 31/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.6616Текущий реальный скор(валидационная часть): 1.3537\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6643 - val_loss: 1.4616 - lr: 1.2500e-04\n",
      "Epoch 32/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6504Текущий реальный скор(валидационная часть): 1.3618\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6495 - val_loss: 1.4687 - lr: 1.2500e-04\n",
      "Epoch 33/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.6423Текущий реальный скор(валидационная часть): 1.3658\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6477 - val_loss: 1.4775 - lr: 1.2500e-04\n",
      "Epoch 34/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6316Текущий реальный скор(валидационная часть): 1.3671\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6348 - val_loss: 1.4792 - lr: 1.2500e-04\n",
      "Epoch 35/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.6168Текущий реальный скор(валидационная часть): 1.3697\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 1.4810 - lr: 1.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.6139Текущий реальный скор(валидационная часть): 1.3713\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 1.4813 - lr: 1.2500e-04\n",
      "Epoch 37/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.6052Текущий реальный скор(валидационная часть): 1.36\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6070 - val_loss: 1.4696 - lr: 6.2500e-05\n",
      "Epoch 38/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5989Текущий реальный скор(валидационная часть): 1.3592\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 1.4684 - lr: 6.2500e-05\n",
      "Epoch 39/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5951Текущий реальный скор(валидационная часть): 1.3608\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5965 - val_loss: 1.4694 - lr: 6.2500e-05\n",
      "Epoch 40/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5900Текущий реальный скор(валидационная часть): 1.3654\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5922 - val_loss: 1.4740 - lr: 6.2500e-05\n",
      "Epoch 41/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5849Текущий реальный скор(валидационная часть): 1.3654\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5871 - val_loss: 1.4743 - lr: 6.2500e-05\n",
      "Epoch 42/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5824Текущий реальный скор(валидационная часть): 1.3679\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5829 - val_loss: 1.4776 - lr: 6.2500e-05\n",
      "Epoch 43/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5768Текущий реальный скор(валидационная часть): 1.3679\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5788 - val_loss: 1.4780 - lr: 6.2500e-05\n",
      "Epoch 44/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5752Текущий реальный скор(валидационная часть): 1.3706\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5755 - val_loss: 1.4815 - lr: 6.2500e-05\n",
      "Epoch 45/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5658Текущий реальный скор(валидационная часть): 1.3873\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5697 - val_loss: 1.4964 - lr: 6.2500e-05\n",
      "Epoch 46/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5713Текущий реальный скор(валидационная часть): 1.3744\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5713 - val_loss: 1.4850 - lr: 6.2500e-05\n",
      "Epoch 47/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5728Текущий реальный скор(валидационная часть): 1.3685\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5727 - val_loss: 1.4758 - lr: 3.1250e-05\n",
      "Epoch 48/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5678Текущий реальный скор(валидационная часть): 1.3682\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5697 - val_loss: 1.4759 - lr: 3.1250e-05\n",
      "Epoch 49/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5666Текущий реальный скор(валидационная часть): 1.3685\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5667 - val_loss: 1.4769 - lr: 3.1250e-05\n",
      "Epoch 50/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5622Текущий реальный скор(валидационная часть): 1.3685\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5641 - val_loss: 1.4771 - lr: 3.1250e-05\n",
      "Epoch 51/500\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.5602Текущий реальный скор(валидационная часть): 1.3689\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5616 - val_loss: 1.4779 - lr: 3.1250e-05\n",
      "Epoch 52/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5594Текущий реальный скор(валидационная часть): 1.3694\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5593 - val_loss: 1.4783 - lr: 3.1250e-05\n",
      "Epoch 53/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5563Текущий реальный скор(валидационная часть): 1.3698\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5572 - val_loss: 1.4786 - lr: 3.1250e-05\n",
      "Epoch 54/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5549Текущий реальный скор(валидационная часть): 1.3711\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5551 - val_loss: 1.4800 - lr: 3.1250e-05\n",
      "Epoch 55/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5527Текущий реальный скор(валидационная часть): 1.3717\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5531 - val_loss: 1.4807 - lr: 3.1250e-05\n",
      "Epoch 56/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5500Текущий реальный скор(валидационная часть): 1.372\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5509 - val_loss: 1.4811 - lr: 3.1250e-05\n",
      "Epoch 57/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5516Текущий реальный скор(валидационная часть): 1.3819\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5557 - val_loss: 1.4907 - lr: 1.5625e-05\n",
      "Epoch 58/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.5560Текущий реальный скор(валидационная часть): 1.3825\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5549 - val_loss: 1.4943 - lr: 1.5625e-05\n",
      "Epoch 59/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5528Текущий реальный скор(валидационная часть): 1.3828\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5534 - val_loss: 1.4946 - lr: 1.5625e-05\n",
      "Epoch 60/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5536Текущий реальный скор(валидационная часть): 1.383\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 1.4949 - lr: 1.5625e-05\n",
      "Epoch 61/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5496Текущий реальный скор(валидационная часть): 1.3833\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5506 - val_loss: 1.4952 - lr: 1.5625e-05\n",
      "Epoch 62/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5508Текущий реальный скор(валидационная часть): 1.3834\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5494 - val_loss: 1.4954 - lr: 1.5625e-05\n",
      "Epoch 63/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5480Текущий реальный скор(валидационная часть): 1.3837\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5482 - val_loss: 1.4957 - lr: 1.5625e-05\n",
      "Epoch 64/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5448Текущий реальный скор(валидационная часть): 1.3836\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5470 - val_loss: 1.4954 - lr: 1.5625e-05\n",
      "Epoch 65/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5457Текущий реальный скор(валидационная часть): 1.3839\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5459 - val_loss: 1.4955 - lr: 1.5625e-05\n",
      "Epoch 66/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5461Текущий реальный скор(валидационная часть): 1.3838\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5448 - val_loss: 1.4953 - lr: 1.5625e-05\n",
      "Epoch 67/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5454Текущий реальный скор(валидационная часть): 1.3782\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5454 - val_loss: 1.4861 - lr: 7.8125e-06\n",
      "Epoch 68/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 0.5452Текущий реальный скор(валидационная часть): 1.3782\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5447 - val_loss: 1.4861 - lr: 7.8125e-06\n",
      "Epoch 69/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5428Текущий реальный скор(валидационная часть): 1.3781\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5439 - val_loss: 1.4859 - lr: 7.8125e-06\n",
      "Epoch 70/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.5424Текущий реальный скор(валидационная часть): 1.3781\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5432 - val_loss: 1.4859 - lr: 7.8125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5422Текущий реальный скор(валидационная часть): 1.3782\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5425 - val_loss: 1.4860 - lr: 7.8125e-06\n",
      "Epoch 72/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.5402Текущий реальный скор(валидационная часть): 1.3783\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 1.4860 - lr: 7.8125e-06\n",
      "Epoch 73/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5408Текущий реальный скор(валидационная часть): 1.3785\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5412 - val_loss: 1.4862 - lr: 7.8125e-06\n",
      "Epoch 74/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5386Текущий реальный скор(валидационная часть): 1.3788\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5406 - val_loss: 1.4865 - lr: 7.8125e-06\n",
      "Epoch 75/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5399Текущий реальный скор(валидационная часть): 1.3789\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5400 - val_loss: 1.4865 - lr: 7.8125e-06\n",
      "Epoch 76/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5378Текущий реальный скор(валидационная часть): 1.3792\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 1.4869 - lr: 7.8125e-06\n",
      "Epoch 77/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5343Текущий реальный скор(валидационная часть): 1.38\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5390 - val_loss: 1.4880 - lr: 3.9063e-06\n",
      "Epoch 78/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.5363Текущий реальный скор(валидационная часть): 1.3805\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 1.4884 - lr: 3.9063e-06\n",
      "Epoch 79/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5380Текущий реальный скор(валидационная часть): 1.3807\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5383 - val_loss: 1.4886 - lr: 3.9063e-06\n",
      "Epoch 80/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5389Текущий реальный скор(валидационная часть): 1.3809\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5380 - val_loss: 1.4888 - lr: 3.9063e-06\n",
      "Epoch 81/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5365Текущий реальный скор(валидационная часть): 1.3811\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5376 - val_loss: 1.4890 - lr: 3.9063e-06\n",
      "Epoch 82/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5381Текущий реальный скор(валидационная часть): 1.3814\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5372 - val_loss: 1.4892 - lr: 3.9063e-06\n",
      "Epoch 83/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5366Текущий реальный скор(валидационная часть): 1.3815\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 1.4893 - lr: 3.9063e-06\n",
      "Epoch 84/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5380Текущий реальный скор(валидационная часть): 1.3818\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 1.4895 - lr: 3.9063e-06\n",
      "Epoch 85/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5351Текущий реальный скор(валидационная часть): 1.382\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5362 - val_loss: 1.4897 - lr: 3.9063e-06\n",
      "Epoch 86/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.5345Текущий реальный скор(валидационная часть): 1.3822\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5359 - val_loss: 1.4898 - lr: 3.9063e-06\n",
      "Epoch 87/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5343Текущий реальный скор(валидационная часть): 1.383\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 1.4929 - lr: 1.9531e-06\n",
      "Epoch 88/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.5331Текущий реальный скор(валидационная часть): 1.3832\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5346 - val_loss: 1.4930 - lr: 1.9531e-06\n",
      "Epoch 89/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5334Текущий реальный скор(валидационная часть): 1.3833\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5343 - val_loss: 1.4931 - lr: 1.9531e-06\n",
      "Epoch 90/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5326Текущий реальный скор(валидационная часть): 1.3833\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 1.4932 - lr: 1.9531e-06\n",
      "Epoch 91/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5338Текущий реальный скор(валидационная часть): 1.3834\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5340 - val_loss: 1.4932 - lr: 1.9531e-06\n",
      "Epoch 92/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5323Текущий реальный скор(валидационная часть): 1.3835\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5338 - val_loss: 1.4933 - lr: 1.9531e-06\n",
      "Epoch 93/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5328Текущий реальный скор(валидационная часть): 1.3836\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5337 - val_loss: 1.4934 - lr: 1.9531e-06\n",
      "Epoch 94/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5291Текущий реальный скор(валидационная часть): 1.3837\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5335 - val_loss: 1.4934 - lr: 1.9531e-06\n",
      "Epoch 95/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5331Текущий реальный скор(валидационная часть): 1.3838\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 1.4935 - lr: 1.9531e-06\n",
      "Epoch 96/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5323Текущий реальный скор(валидационная часть): 1.3839\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5332 - val_loss: 1.4936 - lr: 1.9531e-06\n",
      "Epoch 97/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5327Текущий реальный скор(валидационная часть): 1.3841\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5325 - val_loss: 1.4937 - lr: 9.7656e-07\n",
      "Epoch 98/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5313Текущий реальный скор(валидационная часть): 1.3842\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 1.4939 - lr: 9.7656e-07\n",
      "Epoch 99/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5278Текущий реальный скор(валидационная часть): 1.3843\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 1.4939 - lr: 9.7656e-07\n",
      "Epoch 100/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5318Текущий реальный скор(валидационная часть): 1.3844\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5320 - val_loss: 1.4940 - lr: 9.7656e-07\n",
      "Epoch 101/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.5329Текущий реальный скор(валидационная часть): 1.3845\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 1.4940 - lr: 9.7656e-07\n",
      "Epoch 102/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.5321Текущий реальный скор(валидационная часть): 1.3845\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 1.4941 - lr: 9.7656e-07\n",
      "Epoch 103/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.5327Текущий реальный скор(валидационная часть): 1.3846\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 1.4941 - lr: 9.7656e-07\n",
      "Epoch 104/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.5315Текущий реальный скор(валидационная часть): 1.3846\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 1.4942 - lr: 9.7656e-07\n",
      "Epoch 105/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.5331Текущий реальный скор(валидационная часть): 1.3847\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5316 - val_loss: 1.4942 - lr: 9.7656e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.5307Текущий реальный скор(валидационная часть): 1.2607\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5316 - val_loss: 1.4943 - lr: 9.7656e-07\n",
      "Скор для фолда(18) : 1.2607 средний скор на префиксе = 1.3685 это заняло = 26 сек.\n",
      "Фолд: 19\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer flatten_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Модель: input_shape = [(None, 73), (None, 1), (None, 1), (None, 1)] output_shape = (None, 1)\n",
      "Начинаю обучение модели (СPU) количество эпох = 500\n",
      "Epoch 1/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 4.0368Текущий реальный скор(валидационная часть): 2.3069\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 3.7952 - val_loss: 2.4115 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "108/134 [=======================>......] - ETA: 0s - loss: 1.9888Текущий реальный скор(валидационная часть): 1.8302\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9364 - val_loss: 1.9457 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.6499Текущий реальный скор(валидационная часть): 1.6782\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6426 - val_loss: 1.7928 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.5007Текущий реальный скор(валидационная часть): 1.5862\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4937 - val_loss: 1.7138 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.3983Текущий реальный скор(валидационная часть): 1.5762\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3948 - val_loss: 1.6873 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 1.3312Текущий реальный скор(валидационная часть): 1.5638\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3287 - val_loss: 1.6608 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.2715Текущий реальный скор(валидационная часть): 1.5535\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2678 - val_loss: 1.6426 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 1.2121Текущий реальный скор(валидационная часть): 1.5228\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2124 - val_loss: 1.6154 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 1.1712Текущий реальный скор(валидационная часть): 1.507\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1672 - val_loss: 1.5882 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 1.1221Текущий реальный скор(валидационная часть): 1.5506\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1256 - val_loss: 1.6245 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 1.0931Текущий реальный скор(валидационная часть): 1.5334\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0902 - val_loss: 1.6064 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "113/134 [========================>.....] - ETA: 0s - loss: 1.0598Текущий реальный скор(валидационная часть): 1.538\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0591 - val_loss: 1.6119 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 1.0197Текущий реальный скор(валидационная часть): 1.5096\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0190 - val_loss: 1.5793 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.9867Текущий реальный скор(валидационная часть): 1.5177\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9823 - val_loss: 1.5922 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.9564Текущий реальный скор(валидационная часть): 1.5409\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9568 - val_loss: 1.6150 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 1.0162Текущий реальный скор(валидационная часть): 1.4918\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0036 - val_loss: 1.5770 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.9599Текущий реальный скор(валидационная часть): 1.4146\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9627 - val_loss: 1.5269 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.9256Текущий реальный скор(валидационная часть): 1.5035\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9166 - val_loss: 1.6076 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.8876Текущий реальный скор(валидационная часть): 1.4508\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8849 - val_loss: 1.5773 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.8711Текущий реальный скор(валидационная часть): 1.4596\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8644 - val_loss: 1.5673 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.8662Текущий реальный скор(валидационная часть): 1.4525\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8645 - val_loss: 1.5503 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.8777Текущий реальный скор(валидационная часть): 1.4077\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8662 - val_loss: 1.5005 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.8162Текущий реальный скор(валидационная часть): 1.3631\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8139 - val_loss: 1.4969 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7898Текущий реальный скор(валидационная часть): 1.3381\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7884 - val_loss: 1.4465 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7525Текущий реальный скор(валидационная часть): 1.4042\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7557 - val_loss: 1.5054 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.7937Текущий реальный скор(валидационная часть): 1.3597\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7901 - val_loss: 1.4626 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.8310Текущий реальный скор(валидационная часть): 1.2841\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8217 - val_loss: 1.3804 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.7757Текущий реальный скор(валидационная часть): 1.2764\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7641 - val_loss: 1.3879 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7679Текущий реальный скор(валидационная часть): 1.3076\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7627 - val_loss: 1.4329 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.8168Текущий реальный скор(валидационная часть): 1.3455\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8083 - val_loss: 1.4480 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.7637Текущий реальный скор(валидационная часть): 1.5879\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7621 - val_loss: 1.6834 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7629Текущий реальный скор(валидационная часть): 1.2568\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7734 - val_loss: 1.3643 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7450Текущий реальный скор(валидационная часть): 1.1985\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7436 - val_loss: 1.3117 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.7241Текущий реальный скор(валидационная часть): 1.2587\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7171 - val_loss: 1.3912 - lr: 5.0000e-04\n",
      "Epoch 35/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.7113Текущий реальный скор(валидационная часть): 1.2044\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7067 - val_loss: 1.3184 - lr: 5.0000e-04\n",
      "Epoch 36/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.7115Текущий реальный скор(валидационная часть): 1.2672\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7063 - val_loss: 1.3892 - lr: 5.0000e-04\n",
      "Epoch 37/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.6959Текущий реальный скор(валидационная часть): 1.3097\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6929 - val_loss: 1.4319 - lr: 5.0000e-04\n",
      "Epoch 38/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.6979Текущий реальный скор(валидационная часть): 1.3999\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7021 - val_loss: 1.5120 - lr: 5.0000e-04\n",
      "Epoch 39/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.6595Текущий реальный скор(валидационная часть): 1.3825\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6820 - val_loss: 1.5279 - lr: 5.0000e-04\n",
      "Epoch 40/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.6612Текущий реальный скор(валидационная часть): 1.2947\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6632 - val_loss: 1.4289 - lr: 5.0000e-04\n",
      "Epoch 41/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.6184Текущий реальный скор(валидационная часть): 1.4604\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6360 - val_loss: 1.5983 - lr: 5.0000e-04\n",
      "Epoch 42/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.6360Текущий реальный скор(валидационная часть): 1.4561\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6384 - val_loss: 1.5940 - lr: 5.0000e-04\n",
      "Epoch 43/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.6557Текущий реальный скор(валидационная часть): 1.3616\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6481 - val_loss: 1.4990 - lr: 5.0000e-04\n",
      "Epoch 44/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.7244Текущий реальный скор(валидационная часть): 1.2174\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7246 - val_loss: 1.3474 - lr: 2.5000e-04\n",
      "Epoch 45/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.6287Текущий реальный скор(валидационная часть): 1.181\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6342 - val_loss: 1.3065 - lr: 2.5000e-04\n",
      "Epoch 46/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.5753Текущий реальный скор(валидационная часть): 1.1834\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5740 - val_loss: 1.3120 - lr: 2.5000e-04\n",
      "Epoch 47/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.5346Текущий реальный скор(валидационная часть): 1.1864\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 1.3167 - lr: 2.5000e-04\n",
      "Epoch 48/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.5151Текущий реальный скор(валидационная часть): 1.1801\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 1.3119 - lr: 2.5000e-04\n",
      "Epoch 49/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.4934Текущий реальный скор(валидационная часть): 1.182\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5008 - val_loss: 1.3104 - lr: 2.5000e-04\n",
      "Epoch 50/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4865Текущий реальный скор(валидационная часть): 1.1863\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 1.3135 - lr: 2.5000e-04\n",
      "Epoch 51/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4690Текущий реальный скор(валидационная часть): 1.1863\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 1.3161 - lr: 2.5000e-04\n",
      "Epoch 52/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.4643Текущий реальный скор(валидационная часть): 1.1948\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 1.3257 - lr: 2.5000e-04\n",
      "Epoch 53/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4482Текущий реальный скор(валидационная часть): 1.1959\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 1.3224 - lr: 2.5000e-04\n",
      "Epoch 54/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4464Текущий реальный скор(валидационная часть): 1.1988\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 1.3227 - lr: 2.5000e-04\n",
      "Epoch 55/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4361Текущий реальный скор(валидационная часть): 1.2031\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4368 - val_loss: 1.3253 - lr: 2.5000e-04\n",
      "Epoch 56/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.4656Текущий реальный скор(валидационная часть): 1.2018\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4669 - val_loss: 1.3188 - lr: 1.2500e-04\n",
      "Epoch 57/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.4522Текущий реальный скор(валидационная часть): 1.1992\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 1.3199 - lr: 1.2500e-04\n",
      "Epoch 58/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.4350Текущий реальный скор(валидационная часть): 1.2065\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 1.3260 - lr: 1.2500e-04\n",
      "Epoch 59/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.4167Текущий реальный скор(валидационная часть): 1.2096\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4258 - val_loss: 1.3276 - lr: 1.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4154Текущий реальный скор(валидационная часть): 1.2147\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 1.3351 - lr: 1.2500e-04\n",
      "Epoch 61/500\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4081Текущий реальный скор(валидационная часть): 1.2121\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4081 - val_loss: 1.3319 - lr: 1.2500e-04\n",
      "Epoch 62/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.4005Текущий реальный скор(валидационная часть): 1.215\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4006 - val_loss: 1.3345 - lr: 1.2500e-04\n",
      "Epoch 63/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3926Текущий реальный скор(валидационная часть): 1.2145\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3953 - val_loss: 1.3314 - lr: 1.2500e-04\n",
      "Epoch 64/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3903Текущий реальный скор(валидационная часть): 1.218\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3905 - val_loss: 1.3353 - lr: 1.2500e-04\n",
      "Epoch 65/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3835Текущий реальный скор(валидационная часть): 1.219\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 1.3364 - lr: 1.2500e-04\n",
      "Epoch 66/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3943Текущий реальный скор(валидационная часть): 1.2055\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3961 - val_loss: 1.3256 - lr: 6.2500e-05\n",
      "Epoch 67/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3901Текущий реальный скор(валидационная часть): 1.204\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3937 - val_loss: 1.3257 - lr: 6.2500e-05\n",
      "Epoch 68/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3897Текущий реальный скор(валидационная часть): 1.203\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3903 - val_loss: 1.3240 - lr: 6.2500e-05\n",
      "Epoch 69/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3793Текущий реальный скор(валидационная часть): 1.2046\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 1.3243 - lr: 6.2500e-05\n",
      "Epoch 70/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3838Текущий реальный скор(валидационная часть): 1.2034\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 1.3225 - lr: 6.2500e-05\n",
      "Epoch 71/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3786Текущий реальный скор(валидационная часть): 1.2038\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3814 - val_loss: 1.3231 - lr: 6.2500e-05\n",
      "Epoch 72/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3786Текущий реальный скор(валидационная часть): 1.2052\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 1.3245 - lr: 6.2500e-05\n",
      "Epoch 73/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3696Текущий реальный скор(валидационная часть): 1.208\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 1.3277 - lr: 6.2500e-05\n",
      "Epoch 74/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3731Текущий реальный скор(валидационная часть): 1.2089\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 1.3291 - lr: 6.2500e-05\n",
      "Epoch 75/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3646Текущий реальный скор(валидационная часть): 1.2112\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 1.3318 - lr: 6.2500e-05\n",
      "Epoch 76/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3952Текущий реальный скор(валидационная часть): 1.2176\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3949 - val_loss: 1.3410 - lr: 3.1250e-05\n",
      "Epoch 77/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3878Текущий реальный скор(валидационная часть): 1.2216\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 1.3428 - lr: 3.1250e-05\n",
      "Epoch 78/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3901Текущий реальный скор(валидационная часть): 1.2251\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3880 - val_loss: 1.3444 - lr: 3.1250e-05\n",
      "Epoch 79/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.3838Текущий реальный скор(валидационная часть): 1.2271\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 1.3453 - lr: 3.1250e-05\n",
      "Epoch 80/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3820Текущий реальный скор(валидационная часть): 1.228\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 1.3452 - lr: 3.1250e-05\n",
      "Epoch 81/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3702Текущий реальный скор(валидационная часть): 1.2293\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3772 - val_loss: 1.3455 - lr: 3.1250e-05\n",
      "Epoch 82/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3747Текущий реальный скор(валидационная часть): 1.2301\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 1.3458 - lr: 3.1250e-05\n",
      "Epoch 83/500\n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.3683Текущий реальный скор(валидационная часть): 1.2311\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 1.3465 - lr: 3.1250e-05\n",
      "Epoch 84/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.3706Текущий реальный скор(валидационная часть): 1.232\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 1.3468 - lr: 3.1250e-05\n",
      "Epoch 85/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3629Текущий реальный скор(валидационная часть): 1.2331\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 1.3475 - lr: 3.1250e-05\n",
      "Epoch 86/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3770Текущий реальный скор(валидационная часть): 1.2292\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 1.3448 - lr: 1.5625e-05\n",
      "Epoch 87/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3699Текущий реальный скор(валидационная часть): 1.2268\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 1.3429 - lr: 1.5625e-05\n",
      "Epoch 88/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3710Текущий реальный скор(валидационная часть): 1.2252\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 1.3416 - lr: 1.5625e-05\n",
      "Epoch 89/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3663Текущий реальный скор(валидационная часть): 1.224\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 1.3406 - lr: 1.5625e-05\n",
      "Epoch 90/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3697Текущий реальный скор(валидационная часть): 1.2235\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 1.3404 - lr: 1.5625e-05\n",
      "Epoch 91/500\n",
      "114/134 [========================>.....] - ETA: 0s - loss: 0.3634Текущий реальный скор(валидационная часть): 1.223\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 1.3401 - lr: 1.5625e-05\n",
      "Epoch 92/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3655Текущий реальный скор(валидационная часть): 1.2232\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 1.3404 - lr: 1.5625e-05\n",
      "Epoch 93/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3644Текущий реальный скор(валидационная часть): 1.223\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3642 - val_loss: 1.3405 - lr: 1.5625e-05\n",
      "Epoch 94/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3636Текущий реальный скор(валидационная часть): 1.2233\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3632 - val_loss: 1.3410 - lr: 1.5625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3621Текущий реальный скор(валидационная часть): 1.223\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 1.3407 - lr: 1.5625e-05\n",
      "Epoch 96/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3621Текущий реальный скор(валидационная часть): 1.2138\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 1.3368 - lr: 7.8125e-06\n",
      "Epoch 97/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3629Текущий реальный скор(валидационная часть): 1.2131\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3616 - val_loss: 1.3364 - lr: 7.8125e-06\n",
      "Epoch 98/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3608Текущий реальный скор(валидационная часть): 1.213\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3608 - val_loss: 1.3366 - lr: 7.8125e-06\n",
      "Epoch 99/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3601Текущий реальный скор(валидационная часть): 1.2128\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3602 - val_loss: 1.3367 - lr: 7.8125e-06\n",
      "Epoch 100/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3594Текущий реальный скор(валидационная часть): 1.2128\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3595 - val_loss: 1.3369 - lr: 7.8125e-06\n",
      "Epoch 101/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3588Текущий реальный скор(валидационная часть): 1.213\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3589 - val_loss: 1.3373 - lr: 7.8125e-06\n",
      "Epoch 102/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3595Текущий реальный скор(валидационная часть): 1.213\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3583 - val_loss: 1.3375 - lr: 7.8125e-06\n",
      "Epoch 103/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.3571Текущий реальный скор(валидационная часть): 1.2131\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3578 - val_loss: 1.3378 - lr: 7.8125e-06\n",
      "Epoch 104/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3569Текущий реальный скор(валидационная часть): 1.2133\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3573 - val_loss: 1.3382 - lr: 7.8125e-06\n",
      "Epoch 105/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3561Текущий реальный скор(валидационная часть): 1.2134\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3568 - val_loss: 1.3385 - lr: 7.8125e-06\n",
      "Epoch 106/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.3572Текущий реальный скор(валидационная часть): 1.2123\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3564 - val_loss: 1.3372 - lr: 3.9063e-06\n",
      "Epoch 107/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3529Текущий реальный скор(валидационная часть): 1.2116\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3559 - val_loss: 1.3364 - lr: 3.9063e-06\n",
      "Epoch 108/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3569Текущий реальный скор(валидационная часть): 1.2112\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3555 - val_loss: 1.3360 - lr: 3.9063e-06\n",
      "Epoch 109/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.3545Текущий реальный скор(валидационная часть): 1.211\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3551 - val_loss: 1.3356 - lr: 3.9063e-06\n",
      "Epoch 110/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3562Текущий реальный скор(валидационная часть): 1.2107\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3548 - val_loss: 1.3353 - lr: 3.9063e-06\n",
      "Epoch 111/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3514Текущий реальный скор(валидационная часть): 1.2106\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3545 - val_loss: 1.3350 - lr: 3.9063e-06\n",
      "Epoch 112/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3535Текущий реальный скор(валидационная часть): 1.2105\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3542 - val_loss: 1.3348 - lr: 3.9063e-06\n",
      "Epoch 113/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3536Текущий реальный скор(валидационная часть): 1.2104\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 1.3346 - lr: 3.9063e-06\n",
      "Epoch 114/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3529Текущий реальный скор(валидационная часть): 1.2103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3536 - val_loss: 1.3344 - lr: 3.9063e-06\n",
      "Epoch 115/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3502Текущий реальный скор(валидационная часть): 1.2103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 1.3343 - lr: 3.9063e-06\n",
      "Epoch 116/500\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.3519Текущий реальный скор(валидационная часть): 1.2109\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3526 - val_loss: 1.3348 - lr: 1.9531e-06\n",
      "Epoch 117/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3517Текущий реальный скор(валидационная часть): 1.2107\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3520 - val_loss: 1.3347 - lr: 1.9531e-06\n",
      "Epoch 118/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3510Текущий реальный скор(валидационная часть): 1.2106\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 1.3345 - lr: 1.9531e-06\n",
      "Epoch 119/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.3518Текущий реальный скор(валидационная часть): 1.2104\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3517 - val_loss: 1.3343 - lr: 1.9531e-06\n",
      "Epoch 120/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3454Текущий реальный скор(валидационная часть): 1.2103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3515 - val_loss: 1.3342 - lr: 1.9531e-06\n",
      "Epoch 121/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3512Текущий реальный скор(валидационная часть): 1.2102\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3514 - val_loss: 1.3341 - lr: 1.9531e-06\n",
      "Epoch 122/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3523Текущий реальный скор(валидационная часть): 1.2102\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3513 - val_loss: 1.3340 - lr: 1.9531e-06\n",
      "Epoch 123/500\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.3517- ETA: 0s - loss: 0.33Текущий реальный скор(валидационная часть): 1.2101\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3511 - val_loss: 1.3338 - lr: 1.9531e-06\n",
      "Epoch 124/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3501Текущий реальный скор(валидационная часть): 1.21\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3510 - val_loss: 1.3338 - lr: 1.9531e-06\n",
      "Epoch 125/500\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.3521Текущий реальный скор(валидационная часть): 1.2099\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3509 - val_loss: 1.3337 - lr: 1.9531e-06\n",
      "Epoch 126/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3439Текущий реальный скор(валидационная часть): 1.2103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3502 - val_loss: 1.3339 - lr: 9.7656e-07\n",
      "Epoch 127/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3496Текущий реальный скор(валидационная часть): 1.2104\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3500 - val_loss: 1.3340 - lr: 9.7656e-07\n",
      "Epoch 128/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3435Текущий реальный скор(валидационная часть): 1.2104\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 1.3340 - lr: 9.7656e-07\n",
      "Epoch 129/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3494Текущий реальный скор(валидационная часть): 1.2104\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 1.3339 - lr: 9.7656e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/500\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.3486Текущий реальный скор(валидационная часть): 1.2103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3497 - val_loss: 1.3338 - lr: 9.7656e-07\n",
      "Epoch 131/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3494Текущий реальный скор(валидационная часть): 1.2102\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 1.3338 - lr: 9.7656e-07\n",
      "Epoch 132/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3432Текущий реальный скор(валидационная часть): 1.2102\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 1.3337 - lr: 9.7656e-07\n",
      "Epoch 133/500\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.3493Текущий реальный скор(валидационная часть): 1.2101\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3495 - val_loss: 1.3337 - lr: 9.7656e-07\n",
      "Epoch 134/500\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.3466Текущий реальный скор(валидационная часть): 1.2101\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3495 - val_loss: 1.3336 - lr: 9.7656e-07\n",
      "Epoch 135/500\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.3495Текущий реальный скор(валидационная часть): 1.2101\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3494 - val_loss: 1.3335 - lr: 9.7656e-07\n",
      "Epoch 136/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3425Текущий реальный скор(валидационная часть): 1.2102\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 1.3336 - lr: 4.8828e-07\n",
      "Epoch 137/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.3480Текущий реальный скор(валидационная часть): 1.2103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 1.3337 - lr: 4.8828e-07\n",
      "Epoch 138/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3496Текущий реальный скор(валидационная часть): 1.2103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 1.3337 - lr: 4.8828e-07\n",
      "Epoch 139/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.3490Текущий реальный скор(валидационная часть): 1.2103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 1.3337 - lr: 4.8828e-07\n",
      "Epoch 140/500\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.3476Текущий реальный скор(валидационная часть): 1.2103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 1.3337 - lr: 4.8828e-07\n",
      "Epoch 141/500\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.3483Текущий реальный скор(валидационная часть): 1.2103\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 1.3336 - lr: 4.8828e-07\n",
      "Epoch 142/500\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3494Текущий реальный скор(валидационная часть): 1.2102\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 1.3336 - lr: 4.8828e-07\n",
      "Epoch 143/500\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.3478Текущий реальный скор(валидационная часть): 1.2102\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 1.3336 - lr: 4.8828e-07\n",
      "Epoch 144/500\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.3421Текущий реальный скор(валидационная часть): 1.2102\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 1.3335 - lr: 4.8828e-07\n",
      "Epoch 145/500\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.3453Текущий реальный скор(валидационная часть): 1.181\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 1.3335 - lr: 4.8828e-07\n",
      "Скор для фолда(19) : 1.181 средний скор на префиксе = 1.3591 это заняло = 36 сек.\n",
      "Процесс обучения модели занял = 685 секунд\n"
     ]
    }
   ],
   "source": [
    "features_columns_order = get_columns_order(train.columns.values.tolist())\n",
    "split_list = get_standart_split(train, n_splits=20)\n",
    "\n",
    "start_train_model_time = time.time()\n",
    "# Размер батча для Dataset\n",
    "BATCH_SIZE = int(2 ** 5)\n",
    "# Количество эпох обучения\n",
    "EPOCHS = 500\n",
    "# Количество численных входных переменных модели\n",
    "NUM_FEATURES = len(NUM_FEATURES_COLUMNS)\n",
    "# Макс. значения категориалных фичей\n",
    "MAX_REALTY = max(train['realty_type'].max(), test['realty_type'].max())\n",
    "MAX_REGION = max(train['region'].max(), test['region'].max())\n",
    "MAX_CITY = max(train['city'].max(), test['city'].max())\n",
    "# Коэффициент домножения таргета, с целью быстрейшего сходимости модельки и лучшего обучения\n",
    "MUL_TARGET = 5e-5\n",
    "\n",
    "scores = []\n",
    "nn_predicts = np.zeros(len(train))\n",
    "models_nn = []\n",
    "\n",
    "for fold_num, (train_indexes, valid_indexes) in enumerate(split_list):\n",
    "    start_time = time.time()\n",
    "    print(f\"Фолд: {fold_num}\")\n",
    "\n",
    "    train_sub_df = train[features_columns_order].loc[train_indexes].reset_index(drop=True)\n",
    "    valid_sub_df = train[features_columns_order].loc[valid_indexes].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Размер трейна = {train_sub_df.shape} Размер валидации = {valid_sub_df.shape}\")\n",
    "\n",
    "    # Строим датасеты\n",
    "    train_ds = get_dataset(\n",
    "        train_sub_df[NUM_FEATURES_COLUMNS].values,\n",
    "        train_sub_df[TARGET_COLUMNS].values * MUL_TARGET,\n",
    "        train_sub_df[['region']].values,\n",
    "        train_sub_df[['city']].values,\n",
    "        train_sub_df[['realty_type']].values,\n",
    "        BATCH_SIZE)\n",
    "    valid_ds = get_dataset(\n",
    "        valid_sub_df[NUM_FEATURES_COLUMNS].values,\n",
    "        valid_sub_df[TARGET_COLUMNS].values * MUL_TARGET,\n",
    "        valid_sub_df[['region']].values,\n",
    "        valid_sub_df[['city']].values,\n",
    "        valid_sub_df[['realty_type']].values,\n",
    "        len(valid_sub_df))\n",
    "\n",
    "    # Компилируем модель\n",
    "    model = compile_model(train_ds, valid_ds, NUM_FEATURES, MAX_REALTY, MAX_REGION, MAX_CITY)\n",
    "    # Обучаем модель\n",
    "    fit(model, EPOCHS, train_ds, valid_ds, valid_sub_df[TARGET_COLUMNS].values * MUL_TARGET)\n",
    "\n",
    "    predict_on_validation = model.predict(valid_ds)[:, 0] / MUL_TARGET\n",
    "    nn_predicts[valid_indexes] = predict_on_validation\n",
    "    targets_for_validation = valid_sub_df[TARGET_COLUMNS].values[:, 0]\n",
    "    current_score = deviation_metric(targets_for_validation, predict_on_validation)\n",
    "    scores += [current_score]\n",
    "    models_nn += [model]\n",
    "    print(\n",
    "        f\"Скор для фолда({fold_num}) : {np.round(current_score, 4)} средний скор на префиксе = {np.round(np.mean(scores), 4)} это заняло = {int(time.time() - start_time)} сек.\")\n",
    "print(f\"Процесс обучения модели занял = {int(time.time() - start_train_model_time)} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b167b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предикт нейронной сетью на test\n",
    "def get_nn_predict(models, test):\n",
    "    result = np.zeros(len(test))\n",
    "    test_ds = get_dataset(\n",
    "        test[NUM_FEATURES_COLUMNS].values,\n",
    "        np.zeros(len(test)),\n",
    "        test[['region']].values,\n",
    "        test[['city']].values,\n",
    "        test[['realty_type']].values,\n",
    "        len(test))\n",
    "    for model in models:\n",
    "        predict = model.predict(test_ds)[:, 0]\n",
    "        result += (predict / MUL_TARGET) / len(models)\n",
    "    return result\n",
    "\n",
    "\n",
    "test_nn_predict = get_nn_predict(models_nn, test)\n",
    "\n",
    "test_submission = pd.read_csv('dataset/test_submission.csv')\n",
    "\n",
    "test_submission['per_square_meter_price'] = test_nn_predict\n",
    "test_submission.to_csv('nn2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68177650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c3751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f673432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36316db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фолд: 0\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.24152\tvalid_1's deviation_error: 1.51488\n",
      "[200]\ttraining's deviation_error: 1.00517\tvalid_1's deviation_error: 1.37652\n",
      "[300]\ttraining's deviation_error: 0.90895\tvalid_1's deviation_error: 1.33996\n",
      "[400]\ttraining's deviation_error: 0.84622\tvalid_1's deviation_error: 1.32104\n",
      "[500]\ttraining's deviation_error: 0.795471\tvalid_1's deviation_error: 1.30655\n",
      "[600]\ttraining's deviation_error: 0.763442\tvalid_1's deviation_error: 1.29798\n",
      "[700]\ttraining's deviation_error: 0.732594\tvalid_1's deviation_error: 1.28593\n",
      "[800]\ttraining's deviation_error: 0.709994\tvalid_1's deviation_error: 1.28508\n",
      "[900]\ttraining's deviation_error: 0.691849\tvalid_1's deviation_error: 1.27828\n",
      "[1000]\ttraining's deviation_error: 0.675379\tvalid_1's deviation_error: 1.27753\n",
      "[1100]\ttraining's deviation_error: 0.660379\tvalid_1's deviation_error: 1.26875\n",
      "[1200]\ttraining's deviation_error: 0.644585\tvalid_1's deviation_error: 1.26316\n",
      "[1300]\ttraining's deviation_error: 0.63299\tvalid_1's deviation_error: 1.25507\n",
      "[1400]\ttraining's deviation_error: 0.622627\tvalid_1's deviation_error: 1.24858\n",
      "[1500]\ttraining's deviation_error: 0.612353\tvalid_1's deviation_error: 1.24109\n",
      "[1600]\ttraining's deviation_error: 0.603885\tvalid_1's deviation_error: 1.24002\n",
      "[1700]\ttraining's deviation_error: 0.595365\tvalid_1's deviation_error: 1.23797\n",
      "[1800]\ttraining's deviation_error: 0.588682\tvalid_1's deviation_error: 1.23692\n",
      "[1900]\ttraining's deviation_error: 0.581205\tvalid_1's deviation_error: 1.23156\n",
      "[2000]\ttraining's deviation_error: 0.575689\tvalid_1's deviation_error: 1.22906\n",
      "[2100]\ttraining's deviation_error: 0.569514\tvalid_1's deviation_error: 1.22788\n",
      "[2200]\ttraining's deviation_error: 0.564816\tvalid_1's deviation_error: 1.22547\n",
      "[2300]\ttraining's deviation_error: 0.559632\tvalid_1's deviation_error: 1.22296\n",
      "[2400]\ttraining's deviation_error: 0.554967\tvalid_1's deviation_error: 1.2206\n",
      "[2500]\ttraining's deviation_error: 0.550903\tvalid_1's deviation_error: 1.21964\n",
      "[2600]\ttraining's deviation_error: 0.547424\tvalid_1's deviation_error: 1.21828\n",
      "[2700]\ttraining's deviation_error: 0.543622\tvalid_1's deviation_error: 1.21691\n",
      "[2800]\ttraining's deviation_error: 0.540121\tvalid_1's deviation_error: 1.21541\n",
      "[2900]\ttraining's deviation_error: 0.535998\tvalid_1's deviation_error: 1.21278\n",
      "[3000]\ttraining's deviation_error: 0.532822\tvalid_1's deviation_error: 1.21324\n",
      "[3100]\ttraining's deviation_error: 0.530379\tvalid_1's deviation_error: 1.21239\n",
      "[3200]\ttraining's deviation_error: 0.527899\tvalid_1's deviation_error: 1.21144\n",
      "[3300]\ttraining's deviation_error: 0.525195\tvalid_1's deviation_error: 1.21144\n",
      "[3400]\ttraining's deviation_error: 0.522606\tvalid_1's deviation_error: 1.20917\n",
      "[3500]\ttraining's deviation_error: 0.520549\tvalid_1's deviation_error: 1.20952\n",
      "Early stopping, best iteration is:\n",
      "[3408]\ttraining's deviation_error: 0.522439\tvalid_1's deviation_error: 1.20903\n",
      "Скор для фолда(0) : 9.0 средний скор на префиксе = 9.0 это заняло = 87 сек.\n",
      "Фолд: 1\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.24775\tvalid_1's deviation_error: 1.43252\n",
      "[200]\ttraining's deviation_error: 1.01523\tvalid_1's deviation_error: 1.37243\n",
      "[300]\ttraining's deviation_error: 0.92723\tvalid_1's deviation_error: 1.3263\n",
      "[400]\ttraining's deviation_error: 0.868508\tvalid_1's deviation_error: 1.3039\n",
      "[500]\ttraining's deviation_error: 0.820092\tvalid_1's deviation_error: 1.275\n",
      "[600]\ttraining's deviation_error: 0.785767\tvalid_1's deviation_error: 1.24615\n",
      "[700]\ttraining's deviation_error: 0.756932\tvalid_1's deviation_error: 1.22568\n",
      "[800]\ttraining's deviation_error: 0.732444\tvalid_1's deviation_error: 1.21548\n",
      "[900]\ttraining's deviation_error: 0.710849\tvalid_1's deviation_error: 1.20954\n",
      "[1000]\ttraining's deviation_error: 0.691103\tvalid_1's deviation_error: 1.20278\n",
      "[1100]\ttraining's deviation_error: 0.674662\tvalid_1's deviation_error: 1.20171\n",
      "[1200]\ttraining's deviation_error: 0.661643\tvalid_1's deviation_error: 1.19634\n",
      "[1300]\ttraining's deviation_error: 0.648608\tvalid_1's deviation_error: 1.19189\n",
      "[1400]\ttraining's deviation_error: 0.637993\tvalid_1's deviation_error: 1.18378\n",
      "[1500]\ttraining's deviation_error: 0.627048\tvalid_1's deviation_error: 1.17872\n",
      "[1600]\ttraining's deviation_error: 0.618697\tvalid_1's deviation_error: 1.17983\n",
      "Early stopping, best iteration is:\n",
      "[1512]\ttraining's deviation_error: 0.626103\tvalid_1's deviation_error: 1.17823\n",
      "Скор для фолда(1) : 9.0 средний скор на префиксе = 9.0 это заняло = 41 сек.\n",
      "Фолд: 2\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.27217\tvalid_1's deviation_error: 1.24395\n",
      "[200]\ttraining's deviation_error: 1.02591\tvalid_1's deviation_error: 0.996093\n",
      "[300]\ttraining's deviation_error: 0.933003\tvalid_1's deviation_error: 0.93837\n",
      "[400]\ttraining's deviation_error: 0.875428\tvalid_1's deviation_error: 0.92503\n",
      "[500]\ttraining's deviation_error: 0.831992\tvalid_1's deviation_error: 0.903246\n",
      "[600]\ttraining's deviation_error: 0.797122\tvalid_1's deviation_error: 0.888664\n",
      "[700]\ttraining's deviation_error: 0.767592\tvalid_1's deviation_error: 0.876761\n",
      "[800]\ttraining's deviation_error: 0.744006\tvalid_1's deviation_error: 0.866539\n",
      "[900]\ttraining's deviation_error: 0.723169\tvalid_1's deviation_error: 0.859941\n",
      "[1000]\ttraining's deviation_error: 0.707007\tvalid_1's deviation_error: 0.852352\n",
      "[1100]\ttraining's deviation_error: 0.692097\tvalid_1's deviation_error: 0.849525\n",
      "[1200]\ttraining's deviation_error: 0.677866\tvalid_1's deviation_error: 0.848751\n",
      "[1300]\ttraining's deviation_error: 0.66395\tvalid_1's deviation_error: 0.84463\n",
      "[1400]\ttraining's deviation_error: 0.652567\tvalid_1's deviation_error: 0.839695\n",
      "[1500]\ttraining's deviation_error: 0.641521\tvalid_1's deviation_error: 0.83746\n",
      "[1600]\ttraining's deviation_error: 0.631484\tvalid_1's deviation_error: 0.835853\n",
      "[1700]\ttraining's deviation_error: 0.624181\tvalid_1's deviation_error: 0.83273\n",
      "[1800]\ttraining's deviation_error: 0.616529\tvalid_1's deviation_error: 0.828811\n",
      "[1900]\ttraining's deviation_error: 0.610329\tvalid_1's deviation_error: 0.82686\n",
      "[2000]\ttraining's deviation_error: 0.602708\tvalid_1's deviation_error: 0.826294\n",
      "Early stopping, best iteration is:\n",
      "[1925]\ttraining's deviation_error: 0.60835\tvalid_1's deviation_error: 0.825693\n",
      "Скор для фолда(2) : 9.0 средний скор на префиксе = 9.0 это заняло = 51 сек.\n",
      "Фолд: 3\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.24959\tvalid_1's deviation_error: 1.59603\n",
      "[200]\ttraining's deviation_error: 1.02621\tvalid_1's deviation_error: 1.39044\n",
      "[300]\ttraining's deviation_error: 0.934381\tvalid_1's deviation_error: 1.32297\n",
      "[400]\ttraining's deviation_error: 0.875928\tvalid_1's deviation_error: 1.28143\n",
      "[500]\ttraining's deviation_error: 0.83071\tvalid_1's deviation_error: 1.25348\n",
      "[600]\ttraining's deviation_error: 0.792592\tvalid_1's deviation_error: 1.2313\n",
      "[700]\ttraining's deviation_error: 0.761302\tvalid_1's deviation_error: 1.21435\n",
      "[800]\ttraining's deviation_error: 0.737798\tvalid_1's deviation_error: 1.19286\n",
      "[900]\ttraining's deviation_error: 0.717435\tvalid_1's deviation_error: 1.18557\n",
      "[1000]\ttraining's deviation_error: 0.69989\tvalid_1's deviation_error: 1.17468\n",
      "[1100]\ttraining's deviation_error: 0.685326\tvalid_1's deviation_error: 1.16882\n",
      "[1200]\ttraining's deviation_error: 0.670602\tvalid_1's deviation_error: 1.15708\n",
      "[1300]\ttraining's deviation_error: 0.657109\tvalid_1's deviation_error: 1.14973\n",
      "[1400]\ttraining's deviation_error: 0.644215\tvalid_1's deviation_error: 1.14352\n",
      "[1500]\ttraining's deviation_error: 0.634981\tvalid_1's deviation_error: 1.14022\n",
      "[1600]\ttraining's deviation_error: 0.626306\tvalid_1's deviation_error: 1.13309\n",
      "[1700]\ttraining's deviation_error: 0.616513\tvalid_1's deviation_error: 1.12647\n",
      "[1800]\ttraining's deviation_error: 0.609955\tvalid_1's deviation_error: 1.12372\n",
      "[1900]\ttraining's deviation_error: 0.603113\tvalid_1's deviation_error: 1.12108\n",
      "[2000]\ttraining's deviation_error: 0.596684\tvalid_1's deviation_error: 1.11823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2100]\ttraining's deviation_error: 0.590709\tvalid_1's deviation_error: 1.11698\n",
      "[2200]\ttraining's deviation_error: 0.583778\tvalid_1's deviation_error: 1.11528\n",
      "[2300]\ttraining's deviation_error: 0.578963\tvalid_1's deviation_error: 1.11102\n",
      "[2400]\ttraining's deviation_error: 0.57241\tvalid_1's deviation_error: 1.10991\n",
      "[2500]\ttraining's deviation_error: 0.567298\tvalid_1's deviation_error: 1.10578\n",
      "[2600]\ttraining's deviation_error: 0.562303\tvalid_1's deviation_error: 1.10409\n",
      "[2700]\ttraining's deviation_error: 0.557586\tvalid_1's deviation_error: 1.10377\n",
      "Early stopping, best iteration is:\n",
      "[2629]\ttraining's deviation_error: 0.561344\tvalid_1's deviation_error: 1.10268\n",
      "Скор для фолда(3) : 9.0 средний скор на префиксе = 9.0 это заняло = 67 сек.\n",
      "Фолд: 4\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.25062\tvalid_1's deviation_error: 1.49469\n",
      "[200]\ttraining's deviation_error: 1.01512\tvalid_1's deviation_error: 1.32351\n",
      "[300]\ttraining's deviation_error: 0.926184\tvalid_1's deviation_error: 1.32104\n",
      "[400]\ttraining's deviation_error: 0.866103\tvalid_1's deviation_error: 1.2998\n",
      "[500]\ttraining's deviation_error: 0.819868\tvalid_1's deviation_error: 1.29664\n",
      "[600]\ttraining's deviation_error: 0.784833\tvalid_1's deviation_error: 1.29204\n",
      "[700]\ttraining's deviation_error: 0.756228\tvalid_1's deviation_error: 1.28885\n",
      "[800]\ttraining's deviation_error: 0.734257\tvalid_1's deviation_error: 1.28911\n",
      "Early stopping, best iteration is:\n",
      "[676]\ttraining's deviation_error: 0.761904\tvalid_1's deviation_error: 1.28679\n",
      "Скор для фолда(4) : 9.0 средний скор на префиксе = 9.0 это заняло = 21 сек.\n",
      "Фолд: 5\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.22405\tvalid_1's deviation_error: 1.79921\n",
      "[200]\ttraining's deviation_error: 0.996687\tvalid_1's deviation_error: 1.6192\n",
      "[300]\ttraining's deviation_error: 0.907206\tvalid_1's deviation_error: 1.57733\n",
      "[400]\ttraining's deviation_error: 0.844186\tvalid_1's deviation_error: 1.56478\n",
      "[500]\ttraining's deviation_error: 0.803592\tvalid_1's deviation_error: 1.55364\n",
      "[600]\ttraining's deviation_error: 0.768674\tvalid_1's deviation_error: 1.54363\n",
      "[700]\ttraining's deviation_error: 0.741767\tvalid_1's deviation_error: 1.5346\n",
      "[800]\ttraining's deviation_error: 0.717916\tvalid_1's deviation_error: 1.52167\n",
      "[900]\ttraining's deviation_error: 0.698118\tvalid_1's deviation_error: 1.5186\n",
      "[1000]\ttraining's deviation_error: 0.682585\tvalid_1's deviation_error: 1.50383\n",
      "[1100]\ttraining's deviation_error: 0.670615\tvalid_1's deviation_error: 1.4965\n",
      "[1200]\ttraining's deviation_error: 0.656405\tvalid_1's deviation_error: 1.49107\n",
      "[1300]\ttraining's deviation_error: 0.644461\tvalid_1's deviation_error: 1.48737\n",
      "[1400]\ttraining's deviation_error: 0.63433\tvalid_1's deviation_error: 1.48306\n",
      "[1500]\ttraining's deviation_error: 0.624343\tvalid_1's deviation_error: 1.47878\n",
      "[1600]\ttraining's deviation_error: 0.61597\tvalid_1's deviation_error: 1.47619\n",
      "[1700]\ttraining's deviation_error: 0.608803\tvalid_1's deviation_error: 1.47419\n",
      "[1800]\ttraining's deviation_error: 0.602044\tvalid_1's deviation_error: 1.47228\n",
      "[1900]\ttraining's deviation_error: 0.596088\tvalid_1's deviation_error: 1.46962\n",
      "[2000]\ttraining's deviation_error: 0.590283\tvalid_1's deviation_error: 1.46794\n",
      "[2100]\ttraining's deviation_error: 0.584439\tvalid_1's deviation_error: 1.46861\n",
      "[2200]\ttraining's deviation_error: 0.579508\tvalid_1's deviation_error: 1.46676\n",
      "[2300]\ttraining's deviation_error: 0.574547\tvalid_1's deviation_error: 1.46513\n",
      "[2400]\ttraining's deviation_error: 0.570139\tvalid_1's deviation_error: 1.46332\n",
      "[2500]\ttraining's deviation_error: 0.565893\tvalid_1's deviation_error: 1.45993\n",
      "[2600]\ttraining's deviation_error: 0.562001\tvalid_1's deviation_error: 1.45911\n",
      "[2700]\ttraining's deviation_error: 0.55734\tvalid_1's deviation_error: 1.45723\n",
      "[2800]\ttraining's deviation_error: 0.554666\tvalid_1's deviation_error: 1.45749\n",
      "Early stopping, best iteration is:\n",
      "[2643]\ttraining's deviation_error: 0.559559\tvalid_1's deviation_error: 1.45641\n",
      "Скор для фолда(5) : 9.0 средний скор на префиксе = 9.0 это заняло = 69 сек.\n",
      "Фолд: 6\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.26833\tvalid_1's deviation_error: 1.26344\n",
      "[200]\ttraining's deviation_error: 1.01622\tvalid_1's deviation_error: 1.15625\n",
      "[300]\ttraining's deviation_error: 0.922402\tvalid_1's deviation_error: 1.1497\n",
      "[400]\ttraining's deviation_error: 0.860488\tvalid_1's deviation_error: 1.13859\n",
      "[500]\ttraining's deviation_error: 0.814005\tvalid_1's deviation_error: 1.13957\n",
      "[600]\ttraining's deviation_error: 0.776683\tvalid_1's deviation_error: 1.1407\n",
      "[700]\ttraining's deviation_error: 0.748136\tvalid_1's deviation_error: 1.12491\n",
      "[800]\ttraining's deviation_error: 0.724382\tvalid_1's deviation_error: 1.1215\n",
      "[900]\ttraining's deviation_error: 0.704711\tvalid_1's deviation_error: 1.11386\n",
      "[1000]\ttraining's deviation_error: 0.685818\tvalid_1's deviation_error: 1.11406\n",
      "[1100]\ttraining's deviation_error: 0.672208\tvalid_1's deviation_error: 1.11227\n",
      "[1200]\ttraining's deviation_error: 0.659374\tvalid_1's deviation_error: 1.10884\n",
      "[1300]\ttraining's deviation_error: 0.646396\tvalid_1's deviation_error: 1.10078\n",
      "[1400]\ttraining's deviation_error: 0.634883\tvalid_1's deviation_error: 1.10261\n",
      "[1500]\ttraining's deviation_error: 0.624658\tvalid_1's deviation_error: 1.09676\n",
      "[1600]\ttraining's deviation_error: 0.617183\tvalid_1's deviation_error: 1.09347\n",
      "[1700]\ttraining's deviation_error: 0.609481\tvalid_1's deviation_error: 1.09269\n",
      "[1800]\ttraining's deviation_error: 0.603993\tvalid_1's deviation_error: 1.09254\n",
      "[1900]\ttraining's deviation_error: 0.596154\tvalid_1's deviation_error: 1.09444\n",
      "Early stopping, best iteration is:\n",
      "[1748]\ttraining's deviation_error: 0.607343\tvalid_1's deviation_error: 1.09144\n",
      "Скор для фолда(6) : 9.0 средний скор на префиксе = 9.0 это заняло = 48 сек.\n",
      "Фолд: 7\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.27099\tvalid_1's deviation_error: 1.49009\n",
      "[200]\ttraining's deviation_error: 1.02053\tvalid_1's deviation_error: 1.32305\n",
      "[300]\ttraining's deviation_error: 0.927055\tvalid_1's deviation_error: 1.27601\n",
      "[400]\ttraining's deviation_error: 0.862542\tvalid_1's deviation_error: 1.25251\n",
      "[500]\ttraining's deviation_error: 0.816105\tvalid_1's deviation_error: 1.23062\n",
      "[600]\ttraining's deviation_error: 0.77927\tvalid_1's deviation_error: 1.2201\n",
      "[700]\ttraining's deviation_error: 0.751405\tvalid_1's deviation_error: 1.20618\n",
      "[800]\ttraining's deviation_error: 0.726213\tvalid_1's deviation_error: 1.19874\n",
      "[900]\ttraining's deviation_error: 0.70599\tvalid_1's deviation_error: 1.18763\n",
      "[1000]\ttraining's deviation_error: 0.688202\tvalid_1's deviation_error: 1.17701\n",
      "[1100]\ttraining's deviation_error: 0.672035\tvalid_1's deviation_error: 1.16804\n",
      "[1200]\ttraining's deviation_error: 0.658511\tvalid_1's deviation_error: 1.16294\n",
      "[1300]\ttraining's deviation_error: 0.646294\tvalid_1's deviation_error: 1.15522\n",
      "[1400]\ttraining's deviation_error: 0.636491\tvalid_1's deviation_error: 1.15394\n",
      "[1500]\ttraining's deviation_error: 0.626194\tvalid_1's deviation_error: 1.14912\n",
      "[1600]\ttraining's deviation_error: 0.617108\tvalid_1's deviation_error: 1.14509\n",
      "[1700]\ttraining's deviation_error: 0.610438\tvalid_1's deviation_error: 1.14151\n",
      "[1800]\ttraining's deviation_error: 0.603056\tvalid_1's deviation_error: 1.13905\n",
      "[1900]\ttraining's deviation_error: 0.596886\tvalid_1's deviation_error: 1.13551\n",
      "[2000]\ttraining's deviation_error: 0.591072\tvalid_1's deviation_error: 1.13283\n",
      "[2100]\ttraining's deviation_error: 0.584833\tvalid_1's deviation_error: 1.13493\n",
      "[2200]\ttraining's deviation_error: 0.578923\tvalid_1's deviation_error: 1.13125\n",
      "[2300]\ttraining's deviation_error: 0.573539\tvalid_1's deviation_error: 1.12835\n",
      "[2400]\ttraining's deviation_error: 0.568054\tvalid_1's deviation_error: 1.12475\n",
      "[2500]\ttraining's deviation_error: 0.562532\tvalid_1's deviation_error: 1.12374\n",
      "[2600]\ttraining's deviation_error: 0.557801\tvalid_1's deviation_error: 1.12221\n",
      "[2700]\ttraining's deviation_error: 0.553839\tvalid_1's deviation_error: 1.11994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2800]\ttraining's deviation_error: 0.550136\tvalid_1's deviation_error: 1.11889\n",
      "[2900]\ttraining's deviation_error: 0.545386\tvalid_1's deviation_error: 1.11691\n",
      "[3000]\ttraining's deviation_error: 0.542543\tvalid_1's deviation_error: 1.11433\n",
      "[3100]\ttraining's deviation_error: 0.539008\tvalid_1's deviation_error: 1.11014\n",
      "[3200]\ttraining's deviation_error: 0.535287\tvalid_1's deviation_error: 1.10979\n",
      "[3300]\ttraining's deviation_error: 0.531793\tvalid_1's deviation_error: 1.10914\n",
      "[3400]\ttraining's deviation_error: 0.528306\tvalid_1's deviation_error: 1.10789\n",
      "[3500]\ttraining's deviation_error: 0.525941\tvalid_1's deviation_error: 1.10662\n",
      "[3600]\ttraining's deviation_error: 0.522652\tvalid_1's deviation_error: 1.10385\n",
      "[3700]\ttraining's deviation_error: 0.519867\tvalid_1's deviation_error: 1.10423\n",
      "[3800]\ttraining's deviation_error: 0.516957\tvalid_1's deviation_error: 1.10197\n",
      "[3900]\ttraining's deviation_error: 0.514725\tvalid_1's deviation_error: 1.10077\n",
      "[4000]\ttraining's deviation_error: 0.512087\tvalid_1's deviation_error: 1.09635\n",
      "[4100]\ttraining's deviation_error: 0.510217\tvalid_1's deviation_error: 1.09602\n",
      "[4200]\ttraining's deviation_error: 0.507428\tvalid_1's deviation_error: 1.09525\n",
      "[4300]\ttraining's deviation_error: 0.504797\tvalid_1's deviation_error: 1.0957\n",
      "Early stopping, best iteration is:\n",
      "[4223]\ttraining's deviation_error: 0.506954\tvalid_1's deviation_error: 1.09442\n",
      "Скор для фолда(7) : 9.0 средний скор на префиксе = 9.0 это заняло = 110 сек.\n",
      "Фолд: 8\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.26547\tvalid_1's deviation_error: 1.08937\n",
      "[200]\ttraining's deviation_error: 1.02943\tvalid_1's deviation_error: 0.946235\n",
      "[300]\ttraining's deviation_error: 0.93075\tvalid_1's deviation_error: 0.914096\n",
      "[400]\ttraining's deviation_error: 0.867789\tvalid_1's deviation_error: 0.90483\n",
      "[500]\ttraining's deviation_error: 0.822505\tvalid_1's deviation_error: 0.900928\n",
      "[600]\ttraining's deviation_error: 0.789782\tvalid_1's deviation_error: 0.894682\n",
      "[700]\ttraining's deviation_error: 0.757729\tvalid_1's deviation_error: 0.894659\n",
      "[800]\ttraining's deviation_error: 0.733845\tvalid_1's deviation_error: 0.886366\n",
      "[900]\ttraining's deviation_error: 0.712401\tvalid_1's deviation_error: 0.886705\n",
      "Early stopping, best iteration is:\n",
      "[798]\ttraining's deviation_error: 0.734342\tvalid_1's deviation_error: 0.885597\n",
      "Скор для фолда(8) : 9.0 средний скор на префиксе = 9.0 это заняло = 24 сек.\n",
      "Фолд: 9\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.24415\tvalid_1's deviation_error: 1.46918\n",
      "[200]\ttraining's deviation_error: 1.00124\tvalid_1's deviation_error: 1.30587\n",
      "[300]\ttraining's deviation_error: 0.90731\tvalid_1's deviation_error: 1.25499\n",
      "[400]\ttraining's deviation_error: 0.845055\tvalid_1's deviation_error: 1.21709\n",
      "[500]\ttraining's deviation_error: 0.7978\tvalid_1's deviation_error: 1.19575\n",
      "[600]\ttraining's deviation_error: 0.765272\tvalid_1's deviation_error: 1.17811\n",
      "[700]\ttraining's deviation_error: 0.73628\tvalid_1's deviation_error: 1.17559\n",
      "[800]\ttraining's deviation_error: 0.713307\tvalid_1's deviation_error: 1.17032\n",
      "[900]\ttraining's deviation_error: 0.692244\tvalid_1's deviation_error: 1.16918\n",
      "[1000]\ttraining's deviation_error: 0.675958\tvalid_1's deviation_error: 1.16711\n",
      "Early stopping, best iteration is:\n",
      "[842]\ttraining's deviation_error: 0.703417\tvalid_1's deviation_error: 1.16571\n",
      "Скор для фолда(9) : 9.0 средний скор на префиксе = 9.0 это заняло = 25 сек.\n",
      "Фолд: 10\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.25857\tvalid_1's deviation_error: 1.45403\n",
      "[200]\ttraining's deviation_error: 1.00994\tvalid_1's deviation_error: 1.21031\n",
      "[300]\ttraining's deviation_error: 0.919561\tvalid_1's deviation_error: 1.14759\n",
      "[400]\ttraining's deviation_error: 0.857719\tvalid_1's deviation_error: 1.11512\n",
      "[500]\ttraining's deviation_error: 0.81157\tvalid_1's deviation_error: 1.10305\n",
      "[600]\ttraining's deviation_error: 0.774146\tvalid_1's deviation_error: 1.09558\n",
      "[700]\ttraining's deviation_error: 0.743441\tvalid_1's deviation_error: 1.09008\n",
      "[800]\ttraining's deviation_error: 0.718753\tvalid_1's deviation_error: 1.09189\n",
      "Early stopping, best iteration is:\n",
      "[702]\ttraining's deviation_error: 0.743031\tvalid_1's deviation_error: 1.08965\n",
      "Скор для фолда(10) : 9.0 средний скор на префиксе = 9.0 это заняло = 21 сек.\n",
      "Фолд: 11\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.24999\tvalid_1's deviation_error: 1.76883\n",
      "[200]\ttraining's deviation_error: 1.00912\tvalid_1's deviation_error: 1.60402\n",
      "[300]\ttraining's deviation_error: 0.915461\tvalid_1's deviation_error: 1.53902\n",
      "[400]\ttraining's deviation_error: 0.855109\tvalid_1's deviation_error: 1.49819\n",
      "[500]\ttraining's deviation_error: 0.812194\tvalid_1's deviation_error: 1.47064\n",
      "[600]\ttraining's deviation_error: 0.780647\tvalid_1's deviation_error: 1.45776\n",
      "[700]\ttraining's deviation_error: 0.756277\tvalid_1's deviation_error: 1.45484\n",
      "[800]\ttraining's deviation_error: 0.734163\tvalid_1's deviation_error: 1.44905\n",
      "[900]\ttraining's deviation_error: 0.714365\tvalid_1's deviation_error: 1.4398\n",
      "[1000]\ttraining's deviation_error: 0.697911\tvalid_1's deviation_error: 1.43764\n",
      "[1100]\ttraining's deviation_error: 0.681852\tvalid_1's deviation_error: 1.43557\n",
      "[1200]\ttraining's deviation_error: 0.669277\tvalid_1's deviation_error: 1.4311\n",
      "[1300]\ttraining's deviation_error: 0.657004\tvalid_1's deviation_error: 1.42694\n",
      "[1400]\ttraining's deviation_error: 0.646614\tvalid_1's deviation_error: 1.42323\n",
      "[1500]\ttraining's deviation_error: 0.635656\tvalid_1's deviation_error: 1.42021\n",
      "[1600]\ttraining's deviation_error: 0.625627\tvalid_1's deviation_error: 1.4183\n",
      "[1700]\ttraining's deviation_error: 0.619212\tvalid_1's deviation_error: 1.41523\n",
      "[1800]\ttraining's deviation_error: 0.612482\tvalid_1's deviation_error: 1.41455\n",
      "[1900]\ttraining's deviation_error: 0.606493\tvalid_1's deviation_error: 1.41423\n",
      "[2000]\ttraining's deviation_error: 0.601702\tvalid_1's deviation_error: 1.41458\n",
      "[2100]\ttraining's deviation_error: 0.595674\tvalid_1's deviation_error: 1.40893\n",
      "[2200]\ttraining's deviation_error: 0.590055\tvalid_1's deviation_error: 1.40804\n",
      "[2300]\ttraining's deviation_error: 0.585845\tvalid_1's deviation_error: 1.40577\n",
      "[2400]\ttraining's deviation_error: 0.581042\tvalid_1's deviation_error: 1.40395\n",
      "[2500]\ttraining's deviation_error: 0.576513\tvalid_1's deviation_error: 1.40323\n",
      "[2600]\ttraining's deviation_error: 0.572616\tvalid_1's deviation_error: 1.40116\n",
      "[2700]\ttraining's deviation_error: 0.568203\tvalid_1's deviation_error: 1.39969\n",
      "[2800]\ttraining's deviation_error: 0.563641\tvalid_1's deviation_error: 1.40168\n",
      "Early stopping, best iteration is:\n",
      "[2704]\ttraining's deviation_error: 0.567971\tvalid_1's deviation_error: 1.39945\n",
      "Скор для фолда(11) : 9.0 средний скор на префиксе = 9.0 это заняло = 69 сек.\n",
      "Фолд: 12\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.24515\tvalid_1's deviation_error: 1.48276\n",
      "[200]\ttraining's deviation_error: 1.00558\tvalid_1's deviation_error: 1.36021\n",
      "[300]\ttraining's deviation_error: 0.90457\tvalid_1's deviation_error: 1.32711\n",
      "[400]\ttraining's deviation_error: 0.842165\tvalid_1's deviation_error: 1.32396\n",
      "[500]\ttraining's deviation_error: 0.799242\tvalid_1's deviation_error: 1.33168\n",
      "[600]\ttraining's deviation_error: 0.764923\tvalid_1's deviation_error: 1.317\n",
      "[700]\ttraining's deviation_error: 0.738085\tvalid_1's deviation_error: 1.30963\n",
      "[800]\ttraining's deviation_error: 0.716954\tvalid_1's deviation_error: 1.31036\n",
      "[900]\ttraining's deviation_error: 0.693977\tvalid_1's deviation_error: 1.31148\n",
      "[1000]\ttraining's deviation_error: 0.676356\tvalid_1's deviation_error: 1.31665\n",
      "Early stopping, best iteration is:\n",
      "[869]\ttraining's deviation_error: 0.700652\tvalid_1's deviation_error: 1.30449\n",
      "Скор для фолда(12) : 9.0 средний скор на префиксе = 9.0 это заняло = 30 сек.\n",
      "Фолд: 13\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's deviation_error: 1.23892\tvalid_1's deviation_error: 1.79407\n",
      "[200]\ttraining's deviation_error: 0.985783\tvalid_1's deviation_error: 1.52817\n",
      "[300]\ttraining's deviation_error: 0.899394\tvalid_1's deviation_error: 1.44138\n",
      "[400]\ttraining's deviation_error: 0.845258\tvalid_1's deviation_error: 1.4001\n",
      "[500]\ttraining's deviation_error: 0.803106\tvalid_1's deviation_error: 1.36066\n",
      "[600]\ttraining's deviation_error: 0.774159\tvalid_1's deviation_error: 1.34057\n",
      "[700]\ttraining's deviation_error: 0.749662\tvalid_1's deviation_error: 1.32329\n",
      "[800]\ttraining's deviation_error: 0.725621\tvalid_1's deviation_error: 1.31042\n",
      "[900]\ttraining's deviation_error: 0.706279\tvalid_1's deviation_error: 1.30182\n",
      "[1000]\ttraining's deviation_error: 0.688198\tvalid_1's deviation_error: 1.29427\n",
      "[1100]\ttraining's deviation_error: 0.670767\tvalid_1's deviation_error: 1.28849\n",
      "[1200]\ttraining's deviation_error: 0.658176\tvalid_1's deviation_error: 1.28701\n",
      "[1300]\ttraining's deviation_error: 0.645009\tvalid_1's deviation_error: 1.2804\n",
      "[1400]\ttraining's deviation_error: 0.633288\tvalid_1's deviation_error: 1.27931\n",
      "[1500]\ttraining's deviation_error: 0.623749\tvalid_1's deviation_error: 1.27408\n",
      "[1600]\ttraining's deviation_error: 0.616361\tvalid_1's deviation_error: 1.27449\n",
      "[1700]\ttraining's deviation_error: 0.60789\tvalid_1's deviation_error: 1.27161\n",
      "[1800]\ttraining's deviation_error: 0.600801\tvalid_1's deviation_error: 1.26788\n",
      "[1900]\ttraining's deviation_error: 0.593853\tvalid_1's deviation_error: 1.26481\n",
      "[2000]\ttraining's deviation_error: 0.586262\tvalid_1's deviation_error: 1.2646\n",
      "[2100]\ttraining's deviation_error: 0.58049\tvalid_1's deviation_error: 1.26418\n",
      "Early stopping, best iteration is:\n",
      "[2032]\ttraining's deviation_error: 0.584579\tvalid_1's deviation_error: 1.26203\n",
      "Скор для фолда(13) : 9.0 средний скор на префиксе = 9.0 это заняло = 55 сек.\n",
      "Фолд: 14\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.26337\tvalid_1's deviation_error: 1.18176\n",
      "[200]\ttraining's deviation_error: 1.01347\tvalid_1's deviation_error: 1.05448\n",
      "[300]\ttraining's deviation_error: 0.919058\tvalid_1's deviation_error: 1.03062\n",
      "[400]\ttraining's deviation_error: 0.855213\tvalid_1's deviation_error: 1.01143\n",
      "[500]\ttraining's deviation_error: 0.809362\tvalid_1's deviation_error: 0.989509\n",
      "[600]\ttraining's deviation_error: 0.77554\tvalid_1's deviation_error: 0.986224\n",
      "[700]\ttraining's deviation_error: 0.749124\tvalid_1's deviation_error: 0.982939\n",
      "[800]\ttraining's deviation_error: 0.723657\tvalid_1's deviation_error: 0.981748\n",
      "[900]\ttraining's deviation_error: 0.703223\tvalid_1's deviation_error: 0.980459\n",
      "[1000]\ttraining's deviation_error: 0.684739\tvalid_1's deviation_error: 0.982029\n",
      "Early stopping, best iteration is:\n",
      "[884]\ttraining's deviation_error: 0.705954\tvalid_1's deviation_error: 0.977687\n",
      "Скор для фолда(14) : 9.0 средний скор на префиксе = 9.0 это заняло = 27 сек.\n",
      "Фолд: 15\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.25143\tvalid_1's deviation_error: 1.50146\n",
      "[200]\ttraining's deviation_error: 1.01848\tvalid_1's deviation_error: 1.38795\n",
      "[300]\ttraining's deviation_error: 0.926631\tvalid_1's deviation_error: 1.33554\n",
      "[400]\ttraining's deviation_error: 0.868649\tvalid_1's deviation_error: 1.31159\n",
      "[500]\ttraining's deviation_error: 0.825292\tvalid_1's deviation_error: 1.28235\n",
      "[600]\ttraining's deviation_error: 0.790125\tvalid_1's deviation_error: 1.26282\n",
      "[700]\ttraining's deviation_error: 0.761784\tvalid_1's deviation_error: 1.24401\n",
      "[800]\ttraining's deviation_error: 0.737502\tvalid_1's deviation_error: 1.23464\n",
      "[900]\ttraining's deviation_error: 0.716226\tvalid_1's deviation_error: 1.22033\n",
      "[1000]\ttraining's deviation_error: 0.699736\tvalid_1's deviation_error: 1.20777\n",
      "[1100]\ttraining's deviation_error: 0.68253\tvalid_1's deviation_error: 1.19928\n",
      "[1200]\ttraining's deviation_error: 0.669125\tvalid_1's deviation_error: 1.19152\n",
      "[1300]\ttraining's deviation_error: 0.655463\tvalid_1's deviation_error: 1.18979\n",
      "[1400]\ttraining's deviation_error: 0.644533\tvalid_1's deviation_error: 1.18956\n",
      "[1500]\ttraining's deviation_error: 0.634389\tvalid_1's deviation_error: 1.18886\n",
      "[1600]\ttraining's deviation_error: 0.625517\tvalid_1's deviation_error: 1.18654\n",
      "[1700]\ttraining's deviation_error: 0.617758\tvalid_1's deviation_error: 1.18161\n",
      "[1800]\ttraining's deviation_error: 0.609934\tvalid_1's deviation_error: 1.17762\n",
      "[1900]\ttraining's deviation_error: 0.602317\tvalid_1's deviation_error: 1.17315\n",
      "[2000]\ttraining's deviation_error: 0.594923\tvalid_1's deviation_error: 1.17259\n",
      "[2100]\ttraining's deviation_error: 0.588303\tvalid_1's deviation_error: 1.17247\n",
      "[2200]\ttraining's deviation_error: 0.58333\tvalid_1's deviation_error: 1.17198\n",
      "[2300]\ttraining's deviation_error: 0.578513\tvalid_1's deviation_error: 1.16758\n",
      "[2400]\ttraining's deviation_error: 0.573151\tvalid_1's deviation_error: 1.16572\n",
      "[2500]\ttraining's deviation_error: 0.568979\tvalid_1's deviation_error: 1.16167\n",
      "[2600]\ttraining's deviation_error: 0.565961\tvalid_1's deviation_error: 1.16295\n",
      "Early stopping, best iteration is:\n",
      "[2531]\ttraining's deviation_error: 0.568098\tvalid_1's deviation_error: 1.1608\n",
      "Скор для фолда(15) : 9.0 средний скор на префиксе = 9.0 это заняло = 68 сек.\n",
      "Фолд: 16\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.24924\tvalid_1's deviation_error: 1.53253\n",
      "[200]\ttraining's deviation_error: 1.01194\tvalid_1's deviation_error: 1.35757\n",
      "[300]\ttraining's deviation_error: 0.914346\tvalid_1's deviation_error: 1.28411\n",
      "[400]\ttraining's deviation_error: 0.853723\tvalid_1's deviation_error: 1.26139\n",
      "[500]\ttraining's deviation_error: 0.81067\tvalid_1's deviation_error: 1.2324\n",
      "[600]\ttraining's deviation_error: 0.775463\tvalid_1's deviation_error: 1.20812\n",
      "[700]\ttraining's deviation_error: 0.744838\tvalid_1's deviation_error: 1.1981\n",
      "[800]\ttraining's deviation_error: 0.719858\tvalid_1's deviation_error: 1.20055\n",
      "[900]\ttraining's deviation_error: 0.698658\tvalid_1's deviation_error: 1.19802\n",
      "[1000]\ttraining's deviation_error: 0.680635\tvalid_1's deviation_error: 1.19292\n",
      "[1100]\ttraining's deviation_error: 0.664794\tvalid_1's deviation_error: 1.18514\n",
      "[1200]\ttraining's deviation_error: 0.650856\tvalid_1's deviation_error: 1.18078\n",
      "[1300]\ttraining's deviation_error: 0.639512\tvalid_1's deviation_error: 1.17932\n",
      "[1400]\ttraining's deviation_error: 0.631708\tvalid_1's deviation_error: 1.18084\n",
      "Early stopping, best iteration is:\n",
      "[1267]\ttraining's deviation_error: 0.642126\tvalid_1's deviation_error: 1.17744\n",
      "Скор для фолда(16) : 9.0 средний скор на префиксе = 9.0 это заняло = 36 сек.\n",
      "Фолд: 17\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.27291\tvalid_1's deviation_error: 1.26163\n",
      "[200]\ttraining's deviation_error: 1.02833\tvalid_1's deviation_error: 1.11863\n",
      "[300]\ttraining's deviation_error: 0.928805\tvalid_1's deviation_error: 1.08401\n",
      "[400]\ttraining's deviation_error: 0.863187\tvalid_1's deviation_error: 1.07608\n",
      "[500]\ttraining's deviation_error: 0.818619\tvalid_1's deviation_error: 1.07981\n",
      "[600]\ttraining's deviation_error: 0.779994\tvalid_1's deviation_error: 1.07669\n",
      "[700]\ttraining's deviation_error: 0.750287\tvalid_1's deviation_error: 1.07221\n",
      "[800]\ttraining's deviation_error: 0.726295\tvalid_1's deviation_error: 1.07298\n",
      "[900]\ttraining's deviation_error: 0.70646\tvalid_1's deviation_error: 1.0742\n",
      "Early stopping, best iteration is:\n",
      "[741]\ttraining's deviation_error: 0.740751\tvalid_1's deviation_error: 1.06924\n",
      "Скор для фолда(17) : 9.0 средний скор на префиксе = 9.0 это заняло = 23 сек.\n",
      "Фолд: 18\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.25757\tvalid_1's deviation_error: 1.20496\n",
      "[200]\ttraining's deviation_error: 1.01047\tvalid_1's deviation_error: 1.10612\n",
      "[300]\ttraining's deviation_error: 0.920148\tvalid_1's deviation_error: 1.08716\n",
      "[400]\ttraining's deviation_error: 0.858269\tvalid_1's deviation_error: 1.07676\n",
      "[500]\ttraining's deviation_error: 0.814109\tvalid_1's deviation_error: 1.05825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's deviation_error: 0.780037\tvalid_1's deviation_error: 1.04759\n",
      "[700]\ttraining's deviation_error: 0.753476\tvalid_1's deviation_error: 1.03437\n",
      "[800]\ttraining's deviation_error: 0.728477\tvalid_1's deviation_error: 1.021\n",
      "[900]\ttraining's deviation_error: 0.709142\tvalid_1's deviation_error: 1.01337\n",
      "[1000]\ttraining's deviation_error: 0.69251\tvalid_1's deviation_error: 1.00744\n",
      "[1100]\ttraining's deviation_error: 0.6766\tvalid_1's deviation_error: 1.00125\n",
      "[1200]\ttraining's deviation_error: 0.662214\tvalid_1's deviation_error: 0.996647\n",
      "[1300]\ttraining's deviation_error: 0.649438\tvalid_1's deviation_error: 0.993539\n",
      "[1400]\ttraining's deviation_error: 0.638754\tvalid_1's deviation_error: 0.990488\n",
      "[1500]\ttraining's deviation_error: 0.630126\tvalid_1's deviation_error: 0.987368\n",
      "[1600]\ttraining's deviation_error: 0.621695\tvalid_1's deviation_error: 0.989218\n",
      "[1700]\ttraining's deviation_error: 0.612588\tvalid_1's deviation_error: 0.986113\n",
      "[1800]\ttraining's deviation_error: 0.605466\tvalid_1's deviation_error: 0.985745\n",
      "[1900]\ttraining's deviation_error: 0.598638\tvalid_1's deviation_error: 0.985813\n",
      "Early stopping, best iteration is:\n",
      "[1750]\ttraining's deviation_error: 0.608951\tvalid_1's deviation_error: 0.983987\n",
      "Скор для фолда(18) : 9.0 средний скор на префиксе = 9.0 это заняло = 50 сек.\n",
      "Фолд: 19\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "Training until validation scores don't improve for 166 rounds\n",
      "[100]\ttraining's deviation_error: 1.24329\tvalid_1's deviation_error: 1.47706\n",
      "[200]\ttraining's deviation_error: 1.01666\tvalid_1's deviation_error: 1.31136\n",
      "[300]\ttraining's deviation_error: 0.926232\tvalid_1's deviation_error: 1.19214\n",
      "[400]\ttraining's deviation_error: 0.86162\tvalid_1's deviation_error: 1.12873\n",
      "[500]\ttraining's deviation_error: 0.819537\tvalid_1's deviation_error: 1.08928\n",
      "[600]\ttraining's deviation_error: 0.783183\tvalid_1's deviation_error: 1.06323\n",
      "[700]\ttraining's deviation_error: 0.752363\tvalid_1's deviation_error: 1.03651\n",
      "[800]\ttraining's deviation_error: 0.730756\tvalid_1's deviation_error: 1.01819\n",
      "[900]\ttraining's deviation_error: 0.71165\tvalid_1's deviation_error: 1.00334\n",
      "[1000]\ttraining's deviation_error: 0.692983\tvalid_1's deviation_error: 0.992613\n",
      "[1100]\ttraining's deviation_error: 0.675798\tvalid_1's deviation_error: 0.985852\n",
      "[1200]\ttraining's deviation_error: 0.661611\tvalid_1's deviation_error: 0.977956\n",
      "[1300]\ttraining's deviation_error: 0.650158\tvalid_1's deviation_error: 0.968288\n",
      "[1400]\ttraining's deviation_error: 0.639213\tvalid_1's deviation_error: 0.963797\n",
      "[1500]\ttraining's deviation_error: 0.629406\tvalid_1's deviation_error: 0.958502\n",
      "[1600]\ttraining's deviation_error: 0.619494\tvalid_1's deviation_error: 0.951048\n",
      "[1700]\ttraining's deviation_error: 0.611988\tvalid_1's deviation_error: 0.947733\n",
      "[1800]\ttraining's deviation_error: 0.604703\tvalid_1's deviation_error: 0.94498\n",
      "[1900]\ttraining's deviation_error: 0.596841\tvalid_1's deviation_error: 0.941687\n",
      "[2000]\ttraining's deviation_error: 0.587825\tvalid_1's deviation_error: 0.933337\n",
      "[2100]\ttraining's deviation_error: 0.581335\tvalid_1's deviation_error: 0.932035\n",
      "[2200]\ttraining's deviation_error: 0.576019\tvalid_1's deviation_error: 0.929021\n",
      "[2300]\ttraining's deviation_error: 0.570953\tvalid_1's deviation_error: 0.926395\n",
      "[2400]\ttraining's deviation_error: 0.565267\tvalid_1's deviation_error: 0.926001\n",
      "[2500]\ttraining's deviation_error: 0.558949\tvalid_1's deviation_error: 0.925247\n",
      "[2600]\ttraining's deviation_error: 0.554785\tvalid_1's deviation_error: 0.923494\n",
      "[2700]\ttraining's deviation_error: 0.550124\tvalid_1's deviation_error: 0.921355\n",
      "[2800]\ttraining's deviation_error: 0.54574\tvalid_1's deviation_error: 0.917469\n",
      "[2900]\ttraining's deviation_error: 0.542345\tvalid_1's deviation_error: 0.917925\n",
      "[3000]\ttraining's deviation_error: 0.538017\tvalid_1's deviation_error: 0.915203\n",
      "[3100]\ttraining's deviation_error: 0.53438\tvalid_1's deviation_error: 0.91379\n",
      "[3200]\ttraining's deviation_error: 0.53158\tvalid_1's deviation_error: 0.911061\n",
      "[3300]\ttraining's deviation_error: 0.529079\tvalid_1's deviation_error: 0.910726\n",
      "[3400]\ttraining's deviation_error: 0.525943\tvalid_1's deviation_error: 0.90972\n",
      "[3500]\ttraining's deviation_error: 0.523415\tvalid_1's deviation_error: 0.909287\n",
      "[3600]\ttraining's deviation_error: 0.519525\tvalid_1's deviation_error: 0.909154\n",
      "[3700]\ttraining's deviation_error: 0.517263\tvalid_1's deviation_error: 0.9095\n",
      "Early stopping, best iteration is:\n",
      "[3573]\ttraining's deviation_error: 0.52077\tvalid_1's deviation_error: 0.908216\n",
      "Скор для фолда(19) : 9.0 средний скор на префиксе = 9.0 это заняло = 95 сек.\n",
      "Процесс обучения модели занял = 1027 секунд\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LightGBM кастомная метрика\n",
    "def feval_deviation(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'deviation_error', deviation_metric(np.exp(y_true), np.exp(y_pred)/1.1), False\n",
    "\n",
    "\n",
    "# Функция для обучения модели LightGBM\n",
    "def train_lgb(train, valid, num_features, categorical_features, target_train, target_valid, EPOCHS, params):\n",
    "    # feature_importances = np.zeros(len(features))\n",
    "    train_dataset = lgb.Dataset(train[num_features + categorical_features], np.log(target_train), \n",
    "                                categorical_feature=categorical_features)\n",
    "    valid_dataset = lgb.Dataset(valid[num_features + categorical_features], np.log(target_valid), \n",
    "#                                 weight=(1.0 / target_valid),\n",
    "                                categorical_feature=categorical_features)\n",
    "    model = lgb.train(\n",
    "        params=params,\n",
    "        num_boost_round=EPOCHS,\n",
    "        train_set=train_dataset,\n",
    "        valid_sets=[train_dataset, valid_dataset],\n",
    "        verbose_eval=100,\n",
    "        early_stopping_rounds=int(5 / params['learning_rate']),\n",
    "        feval=feval_deviation)\n",
    "\n",
    "    y_valid = model.predict(valid[num_features + categorical_features])\n",
    "    # feature_importances = model.feature_importance(importance_type='gain') / 5.0\n",
    "    # lgb.plot_importance(model,max_num_features = 41)\n",
    "\n",
    "    return model, np.exp(y_valid)\n",
    "\n",
    "\n",
    "start_train_model_time = time.time()\n",
    "\n",
    "boosting_seed = 41\n",
    "boosting_params = {\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 1,\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.9,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.03,\n",
    "    'metric': 'custom',\n",
    "    'objective': 'regression_l1',\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': boosting_seed,\n",
    "    'feature_fraction_seed': boosting_seed,\n",
    "    'bagging_seed': boosting_seed,\n",
    "    'drop_seed': boosting_seed,\n",
    "    'data_random_seed': boosting_seed,\n",
    "}\n",
    "\n",
    "# Количество эпох обучения\n",
    "EPOCHS = 10000\n",
    "scores = []\n",
    "lgb_predicts = np.zeros(len(train))\n",
    "\n",
    "lgb_models = []\n",
    "for fold_num, (train_indexes, valid_indexes) in enumerate(split_list):\n",
    "    start_time = time.time()\n",
    "    print(f\"Фолд: {fold_num}\")\n",
    "\n",
    "    train_sub_df = train[features_columns_order].loc[train_indexes].reset_index(drop=True)\n",
    "    valid_sub_df = train[features_columns_order].loc[valid_indexes].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Размер трейна = {train_sub_df.shape} Размер валидации = {valid_sub_df.shape}\")\n",
    "    # Обучаем LightGBM и делаем предикт на валидационной выборке\n",
    "    model, predict_validation = train_lgb(\n",
    "        train_sub_df,\n",
    "        valid_sub_df,\n",
    "        NUM_FEATURES_COLUMNS,\n",
    "        CATEGORICAL_FEATURES_COLUMNS,\n",
    "        train_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        valid_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        EPOCHS,\n",
    "        boosting_params)\n",
    "\n",
    "    lgb_models += [model]\n",
    "    predict_on_validation = model.predict(valid_sub_df[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS])\n",
    "    lgb_predicts[valid_indexes] = np.exp(predict_on_validation)\n",
    "    targets_for_validation = valid_sub_df[TARGET_COLUMNS].values[:, 0]\n",
    "    current_score = deviation_metric(targets_for_validation, predict_on_validation)\n",
    "    scores += [current_score]\n",
    "    print(\n",
    "        f\"Скор для фолда({fold_num}) : {np.round(current_score, 4)} средний скор на префиксе = {np.round(np.mean(scores), 4)} это заняло = {int(time.time() - start_time)} сек.\")\n",
    "print(f\"Процесс обучения модели занял = {int(time.time() - start_train_model_time)} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c263298b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17235.261783495247, 459168.7004751519, 60440.58801072709)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Предикт lgb на test\n",
    "def get_lgb_predict(models, test):\n",
    "    result = np.zeros(len(test))\n",
    "    for model in models:\n",
    "        predict = model.predict(test[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS])\n",
    "        result += np.exp(predict) / len(models)\n",
    "    return result\n",
    "\n",
    "\n",
    "test_lgb_predict = get_lgb_predict(lgb_models, test)\n",
    "\n",
    "test_lgb_predict.min(), test_lgb_predict.max(), test_lgb_predict.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67ea26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a468d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c571cbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фолд: 0\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.79933\n",
      "[500]\tvalid-deviation_error:1.20866\n",
      "[750]\tvalid-deviation_error:1.18503\n",
      "[1000]\tvalid-deviation_error:1.14266\n",
      "[1250]\tvalid-deviation_error:1.12162\n",
      "[1500]\tvalid-deviation_error:1.11663\n",
      "[1750]\tvalid-deviation_error:1.10325\n",
      "[2000]\tvalid-deviation_error:1.09861\n",
      "[2250]\tvalid-deviation_error:1.09426\n",
      "[2500]\tvalid-deviation_error:1.08948\n",
      "[2750]\tvalid-deviation_error:1.08501\n",
      "[3000]\tvalid-deviation_error:1.08590\n",
      "[3250]\tvalid-deviation_error:1.08481\n",
      "[3359]\tvalid-deviation_error:1.08481\n",
      "Скор для фолда(0) : 9.0 средний скор на префиксе = 9.0 это заняло = 25 сек.\n",
      "Фолд: 1\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.92815\n",
      "[500]\tvalid-deviation_error:1.08376\n",
      "[750]\tvalid-deviation_error:1.06931\n",
      "[1000]\tvalid-deviation_error:1.04807\n",
      "[1250]\tvalid-deviation_error:1.03123\n",
      "[1500]\tvalid-deviation_error:1.01953\n",
      "[1750]\tvalid-deviation_error:1.01462\n",
      "[2000]\tvalid-deviation_error:1.00937\n",
      "[2250]\tvalid-deviation_error:1.00895\n",
      "[2500]\tvalid-deviation_error:1.01066\n",
      "[2693]\tvalid-deviation_error:1.00883\n",
      "Скор для фолда(1) : 9.0 средний скор на префиксе = 9.0 это заняло = 20 сек.\n",
      "Фолд: 2\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.86171\n",
      "[500]\tvalid-deviation_error:0.93673\n",
      "[750]\tvalid-deviation_error:0.98290\n",
      "[940]\tvalid-deviation_error:0.99189\n",
      "Скор для фолда(2) : 9.0 средний скор на префиксе = 9.0 это заняло = 7 сек.\n",
      "Фолд: 3\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.78083\n",
      "[500]\tvalid-deviation_error:1.06229\n",
      "[750]\tvalid-deviation_error:1.04621\n",
      "[1000]\tvalid-deviation_error:1.02983\n",
      "[1250]\tvalid-deviation_error:1.01970\n",
      "[1500]\tvalid-deviation_error:1.00867\n",
      "[1750]\tvalid-deviation_error:1.00303\n",
      "[2000]\tvalid-deviation_error:0.99927\n",
      "[2250]\tvalid-deviation_error:0.99684\n",
      "[2500]\tvalid-deviation_error:0.99316\n",
      "[2750]\tvalid-deviation_error:0.99089\n",
      "[3000]\tvalid-deviation_error:0.99198\n",
      "[3250]\tvalid-deviation_error:0.99123\n",
      "[3435]\tvalid-deviation_error:0.99256\n",
      "Скор для фолда(3) : 9.0 средний скор на префиксе = 9.0 это заняло = 27 сек.\n",
      "Фолд: 4\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.79160\n",
      "[500]\tvalid-deviation_error:1.10008\n",
      "[750]\tvalid-deviation_error:1.11658\n",
      "[934]\tvalid-deviation_error:1.11824\n",
      "Скор для фолда(4) : 9.0 средний скор на префиксе = 9.0 это заняло = 7 сек.\n",
      "Фолд: 5\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.06224\n",
      "[500]\tvalid-deviation_error:1.35485\n",
      "[750]\tvalid-deviation_error:1.35076\n",
      "[1000]\tvalid-deviation_error:1.34104\n",
      "[1250]\tvalid-deviation_error:1.32957\n",
      "[1500]\tvalid-deviation_error:1.33103\n",
      "[1750]\tvalid-deviation_error:1.33178\n",
      "[1839]\tvalid-deviation_error:1.33563\n",
      "Скор для фолда(5) : 9.0 средний скор на префиксе = 9.0 это заняло = 14 сек.\n",
      "Фолд: 6\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.79588\n",
      "[500]\tvalid-deviation_error:1.08324\n",
      "[750]\tvalid-deviation_error:1.06350\n",
      "[1000]\tvalid-deviation_error:1.04495\n",
      "[1250]\tvalid-deviation_error:1.05546\n",
      "[1500]\tvalid-deviation_error:1.04871\n",
      "[1546]\tvalid-deviation_error:1.04972\n",
      "Скор для фолда(6) : 9.0 средний скор на префиксе = 9.0 это заняло = 12 сек.\n",
      "Фолд: 7\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.59745\n",
      "[500]\tvalid-deviation_error:1.07945\n",
      "[750]\tvalid-deviation_error:1.06858\n",
      "[1000]\tvalid-deviation_error:1.05603\n",
      "[1250]\tvalid-deviation_error:1.04181\n",
      "[1500]\tvalid-deviation_error:1.04042\n",
      "[1750]\tvalid-deviation_error:1.04559\n",
      "[1850]\tvalid-deviation_error:1.04421\n",
      "Скор для фолда(7) : 9.0 средний скор на префиксе = 9.0 это заняло = 15 сек.\n",
      "Фолд: 8\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.60542\n",
      "[500]\tvalid-deviation_error:0.87701\n",
      "[750]\tvalid-deviation_error:0.90195\n",
      "[916]\tvalid-deviation_error:0.90260\n",
      "Скор для фолда(8) : 9.0 средний скор на префиксе = 9.0 это заняло = 8 сек.\n",
      "Фолд: 9\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.88878\n",
      "[500]\tvalid-deviation_error:1.08278\n",
      "[750]\tvalid-deviation_error:1.06792\n",
      "[1000]\tvalid-deviation_error:1.06710\n",
      "[1250]\tvalid-deviation_error:1.06878\n",
      "[1430]\tvalid-deviation_error:1.08051\n",
      "Скор для фолда(9) : 9.0 средний скор на префиксе = 9.0 это заняло = 11 сек.\n",
      "Фолд: 10\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.66416\n",
      "[500]\tvalid-deviation_error:1.08777\n",
      "[750]\tvalid-deviation_error:1.12215\n",
      "[899]\tvalid-deviation_error:1.12798\n",
      "Скор для фолда(10) : 9.0 средний скор на префиксе = 9.0 это заняло = 7 сек.\n",
      "Фолд: 11\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.60459\n",
      "[500]\tvalid-deviation_error:1.33199\n",
      "[750]\tvalid-deviation_error:1.32525\n",
      "[906]\tvalid-deviation_error:1.31910\n",
      "Скор для фолда(11) : 9.0 средний скор на префиксе = 9.0 это заняло = 7 сек.\n",
      "Фолд: 12\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.72316\n",
      "[500]\tvalid-deviation_error:1.17900\n",
      "[750]\tvalid-deviation_error:1.19062\n",
      "[896]\tvalid-deviation_error:1.16681\n",
      "Скор для фолда(12) : 9.0 средний скор на префиксе = 9.0 это заняло = 6 сек.\n",
      "Фолд: 13\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.95827\n",
      "[500]\tvalid-deviation_error:1.21591\n",
      "[750]\tvalid-deviation_error:1.20297\n",
      "[915]\tvalid-deviation_error:1.20153\n",
      "Скор для фолда(13) : 9.0 средний скор на префиксе = 9.0 это заняло = 7 сек.\n",
      "Фолд: 14\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.75908\n",
      "[500]\tvalid-deviation_error:0.98227\n",
      "[750]\tvalid-deviation_error:0.99272\n",
      "[909]\tvalid-deviation_error:0.97938\n",
      "Скор для фолда(14) : 9.0 средний скор на префиксе = 9.0 это заняло = 7 сек.\n",
      "Фолд: 15\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:3.86201\n",
      "[500]\tvalid-deviation_error:1.27857\n",
      "[750]\tvalid-deviation_error:1.19659\n",
      "[1000]\tvalid-deviation_error:1.15280\n",
      "[1250]\tvalid-deviation_error:1.12008\n",
      "[1500]\tvalid-deviation_error:1.09861\n",
      "[1750]\tvalid-deviation_error:1.09048\n",
      "[2000]\tvalid-deviation_error:1.08561\n",
      "[2250]\tvalid-deviation_error:1.08096\n",
      "[2500]\tvalid-deviation_error:1.08227\n",
      "[2750]\tvalid-deviation_error:1.07894\n",
      "[3000]\tvalid-deviation_error:1.07746\n",
      "[3250]\tvalid-deviation_error:1.07777\n",
      "[3500]\tvalid-deviation_error:1.07810\n",
      "[3536]\tvalid-deviation_error:1.07852\n",
      "Скор для фолда(15) : 9.0 средний скор на префиксе = 9.0 это заняло = 29 сек.\n",
      "Фолд: 16\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.11090\n",
      "[500]\tvalid-deviation_error:1.26620\n",
      "[750]\tvalid-deviation_error:1.24766\n",
      "[1000]\tvalid-deviation_error:1.23163\n",
      "[1250]\tvalid-deviation_error:1.22941\n",
      "[1500]\tvalid-deviation_error:1.22657\n",
      "[1750]\tvalid-deviation_error:1.23223\n",
      "[1875]\tvalid-deviation_error:1.23331\n",
      "Скор для фолда(16) : 9.0 средний скор на префиксе = 9.0 это заняло = 14 сек.\n",
      "Фолд: 17\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.16317\n",
      "[500]\tvalid-deviation_error:0.97617\n",
      "[750]\tvalid-deviation_error:0.93920\n",
      "[1000]\tvalid-deviation_error:0.92992\n",
      "[1250]\tvalid-deviation_error:0.92726\n",
      "[1500]\tvalid-deviation_error:0.92318\n",
      "[1750]\tvalid-deviation_error:0.92555\n",
      "[2000]\tvalid-deviation_error:0.92155\n",
      "[2250]\tvalid-deviation_error:0.91888\n",
      "[2500]\tvalid-deviation_error:0.91872\n",
      "[2750]\tvalid-deviation_error:0.91697\n",
      "[3000]\tvalid-deviation_error:0.91513\n",
      "[3250]\tvalid-deviation_error:0.91701\n",
      "[3453]\tvalid-deviation_error:0.91897\n",
      "Скор для фолда(17) : 9.0 средний скор на префиксе = 9.0 это заняло = 26 сек.\n",
      "Фолд: 18\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalid-deviation_error:3.83868\n",
      "[500]\tvalid-deviation_error:0.97363\n",
      "[750]\tvalid-deviation_error:0.97674\n",
      "[1000]\tvalid-deviation_error:0.95682\n",
      "[1250]\tvalid-deviation_error:0.94234\n",
      "[1500]\tvalid-deviation_error:0.94216\n",
      "[1750]\tvalid-deviation_error:0.94449\n",
      "[1803]\tvalid-deviation_error:0.94351\n",
      "Скор для фолда(18) : 9.0 средний скор на префиксе = 9.0 это заняло = 14 сек.\n",
      "Фолд: 19\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.12486\n",
      "[500]\tvalid-deviation_error:0.97530\n",
      "[750]\tvalid-deviation_error:0.88909\n",
      "[1000]\tvalid-deviation_error:0.86000\n",
      "[1250]\tvalid-deviation_error:0.84198\n",
      "[1500]\tvalid-deviation_error:0.83646\n",
      "[1750]\tvalid-deviation_error:0.82904\n",
      "[2000]\tvalid-deviation_error:0.83065\n",
      "[2250]\tvalid-deviation_error:0.83067\n",
      "[2500]\tvalid-deviation_error:0.83510\n",
      "[2651]\tvalid-deviation_error:0.83728\n",
      "Скор для фолда(19) : 9.0 средний скор на префиксе = 9.0 это заняло = 20 сек.\n",
      "Процесс обучения модели занял = 291 секунд\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Кастомная метрика для xgboost\n",
    "def xbg_error(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    err = deviation_metric(np.exp(labels), np.exp(preds)/1.05)\n",
    "    return 'deviation_error', err\n",
    "\n",
    "\n",
    "def train_xgb(train, valid, num_features, categorical_features, target_train, target_valid, EPOCHS, params):\n",
    "    dtest = xgb.DMatrix(test[num_features + categorical_features])\n",
    "    y_valid = np.zeros(len(valid))\n",
    "\n",
    "    dtrain = xgb.DMatrix(train[num_features + categorical_features], np.log(target_train), \n",
    "                        )\n",
    "    dvalid = xgb.DMatrix(valid[num_features + categorical_features], np.log(target_valid), \n",
    "                        )\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        EPOCHS,\n",
    "        [(dvalid, \"valid\")],\n",
    "        verbose_eval=250,\n",
    "        early_stopping_rounds=500,\n",
    "        feval=xbg_error,\n",
    "    )\n",
    "    y_valid = model.predict(dvalid)\n",
    "\n",
    "    return model, y_valid\n",
    "\n",
    "\n",
    "start_train_model_time = time.time()\n",
    "\n",
    "xgboost_seed = 41\n",
    "xgboost_params = {\n",
    "    \"subsample\": 0.70,\n",
    "    \"colsample_bytree\": 0.50,\n",
    "    \"max_depth\": 7,\n",
    "    \"learning_rate\": 0.012,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'disable_default_eval_metric': 1,\n",
    "    \"nthread\": -1,\n",
    "    \"max_bin\": 128,\n",
    "    'min_child_weight': 0.0,\n",
    "    'reg_lambda': 0.0,\n",
    "    'reg_alpha': 0.0,\n",
    "    'seed': xgboost_seed,\n",
    "}\n",
    "\n",
    "# Количество эпох обучения\n",
    "EPOCHS = 10000\n",
    "scores = []\n",
    "xgb_predicts = np.zeros(len(train))\n",
    "\n",
    "xgb_models = []\n",
    "for fold_num, (train_indexes, valid_indexes) in enumerate(split_list):\n",
    "    start_time = time.time()\n",
    "    print(f\"Фолд: {fold_num}\")\n",
    "\n",
    "    train_sub_df = train[features_columns_order].loc[train_indexes].reset_index(drop=True)\n",
    "    valid_sub_df = train[features_columns_order].loc[valid_indexes].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Размер трейна = {train_sub_df.shape} Размер валидации = {valid_sub_df.shape}\")\n",
    "    # Обучаем Xgboost и делаем предикт на валидационной выборке\n",
    "    model, predict_validation = train_xgb(\n",
    "        train_sub_df,\n",
    "        valid_sub_df,\n",
    "        NUM_FEATURES_COLUMNS,\n",
    "        CATEGORICAL_FEATURES_COLUMNS,\n",
    "        train_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        valid_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        EPOCHS,\n",
    "        xgboost_params)\n",
    "\n",
    "    xgb_models += [model]\n",
    "    predict_on_validation = model.predict(\n",
    "        xgb.DMatrix(valid_sub_df[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS]))\n",
    "    xgb_predicts[valid_indexes] = np.exp(predict_on_validation)\n",
    "    targets_for_validation = valid_sub_df[TARGET_COLUMNS].values[:, 0]\n",
    "    current_score = deviation_metric(targets_for_validation, predict_on_validation)\n",
    "    scores += [current_score]\n",
    "    print(\n",
    "        f\"Скор для фолда({fold_num}) : {np.round(current_score, 4)} средний скор на префиксе = {np.round(np.mean(scores), 4)} это заняло = {int(time.time() - start_time)} сек.\")\n",
    "print(f\"Процесс обучения модели занял = {int(time.time() - start_train_model_time)} секунд\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad2270cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предикт xgb на test\n",
    "def get_xgb_predict(models, test):\n",
    "    result = np.zeros(len(test))\n",
    "    for model in models:\n",
    "        predict = model.predict(xgb.DMatrix(test[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS]))\n",
    "        result += predict / len(models)\n",
    "    return result\n",
    "\n",
    "test_xgb_predict = get_xgb_predict(xgb_models, test)\n",
    "\n",
    "test_xgb_predict=np.exp(test_xgb_predict)\n",
    "\n",
    "test_xgb_predict.min(), test_xgb_predict.max(), test_xgb_predict.mean()\n",
    "\n",
    "train_targets = train[TARGET_COLUMNS[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c42a653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccd37e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e42f16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f295b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de8d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d1e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98479c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a4e2d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фолд: 0\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.6306521\ttest: 3.3506941\tbest: 3.3506941 (0)\ttotal: 78.6ms\tremaining: 19m 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7437735\ttest: 2.5529870\tbest: 2.5529870 (50)\ttotal: 408ms\tremaining: 1m 59s\n",
      "100:\tlearn: 2.2825363\ttest: 2.2303113\tbest: 2.2303113 (100)\ttotal: 742ms\tremaining: 1m 49s\n",
      "150:\tlearn: 2.0246339\ttest: 2.0709647\tbest: 2.0709647 (150)\ttotal: 1.07s\tremaining: 1m 45s\n",
      "200:\tlearn: 1.8561306\ttest: 2.0013843\tbest: 2.0013843 (200)\ttotal: 1.4s\tremaining: 1m 42s\n",
      "250:\tlearn: 1.7419400\ttest: 1.9760976\tbest: 1.9760075 (246)\ttotal: 1.74s\tremaining: 1m 41s\n",
      "300:\tlearn: 1.6564567\ttest: 1.9563171\tbest: 1.9563171 (300)\ttotal: 2.07s\tremaining: 1m 41s\n",
      "350:\tlearn: 1.5903019\ttest: 1.9151384\tbest: 1.9151384 (350)\ttotal: 2.39s\tremaining: 1m 39s\n",
      "400:\tlearn: 1.5368943\ttest: 1.8932605\tbest: 1.8932605 (400)\ttotal: 2.73s\tremaining: 1m 39s\n",
      "450:\tlearn: 1.4940564\ttest: 1.8593936\tbest: 1.8593936 (450)\ttotal: 3.05s\tremaining: 1m 38s\n",
      "500:\tlearn: 1.4559319\ttest: 1.8326903\tbest: 1.8326903 (500)\ttotal: 3.38s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4227710\ttest: 1.8176235\tbest: 1.8147836 (547)\ttotal: 3.71s\tremaining: 1m 37s\n",
      "600:\tlearn: 1.3953273\ttest: 1.8024080\tbest: 1.8019016 (598)\ttotal: 4.05s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3721335\ttest: 1.7889084\tbest: 1.7889084 (650)\ttotal: 4.36s\tremaining: 1m 36s\n",
      "700:\tlearn: 1.3474836\ttest: 1.7845184\tbest: 1.7829171 (698)\ttotal: 4.7s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3267957\ttest: 1.7663906\tbest: 1.7663906 (750)\ttotal: 5.03s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.3057225\ttest: 1.7547761\tbest: 1.7547761 (800)\ttotal: 5.35s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.2845542\ttest: 1.7393199\tbest: 1.7393199 (850)\ttotal: 5.69s\tremaining: 1m 34s\n",
      "900:\tlearn: 1.2650245\ttest: 1.7346604\tbest: 1.7346604 (900)\ttotal: 6.02s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2467677\ttest: 1.7269318\tbest: 1.7269318 (950)\ttotal: 6.34s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2265986\ttest: 1.7234413\tbest: 1.7234413 (1000)\ttotal: 6.68s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2081062\ttest: 1.7099162\tbest: 1.7097746 (1049)\ttotal: 7.01s\tremaining: 1m 33s\n",
      "1100:\tlearn: 1.1903301\ttest: 1.6967407\tbest: 1.6967407 (1100)\ttotal: 7.34s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.1729535\ttest: 1.6918625\tbest: 1.6918625 (1150)\ttotal: 7.68s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1555908\ttest: 1.6803587\tbest: 1.6803587 (1200)\ttotal: 8s\tremaining: 1m 31s\n",
      "1250:\tlearn: 1.1389959\ttest: 1.6756570\tbest: 1.6744915 (1240)\ttotal: 8.32s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1224477\ttest: 1.6633173\tbest: 1.6633173 (1300)\ttotal: 8.65s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.1058500\ttest: 1.6519489\tbest: 1.6519489 (1350)\ttotal: 8.98s\tremaining: 1m 30s\n",
      "1400:\tlearn: 1.0898248\ttest: 1.6423531\tbest: 1.6421079 (1393)\ttotal: 9.3s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.0738809\ttest: 1.6326343\tbest: 1.6326343 (1450)\ttotal: 9.64s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0563288\ttest: 1.6249917\tbest: 1.6249878 (1498)\ttotal: 9.97s\tremaining: 1m 29s\n",
      "1550:\tlearn: 1.0401860\ttest: 1.6164852\tbest: 1.6164852 (1550)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0260947\ttest: 1.6107420\tbest: 1.6103270 (1594)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1650:\tlearn: 1.0116324\ttest: 1.6027941\tbest: 1.6027941 (1650)\ttotal: 11s\tremaining: 1m 28s\n",
      "1700:\tlearn: 0.9953446\ttest: 1.5950895\tbest: 1.5950895 (1700)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 0.9807679\ttest: 1.5921138\tbest: 1.5915982 (1749)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1800:\tlearn: 0.9655877\ttest: 1.5860275\tbest: 1.5860275 (1800)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9516125\ttest: 1.5790116\tbest: 1.5788006 (1848)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9364164\ttest: 1.5727530\tbest: 1.5716011 (1891)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1950:\tlearn: 0.9225813\ttest: 1.5671841\tbest: 1.5671841 (1950)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "2000:\tlearn: 0.9101604\ttest: 1.5640711\tbest: 1.5635601 (1993)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.8979709\ttest: 1.5593750\tbest: 1.5593583 (2049)\ttotal: 13.6s\tremaining: 1m 25s\n",
      "2100:\tlearn: 0.8857167\ttest: 1.5548758\tbest: 1.5547501 (2092)\ttotal: 13.9s\tremaining: 1m 25s\n",
      "2150:\tlearn: 0.8703184\ttest: 1.5470514\tbest: 1.5468883 (2140)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8584585\ttest: 1.5430137\tbest: 1.5430137 (2200)\ttotal: 14.6s\tremaining: 1m 24s\n",
      "2250:\tlearn: 0.8439805\ttest: 1.5409787\tbest: 1.5395132 (2239)\ttotal: 14.9s\tremaining: 1m 24s\n",
      "2300:\tlearn: 0.8320163\ttest: 1.5381884\tbest: 1.5369224 (2291)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8180125\ttest: 1.5362702\tbest: 1.5348270 (2331)\ttotal: 15.6s\tremaining: 1m 23s\n",
      "2400:\tlearn: 0.8044324\ttest: 1.5334709\tbest: 1.5334709 (2400)\ttotal: 15.9s\tremaining: 1m 23s\n",
      "2450:\tlearn: 0.7913443\ttest: 1.5316582\tbest: 1.5314584 (2448)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.7786024\ttest: 1.5285045\tbest: 1.5267315 (2487)\ttotal: 16.6s\tremaining: 1m 22s\n",
      "2550:\tlearn: 0.7678844\ttest: 1.5250211\tbest: 1.5250211 (2550)\ttotal: 16.9s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.7575599\ttest: 1.5203389\tbest: 1.5201887 (2599)\ttotal: 17.3s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7471184\ttest: 1.5144362\tbest: 1.5144279 (2649)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7359653\ttest: 1.5125351\tbest: 1.5120207 (2697)\ttotal: 17.9s\tremaining: 1m 21s\n",
      "2750:\tlearn: 0.7243074\ttest: 1.5081382\tbest: 1.5077713 (2747)\ttotal: 18.3s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7147618\ttest: 1.5074256\tbest: 1.5063794 (2789)\ttotal: 18.6s\tremaining: 1m 20s\n",
      "2850:\tlearn: 0.7044799\ttest: 1.5046817\tbest: 1.5046817 (2850)\ttotal: 18.9s\tremaining: 1m 20s\n",
      "2900:\tlearn: 0.6943183\ttest: 1.5006714\tbest: 1.5006546 (2899)\ttotal: 19.2s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.6846180\ttest: 1.5003886\tbest: 1.5002876 (2947)\ttotal: 19.6s\tremaining: 1m 19s\n",
      "3000:\tlearn: 0.6751468\ttest: 1.4983558\tbest: 1.4983558 (3000)\ttotal: 19.9s\tremaining: 1m 19s\n",
      "3050:\tlearn: 0.6654095\ttest: 1.4940657\tbest: 1.4940657 (3050)\ttotal: 20.2s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6562720\ttest: 1.4916413\tbest: 1.4915587 (3097)\ttotal: 20.6s\tremaining: 1m 18s\n",
      "3150:\tlearn: 0.6459021\ttest: 1.4859706\tbest: 1.4858007 (3148)\ttotal: 20.9s\tremaining: 1m 18s\n",
      "3200:\tlearn: 0.6359791\ttest: 1.4845013\tbest: 1.4837255 (3184)\ttotal: 21.2s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6260786\ttest: 1.4812219\tbest: 1.4812219 (3250)\ttotal: 21.6s\tremaining: 1m 17s\n",
      "3300:\tlearn: 0.6158458\ttest: 1.4779231\tbest: 1.4777674 (3295)\ttotal: 21.9s\tremaining: 1m 17s\n",
      "3350:\tlearn: 0.6080591\ttest: 1.4768449\tbest: 1.4766142 (3333)\ttotal: 22.2s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.5984728\ttest: 1.4742060\tbest: 1.4735517 (3392)\ttotal: 22.6s\tremaining: 1m 16s\n",
      "3450:\tlearn: 0.5909696\ttest: 1.4723452\tbest: 1.4717377 (3443)\ttotal: 22.9s\tremaining: 1m 16s\n",
      "3500:\tlearn: 0.5824871\ttest: 1.4690673\tbest: 1.4690673 (3500)\ttotal: 23.2s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5726322\ttest: 1.4633004\tbest: 1.4633004 (3550)\ttotal: 23.6s\tremaining: 1m 15s\n",
      "3600:\tlearn: 0.5641332\ttest: 1.4619476\tbest: 1.4612551 (3576)\ttotal: 23.9s\tremaining: 1m 15s\n",
      "3650:\tlearn: 0.5564610\ttest: 1.4585590\tbest: 1.4585590 (3650)\ttotal: 24.2s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5483025\ttest: 1.4540864\tbest: 1.4538226 (3698)\ttotal: 24.6s\tremaining: 1m 14s\n",
      "3750:\tlearn: 0.5394171\ttest: 1.4496193\tbest: 1.4494973 (3748)\ttotal: 24.9s\tremaining: 1m 14s\n",
      "3800:\tlearn: 0.5312369\ttest: 1.4509796\tbest: 1.4488459 (3786)\ttotal: 25.2s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5243841\ttest: 1.4488457\tbest: 1.4479553 (3827)\ttotal: 25.6s\tremaining: 1m 13s\n",
      "3900:\tlearn: 0.5167293\ttest: 1.4494896\tbest: 1.4479553 (3827)\ttotal: 25.9s\tremaining: 1m 13s\n",
      "3950:\tlearn: 0.5094675\ttest: 1.4469309\tbest: 1.4467783 (3948)\ttotal: 26.2s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.5030180\ttest: 1.4476215\tbest: 1.4466186 (3968)\ttotal: 26.6s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.4944823\ttest: 1.4437025\tbest: 1.4437025 (4050)\ttotal: 26.9s\tremaining: 1m 12s\n",
      "4100:\tlearn: 0.4870396\ttest: 1.4410964\tbest: 1.4408177 (4076)\ttotal: 27.2s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4800437\ttest: 1.4403516\tbest: 1.4401385 (4146)\ttotal: 27.6s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4725702\ttest: 1.4396788\tbest: 1.4394072 (4159)\ttotal: 27.9s\tremaining: 1m 11s\n",
      "4250:\tlearn: 0.4651342\ttest: 1.4394677\tbest: 1.4393382 (4221)\ttotal: 28.2s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4589134\ttest: 1.4388207\tbest: 1.4387671 (4298)\ttotal: 28.6s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4514007\ttest: 1.4361372\tbest: 1.4355994 (4347)\ttotal: 28.9s\tremaining: 1m 10s\n",
      "4400:\tlearn: 0.4436337\ttest: 1.4357131\tbest: 1.4339938 (4380)\ttotal: 29.2s\tremaining: 1m 10s\n",
      "4450:\tlearn: 0.4379206\ttest: 1.4348850\tbest: 1.4336120 (4424)\ttotal: 29.5s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4330121\ttest: 1.4333186\tbest: 1.4333186 (4500)\ttotal: 29.9s\tremaining: 1m 9s\n",
      "4550:\tlearn: 0.4267195\ttest: 1.4331883\tbest: 1.4321611 (4525)\ttotal: 30.2s\tremaining: 1m 9s\n",
      "4600:\tlearn: 0.4202779\ttest: 1.4334267\tbest: 1.4321611 (4525)\ttotal: 30.5s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4133502\ttest: 1.4315901\tbest: 1.4314675 (4648)\ttotal: 30.9s\tremaining: 1m 8s\n",
      "4700:\tlearn: 0.4069490\ttest: 1.4318253\tbest: 1.4310959 (4652)\ttotal: 31.2s\tremaining: 1m 8s\n",
      "4750:\tlearn: 0.4013808\ttest: 1.4288943\tbest: 1.4288943 (4750)\ttotal: 31.5s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.3951921\ttest: 1.4265970\tbest: 1.4265970 (4800)\ttotal: 31.9s\tremaining: 1m 7s\n",
      "4850:\tlearn: 0.3897914\ttest: 1.4262991\tbest: 1.4252903 (4809)\ttotal: 32.2s\tremaining: 1m 7s\n",
      "4900:\tlearn: 0.3846513\ttest: 1.4245582\tbest: 1.4245582 (4900)\ttotal: 32.5s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3789320\ttest: 1.4219940\tbest: 1.4219940 (4950)\ttotal: 32.9s\tremaining: 1m 6s\n",
      "5000:\tlearn: 0.3745140\ttest: 1.4210193\tbest: 1.4207749 (4997)\ttotal: 33.2s\tremaining: 1m 6s\n",
      "5050:\tlearn: 0.3690261\ttest: 1.4205905\tbest: 1.4204902 (5048)\ttotal: 33.5s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3643679\ttest: 1.4178661\tbest: 1.4173678 (5086)\ttotal: 33.9s\tremaining: 1m 5s\n",
      "5150:\tlearn: 0.3592730\ttest: 1.4181961\tbest: 1.4173678 (5086)\ttotal: 34.2s\tremaining: 1m 5s\n",
      "5200:\tlearn: 0.3537791\ttest: 1.4175801\tbest: 1.4171665 (5193)\ttotal: 34.5s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3480081\ttest: 1.4168626\tbest: 1.4166320 (5205)\ttotal: 34.9s\tremaining: 1m 4s\n",
      "5300:\tlearn: 0.3423289\ttest: 1.4145964\tbest: 1.4143730 (5296)\ttotal: 35.2s\tremaining: 1m 4s\n",
      "5350:\tlearn: 0.3372225\ttest: 1.4137724\tbest: 1.4127759 (5326)\ttotal: 35.5s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3324521\ttest: 1.4109554\tbest: 1.4107054 (5385)\ttotal: 35.9s\tremaining: 1m 3s\n",
      "5450:\tlearn: 0.3271701\ttest: 1.4097733\tbest: 1.4097733 (5450)\ttotal: 36.2s\tremaining: 1m 3s\n",
      "5500:\tlearn: 0.3215921\ttest: 1.4079218\tbest: 1.4079218 (5500)\ttotal: 36.5s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3161603\ttest: 1.4071332\tbest: 1.4067894 (5534)\ttotal: 36.9s\tremaining: 1m 2s\n",
      "5600:\tlearn: 0.3107732\ttest: 1.4061239\tbest: 1.4059404 (5579)\ttotal: 37.2s\tremaining: 1m 2s\n",
      "5650:\tlearn: 0.3060731\ttest: 1.4049752\tbest: 1.4049752 (5650)\ttotal: 37.5s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.3013921\ttest: 1.4037350\tbest: 1.4032017 (5698)\ttotal: 37.9s\tremaining: 1m 1s\n",
      "5750:\tlearn: 0.2970718\ttest: 1.4028082\tbest: 1.4022150 (5747)\ttotal: 38.2s\tremaining: 1m 1s\n",
      "5800:\tlearn: 0.2933392\ttest: 1.4023706\tbest: 1.4013075 (5791)\ttotal: 38.5s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2888136\ttest: 1.4006767\tbest: 1.4006517 (5849)\ttotal: 38.9s\tremaining: 1m\n",
      "5900:\tlearn: 0.2842517\ttest: 1.3989821\tbest: 1.3985539 (5883)\ttotal: 39.2s\tremaining: 1m\n",
      "5950:\tlearn: 0.2797223\ttest: 1.3959205\tbest: 1.3959205 (5950)\ttotal: 39.5s\tremaining: 1m\n",
      "6000:\tlearn: 0.2752433\ttest: 1.3954225\tbest: 1.3954225 (6000)\ttotal: 39.9s\tremaining: 59.8s\n",
      "6050:\tlearn: 0.2713546\ttest: 1.3944108\tbest: 1.3943313 (6045)\ttotal: 40.2s\tremaining: 59.4s\n",
      "6100:\tlearn: 0.2674295\ttest: 1.3940120\tbest: 1.3934330 (6094)\ttotal: 40.5s\tremaining: 59.1s\n",
      "6150:\tlearn: 0.2638245\ttest: 1.3949343\tbest: 1.3933529 (6117)\ttotal: 40.9s\tremaining: 58.8s\n",
      "6200:\tlearn: 0.2600136\ttest: 1.3927671\tbest: 1.3926280 (6192)\ttotal: 41.2s\tremaining: 58.4s\n",
      "6250:\tlearn: 0.2566769\ttest: 1.3905626\tbest: 1.3905626 (6250)\ttotal: 41.5s\tremaining: 58.1s\n",
      "6300:\tlearn: 0.2525411\ttest: 1.3884758\tbest: 1.3881278 (6298)\ttotal: 41.9s\tremaining: 57.8s\n",
      "6350:\tlearn: 0.2493804\ttest: 1.3883088\tbest: 1.3867745 (6322)\ttotal: 42.2s\tremaining: 57.4s\n",
      "6400:\tlearn: 0.2456573\ttest: 1.3869012\tbest: 1.3865873 (6387)\ttotal: 42.5s\tremaining: 57.1s\n",
      "6450:\tlearn: 0.2413127\ttest: 1.3857458\tbest: 1.3851133 (6435)\ttotal: 42.9s\tremaining: 56.8s\n",
      "6500:\tlearn: 0.2379627\ttest: 1.3867743\tbest: 1.3851133 (6435)\ttotal: 43.2s\tremaining: 56.5s\n",
      "6550:\tlearn: 0.2334325\ttest: 1.3856329\tbest: 1.3851133 (6435)\ttotal: 43.5s\tremaining: 56.1s\n",
      "6600:\tlearn: 0.2290755\ttest: 1.3845704\tbest: 1.3842102 (6590)\ttotal: 43.9s\tremaining: 55.8s\n",
      "6650:\tlearn: 0.2256703\ttest: 1.3825613\tbest: 1.3816608 (6646)\ttotal: 44.2s\tremaining: 55.5s\n",
      "6700:\tlearn: 0.2220821\ttest: 1.3795825\tbest: 1.3795825 (6700)\ttotal: 44.5s\tremaining: 55.1s\n",
      "6750:\tlearn: 0.2188382\ttest: 1.3788382\tbest: 1.3784266 (6714)\ttotal: 44.9s\tremaining: 54.8s\n",
      "6800:\tlearn: 0.2156923\ttest: 1.3784227\tbest: 1.3779948 (6794)\ttotal: 45.2s\tremaining: 54.5s\n",
      "6850:\tlearn: 0.2129475\ttest: 1.3759303\tbest: 1.3759303 (6850)\ttotal: 45.5s\tremaining: 54.2s\n",
      "6900:\tlearn: 0.2091976\ttest: 1.3736970\tbest: 1.3734855 (6897)\ttotal: 45.9s\tremaining: 53.9s\n",
      "6950:\tlearn: 0.2064321\ttest: 1.3742579\tbest: 1.3734680 (6904)\ttotal: 46.2s\tremaining: 53.5s\n",
      "7000:\tlearn: 0.2028621\ttest: 1.3724800\tbest: 1.3724800 (7000)\ttotal: 46.6s\tremaining: 53.2s\n",
      "7050:\tlearn: 0.2004060\ttest: 1.3717970\tbest: 1.3714053 (7016)\ttotal: 46.9s\tremaining: 52.9s\n",
      "7100:\tlearn: 0.1972289\ttest: 1.3704414\tbest: 1.3703611 (7068)\ttotal: 47.2s\tremaining: 52.5s\n",
      "7150:\tlearn: 0.1941430\ttest: 1.3676775\tbest: 1.3676775 (7150)\ttotal: 47.6s\tremaining: 52.2s\n",
      "7200:\tlearn: 0.1920574\ttest: 1.3669767\tbest: 1.3666677 (7190)\ttotal: 47.9s\tremaining: 51.9s\n",
      "7250:\tlearn: 0.1893401\ttest: 1.3663978\tbest: 1.3655415 (7237)\ttotal: 48.2s\tremaining: 51.5s\n",
      "7300:\tlearn: 0.1862892\ttest: 1.3647830\tbest: 1.3647830 (7300)\ttotal: 48.6s\tremaining: 51.2s\n",
      "7350:\tlearn: 0.1836399\ttest: 1.3648132\tbest: 1.3637148 (7320)\ttotal: 48.9s\tremaining: 50.9s\n",
      "7400:\tlearn: 0.1813002\ttest: 1.3640020\tbest: 1.3637148 (7320)\ttotal: 49.2s\tremaining: 50.6s\n",
      "7450:\tlearn: 0.1789462\ttest: 1.3630520\tbest: 1.3622267 (7430)\ttotal: 49.6s\tremaining: 50.2s\n",
      "7500:\tlearn: 0.1761383\ttest: 1.3632427\tbest: 1.3622267 (7430)\ttotal: 49.9s\tremaining: 49.9s\n",
      "7550:\tlearn: 0.1736084\ttest: 1.3607174\tbest: 1.3607174 (7550)\ttotal: 50.3s\tremaining: 49.6s\n",
      "7600:\tlearn: 0.1713398\ttest: 1.3586687\tbest: 1.3585560 (7595)\ttotal: 50.6s\tremaining: 49.3s\n",
      "7650:\tlearn: 0.1689533\ttest: 1.3576344\tbest: 1.3576344 (7650)\ttotal: 50.9s\tremaining: 48.9s\n",
      "7700:\tlearn: 0.1665959\ttest: 1.3591028\tbest: 1.3571293 (7675)\ttotal: 51.3s\tremaining: 48.6s\n",
      "7750:\tlearn: 0.1640740\ttest: 1.3568490\tbest: 1.3565747 (7745)\ttotal: 51.6s\tremaining: 48.3s\n",
      "7800:\tlearn: 0.1617755\ttest: 1.3553208\tbest: 1.3553208 (7800)\ttotal: 51.9s\tremaining: 47.9s\n",
      "7850:\tlearn: 0.1592138\ttest: 1.3547900\tbest: 1.3534770 (7829)\ttotal: 52.3s\tremaining: 47.6s\n",
      "7900:\tlearn: 0.1566734\ttest: 1.3522263\tbest: 1.3522263 (7900)\ttotal: 52.6s\tremaining: 47.3s\n",
      "7950:\tlearn: 0.1540647\ttest: 1.3508558\tbest: 1.3506169 (7938)\ttotal: 52.9s\tremaining: 46.9s\n",
      "8000:\tlearn: 0.1515267\ttest: 1.3492705\tbest: 1.3491558 (7997)\ttotal: 53.3s\tremaining: 46.6s\n",
      "8050:\tlearn: 0.1492765\ttest: 1.3484385\tbest: 1.3484385 (8050)\ttotal: 53.6s\tremaining: 46.3s\n",
      "8100:\tlearn: 0.1471642\ttest: 1.3468895\tbest: 1.3468895 (8100)\ttotal: 53.9s\tremaining: 45.9s\n",
      "8150:\tlearn: 0.1449132\ttest: 1.3464146\tbest: 1.3456429 (8117)\ttotal: 54.3s\tremaining: 45.6s\n",
      "8200:\tlearn: 0.1429919\ttest: 1.3443695\tbest: 1.3440864 (8194)\ttotal: 54.6s\tremaining: 45.3s\n",
      "8250:\tlearn: 0.1409741\ttest: 1.3435494\tbest: 1.3430997 (8247)\ttotal: 54.9s\tremaining: 44.9s\n",
      "8300:\tlearn: 0.1390570\ttest: 1.3428334\tbest: 1.3428334 (8300)\ttotal: 55.3s\tremaining: 44.6s\n",
      "8350:\tlearn: 0.1371658\ttest: 1.3409211\tbest: 1.3409211 (8350)\ttotal: 55.6s\tremaining: 44.3s\n",
      "8400:\tlearn: 0.1349000\ttest: 1.3380985\tbest: 1.3379625 (8398)\ttotal: 55.9s\tremaining: 43.9s\n",
      "8450:\tlearn: 0.1329253\ttest: 1.3367696\tbest: 1.3365159 (8446)\ttotal: 56.3s\tremaining: 43.6s\n",
      "8500:\tlearn: 0.1308308\ttest: 1.3369730\tbest: 1.3363217 (8481)\ttotal: 56.6s\tremaining: 43.3s\n",
      "8550:\tlearn: 0.1289091\ttest: 1.3353884\tbest: 1.3353884 (8550)\ttotal: 56.9s\tremaining: 42.9s\n",
      "8600:\tlearn: 0.1270685\ttest: 1.3335968\tbest: 1.3335968 (8600)\ttotal: 57.3s\tremaining: 42.6s\n",
      "8650:\tlearn: 0.1252737\ttest: 1.3325647\tbest: 1.3325286 (8649)\ttotal: 57.6s\tremaining: 42.3s\n",
      "8700:\tlearn: 0.1235770\ttest: 1.3321801\tbest: 1.3314127 (8687)\ttotal: 57.9s\tremaining: 41.9s\n",
      "8750:\tlearn: 0.1219987\ttest: 1.3322989\tbest: 1.3314127 (8687)\ttotal: 58.3s\tremaining: 41.6s\n",
      "8800:\tlearn: 0.1204083\ttest: 1.3318077\tbest: 1.3314127 (8687)\ttotal: 58.6s\tremaining: 41.3s\n",
      "8850:\tlearn: 0.1184813\ttest: 1.3311818\tbest: 1.3306967 (8831)\ttotal: 58.9s\tremaining: 40.9s\n",
      "8900:\tlearn: 0.1168620\ttest: 1.3308008\tbest: 1.3306637 (8897)\ttotal: 59.3s\tremaining: 40.6s\n",
      "8950:\tlearn: 0.1151831\ttest: 1.3306176\tbest: 1.3306176 (8950)\ttotal: 59.6s\tremaining: 40.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000:\tlearn: 0.1137623\ttest: 1.3287239\tbest: 1.3285460 (8993)\ttotal: 60s\tremaining: 40s\n",
      "9050:\tlearn: 0.1121136\ttest: 1.3272415\tbest: 1.3270474 (9033)\ttotal: 1m\tremaining: 39.6s\n",
      "9100:\tlearn: 0.1106201\ttest: 1.3267792\tbest: 1.3254563 (9085)\ttotal: 1m\tremaining: 39.3s\n",
      "9150:\tlearn: 0.1092699\ttest: 1.3259285\tbest: 1.3254563 (9085)\ttotal: 1m\tremaining: 39s\n",
      "9200:\tlearn: 0.1077485\ttest: 1.3250922\tbest: 1.3250922 (9200)\ttotal: 1m 1s\tremaining: 38.6s\n",
      "9250:\tlearn: 0.1062121\ttest: 1.3236869\tbest: 1.3235176 (9247)\ttotal: 1m 1s\tremaining: 38.3s\n",
      "9300:\tlearn: 0.1040683\ttest: 1.3225128\tbest: 1.3225128 (9300)\ttotal: 1m 1s\tremaining: 38s\n",
      "9350:\tlearn: 0.1024694\ttest: 1.3220058\tbest: 1.3219963 (9348)\ttotal: 1m 2s\tremaining: 37.6s\n",
      "9400:\tlearn: 0.1006324\ttest: 1.3196980\tbest: 1.3195212 (9399)\ttotal: 1m 2s\tremaining: 37.3s\n",
      "9450:\tlearn: 0.0994663\ttest: 1.3177843\tbest: 1.3176847 (9449)\ttotal: 1m 2s\tremaining: 37s\n",
      "9500:\tlearn: 0.0981823\ttest: 1.3184463\tbest: 1.3173065 (9457)\ttotal: 1m 3s\tremaining: 36.6s\n",
      "9550:\tlearn: 0.0968218\ttest: 1.3180021\tbest: 1.3173065 (9457)\ttotal: 1m 3s\tremaining: 36.3s\n",
      "9600:\tlearn: 0.0954731\ttest: 1.3164534\tbest: 1.3164355 (9598)\ttotal: 1m 3s\tremaining: 36s\n",
      "9650:\tlearn: 0.0938130\ttest: 1.3155437\tbest: 1.3149152 (9625)\ttotal: 1m 4s\tremaining: 35.6s\n",
      "9700:\tlearn: 0.0920362\ttest: 1.3139712\tbest: 1.3132441 (9690)\ttotal: 1m 4s\tremaining: 35.3s\n",
      "9750:\tlearn: 0.0905893\ttest: 1.3136996\tbest: 1.3132237 (9709)\ttotal: 1m 4s\tremaining: 35s\n",
      "9800:\tlearn: 0.0893095\ttest: 1.3122112\tbest: 1.3113940 (9783)\ttotal: 1m 5s\tremaining: 34.7s\n",
      "9850:\tlearn: 0.0881058\ttest: 1.3108447\tbest: 1.3106711 (9831)\ttotal: 1m 5s\tremaining: 34.3s\n",
      "9900:\tlearn: 0.0870571\ttest: 1.3094466\tbest: 1.3094466 (9900)\ttotal: 1m 5s\tremaining: 34s\n",
      "9950:\tlearn: 0.0855839\ttest: 1.3088917\tbest: 1.3088917 (9950)\ttotal: 1m 6s\tremaining: 33.7s\n",
      "10000:\tlearn: 0.0842021\ttest: 1.3089155\tbest: 1.3086145 (9981)\ttotal: 1m 6s\tremaining: 33.3s\n",
      "10050:\tlearn: 0.0831769\ttest: 1.3075877\tbest: 1.3071127 (10031)\ttotal: 1m 6s\tremaining: 33s\n",
      "10100:\tlearn: 0.0820706\ttest: 1.3073958\tbest: 1.3068490 (10095)\ttotal: 1m 7s\tremaining: 32.7s\n",
      "10150:\tlearn: 0.0808662\ttest: 1.3078073\tbest: 1.3068490 (10095)\ttotal: 1m 7s\tremaining: 32.3s\n",
      "10200:\tlearn: 0.0795728\ttest: 1.3061791\tbest: 1.3061771 (10198)\ttotal: 1m 7s\tremaining: 32s\n",
      "10250:\tlearn: 0.0783913\ttest: 1.3054530\tbest: 1.3052969 (10229)\ttotal: 1m 8s\tremaining: 31.7s\n",
      "10300:\tlearn: 0.0771590\ttest: 1.3052268\tbest: 1.3048991 (10271)\ttotal: 1m 8s\tremaining: 31.3s\n",
      "10350:\tlearn: 0.0758460\ttest: 1.3042046\tbest: 1.3041374 (10349)\ttotal: 1m 8s\tremaining: 31s\n",
      "10400:\tlearn: 0.0746636\ttest: 1.3034029\tbest: 1.3028817 (10388)\ttotal: 1m 9s\tremaining: 30.7s\n",
      "10450:\tlearn: 0.0734804\ttest: 1.3024512\tbest: 1.3022574 (10448)\ttotal: 1m 9s\tremaining: 30.3s\n",
      "10500:\tlearn: 0.0723759\ttest: 1.3018433\tbest: 1.3016045 (10482)\ttotal: 1m 9s\tremaining: 30s\n",
      "10550:\tlearn: 0.0712974\ttest: 1.3001033\tbest: 1.3001033 (10550)\ttotal: 1m 10s\tremaining: 29.7s\n",
      "10600:\tlearn: 0.0700974\ttest: 1.2999844\tbest: 1.2996651 (10563)\ttotal: 1m 10s\tremaining: 29.3s\n",
      "10650:\tlearn: 0.0691181\ttest: 1.2991066\tbest: 1.2990443 (10638)\ttotal: 1m 10s\tremaining: 29s\n",
      "10700:\tlearn: 0.0681408\ttest: 1.2970688\tbest: 1.2970688 (10700)\ttotal: 1m 11s\tremaining: 28.7s\n",
      "10750:\tlearn: 0.0671341\ttest: 1.2975344\tbest: 1.2969001 (10712)\ttotal: 1m 11s\tremaining: 28.3s\n",
      "10800:\tlearn: 0.0661648\ttest: 1.2971868\tbest: 1.2968449 (10783)\ttotal: 1m 11s\tremaining: 28s\n",
      "10850:\tlearn: 0.0650149\ttest: 1.2968213\tbest: 1.2968213 (10850)\ttotal: 1m 12s\tremaining: 27.7s\n",
      "10900:\tlearn: 0.0641069\ttest: 1.2971241\tbest: 1.2965056 (10884)\ttotal: 1m 12s\tremaining: 27.3s\n",
      "10950:\tlearn: 0.0631436\ttest: 1.2977199\tbest: 1.2965056 (10884)\ttotal: 1m 13s\tremaining: 27s\n",
      "11000:\tlearn: 0.0621810\ttest: 1.2978677\tbest: 1.2965056 (10884)\ttotal: 1m 13s\tremaining: 26.7s\n",
      "11050:\tlearn: 0.0613493\ttest: 1.2988925\tbest: 1.2965056 (10884)\ttotal: 1m 13s\tremaining: 26.3s\n",
      "11100:\tlearn: 0.0605665\ttest: 1.2984579\tbest: 1.2965056 (10884)\ttotal: 1m 14s\tremaining: 26s\n",
      "11150:\tlearn: 0.0595191\ttest: 1.2977186\tbest: 1.2965056 (10884)\ttotal: 1m 14s\tremaining: 25.7s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.296505555\n",
      "bestIteration = 10884\n",
      "\n",
      "Shrink model to first 10885 iterations.\n",
      "Скор для фолда(0) : 9.0 средний скор на префиксе = 9.0 это заняло = 75 сек.\n",
      "Фолд: 1\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.5956751\ttest: 3.4685541\tbest: 3.4685541 (0)\ttotal: 27.2ms\tremaining: 6m 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7328784\ttest: 2.5512925\tbest: 2.5512925 (50)\ttotal: 370ms\tremaining: 1m 48s\n",
      "100:\tlearn: 2.2720424\ttest: 2.1555536\tbest: 2.1555536 (100)\ttotal: 696ms\tremaining: 1m 42s\n",
      "150:\tlearn: 2.0197101\ttest: 1.9510163\tbest: 1.9510163 (150)\ttotal: 1.03s\tremaining: 1m 41s\n",
      "200:\tlearn: 1.8594761\ttest: 1.8304153\tbest: 1.8304153 (200)\ttotal: 1.37s\tremaining: 1m 41s\n",
      "250:\tlearn: 1.7475463\ttest: 1.7563831\tbest: 1.7563831 (250)\ttotal: 1.72s\tremaining: 1m 41s\n",
      "300:\tlearn: 1.6611104\ttest: 1.7020631\tbest: 1.7020631 (300)\ttotal: 2.06s\tremaining: 1m 40s\n",
      "350:\tlearn: 1.6018290\ttest: 1.6773239\tbest: 1.6773239 (350)\ttotal: 2.4s\tremaining: 1m 40s\n",
      "400:\tlearn: 1.5477206\ttest: 1.6464018\tbest: 1.6464018 (400)\ttotal: 2.72s\tremaining: 1m 39s\n",
      "450:\tlearn: 1.5043351\ttest: 1.6164146\tbest: 1.6164146 (450)\ttotal: 3.05s\tremaining: 1m 38s\n",
      "500:\tlearn: 1.4690814\ttest: 1.5961961\tbest: 1.5961961 (500)\ttotal: 3.38s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4375395\ttest: 1.5852692\tbest: 1.5847105 (539)\ttotal: 3.71s\tremaining: 1m 37s\n",
      "600:\tlearn: 1.4076859\ttest: 1.5743455\tbest: 1.5732539 (598)\ttotal: 4.04s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3817186\ttest: 1.5604970\tbest: 1.5604970 (650)\ttotal: 4.37s\tremaining: 1m 36s\n",
      "700:\tlearn: 1.3608637\ttest: 1.5529131\tbest: 1.5528527 (699)\ttotal: 4.69s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3370738\ttest: 1.5431392\tbest: 1.5430832 (748)\ttotal: 5.02s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.3188067\ttest: 1.5321617\tbest: 1.5321617 (800)\ttotal: 5.36s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.3027567\ttest: 1.5245511\tbest: 1.5244778 (848)\ttotal: 5.69s\tremaining: 1m 34s\n",
      "900:\tlearn: 1.2868625\ttest: 1.5201521\tbest: 1.5201521 (900)\ttotal: 6.01s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2707594\ttest: 1.5140879\tbest: 1.5140879 (950)\ttotal: 6.35s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2523662\ttest: 1.5110307\tbest: 1.5104492 (983)\ttotal: 6.67s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2378308\ttest: 1.5091851\tbest: 1.5083349 (1040)\ttotal: 6.99s\tremaining: 1m 32s\n",
      "1100:\tlearn: 1.2229095\ttest: 1.5071314\tbest: 1.5062180 (1087)\ttotal: 7.32s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.2069918\ttest: 1.5057383\tbest: 1.5047856 (1137)\ttotal: 7.64s\tremaining: 1m 31s\n",
      "1200:\tlearn: 1.1886865\ttest: 1.5042462\tbest: 1.5042462 (1200)\ttotal: 7.97s\tremaining: 1m 31s\n",
      "1250:\tlearn: 1.1717723\ttest: 1.5007209\tbest: 1.5007209 (1250)\ttotal: 8.3s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1530523\ttest: 1.4948785\tbest: 1.4948785 (1300)\ttotal: 8.62s\tremaining: 1m 30s\n",
      "1350:\tlearn: 1.1368440\ttest: 1.4926382\tbest: 1.4910545 (1338)\ttotal: 8.95s\tremaining: 1m 30s\n",
      "1400:\tlearn: 1.1192088\ttest: 1.4912343\tbest: 1.4910545 (1338)\ttotal: 9.28s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.1008313\ttest: 1.4907261\tbest: 1.4900985 (1447)\ttotal: 9.6s\tremaining: 1m 29s\n",
      "1500:\tlearn: 1.0820300\ttest: 1.4912083\tbest: 1.4888354 (1464)\ttotal: 9.93s\tremaining: 1m 29s\n",
      "1550:\tlearn: 1.0661625\ttest: 1.4886189\tbest: 1.4871862 (1529)\ttotal: 10.3s\tremaining: 1m 28s\n",
      "1600:\tlearn: 1.0509063\ttest: 1.4889824\tbest: 1.4871862 (1529)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1650:\tlearn: 1.0361384\ttest: 1.4894359\tbest: 1.4871862 (1529)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1700:\tlearn: 1.0191220\ttest: 1.4870048\tbest: 1.4869263 (1690)\ttotal: 11.3s\tremaining: 1m 27s\n",
      "1750:\tlearn: 1.0075867\ttest: 1.4871822\tbest: 1.4869246 (1702)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1800:\tlearn: 0.9896762\ttest: 1.4850879\tbest: 1.4847453 (1790)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9734506\ttest: 1.4858714\tbest: 1.4844790 (1832)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9592159\ttest: 1.4862984\tbest: 1.4835112 (1875)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1950:\tlearn: 0.9442838\ttest: 1.4876349\tbest: 1.4835112 (1875)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "2000:\tlearn: 0.9293737\ttest: 1.4886650\tbest: 1.4835112 (1875)\ttotal: 13.2s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.9156812\ttest: 1.4858653\tbest: 1.4835112 (1875)\ttotal: 13.6s\tremaining: 1m 25s\n",
      "2100:\tlearn: 0.9014189\ttest: 1.4852318\tbest: 1.4835112 (1875)\ttotal: 13.9s\tremaining: 1m 25s\n",
      "2150:\tlearn: 0.8905116\ttest: 1.4827402\tbest: 1.4827402 (2150)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8799533\ttest: 1.4805429\tbest: 1.4804469 (2188)\ttotal: 14.6s\tremaining: 1m 24s\n",
      "2250:\tlearn: 0.8669815\ttest: 1.4788023\tbest: 1.4787722 (2249)\ttotal: 14.9s\tremaining: 1m 24s\n",
      "2300:\tlearn: 0.8529534\ttest: 1.4735357\tbest: 1.4735357 (2300)\ttotal: 15.2s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8397028\ttest: 1.4743964\tbest: 1.4716848 (2312)\ttotal: 15.6s\tremaining: 1m 23s\n",
      "2400:\tlearn: 0.8284255\ttest: 1.4714173\tbest: 1.4714173 (2400)\ttotal: 15.9s\tremaining: 1m 23s\n",
      "2450:\tlearn: 0.8146906\ttest: 1.4693297\tbest: 1.4678819 (2439)\ttotal: 16.2s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.8013110\ttest: 1.4701838\tbest: 1.4678819 (2439)\ttotal: 16.6s\tremaining: 1m 22s\n",
      "2550:\tlearn: 0.7881610\ttest: 1.4712525\tbest: 1.4678819 (2439)\ttotal: 16.9s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.7777415\ttest: 1.4683515\tbest: 1.4678819 (2439)\ttotal: 17.2s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7668844\ttest: 1.4664618\tbest: 1.4663465 (2649)\ttotal: 17.5s\tremaining: 1m 21s\n",
      "2700:\tlearn: 0.7568707\ttest: 1.4623749\tbest: 1.4621351 (2694)\ttotal: 17.9s\tremaining: 1m 21s\n",
      "2750:\tlearn: 0.7447942\ttest: 1.4596902\tbest: 1.4596461 (2749)\ttotal: 18.2s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7340164\ttest: 1.4580617\tbest: 1.4564086 (2780)\ttotal: 18.5s\tremaining: 1m 20s\n",
      "2850:\tlearn: 0.7231629\ttest: 1.4554520\tbest: 1.4549490 (2843)\ttotal: 18.9s\tremaining: 1m 20s\n",
      "2900:\tlearn: 0.7129372\ttest: 1.4544000\tbest: 1.4543736 (2896)\ttotal: 19.2s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.7025047\ttest: 1.4537736\tbest: 1.4526163 (2926)\ttotal: 19.5s\tremaining: 1m 19s\n",
      "3000:\tlearn: 0.6935260\ttest: 1.4512814\tbest: 1.4509039 (2999)\ttotal: 19.9s\tremaining: 1m 19s\n",
      "3050:\tlearn: 0.6844602\ttest: 1.4517185\tbest: 1.4505290 (3022)\ttotal: 20.2s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6746713\ttest: 1.4513679\tbest: 1.4505290 (3022)\ttotal: 20.5s\tremaining: 1m 18s\n",
      "3150:\tlearn: 0.6643015\ttest: 1.4485120\tbest: 1.4479202 (3143)\ttotal: 20.9s\tremaining: 1m 18s\n",
      "3200:\tlearn: 0.6560318\ttest: 1.4453663\tbest: 1.4451518 (3192)\ttotal: 21.2s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6459684\ttest: 1.4418154\tbest: 1.4415429 (3248)\ttotal: 21.5s\tremaining: 1m 17s\n",
      "3300:\tlearn: 0.6369446\ttest: 1.4428185\tbest: 1.4415429 (3248)\ttotal: 21.9s\tremaining: 1m 17s\n",
      "3350:\tlearn: 0.6265027\ttest: 1.4423754\tbest: 1.4412767 (3336)\ttotal: 22.2s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.6152593\ttest: 1.4425962\tbest: 1.4412767 (3336)\ttotal: 22.5s\tremaining: 1m 16s\n",
      "3450:\tlearn: 0.6059229\ttest: 1.4423431\tbest: 1.4411853 (3425)\ttotal: 22.9s\tremaining: 1m 16s\n",
      "3500:\tlearn: 0.5954904\ttest: 1.4429154\tbest: 1.4411853 (3425)\ttotal: 23.2s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5863382\ttest: 1.4426840\tbest: 1.4411853 (3425)\ttotal: 23.5s\tremaining: 1m 15s\n",
      "3600:\tlearn: 0.5777139\ttest: 1.4400215\tbest: 1.4400215 (3600)\ttotal: 23.9s\tremaining: 1m 15s\n",
      "3650:\tlearn: 0.5682378\ttest: 1.4377064\tbest: 1.4374040 (3646)\ttotal: 24.2s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5596273\ttest: 1.4359915\tbest: 1.4354877 (3696)\ttotal: 24.5s\tremaining: 1m 14s\n",
      "3750:\tlearn: 0.5510053\ttest: 1.4347616\tbest: 1.4331081 (3725)\ttotal: 24.9s\tremaining: 1m 14s\n",
      "3800:\tlearn: 0.5419828\ttest: 1.4314671\tbest: 1.4314345 (3799)\ttotal: 25.2s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5346051\ttest: 1.4267662\tbest: 1.4266015 (3848)\ttotal: 25.5s\tremaining: 1m 13s\n",
      "3900:\tlearn: 0.5263328\ttest: 1.4238673\tbest: 1.4238673 (3900)\ttotal: 25.9s\tremaining: 1m 13s\n",
      "3950:\tlearn: 0.5183801\ttest: 1.4202531\tbest: 1.4200632 (3949)\ttotal: 26.2s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.5111625\ttest: 1.4160938\tbest: 1.4159669 (3998)\ttotal: 26.6s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.5033251\ttest: 1.4142532\tbest: 1.4142532 (4050)\ttotal: 27s\tremaining: 1m 12s\n",
      "4100:\tlearn: 0.4952241\ttest: 1.4114915\tbest: 1.4105826 (4095)\ttotal: 27.4s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4868367\ttest: 1.4087073\tbest: 1.4085929 (4146)\ttotal: 27.8s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4795728\ttest: 1.4060522\tbest: 1.4060190 (4199)\ttotal: 28.2s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4728825\ttest: 1.4022502\tbest: 1.4022466 (4241)\ttotal: 28.5s\tremaining: 1m 12s\n",
      "4300:\tlearn: 0.4666926\ttest: 1.3999471\tbest: 1.3997037 (4279)\ttotal: 28.9s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4593454\ttest: 1.3966736\tbest: 1.3966736 (4350)\ttotal: 29.2s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4526353\ttest: 1.3929251\tbest: 1.3928930 (4395)\ttotal: 29.6s\tremaining: 1m 11s\n",
      "4450:\tlearn: 0.4452992\ttest: 1.3916269\tbest: 1.3916269 (4450)\ttotal: 29.9s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4379032\ttest: 1.3872413\tbest: 1.3872413 (4500)\ttotal: 30.2s\tremaining: 1m 10s\n",
      "4550:\tlearn: 0.4308969\ttest: 1.3866370\tbest: 1.3864409 (4536)\ttotal: 30.6s\tremaining: 1m 10s\n",
      "4600:\tlearn: 0.4236636\ttest: 1.3862433\tbest: 1.3861175 (4596)\ttotal: 30.9s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4164612\ttest: 1.3836771\tbest: 1.3835913 (4649)\ttotal: 31.3s\tremaining: 1m 9s\n",
      "4700:\tlearn: 0.4089847\ttest: 1.3798458\tbest: 1.3796743 (4698)\ttotal: 31.6s\tremaining: 1m 9s\n",
      "4750:\tlearn: 0.4030717\ttest: 1.3780457\tbest: 1.3780457 (4750)\ttotal: 31.9s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.3977163\ttest: 1.3763860\tbest: 1.3761728 (4799)\ttotal: 32.3s\tremaining: 1m 8s\n",
      "4850:\tlearn: 0.3910788\ttest: 1.3722568\tbest: 1.3722568 (4850)\ttotal: 32.6s\tremaining: 1m 8s\n",
      "4900:\tlearn: 0.3840327\ttest: 1.3689962\tbest: 1.3686906 (4897)\ttotal: 32.9s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3784874\ttest: 1.3690087\tbest: 1.3686906 (4897)\ttotal: 33.3s\tremaining: 1m 7s\n",
      "5000:\tlearn: 0.3726759\ttest: 1.3682348\tbest: 1.3661298 (4990)\ttotal: 33.6s\tremaining: 1m 7s\n",
      "5050:\tlearn: 0.3669192\ttest: 1.3650739\tbest: 1.3650739 (5050)\ttotal: 33.9s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3613008\ttest: 1.3637541\tbest: 1.3634358 (5070)\ttotal: 34.3s\tremaining: 1m 6s\n",
      "5150:\tlearn: 0.3559819\ttest: 1.3628952\tbest: 1.3611945 (5135)\ttotal: 34.6s\tremaining: 1m 6s\n",
      "5200:\tlearn: 0.3514758\ttest: 1.3584871\tbest: 1.3582591 (5195)\ttotal: 34.9s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3459768\ttest: 1.3567736\tbest: 1.3562951 (5244)\ttotal: 35.2s\tremaining: 1m 5s\n",
      "5300:\tlearn: 0.3408449\ttest: 1.3560389\tbest: 1.3553277 (5274)\ttotal: 35.6s\tremaining: 1m 5s\n",
      "5350:\tlearn: 0.3356636\ttest: 1.3564975\tbest: 1.3553277 (5274)\ttotal: 35.9s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3304490\ttest: 1.3580357\tbest: 1.3553277 (5274)\ttotal: 36.2s\tremaining: 1m 4s\n",
      "5450:\tlearn: 0.3256445\ttest: 1.3555268\tbest: 1.3553277 (5274)\ttotal: 36.6s\tremaining: 1m 4s\n",
      "5500:\tlearn: 0.3207375\ttest: 1.3536168\tbest: 1.3536168 (5500)\ttotal: 36.9s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3156784\ttest: 1.3530471\tbest: 1.3524919 (5532)\ttotal: 37.2s\tremaining: 1m 3s\n",
      "5600:\tlearn: 0.3108814\ttest: 1.3519741\tbest: 1.3519741 (5600)\ttotal: 37.6s\tremaining: 1m 3s\n",
      "5650:\tlearn: 0.3061021\ttest: 1.3518578\tbest: 1.3513682 (5601)\ttotal: 37.9s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.3009989\ttest: 1.3529347\tbest: 1.3513682 (5601)\ttotal: 38.2s\tremaining: 1m 2s\n",
      "5750:\tlearn: 0.2958538\ttest: 1.3531020\tbest: 1.3513682 (5601)\ttotal: 38.6s\tremaining: 1m 2s\n",
      "5800:\tlearn: 0.2916801\ttest: 1.3494092\tbest: 1.3494092 (5800)\ttotal: 38.9s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2868168\ttest: 1.3475625\tbest: 1.3474329 (5849)\ttotal: 39.2s\tremaining: 1m 1s\n",
      "5900:\tlearn: 0.2822772\ttest: 1.3451493\tbest: 1.3447777 (5893)\ttotal: 39.6s\tremaining: 1m 1s\n",
      "5950:\tlearn: 0.2772854\ttest: 1.3456507\tbest: 1.3447777 (5893)\ttotal: 39.9s\tremaining: 1m\n",
      "6000:\tlearn: 0.2725629\ttest: 1.3453952\tbest: 1.3443181 (5975)\ttotal: 40.3s\tremaining: 1m\n",
      "6050:\tlearn: 0.2679736\ttest: 1.3447096\tbest: 1.3443181 (5975)\ttotal: 40.6s\tremaining: 1m\n",
      "6100:\tlearn: 0.2639511\ttest: 1.3416665\tbest: 1.3413542 (6099)\ttotal: 40.9s\tremaining: 59.7s\n",
      "6150:\tlearn: 0.2588906\ttest: 1.3399613\tbest: 1.3397808 (6148)\ttotal: 41.3s\tremaining: 59.4s\n",
      "6200:\tlearn: 0.2547596\ttest: 1.3397443\tbest: 1.3392424 (6174)\ttotal: 41.6s\tremaining: 59s\n",
      "6250:\tlearn: 0.2507043\ttest: 1.3386633\tbest: 1.3386633 (6250)\ttotal: 41.9s\tremaining: 58.7s\n",
      "6300:\tlearn: 0.2466815\ttest: 1.3370795\tbest: 1.3368561 (6297)\ttotal: 42.3s\tremaining: 58.4s\n",
      "6350:\tlearn: 0.2437427\ttest: 1.3371979\tbest: 1.3368561 (6297)\ttotal: 42.6s\tremaining: 58s\n",
      "6400:\tlearn: 0.2402587\ttest: 1.3339200\tbest: 1.3338713 (6399)\ttotal: 42.9s\tremaining: 57.7s\n",
      "6450:\tlearn: 0.2363271\ttest: 1.3333095\tbest: 1.3333095 (6450)\ttotal: 43.3s\tremaining: 57.3s\n",
      "6500:\tlearn: 0.2321395\ttest: 1.3321519\tbest: 1.3319250 (6486)\ttotal: 43.6s\tremaining: 57s\n",
      "6550:\tlearn: 0.2285532\ttest: 1.3302274\tbest: 1.3302274 (6550)\ttotal: 43.9s\tremaining: 56.7s\n",
      "6600:\tlearn: 0.2249363\ttest: 1.3283905\tbest: 1.3280709 (6594)\ttotal: 44.3s\tremaining: 56.3s\n",
      "6650:\tlearn: 0.2218520\ttest: 1.3287394\tbest: 1.3280702 (6632)\ttotal: 44.6s\tremaining: 56s\n",
      "6700:\tlearn: 0.2187433\ttest: 1.3266705\tbest: 1.3263146 (6695)\ttotal: 44.9s\tremaining: 55.6s\n",
      "6750:\tlearn: 0.2149706\ttest: 1.3264748\tbest: 1.3261377 (6718)\ttotal: 45.3s\tremaining: 55.3s\n",
      "6800:\tlearn: 0.2117173\ttest: 1.3272584\tbest: 1.3260701 (6777)\ttotal: 45.6s\tremaining: 55s\n",
      "6850:\tlearn: 0.2088324\ttest: 1.3269550\tbest: 1.3260701 (6777)\ttotal: 45.9s\tremaining: 54.6s\n",
      "6900:\tlearn: 0.2057554\ttest: 1.3263551\tbest: 1.3260701 (6777)\ttotal: 46.3s\tremaining: 54.3s\n",
      "6950:\tlearn: 0.2021260\ttest: 1.3261118\tbest: 1.3260539 (6949)\ttotal: 46.6s\tremaining: 53.9s\n",
      "7000:\tlearn: 0.1991160\ttest: 1.3258489\tbest: 1.3245692 (6979)\ttotal: 46.9s\tremaining: 53.6s\n",
      "7050:\tlearn: 0.1954161\ttest: 1.3252472\tbest: 1.3245692 (6979)\ttotal: 47.3s\tremaining: 53.3s\n",
      "7100:\tlearn: 0.1925010\ttest: 1.3252712\tbest: 1.3245692 (6979)\ttotal: 47.6s\tremaining: 52.9s\n",
      "7150:\tlearn: 0.1898055\ttest: 1.3253580\tbest: 1.3245692 (6979)\ttotal: 47.9s\tremaining: 52.6s\n",
      "7200:\tlearn: 0.1870488\ttest: 1.3239753\tbest: 1.3239753 (7200)\ttotal: 48.3s\tremaining: 52.3s\n",
      "7250:\tlearn: 0.1843702\ttest: 1.3228249\tbest: 1.3228249 (7250)\ttotal: 48.6s\tremaining: 51.9s\n",
      "7300:\tlearn: 0.1818003\ttest: 1.3224276\tbest: 1.3222042 (7282)\ttotal: 48.9s\tremaining: 51.6s\n",
      "7350:\tlearn: 0.1792283\ttest: 1.3228762\tbest: 1.3222042 (7282)\ttotal: 49.3s\tremaining: 51.3s\n",
      "7400:\tlearn: 0.1763022\ttest: 1.3221189\tbest: 1.3221189 (7400)\ttotal: 49.6s\tremaining: 50.9s\n",
      "7450:\tlearn: 0.1737189\ttest: 1.3226283\tbest: 1.3218323 (7407)\ttotal: 49.9s\tremaining: 50.6s\n",
      "7500:\tlearn: 0.1709003\ttest: 1.3219085\tbest: 1.3217583 (7489)\ttotal: 50.3s\tremaining: 50.3s\n",
      "7550:\tlearn: 0.1676899\ttest: 1.3201849\tbest: 1.3201070 (7549)\ttotal: 50.6s\tremaining: 49.9s\n",
      "7600:\tlearn: 0.1653288\ttest: 1.3183625\tbest: 1.3183625 (7600)\ttotal: 50.9s\tremaining: 49.6s\n",
      "7650:\tlearn: 0.1625257\ttest: 1.3183040\tbest: 1.3171973 (7617)\ttotal: 51.3s\tremaining: 49.3s\n",
      "7700:\tlearn: 0.1602734\ttest: 1.3178637\tbest: 1.3171973 (7617)\ttotal: 51.6s\tremaining: 48.9s\n",
      "7750:\tlearn: 0.1580987\ttest: 1.3169215\tbest: 1.3169215 (7750)\ttotal: 52s\tremaining: 48.6s\n",
      "7800:\tlearn: 0.1557844\ttest: 1.3161007\tbest: 1.3161007 (7800)\ttotal: 52.3s\tremaining: 48.3s\n",
      "7850:\tlearn: 0.1530083\ttest: 1.3149933\tbest: 1.3149933 (7850)\ttotal: 52.6s\tremaining: 47.9s\n",
      "7900:\tlearn: 0.1508743\ttest: 1.3133112\tbest: 1.3131782 (7897)\ttotal: 52.9s\tremaining: 47.6s\n",
      "7950:\tlearn: 0.1486810\ttest: 1.3110820\tbest: 1.3110820 (7950)\ttotal: 53.3s\tremaining: 47.2s\n",
      "8000:\tlearn: 0.1460330\ttest: 1.3121196\tbest: 1.3110614 (7953)\ttotal: 53.6s\tremaining: 46.9s\n",
      "8050:\tlearn: 0.1434468\ttest: 1.3118319\tbest: 1.3110614 (7953)\ttotal: 53.9s\tremaining: 46.6s\n",
      "8100:\tlearn: 0.1413196\ttest: 1.3104955\tbest: 1.3099382 (8087)\ttotal: 54.3s\tremaining: 46.2s\n",
      "8150:\tlearn: 0.1388604\ttest: 1.3097114\tbest: 1.3094165 (8119)\ttotal: 54.6s\tremaining: 45.9s\n",
      "8200:\tlearn: 0.1363309\ttest: 1.3096428\tbest: 1.3088120 (8177)\ttotal: 54.9s\tremaining: 45.6s\n",
      "8250:\tlearn: 0.1343584\ttest: 1.3091130\tbest: 1.3086082 (8235)\ttotal: 55.3s\tremaining: 45.2s\n",
      "8300:\tlearn: 0.1322989\ttest: 1.3074094\tbest: 1.3074027 (8298)\ttotal: 55.6s\tremaining: 44.9s\n",
      "8350:\tlearn: 0.1298509\ttest: 1.3060623\tbest: 1.3059414 (8342)\ttotal: 55.9s\tremaining: 44.5s\n",
      "8400:\tlearn: 0.1277013\ttest: 1.3066307\tbest: 1.3052365 (8355)\ttotal: 56.3s\tremaining: 44.2s\n",
      "8450:\tlearn: 0.1255951\ttest: 1.3064902\tbest: 1.3052365 (8355)\ttotal: 56.6s\tremaining: 43.9s\n",
      "8500:\tlearn: 0.1236282\ttest: 1.3070159\tbest: 1.3052365 (8355)\ttotal: 56.9s\tremaining: 43.5s\n",
      "8550:\tlearn: 0.1217758\ttest: 1.3074404\tbest: 1.3052365 (8355)\ttotal: 57.3s\tremaining: 43.2s\n",
      "8600:\tlearn: 0.1199427\ttest: 1.3063354\tbest: 1.3052365 (8355)\ttotal: 57.6s\tremaining: 42.9s\n",
      "8650:\tlearn: 0.1182803\ttest: 1.3055220\tbest: 1.3052365 (8355)\ttotal: 57.9s\tremaining: 42.5s\n",
      "8700:\tlearn: 0.1164728\ttest: 1.3042692\tbest: 1.3038248 (8682)\ttotal: 58.3s\tremaining: 42.2s\n",
      "8750:\tlearn: 0.1147922\ttest: 1.3029460\tbest: 1.3025001 (8722)\ttotal: 58.6s\tremaining: 41.9s\n",
      "8800:\tlearn: 0.1131227\ttest: 1.3011486\tbest: 1.3010552 (8791)\ttotal: 59s\tremaining: 41.5s\n",
      "8850:\tlearn: 0.1112359\ttest: 1.2988928\tbest: 1.2988928 (8850)\ttotal: 59.3s\tremaining: 41.2s\n",
      "8900:\tlearn: 0.1092103\ttest: 1.2984639\tbest: 1.2984639 (8900)\ttotal: 59.6s\tremaining: 40.8s\n",
      "8950:\tlearn: 0.1072804\ttest: 1.2970348\tbest: 1.2964170 (8943)\ttotal: 60s\tremaining: 40.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000:\tlearn: 0.1054712\ttest: 1.2969657\tbest: 1.2961683 (8993)\ttotal: 1m\tremaining: 40.2s\n",
      "9050:\tlearn: 0.1039835\ttest: 1.2969567\tbest: 1.2961683 (8993)\ttotal: 1m\tremaining: 39.8s\n",
      "9100:\tlearn: 0.1020676\ttest: 1.2964244\tbest: 1.2961683 (8993)\ttotal: 1m\tremaining: 39.5s\n",
      "9150:\tlearn: 0.1004379\ttest: 1.2955887\tbest: 1.2954199 (9136)\ttotal: 1m 1s\tremaining: 39.2s\n",
      "9200:\tlearn: 0.0987375\ttest: 1.2956990\tbest: 1.2951577 (9184)\ttotal: 1m 1s\tremaining: 38.8s\n",
      "9250:\tlearn: 0.0968817\ttest: 1.2947764\tbest: 1.2947764 (9250)\ttotal: 1m 1s\tremaining: 38.5s\n",
      "9300:\tlearn: 0.0955300\ttest: 1.2942550\tbest: 1.2942084 (9299)\ttotal: 1m 2s\tremaining: 38.2s\n",
      "9350:\tlearn: 0.0939061\ttest: 1.2925032\tbest: 1.2924642 (9348)\ttotal: 1m 2s\tremaining: 37.8s\n",
      "9400:\tlearn: 0.0925951\ttest: 1.2917780\tbest: 1.2916876 (9367)\ttotal: 1m 2s\tremaining: 37.5s\n",
      "9450:\tlearn: 0.0912544\ttest: 1.2909938\tbest: 1.2908565 (9449)\ttotal: 1m 3s\tremaining: 37.2s\n",
      "9500:\tlearn: 0.0897005\ttest: 1.2896907\tbest: 1.2896026 (9482)\ttotal: 1m 3s\tremaining: 36.8s\n",
      "9550:\tlearn: 0.0883914\ttest: 1.2893722\tbest: 1.2893722 (9550)\ttotal: 1m 3s\tremaining: 36.5s\n",
      "9600:\tlearn: 0.0868936\ttest: 1.2876759\tbest: 1.2874386 (9599)\ttotal: 1m 4s\tremaining: 36.2s\n",
      "9650:\tlearn: 0.0855028\ttest: 1.2871731\tbest: 1.2871407 (9642)\ttotal: 1m 4s\tremaining: 35.8s\n",
      "9700:\tlearn: 0.0839431\ttest: 1.2860439\tbest: 1.2855485 (9692)\ttotal: 1m 4s\tremaining: 35.5s\n",
      "9750:\tlearn: 0.0823469\ttest: 1.2856990\tbest: 1.2851694 (9721)\ttotal: 1m 5s\tremaining: 35.2s\n",
      "9800:\tlearn: 0.0811483\ttest: 1.2841575\tbest: 1.2841575 (9800)\ttotal: 1m 5s\tremaining: 34.8s\n",
      "9850:\tlearn: 0.0799047\ttest: 1.2815576\tbest: 1.2814808 (9842)\ttotal: 1m 6s\tremaining: 34.5s\n",
      "9900:\tlearn: 0.0785498\ttest: 1.2815055\tbest: 1.2813395 (9856)\ttotal: 1m 6s\tremaining: 34.2s\n",
      "9950:\tlearn: 0.0773963\ttest: 1.2822304\tbest: 1.2813197 (9903)\ttotal: 1m 6s\tremaining: 33.8s\n",
      "10000:\tlearn: 0.0761474\ttest: 1.2825046\tbest: 1.2813197 (9903)\ttotal: 1m 7s\tremaining: 33.5s\n",
      "10050:\tlearn: 0.0749497\ttest: 1.2828690\tbest: 1.2813197 (9903)\ttotal: 1m 7s\tremaining: 33.2s\n",
      "10100:\tlearn: 0.0738093\ttest: 1.2827218\tbest: 1.2813197 (9903)\ttotal: 1m 7s\tremaining: 32.8s\n",
      "10150:\tlearn: 0.0727174\ttest: 1.2813024\tbest: 1.2811580 (10148)\ttotal: 1m 8s\tremaining: 32.5s\n",
      "10200:\tlearn: 0.0715373\ttest: 1.2799439\tbest: 1.2799252 (10198)\ttotal: 1m 8s\tremaining: 32.2s\n",
      "10250:\tlearn: 0.0702837\ttest: 1.2803051\tbest: 1.2796144 (10206)\ttotal: 1m 8s\tremaining: 31.8s\n",
      "10300:\tlearn: 0.0691371\ttest: 1.2795482\tbest: 1.2794198 (10280)\ttotal: 1m 9s\tremaining: 31.5s\n",
      "10350:\tlearn: 0.0679995\ttest: 1.2795781\tbest: 1.2789313 (10314)\ttotal: 1m 9s\tremaining: 31.2s\n",
      "10400:\tlearn: 0.0670379\ttest: 1.2780875\tbest: 1.2779695 (10397)\ttotal: 1m 9s\tremaining: 30.8s\n",
      "10450:\tlearn: 0.0658701\ttest: 1.2782487\tbest: 1.2772880 (10413)\ttotal: 1m 10s\tremaining: 30.5s\n",
      "10500:\tlearn: 0.0649251\ttest: 1.2770484\tbest: 1.2770484 (10500)\ttotal: 1m 10s\tremaining: 30.2s\n",
      "10550:\tlearn: 0.0637524\ttest: 1.2779186\tbest: 1.2769467 (10506)\ttotal: 1m 10s\tremaining: 29.8s\n",
      "10600:\tlearn: 0.0626686\ttest: 1.2783676\tbest: 1.2769467 (10506)\ttotal: 1m 11s\tremaining: 29.5s\n",
      "10650:\tlearn: 0.0616318\ttest: 1.2775647\tbest: 1.2769467 (10506)\ttotal: 1m 11s\tremaining: 29.2s\n",
      "10700:\tlearn: 0.0605464\ttest: 1.2770455\tbest: 1.2769467 (10506)\ttotal: 1m 11s\tremaining: 28.8s\n",
      "10750:\tlearn: 0.0596393\ttest: 1.2757360\tbest: 1.2757360 (10750)\ttotal: 1m 12s\tremaining: 28.5s\n",
      "10800:\tlearn: 0.0587819\ttest: 1.2749677\tbest: 1.2747808 (10793)\ttotal: 1m 12s\tremaining: 28.1s\n",
      "10850:\tlearn: 0.0578377\ttest: 1.2756073\tbest: 1.2747808 (10793)\ttotal: 1m 12s\tremaining: 27.8s\n",
      "10900:\tlearn: 0.0569475\ttest: 1.2748174\tbest: 1.2745104 (10888)\ttotal: 1m 13s\tremaining: 27.5s\n",
      "10950:\tlearn: 0.0558525\ttest: 1.2744604\tbest: 1.2743039 (10930)\ttotal: 1m 13s\tremaining: 27.1s\n",
      "11000:\tlearn: 0.0549394\ttest: 1.2733776\tbest: 1.2733493 (10999)\ttotal: 1m 13s\tremaining: 26.8s\n",
      "11050:\tlearn: 0.0540261\ttest: 1.2718802\tbest: 1.2718802 (11050)\ttotal: 1m 14s\tremaining: 26.5s\n",
      "11100:\tlearn: 0.0531700\ttest: 1.2725067\tbest: 1.2718218 (11060)\ttotal: 1m 14s\tremaining: 26.1s\n",
      "11150:\tlearn: 0.0522754\ttest: 1.2721107\tbest: 1.2715123 (11128)\ttotal: 1m 14s\tremaining: 25.8s\n",
      "11200:\tlearn: 0.0515599\ttest: 1.2723490\tbest: 1.2715123 (11128)\ttotal: 1m 15s\tremaining: 25.5s\n",
      "11250:\tlearn: 0.0506588\ttest: 1.2711181\tbest: 1.2711072 (11244)\ttotal: 1m 15s\tremaining: 25.1s\n",
      "11300:\tlearn: 0.0498953\ttest: 1.2713850\tbest: 1.2706935 (11264)\ttotal: 1m 15s\tremaining: 24.8s\n",
      "11350:\tlearn: 0.0490964\ttest: 1.2712395\tbest: 1.2706935 (11264)\ttotal: 1m 16s\tremaining: 24.5s\n",
      "11400:\tlearn: 0.0485000\ttest: 1.2703787\tbest: 1.2698111 (11381)\ttotal: 1m 16s\tremaining: 24.1s\n",
      "11450:\tlearn: 0.0477300\ttest: 1.2702015\tbest: 1.2698111 (11381)\ttotal: 1m 16s\tremaining: 23.8s\n",
      "11500:\tlearn: 0.0469519\ttest: 1.2691549\tbest: 1.2691549 (11500)\ttotal: 1m 17s\tremaining: 23.5s\n",
      "11550:\tlearn: 0.0461993\ttest: 1.2687038\tbest: 1.2685528 (11543)\ttotal: 1m 17s\tremaining: 23.1s\n",
      "11600:\tlearn: 0.0454753\ttest: 1.2684883\tbest: 1.2684237 (11586)\ttotal: 1m 17s\tremaining: 22.8s\n",
      "11650:\tlearn: 0.0447941\ttest: 1.2679560\tbest: 1.2679287 (11646)\ttotal: 1m 18s\tremaining: 22.5s\n",
      "11700:\tlearn: 0.0441298\ttest: 1.2669071\tbest: 1.2669045 (11697)\ttotal: 1m 18s\tremaining: 22.1s\n",
      "11750:\tlearn: 0.0435030\ttest: 1.2674991\tbest: 1.2666003 (11718)\ttotal: 1m 18s\tremaining: 21.8s\n",
      "11800:\tlearn: 0.0430009\ttest: 1.2677792\tbest: 1.2666003 (11718)\ttotal: 1m 19s\tremaining: 21.5s\n",
      "11850:\tlearn: 0.0423662\ttest: 1.2680133\tbest: 1.2666003 (11718)\ttotal: 1m 19s\tremaining: 21.1s\n",
      "11900:\tlearn: 0.0417534\ttest: 1.2673145\tbest: 1.2666003 (11718)\ttotal: 1m 19s\tremaining: 20.8s\n",
      "11950:\tlearn: 0.0411359\ttest: 1.2680013\tbest: 1.2666003 (11718)\ttotal: 1m 20s\tremaining: 20.4s\n",
      "12000:\tlearn: 0.0404488\ttest: 1.2670341\tbest: 1.2666003 (11718)\ttotal: 1m 20s\tremaining: 20.1s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.266600318\n",
      "bestIteration = 11718\n",
      "\n",
      "Shrink model to first 11719 iterations.\n",
      "Скор для фолда(1) : 9.0 средний скор на префиксе = 9.0 это заняло = 81 сек.\n",
      "Фолд: 2\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.5890253\ttest: 3.6815244\tbest: 3.6815244 (0)\ttotal: 27.4ms\tremaining: 6m 50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7238555\ttest: 2.7110823\tbest: 2.7110823 (50)\ttotal: 358ms\tremaining: 1m 45s\n",
      "100:\tlearn: 2.2671636\ttest: 2.1929308\tbest: 2.1929308 (100)\ttotal: 691ms\tremaining: 1m 41s\n",
      "150:\tlearn: 2.0202560\ttest: 1.8978668\tbest: 1.8978668 (150)\ttotal: 1.02s\tremaining: 1m 40s\n",
      "200:\tlearn: 1.8609444\ttest: 1.7054856\tbest: 1.7054856 (200)\ttotal: 1.36s\tremaining: 1m 39s\n",
      "250:\tlearn: 1.7531560\ttest: 1.6042597\tbest: 1.6042597 (250)\ttotal: 1.69s\tremaining: 1m 39s\n",
      "300:\tlearn: 1.6711322\ttest: 1.5352535\tbest: 1.5352535 (300)\ttotal: 2.02s\tremaining: 1m 38s\n",
      "350:\tlearn: 1.6066261\ttest: 1.4858086\tbest: 1.4858086 (350)\ttotal: 2.36s\tremaining: 1m 38s\n",
      "400:\tlearn: 1.5530390\ttest: 1.4355300\tbest: 1.4355300 (400)\ttotal: 2.69s\tremaining: 1m 37s\n",
      "450:\tlearn: 1.5069925\ttest: 1.3967584\tbest: 1.3967584 (450)\ttotal: 3.02s\tremaining: 1m 37s\n",
      "500:\tlearn: 1.4704249\ttest: 1.3784919\tbest: 1.3784919 (500)\ttotal: 3.35s\tremaining: 1m 36s\n",
      "550:\tlearn: 1.4393310\ttest: 1.3524563\tbest: 1.3524563 (550)\ttotal: 3.67s\tremaining: 1m 36s\n",
      "600:\tlearn: 1.4136328\ttest: 1.3306881\tbest: 1.3306881 (600)\ttotal: 4s\tremaining: 1m 35s\n",
      "650:\tlearn: 1.3914539\ttest: 1.3205393\tbest: 1.3201633 (649)\ttotal: 4.33s\tremaining: 1m 35s\n",
      "700:\tlearn: 1.3714569\ttest: 1.3060182\tbest: 1.3060182 (700)\ttotal: 4.66s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3517155\ttest: 1.2926994\tbest: 1.2926994 (750)\ttotal: 4.98s\tremaining: 1m 34s\n",
      "800:\tlearn: 1.3327156\ttest: 1.2896893\tbest: 1.2873975 (789)\ttotal: 5.32s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.3133450\ttest: 1.2822009\tbest: 1.2822009 (850)\ttotal: 5.65s\tremaining: 1m 33s\n",
      "900:\tlearn: 1.2972370\ttest: 1.2792314\tbest: 1.2781162 (889)\ttotal: 5.97s\tremaining: 1m 33s\n",
      "950:\tlearn: 1.2801644\ttest: 1.2710969\tbest: 1.2695039 (945)\ttotal: 6.3s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2614192\ttest: 1.2639961\tbest: 1.2634137 (998)\ttotal: 6.63s\tremaining: 1m 32s\n",
      "1050:\tlearn: 1.2434245\ttest: 1.2545825\tbest: 1.2545202 (1047)\ttotal: 6.96s\tremaining: 1m 32s\n",
      "1100:\tlearn: 1.2258127\ttest: 1.2483855\tbest: 1.2474177 (1094)\ttotal: 7.29s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.2080821\ttest: 1.2414950\tbest: 1.2408477 (1141)\ttotal: 7.62s\tremaining: 1m 31s\n",
      "1200:\tlearn: 1.1894101\ttest: 1.2317213\tbest: 1.2317213 (1200)\ttotal: 7.95s\tremaining: 1m 31s\n",
      "1250:\tlearn: 1.1716519\ttest: 1.2260813\tbest: 1.2250372 (1249)\ttotal: 8.28s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1559395\ttest: 1.2192596\tbest: 1.2192596 (1300)\ttotal: 8.61s\tremaining: 1m 30s\n",
      "1350:\tlearn: 1.1388516\ttest: 1.2116263\tbest: 1.2116263 (1350)\ttotal: 8.95s\tremaining: 1m 30s\n",
      "1400:\tlearn: 1.1237033\ttest: 1.2043706\tbest: 1.2037898 (1398)\ttotal: 9.31s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.1064077\ttest: 1.1973302\tbest: 1.1973302 (1450)\ttotal: 9.64s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0921235\ttest: 1.1947892\tbest: 1.1927824 (1494)\ttotal: 9.97s\tremaining: 1m 29s\n",
      "1550:\tlearn: 1.0772023\ttest: 1.1904449\tbest: 1.1904449 (1550)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0621079\ttest: 1.1818566\tbest: 1.1818566 (1600)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1650:\tlearn: 1.0493811\ttest: 1.1781043\tbest: 1.1768576 (1646)\ttotal: 11s\tremaining: 1m 28s\n",
      "1700:\tlearn: 1.0337268\ttest: 1.1734395\tbest: 1.1734395 (1700)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 1.0190558\ttest: 1.1718523\tbest: 1.1718523 (1750)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1800:\tlearn: 1.0036038\ttest: 1.1684835\tbest: 1.1684801 (1799)\ttotal: 12s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9897714\ttest: 1.1665168\tbest: 1.1662174 (1815)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9763042\ttest: 1.1622257\tbest: 1.1619918 (1894)\ttotal: 12.6s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9617089\ttest: 1.1582770\tbest: 1.1582770 (1950)\ttotal: 13s\tremaining: 1m 26s\n",
      "2000:\tlearn: 0.9493612\ttest: 1.1547835\tbest: 1.1539955 (1998)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.9342405\ttest: 1.1487612\tbest: 1.1484911 (2045)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.9213466\ttest: 1.1454828\tbest: 1.1446334 (2096)\ttotal: 14s\tremaining: 1m 25s\n",
      "2150:\tlearn: 0.9092918\ttest: 1.1422055\tbest: 1.1420350 (2133)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8972937\ttest: 1.1373966\tbest: 1.1373403 (2184)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8849918\ttest: 1.1347892\tbest: 1.1343231 (2228)\ttotal: 15s\tremaining: 1m 24s\n",
      "2300:\tlearn: 0.8731142\ttest: 1.1310710\tbest: 1.1307471 (2296)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8598692\ttest: 1.1268036\tbest: 1.1264716 (2348)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8476314\ttest: 1.1250743\tbest: 1.1231708 (2390)\ttotal: 16s\tremaining: 1m 23s\n",
      "2450:\tlearn: 0.8334592\ttest: 1.1273310\tbest: 1.1231708 (2390)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.8221814\ttest: 1.1265855\tbest: 1.1231708 (2390)\ttotal: 16.6s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.8104180\ttest: 1.1221658\tbest: 1.1221658 (2550)\ttotal: 16.9s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.7980362\ttest: 1.1207510\tbest: 1.1206107 (2598)\ttotal: 17.3s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7863708\ttest: 1.1202434\tbest: 1.1193137 (2622)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7747923\ttest: 1.1193544\tbest: 1.1179522 (2689)\ttotal: 17.9s\tremaining: 1m 21s\n",
      "2750:\tlearn: 0.7623617\ttest: 1.1206079\tbest: 1.1179522 (2689)\ttotal: 18.3s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7502231\ttest: 1.1211113\tbest: 1.1179522 (2689)\ttotal: 18.6s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.7387404\ttest: 1.1161034\tbest: 1.1160874 (2849)\ttotal: 19s\tremaining: 1m 20s\n",
      "2900:\tlearn: 0.7279214\ttest: 1.1144263\tbest: 1.1139943 (2874)\ttotal: 19.3s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.7148578\ttest: 1.1129288\tbest: 1.1127148 (2928)\ttotal: 19.6s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.7051070\ttest: 1.1124934\tbest: 1.1116488 (2993)\ttotal: 20s\tremaining: 1m 19s\n",
      "3050:\tlearn: 0.6954969\ttest: 1.1124799\tbest: 1.1116488 (2993)\ttotal: 20.3s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6839960\ttest: 1.1112554\tbest: 1.1108368 (3099)\ttotal: 20.6s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6715604\ttest: 1.1106984\tbest: 1.1087035 (3127)\ttotal: 21s\tremaining: 1m 18s\n",
      "3200:\tlearn: 0.6585750\ttest: 1.1067578\tbest: 1.1067578 (3200)\ttotal: 21.3s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6495201\ttest: 1.1055385\tbest: 1.1052281 (3245)\ttotal: 21.6s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6399121\ttest: 1.1042843\tbest: 1.1041337 (3299)\ttotal: 22s\tremaining: 1m 17s\n",
      "3350:\tlearn: 0.6321113\ttest: 1.1010568\tbest: 1.1004601 (3345)\ttotal: 22.3s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.6228553\ttest: 1.1007440\tbest: 1.1003137 (3393)\ttotal: 22.6s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.6127122\ttest: 1.0997494\tbest: 1.0997494 (3450)\ttotal: 23s\tremaining: 1m 16s\n",
      "3500:\tlearn: 0.6037788\ttest: 1.0979332\tbest: 1.0978443 (3495)\ttotal: 23.3s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5929333\ttest: 1.0994503\tbest: 1.0970826 (3509)\ttotal: 23.6s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5844178\ttest: 1.0984660\tbest: 1.0970826 (3509)\ttotal: 24s\tremaining: 1m 15s\n",
      "3650:\tlearn: 0.5753165\ttest: 1.0973256\tbest: 1.0969521 (3620)\ttotal: 24.3s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5664847\ttest: 1.0972424\tbest: 1.0959493 (3665)\ttotal: 24.6s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5581767\ttest: 1.0978932\tbest: 1.0959493 (3665)\ttotal: 25s\tremaining: 1m 14s\n",
      "3800:\tlearn: 0.5505284\ttest: 1.0974229\tbest: 1.0959493 (3665)\ttotal: 25.3s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5404900\ttest: 1.0971924\tbest: 1.0959493 (3665)\ttotal: 25.7s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5326926\ttest: 1.0964482\tbest: 1.0957002 (3890)\ttotal: 26s\tremaining: 1m 13s\n",
      "3950:\tlearn: 0.5235069\ttest: 1.0946680\tbest: 1.0942775 (3946)\ttotal: 26.3s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.5157485\ttest: 1.0962904\tbest: 1.0942775 (3946)\ttotal: 26.7s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.5064863\ttest: 1.0965601\tbest: 1.0942775 (3946)\ttotal: 27s\tremaining: 1m 12s\n",
      "4100:\tlearn: 0.4977676\ttest: 1.0939949\tbest: 1.0939949 (4100)\ttotal: 27.3s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4899491\ttest: 1.0922414\tbest: 1.0922262 (4148)\ttotal: 27.7s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4817692\ttest: 1.0903673\tbest: 1.0902781 (4199)\ttotal: 28s\tremaining: 1m 11s\n",
      "4250:\tlearn: 0.4749481\ttest: 1.0902310\tbest: 1.0892192 (4229)\ttotal: 28.3s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4673402\ttest: 1.0881864\tbest: 1.0881864 (4300)\ttotal: 28.7s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4595905\ttest: 1.0887773\tbest: 1.0872452 (4313)\ttotal: 29s\tremaining: 1m 10s\n",
      "4400:\tlearn: 0.4517589\ttest: 1.0882760\tbest: 1.0872452 (4313)\ttotal: 29.3s\tremaining: 1m 10s\n",
      "4450:\tlearn: 0.4445462\ttest: 1.0899509\tbest: 1.0872452 (4313)\ttotal: 29.7s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4381817\ttest: 1.0910448\tbest: 1.0872452 (4313)\ttotal: 30s\tremaining: 1m 9s\n",
      "4550:\tlearn: 0.4305024\ttest: 1.0899067\tbest: 1.0872452 (4313)\ttotal: 30.3s\tremaining: 1m 9s\n",
      "4600:\tlearn: 0.4233260\ttest: 1.0901454\tbest: 1.0872452 (4313)\ttotal: 30.7s\tremaining: 1m 9s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.08724516\n",
      "bestIteration = 4313\n",
      "\n",
      "Shrink model to first 4314 iterations.\n",
      "Скор для фолда(2) : 9.0 средний скор на префиксе = 9.0 это заняло = 31 сек.\n",
      "Фолд: 3\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.6256011\ttest: 3.6210549\tbest: 3.6210549 (0)\ttotal: 28.3ms\tremaining: 7m 4s\n",
      "50:\tlearn: 2.7523354\ttest: 2.8708765\tbest: 2.8708765 (50)\ttotal: 363ms\tremaining: 1m 46s\n",
      "100:\tlearn: 2.2892771\ttest: 2.4170456\tbest: 2.4170456 (100)\ttotal: 700ms\tremaining: 1m 43s\n",
      "150:\tlearn: 2.0262652\ttest: 2.1686851\tbest: 2.1686851 (150)\ttotal: 1.03s\tremaining: 1m 41s\n",
      "200:\tlearn: 1.8663964\ttest: 2.0149665\tbest: 2.0149665 (200)\ttotal: 1.36s\tremaining: 1m 40s\n",
      "250:\tlearn: 1.7560840\ttest: 1.9024597\tbest: 1.9024597 (250)\ttotal: 1.71s\tremaining: 1m 40s\n",
      "300:\tlearn: 1.6777082\ttest: 1.8189402\tbest: 1.8189402 (300)\ttotal: 2.04s\tremaining: 1m 39s\n",
      "350:\tlearn: 1.6104607\ttest: 1.7460066\tbest: 1.7460066 (350)\ttotal: 2.37s\tremaining: 1m 38s\n",
      "400:\tlearn: 1.5600202\ttest: 1.6969094\tbest: 1.6969094 (400)\ttotal: 2.7s\tremaining: 1m 38s\n",
      "450:\tlearn: 1.5181787\ttest: 1.6517918\tbest: 1.6517918 (450)\ttotal: 3.03s\tremaining: 1m 37s\n",
      "500:\tlearn: 1.4822111\ttest: 1.6198996\tbest: 1.6198996 (500)\ttotal: 3.36s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4509045\ttest: 1.5888139\tbest: 1.5888139 (550)\ttotal: 3.69s\tremaining: 1m 36s\n",
      "600:\tlearn: 1.4239937\ttest: 1.5712008\tbest: 1.5710809 (599)\ttotal: 4.02s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3978181\ttest: 1.5569581\tbest: 1.5569581 (650)\ttotal: 4.35s\tremaining: 1m 35s\n",
      "700:\tlearn: 1.3739226\ttest: 1.5499295\tbest: 1.5495233 (680)\ttotal: 4.68s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3509289\ttest: 1.5433013\tbest: 1.5426976 (717)\ttotal: 5.01s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.3294027\ttest: 1.5355847\tbest: 1.5355847 (800)\ttotal: 5.34s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.3115297\ttest: 1.5248773\tbest: 1.5248773 (850)\ttotal: 5.68s\tremaining: 1m 34s\n",
      "900:\tlearn: 1.2920587\ttest: 1.5153302\tbest: 1.5153302 (900)\ttotal: 6s\tremaining: 1m 33s\n",
      "950:\tlearn: 1.2724727\ttest: 1.5126946\tbest: 1.5110202 (938)\ttotal: 6.33s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2550633\ttest: 1.5041661\tbest: 1.5041661 (1000)\ttotal: 6.67s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2345745\ttest: 1.4965313\tbest: 1.4954520 (1049)\ttotal: 7s\tremaining: 1m 32s\n",
      "1100:\tlearn: 1.2161251\ttest: 1.4898107\tbest: 1.4898107 (1100)\ttotal: 7.32s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.1986051\ttest: 1.4804780\tbest: 1.4804780 (1150)\ttotal: 7.66s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1809639\ttest: 1.4767095\tbest: 1.4762983 (1196)\ttotal: 8s\tremaining: 1m 31s\n",
      "1250:\tlearn: 1.1630989\ttest: 1.4781332\tbest: 1.4747404 (1217)\ttotal: 8.33s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1453416\ttest: 1.4763344\tbest: 1.4747404 (1217)\ttotal: 8.66s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.1293791\ttest: 1.4713611\tbest: 1.4713611 (1350)\ttotal: 8.99s\tremaining: 1m 30s\n",
      "1400:\tlearn: 1.1128572\ttest: 1.4658112\tbest: 1.4658112 (1400)\ttotal: 9.32s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.0986944\ttest: 1.4659466\tbest: 1.4629795 (1441)\ttotal: 9.65s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0805362\ttest: 1.4631115\tbest: 1.4611848 (1486)\ttotal: 9.98s\tremaining: 1m 29s\n",
      "1550:\tlearn: 1.0648667\ttest: 1.4551561\tbest: 1.4543944 (1545)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0493614\ttest: 1.4460055\tbest: 1.4458026 (1598)\ttotal: 10.6s\tremaining: 1m 29s\n",
      "1650:\tlearn: 1.0367495\ttest: 1.4475511\tbest: 1.4438314 (1618)\ttotal: 11s\tremaining: 1m 28s\n",
      "1700:\tlearn: 1.0205266\ttest: 1.4475821\tbest: 1.4438314 (1618)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 1.0064540\ttest: 1.4461017\tbest: 1.4438314 (1618)\ttotal: 11.6s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9926378\ttest: 1.4371525\tbest: 1.4371525 (1800)\ttotal: 12s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9780920\ttest: 1.4389438\tbest: 1.4354052 (1821)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9629815\ttest: 1.4295035\tbest: 1.4295035 (1900)\ttotal: 12.6s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9498175\ttest: 1.4254411\tbest: 1.4254411 (1950)\ttotal: 13s\tremaining: 1m 26s\n",
      "2000:\tlearn: 0.9367813\ttest: 1.4240845\tbest: 1.4223158 (1989)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.9237021\ttest: 1.4203093\tbest: 1.4203093 (2050)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.9108225\ttest: 1.4203851\tbest: 1.4196177 (2096)\ttotal: 14s\tremaining: 1m 25s\n",
      "2150:\tlearn: 0.8983719\ttest: 1.4098836\tbest: 1.4098836 (2150)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8843745\ttest: 1.4053437\tbest: 1.4046048 (2199)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8705381\ttest: 1.4036861\tbest: 1.4036861 (2250)\ttotal: 15s\tremaining: 1m 24s\n",
      "2300:\tlearn: 0.8588785\ttest: 1.4003359\tbest: 1.4003359 (2300)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8457471\ttest: 1.3917170\tbest: 1.3917170 (2350)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8322136\ttest: 1.3821556\tbest: 1.3821556 (2400)\ttotal: 16s\tremaining: 1m 23s\n",
      "2450:\tlearn: 0.8184900\ttest: 1.3729720\tbest: 1.3729593 (2449)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.8064297\ttest: 1.3662307\tbest: 1.3662307 (2500)\ttotal: 16.6s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7951397\ttest: 1.3629376\tbest: 1.3629376 (2550)\ttotal: 17s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.7829463\ttest: 1.3575712\tbest: 1.3570619 (2591)\ttotal: 17.3s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7709705\ttest: 1.3521690\tbest: 1.3521690 (2650)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7593525\ttest: 1.3463729\tbest: 1.3463729 (2700)\ttotal: 18s\tremaining: 1m 21s\n",
      "2750:\tlearn: 0.7453246\ttest: 1.3400627\tbest: 1.3400627 (2750)\ttotal: 18.3s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7340007\ttest: 1.3380639\tbest: 1.3371440 (2775)\ttotal: 18.6s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.7238972\ttest: 1.3347776\tbest: 1.3347776 (2850)\ttotal: 19s\tremaining: 1m 20s\n",
      "2900:\tlearn: 0.7127709\ttest: 1.3296762\tbest: 1.3296762 (2900)\ttotal: 19.3s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.7020277\ttest: 1.3244171\tbest: 1.3244171 (2950)\ttotal: 19.7s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.6902645\ttest: 1.3191138\tbest: 1.3191138 (3000)\ttotal: 20s\tremaining: 1m 19s\n",
      "3050:\tlearn: 0.6801236\ttest: 1.3169909\tbest: 1.3159360 (3041)\ttotal: 20.3s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6687562\ttest: 1.3119683\tbest: 1.3118026 (3099)\ttotal: 20.7s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6579099\ttest: 1.3062744\tbest: 1.3060457 (3142)\ttotal: 21s\tremaining: 1m 18s\n",
      "3200:\tlearn: 0.6472470\ttest: 1.3005685\tbest: 1.3005212 (3198)\ttotal: 21.3s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6378214\ttest: 1.2975289\tbest: 1.2975265 (3248)\ttotal: 21.7s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6270305\ttest: 1.2923083\tbest: 1.2922806 (3299)\ttotal: 22s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.6169618\ttest: 1.2889321\tbest: 1.2885826 (3344)\ttotal: 22.4s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.6067415\ttest: 1.2860584\tbest: 1.2857200 (3397)\ttotal: 22.7s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.5974319\ttest: 1.2833117\tbest: 1.2833117 (3450)\ttotal: 23s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.5887660\ttest: 1.2799207\tbest: 1.2795482 (3498)\ttotal: 23.4s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5796788\ttest: 1.2746946\tbest: 1.2746946 (3550)\ttotal: 23.7s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5716035\ttest: 1.2705805\tbest: 1.2703403 (3599)\ttotal: 24.1s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.5631987\ttest: 1.2664835\tbest: 1.2664621 (3649)\ttotal: 24.4s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5538766\ttest: 1.2616279\tbest: 1.2613378 (3696)\ttotal: 24.7s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5445865\ttest: 1.2579076\tbest: 1.2578621 (3749)\ttotal: 25.1s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5368236\ttest: 1.2568350\tbest: 1.2566246 (3795)\ttotal: 25.4s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5297994\ttest: 1.2544931\tbest: 1.2544824 (3841)\ttotal: 25.8s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5216679\ttest: 1.2510844\tbest: 1.2510844 (3900)\ttotal: 26.1s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.5126275\ttest: 1.2476283\tbest: 1.2474167 (3946)\ttotal: 26.4s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.5055975\ttest: 1.2432132\tbest: 1.2432132 (4000)\ttotal: 26.8s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.4974513\ttest: 1.2426087\tbest: 1.2419897 (4046)\ttotal: 27.1s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.4893578\ttest: 1.2372718\tbest: 1.2372061 (4099)\ttotal: 27.4s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4808925\ttest: 1.2320984\tbest: 1.2320984 (4150)\ttotal: 27.8s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4735826\ttest: 1.2296644\tbest: 1.2295896 (4198)\ttotal: 28.1s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4663399\ttest: 1.2249798\tbest: 1.2249798 (4250)\ttotal: 28.4s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4592050\ttest: 1.2213000\tbest: 1.2212956 (4299)\ttotal: 28.8s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4505429\ttest: 1.2184194\tbest: 1.2184115 (4349)\ttotal: 29.1s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4434908\ttest: 1.2157597\tbest: 1.2157597 (4400)\ttotal: 29.5s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4450:\tlearn: 0.4362457\ttest: 1.2130223\tbest: 1.2130014 (4449)\ttotal: 29.8s\tremaining: 1m 10s\n",
      "4500:\tlearn: 0.4304455\ttest: 1.2099754\tbest: 1.2099754 (4500)\ttotal: 30.1s\tremaining: 1m 10s\n",
      "4550:\tlearn: 0.4244223\ttest: 1.2069272\tbest: 1.2063959 (4548)\ttotal: 30.5s\tremaining: 1m 9s\n",
      "4600:\tlearn: 0.4184239\ttest: 1.2051494\tbest: 1.2051156 (4598)\ttotal: 30.8s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4118368\ttest: 1.2009928\tbest: 1.2009928 (4650)\ttotal: 31.1s\tremaining: 1m 9s\n",
      "4700:\tlearn: 0.4056608\ttest: 1.1980102\tbest: 1.1979699 (4697)\ttotal: 31.5s\tremaining: 1m 8s\n",
      "4750:\tlearn: 0.3998948\ttest: 1.1944985\tbest: 1.1941230 (4747)\ttotal: 31.8s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.3941951\ttest: 1.1937301\tbest: 1.1935954 (4769)\ttotal: 32.2s\tremaining: 1m 8s\n",
      "4850:\tlearn: 0.3875227\ttest: 1.1906866\tbest: 1.1906866 (4850)\ttotal: 32.5s\tremaining: 1m 7s\n",
      "4900:\tlearn: 0.3817754\ttest: 1.1879969\tbest: 1.1873304 (4898)\ttotal: 32.8s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3757611\ttest: 1.1834788\tbest: 1.1834409 (4948)\ttotal: 33.2s\tremaining: 1m 7s\n",
      "5000:\tlearn: 0.3700815\ttest: 1.1833469\tbest: 1.1828899 (4992)\ttotal: 33.5s\tremaining: 1m 6s\n",
      "5050:\tlearn: 0.3648681\ttest: 1.1813719\tbest: 1.1813719 (5050)\ttotal: 33.8s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3590946\ttest: 1.1782015\tbest: 1.1782015 (5100)\ttotal: 34.2s\tremaining: 1m 6s\n",
      "5150:\tlearn: 0.3536871\ttest: 1.1770468\tbest: 1.1766895 (5147)\ttotal: 34.5s\tremaining: 1m 5s\n",
      "5200:\tlearn: 0.3480682\ttest: 1.1768078\tbest: 1.1761116 (5172)\ttotal: 34.8s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3430988\ttest: 1.1743239\tbest: 1.1742267 (5236)\ttotal: 35.2s\tremaining: 1m 5s\n",
      "5300:\tlearn: 0.3380230\ttest: 1.1733350\tbest: 1.1730961 (5287)\ttotal: 35.5s\tremaining: 1m 4s\n",
      "5350:\tlearn: 0.3330724\ttest: 1.1726862\tbest: 1.1725498 (5348)\ttotal: 35.8s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3281374\ttest: 1.1704089\tbest: 1.1702573 (5392)\ttotal: 36.2s\tremaining: 1m 4s\n",
      "5450:\tlearn: 0.3223849\ttest: 1.1700004\tbest: 1.1690439 (5430)\ttotal: 36.5s\tremaining: 1m 3s\n",
      "5500:\tlearn: 0.3173575\ttest: 1.1696521\tbest: 1.1690362 (5469)\ttotal: 36.8s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3121091\ttest: 1.1693832\tbest: 1.1686254 (5533)\ttotal: 37.2s\tremaining: 1m 3s\n",
      "5600:\tlearn: 0.3077958\ttest: 1.1689123\tbest: 1.1685305 (5586)\ttotal: 37.5s\tremaining: 1m 2s\n",
      "5650:\tlearn: 0.3031143\ttest: 1.1670274\tbest: 1.1669618 (5649)\ttotal: 37.8s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.2982426\ttest: 1.1652514\tbest: 1.1652514 (5700)\ttotal: 38.2s\tremaining: 1m 2s\n",
      "5750:\tlearn: 0.2937950\ttest: 1.1642437\tbest: 1.1641553 (5748)\ttotal: 38.5s\tremaining: 1m 1s\n",
      "5800:\tlearn: 0.2891481\ttest: 1.1625533\tbest: 1.1625015 (5798)\ttotal: 38.8s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2842738\ttest: 1.1594851\tbest: 1.1594851 (5850)\ttotal: 39.2s\tremaining: 1m 1s\n",
      "5900:\tlearn: 0.2797259\ttest: 1.1580584\tbest: 1.1574466 (5888)\ttotal: 39.5s\tremaining: 1m\n",
      "5950:\tlearn: 0.2757631\ttest: 1.1572683\tbest: 1.1572519 (5948)\ttotal: 39.8s\tremaining: 1m\n",
      "6000:\tlearn: 0.2717020\ttest: 1.1564277\tbest: 1.1560045 (5970)\ttotal: 40.2s\tremaining: 1m\n",
      "6050:\tlearn: 0.2680974\ttest: 1.1547218\tbest: 1.1547218 (6050)\ttotal: 40.5s\tremaining: 59.9s\n",
      "6100:\tlearn: 0.2636742\ttest: 1.1537599\tbest: 1.1537021 (6098)\ttotal: 40.8s\tremaining: 59.6s\n",
      "6150:\tlearn: 0.2598017\ttest: 1.1529195\tbest: 1.1526392 (6142)\ttotal: 41.2s\tremaining: 59.2s\n",
      "6200:\tlearn: 0.2558544\ttest: 1.1519556\tbest: 1.1519556 (6200)\ttotal: 41.5s\tremaining: 58.9s\n",
      "6250:\tlearn: 0.2517327\ttest: 1.1503605\tbest: 1.1503360 (6242)\ttotal: 41.8s\tremaining: 58.6s\n",
      "6300:\tlearn: 0.2479653\ttest: 1.1478747\tbest: 1.1478317 (6298)\ttotal: 42.2s\tremaining: 58.2s\n",
      "6350:\tlearn: 0.2445390\ttest: 1.1452590\tbest: 1.1452025 (6345)\ttotal: 42.5s\tremaining: 57.9s\n",
      "6400:\tlearn: 0.2412369\ttest: 1.1449356\tbest: 1.1447731 (6398)\ttotal: 42.8s\tremaining: 57.6s\n",
      "6450:\tlearn: 0.2374586\ttest: 1.1431704\tbest: 1.1430359 (6448)\ttotal: 43.2s\tremaining: 57.2s\n",
      "6500:\tlearn: 0.2343046\ttest: 1.1418203\tbest: 1.1417958 (6498)\ttotal: 43.5s\tremaining: 56.9s\n",
      "6550:\tlearn: 0.2311001\ttest: 1.1408883\tbest: 1.1405303 (6544)\ttotal: 43.9s\tremaining: 56.6s\n",
      "6600:\tlearn: 0.2280715\ttest: 1.1394690\tbest: 1.1393288 (6589)\ttotal: 44.2s\tremaining: 56.2s\n",
      "6650:\tlearn: 0.2248315\ttest: 1.1360950\tbest: 1.1360950 (6650)\ttotal: 44.5s\tremaining: 55.9s\n",
      "6700:\tlearn: 0.2218797\ttest: 1.1345599\tbest: 1.1345326 (6698)\ttotal: 44.9s\tremaining: 55.6s\n",
      "6750:\tlearn: 0.2189423\ttest: 1.1332815\tbest: 1.1331975 (6747)\ttotal: 45.2s\tremaining: 55.2s\n",
      "6800:\tlearn: 0.2148137\ttest: 1.1313082\tbest: 1.1313082 (6800)\ttotal: 45.5s\tremaining: 54.9s\n",
      "6850:\tlearn: 0.2118449\ttest: 1.1291860\tbest: 1.1291676 (6849)\ttotal: 45.9s\tremaining: 54.6s\n",
      "6900:\tlearn: 0.2090935\ttest: 1.1275206\tbest: 1.1274234 (6888)\ttotal: 46.2s\tremaining: 54.2s\n",
      "6950:\tlearn: 0.2062202\ttest: 1.1264512\tbest: 1.1263719 (6940)\ttotal: 46.5s\tremaining: 53.9s\n",
      "7000:\tlearn: 0.2033397\ttest: 1.1257552\tbest: 1.1255272 (6997)\ttotal: 46.9s\tremaining: 53.6s\n",
      "7050:\tlearn: 0.2008270\ttest: 1.1239481\tbest: 1.1236211 (7033)\ttotal: 47.2s\tremaining: 53.2s\n",
      "7100:\tlearn: 0.1978837\ttest: 1.1205894\tbest: 1.1205894 (7100)\ttotal: 47.5s\tremaining: 52.9s\n",
      "7150:\tlearn: 0.1949693\ttest: 1.1194084\tbest: 1.1191953 (7147)\ttotal: 47.9s\tremaining: 52.6s\n",
      "7200:\tlearn: 0.1922137\ttest: 1.1179241\tbest: 1.1177001 (7194)\ttotal: 48.2s\tremaining: 52.2s\n",
      "7250:\tlearn: 0.1899399\ttest: 1.1165798\tbest: 1.1165705 (7237)\ttotal: 48.6s\tremaining: 51.9s\n",
      "7300:\tlearn: 0.1871221\ttest: 1.1149910\tbest: 1.1144662 (7286)\ttotal: 48.9s\tremaining: 51.6s\n",
      "7350:\tlearn: 0.1846576\ttest: 1.1145435\tbest: 1.1139867 (7325)\ttotal: 49.2s\tremaining: 51.2s\n",
      "7400:\tlearn: 0.1819127\ttest: 1.1142995\tbest: 1.1139867 (7325)\ttotal: 49.6s\tremaining: 50.9s\n",
      "7450:\tlearn: 0.1786572\ttest: 1.1136633\tbest: 1.1133470 (7439)\ttotal: 49.9s\tremaining: 50.6s\n",
      "7500:\tlearn: 0.1761444\ttest: 1.1116538\tbest: 1.1116426 (7497)\ttotal: 50.2s\tremaining: 50.2s\n",
      "7550:\tlearn: 0.1734198\ttest: 1.1105742\tbest: 1.1105693 (7549)\ttotal: 50.6s\tremaining: 49.9s\n",
      "7600:\tlearn: 0.1709271\ttest: 1.1103312\tbest: 1.1101363 (7558)\ttotal: 50.9s\tremaining: 49.6s\n",
      "7650:\tlearn: 0.1682863\ttest: 1.1095997\tbest: 1.1095997 (7650)\ttotal: 51.2s\tremaining: 49.2s\n",
      "7700:\tlearn: 0.1655265\ttest: 1.1088995\tbest: 1.1086599 (7693)\ttotal: 51.6s\tremaining: 48.9s\n",
      "7750:\tlearn: 0.1628662\ttest: 1.1080108\tbest: 1.1078687 (7740)\ttotal: 51.9s\tremaining: 48.5s\n",
      "7800:\tlearn: 0.1603968\ttest: 1.1075060\tbest: 1.1071495 (7798)\ttotal: 52.2s\tremaining: 48.2s\n",
      "7850:\tlearn: 0.1582221\ttest: 1.1061011\tbest: 1.1059341 (7847)\ttotal: 52.6s\tremaining: 47.9s\n",
      "7900:\tlearn: 0.1556901\ttest: 1.1042953\tbest: 1.1042603 (7899)\ttotal: 52.9s\tremaining: 47.5s\n",
      "7950:\tlearn: 0.1529311\ttest: 1.1045044\tbest: 1.1036660 (7916)\ttotal: 53.3s\tremaining: 47.2s\n",
      "8000:\tlearn: 0.1504363\ttest: 1.1025629\tbest: 1.1025087 (7999)\ttotal: 53.6s\tremaining: 46.9s\n",
      "8050:\tlearn: 0.1484247\ttest: 1.1026746\tbest: 1.1019492 (8027)\ttotal: 53.9s\tremaining: 46.5s\n",
      "8100:\tlearn: 0.1463748\ttest: 1.1011677\tbest: 1.1006308 (8094)\ttotal: 54.3s\tremaining: 46.2s\n",
      "8150:\tlearn: 0.1443370\ttest: 1.1007307\tbest: 1.1005751 (8117)\ttotal: 54.6s\tremaining: 45.9s\n",
      "8200:\tlearn: 0.1423309\ttest: 1.1000372\tbest: 1.1000166 (8199)\ttotal: 54.9s\tremaining: 45.5s\n",
      "8250:\tlearn: 0.1399303\ttest: 1.0987629\tbest: 1.0987543 (8249)\ttotal: 55.3s\tremaining: 45.2s\n",
      "8300:\tlearn: 0.1379878\ttest: 1.0971357\tbest: 1.0967917 (8293)\ttotal: 55.6s\tremaining: 44.9s\n",
      "8350:\tlearn: 0.1359550\ttest: 1.0957686\tbest: 1.0950872 (8344)\ttotal: 55.9s\tremaining: 44.5s\n",
      "8400:\tlearn: 0.1339375\ttest: 1.0948245\tbest: 1.0948245 (8400)\ttotal: 56.3s\tremaining: 44.2s\n",
      "8450:\tlearn: 0.1317755\ttest: 1.0931591\tbest: 1.0931591 (8450)\ttotal: 56.6s\tremaining: 43.9s\n",
      "8500:\tlearn: 0.1298737\ttest: 1.0930690\tbest: 1.0928295 (8460)\ttotal: 56.9s\tremaining: 43.5s\n",
      "8550:\tlearn: 0.1283016\ttest: 1.0920638\tbest: 1.0919000 (8548)\ttotal: 57.3s\tremaining: 43.2s\n",
      "8600:\tlearn: 0.1268276\ttest: 1.0917555\tbest: 1.0916619 (8598)\ttotal: 57.6s\tremaining: 42.9s\n",
      "8650:\tlearn: 0.1248621\ttest: 1.0919171\tbest: 1.0916553 (8644)\ttotal: 57.9s\tremaining: 42.5s\n",
      "8700:\tlearn: 0.1228884\ttest: 1.0914306\tbest: 1.0914158 (8698)\ttotal: 58.3s\tremaining: 42.2s\n",
      "8750:\tlearn: 0.1209174\ttest: 1.0906996\tbest: 1.0905087 (8745)\ttotal: 58.6s\tremaining: 41.9s\n",
      "8800:\tlearn: 0.1190304\ttest: 1.0897576\tbest: 1.0896867 (8799)\ttotal: 59s\tremaining: 41.5s\n",
      "8850:\tlearn: 0.1170904\ttest: 1.0889907\tbest: 1.0889361 (8849)\ttotal: 59.3s\tremaining: 41.2s\n",
      "8900:\tlearn: 0.1153742\ttest: 1.0881534\tbest: 1.0881408 (8893)\ttotal: 59.6s\tremaining: 40.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8950:\tlearn: 0.1138345\ttest: 1.0863556\tbest: 1.0862235 (8925)\ttotal: 60s\tremaining: 40.5s\n",
      "9000:\tlearn: 0.1124577\ttest: 1.0856772\tbest: 1.0854374 (8979)\ttotal: 1m\tremaining: 40.2s\n",
      "9050:\tlearn: 0.1109112\ttest: 1.0852693\tbest: 1.0849360 (9032)\ttotal: 1m\tremaining: 39.8s\n",
      "9100:\tlearn: 0.1091336\ttest: 1.0847906\tbest: 1.0843956 (9078)\ttotal: 1m\tremaining: 39.5s\n",
      "9150:\tlearn: 0.1071658\ttest: 1.0845452\tbest: 1.0842224 (9141)\ttotal: 1m 1s\tremaining: 39.2s\n",
      "9200:\tlearn: 0.1056167\ttest: 1.0849996\tbest: 1.0842224 (9141)\ttotal: 1m 1s\tremaining: 38.8s\n",
      "9250:\tlearn: 0.1039129\ttest: 1.0848289\tbest: 1.0842224 (9141)\ttotal: 1m 1s\tremaining: 38.5s\n",
      "9300:\tlearn: 0.1024348\ttest: 1.0850207\tbest: 1.0842224 (9141)\ttotal: 1m 2s\tremaining: 38.2s\n",
      "9350:\tlearn: 0.1009464\ttest: 1.0844014\tbest: 1.0842224 (9141)\ttotal: 1m 2s\tremaining: 37.8s\n",
      "9400:\tlearn: 0.0992707\ttest: 1.0836446\tbest: 1.0832419 (9379)\ttotal: 1m 2s\tremaining: 37.5s\n",
      "9450:\tlearn: 0.0979074\ttest: 1.0835989\tbest: 1.0829753 (9409)\ttotal: 1m 3s\tremaining: 37.2s\n",
      "9500:\tlearn: 0.0963807\ttest: 1.0835430\tbest: 1.0829753 (9409)\ttotal: 1m 3s\tremaining: 36.8s\n",
      "9550:\tlearn: 0.0950716\ttest: 1.0823915\tbest: 1.0823915 (9550)\ttotal: 1m 3s\tremaining: 36.5s\n",
      "9600:\tlearn: 0.0938730\ttest: 1.0825200\tbest: 1.0823692 (9551)\ttotal: 1m 4s\tremaining: 36.2s\n",
      "9650:\tlearn: 0.0927158\ttest: 1.0818016\tbest: 1.0817721 (9648)\ttotal: 1m 4s\tremaining: 35.8s\n",
      "9700:\tlearn: 0.0913197\ttest: 1.0818157\tbest: 1.0817282 (9695)\ttotal: 1m 5s\tremaining: 35.5s\n",
      "9750:\tlearn: 0.0897670\ttest: 1.0817147\tbest: 1.0813263 (9732)\ttotal: 1m 5s\tremaining: 35.2s\n",
      "9800:\tlearn: 0.0884179\ttest: 1.0816622\tbest: 1.0813263 (9732)\ttotal: 1m 5s\tremaining: 34.8s\n",
      "9850:\tlearn: 0.0872941\ttest: 1.0813560\tbest: 1.0811433 (9848)\ttotal: 1m 6s\tremaining: 34.5s\n",
      "9900:\tlearn: 0.0860951\ttest: 1.0817641\tbest: 1.0811433 (9848)\ttotal: 1m 6s\tremaining: 34.2s\n",
      "9950:\tlearn: 0.0847253\ttest: 1.0810026\tbest: 1.0809874 (9935)\ttotal: 1m 6s\tremaining: 33.8s\n",
      "10000:\tlearn: 0.0833324\ttest: 1.0808568\tbest: 1.0804241 (9985)\ttotal: 1m 7s\tremaining: 33.5s\n",
      "10050:\tlearn: 0.0821523\ttest: 1.0805400\tbest: 1.0799929 (10012)\ttotal: 1m 7s\tremaining: 33.2s\n",
      "10100:\tlearn: 0.0807988\ttest: 1.0797004\tbest: 1.0795200 (10081)\ttotal: 1m 7s\tremaining: 32.8s\n",
      "10150:\tlearn: 0.0797890\ttest: 1.0785846\tbest: 1.0785304 (10148)\ttotal: 1m 8s\tremaining: 32.5s\n",
      "10200:\tlearn: 0.0785460\ttest: 1.0784816\tbest: 1.0784107 (10199)\ttotal: 1m 8s\tremaining: 32.2s\n",
      "10250:\tlearn: 0.0772877\ttest: 1.0779426\tbest: 1.0777966 (10223)\ttotal: 1m 8s\tremaining: 31.8s\n",
      "10300:\tlearn: 0.0760081\ttest: 1.0786781\tbest: 1.0777966 (10223)\ttotal: 1m 9s\tremaining: 31.5s\n",
      "10350:\tlearn: 0.0748052\ttest: 1.0784213\tbest: 1.0777966 (10223)\ttotal: 1m 9s\tremaining: 31.1s\n",
      "10400:\tlearn: 0.0736148\ttest: 1.0773981\tbest: 1.0772353 (10397)\ttotal: 1m 9s\tremaining: 30.8s\n",
      "10450:\tlearn: 0.0726603\ttest: 1.0770056\tbest: 1.0767714 (10433)\ttotal: 1m 10s\tremaining: 30.5s\n",
      "10500:\tlearn: 0.0713913\ttest: 1.0770082\tbest: 1.0767714 (10433)\ttotal: 1m 10s\tremaining: 30.1s\n",
      "10550:\tlearn: 0.0703221\ttest: 1.0751934\tbest: 1.0751568 (10547)\ttotal: 1m 10s\tremaining: 29.8s\n",
      "10600:\tlearn: 0.0691488\ttest: 1.0758428\tbest: 1.0751568 (10547)\ttotal: 1m 11s\tremaining: 29.5s\n",
      "10650:\tlearn: 0.0680370\ttest: 1.0753610\tbest: 1.0751568 (10547)\ttotal: 1m 11s\tremaining: 29.1s\n",
      "10700:\tlearn: 0.0671484\ttest: 1.0749571\tbest: 1.0743657 (10680)\ttotal: 1m 11s\tremaining: 28.8s\n",
      "10750:\tlearn: 0.0661545\ttest: 1.0740681\tbest: 1.0740681 (10750)\ttotal: 1m 12s\tremaining: 28.5s\n",
      "10800:\tlearn: 0.0652169\ttest: 1.0736833\tbest: 1.0735802 (10777)\ttotal: 1m 12s\tremaining: 28.1s\n",
      "10850:\tlearn: 0.0641157\ttest: 1.0742792\tbest: 1.0735802 (10777)\ttotal: 1m 12s\tremaining: 27.8s\n",
      "10900:\tlearn: 0.0632005\ttest: 1.0749102\tbest: 1.0735802 (10777)\ttotal: 1m 13s\tremaining: 27.5s\n",
      "10950:\tlearn: 0.0620166\ttest: 1.0743092\tbest: 1.0735802 (10777)\ttotal: 1m 13s\tremaining: 27.1s\n",
      "11000:\tlearn: 0.0611101\ttest: 1.0734389\tbest: 1.0734389 (11000)\ttotal: 1m 13s\tremaining: 26.8s\n",
      "11050:\tlearn: 0.0602268\ttest: 1.0734988\tbest: 1.0734095 (11008)\ttotal: 1m 14s\tremaining: 26.5s\n",
      "11100:\tlearn: 0.0590012\ttest: 1.0731820\tbest: 1.0731820 (11100)\ttotal: 1m 14s\tremaining: 26.1s\n",
      "11150:\tlearn: 0.0582094\ttest: 1.0726175\tbest: 1.0722022 (11136)\ttotal: 1m 14s\tremaining: 25.8s\n",
      "11200:\tlearn: 0.0573619\ttest: 1.0717781\tbest: 1.0717781 (11200)\ttotal: 1m 15s\tremaining: 25.5s\n",
      "11250:\tlearn: 0.0564210\ttest: 1.0713899\tbest: 1.0713105 (11247)\ttotal: 1m 15s\tremaining: 25.1s\n",
      "11300:\tlearn: 0.0557050\ttest: 1.0716846\tbest: 1.0713105 (11247)\ttotal: 1m 15s\tremaining: 24.8s\n",
      "11350:\tlearn: 0.0549638\ttest: 1.0715460\tbest: 1.0711579 (11334)\ttotal: 1m 16s\tremaining: 24.4s\n",
      "11400:\tlearn: 0.0541464\ttest: 1.0715624\tbest: 1.0711579 (11334)\ttotal: 1m 16s\tremaining: 24.1s\n",
      "11450:\tlearn: 0.0532443\ttest: 1.0701793\tbest: 1.0701679 (11449)\ttotal: 1m 16s\tremaining: 23.8s\n",
      "11500:\tlearn: 0.0524090\ttest: 1.0701441\tbest: 1.0700075 (11490)\ttotal: 1m 17s\tremaining: 23.4s\n",
      "11550:\tlearn: 0.0516429\ttest: 1.0696692\tbest: 1.0696692 (11550)\ttotal: 1m 17s\tremaining: 23.1s\n",
      "11600:\tlearn: 0.0507109\ttest: 1.0702265\tbest: 1.0696685 (11551)\ttotal: 1m 17s\tremaining: 22.8s\n",
      "11650:\tlearn: 0.0498850\ttest: 1.0699929\tbest: 1.0696685 (11551)\ttotal: 1m 18s\tremaining: 22.4s\n",
      "11700:\tlearn: 0.0491960\ttest: 1.0703513\tbest: 1.0696685 (11551)\ttotal: 1m 18s\tremaining: 22.1s\n",
      "11750:\tlearn: 0.0484793\ttest: 1.0711345\tbest: 1.0696685 (11551)\ttotal: 1m 18s\tremaining: 21.8s\n",
      "11800:\tlearn: 0.0477069\ttest: 1.0717608\tbest: 1.0696685 (11551)\ttotal: 1m 19s\tremaining: 21.4s\n",
      "11850:\tlearn: 0.0469537\ttest: 1.0716639\tbest: 1.0696685 (11551)\ttotal: 1m 19s\tremaining: 21.1s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.069668472\n",
      "bestIteration = 11551\n",
      "\n",
      "Shrink model to first 11552 iterations.\n",
      "Скор для фолда(3) : 9.0 средний скор на префиксе = 9.0 это заняло = 80 сек.\n",
      "Фолд: 4\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.6063421\ttest: 3.7375831\tbest: 3.7375831 (0)\ttotal: 28ms\tremaining: 7m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7265552\ttest: 2.8462750\tbest: 2.8462750 (50)\ttotal: 366ms\tremaining: 1m 47s\n",
      "100:\tlearn: 2.2616274\ttest: 2.5051033\tbest: 2.5051033 (100)\ttotal: 705ms\tremaining: 1m 44s\n",
      "150:\tlearn: 1.9997636\ttest: 2.2695295\tbest: 2.2695295 (150)\ttotal: 1.03s\tremaining: 1m 41s\n",
      "200:\tlearn: 1.8402794\ttest: 2.1292489\tbest: 2.1292489 (200)\ttotal: 1.37s\tremaining: 1m 40s\n",
      "250:\tlearn: 1.7319078\ttest: 2.0236802\tbest: 2.0236802 (250)\ttotal: 1.74s\tremaining: 1m 42s\n",
      "300:\tlearn: 1.6536770\ttest: 1.9204305\tbest: 1.9204305 (300)\ttotal: 2.06s\tremaining: 1m 40s\n",
      "350:\tlearn: 1.5939136\ttest: 1.8399546\tbest: 1.8399546 (350)\ttotal: 2.4s\tremaining: 1m 40s\n",
      "400:\tlearn: 1.5469705\ttest: 1.7789989\tbest: 1.7789989 (400)\ttotal: 2.74s\tremaining: 1m 39s\n",
      "450:\tlearn: 1.5063410\ttest: 1.7359881\tbest: 1.7357969 (448)\ttotal: 3.07s\tremaining: 1m 39s\n",
      "500:\tlearn: 1.4706165\ttest: 1.6949221\tbest: 1.6949221 (500)\ttotal: 3.4s\tremaining: 1m 38s\n",
      "550:\tlearn: 1.4392800\ttest: 1.6490143\tbest: 1.6490143 (550)\ttotal: 3.74s\tremaining: 1m 38s\n",
      "600:\tlearn: 1.4109736\ttest: 1.6178751\tbest: 1.6178751 (600)\ttotal: 4.06s\tremaining: 1m 37s\n",
      "650:\tlearn: 1.3851620\ttest: 1.5989800\tbest: 1.5979433 (637)\ttotal: 4.39s\tremaining: 1m 36s\n",
      "700:\tlearn: 1.3623227\ttest: 1.5772501\tbest: 1.5772501 (700)\ttotal: 4.73s\tremaining: 1m 36s\n",
      "750:\tlearn: 1.3419784\ttest: 1.5599841\tbest: 1.5599841 (750)\ttotal: 5.06s\tremaining: 1m 36s\n",
      "800:\tlearn: 1.3214541\ttest: 1.5378104\tbest: 1.5378104 (800)\ttotal: 5.39s\tremaining: 1m 35s\n",
      "850:\tlearn: 1.2998190\ttest: 1.5170401\tbest: 1.5169568 (849)\ttotal: 5.72s\tremaining: 1m 35s\n",
      "900:\tlearn: 1.2789945\ttest: 1.4994733\tbest: 1.4994733 (900)\ttotal: 6.06s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2592221\ttest: 1.4847443\tbest: 1.4847443 (950)\ttotal: 6.39s\tremaining: 1m 34s\n",
      "1000:\tlearn: 1.2413839\ttest: 1.4731341\tbest: 1.4731341 (1000)\ttotal: 6.72s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2248223\ttest: 1.4631188\tbest: 1.4631025 (1048)\ttotal: 7.04s\tremaining: 1m 33s\n",
      "1100:\tlearn: 1.2072686\ttest: 1.4536198\tbest: 1.4536198 (1100)\ttotal: 7.37s\tremaining: 1m 33s\n",
      "1150:\tlearn: 1.1906907\ttest: 1.4498303\tbest: 1.4493243 (1146)\ttotal: 7.72s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1710002\ttest: 1.4438077\tbest: 1.4432577 (1196)\ttotal: 8.04s\tremaining: 1m 32s\n",
      "1250:\tlearn: 1.1514738\ttest: 1.4330592\tbest: 1.4328861 (1248)\ttotal: 8.37s\tremaining: 1m 32s\n",
      "1300:\tlearn: 1.1344347\ttest: 1.4264231\tbest: 1.4263107 (1294)\ttotal: 8.71s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.1193168\ttest: 1.4225873\tbest: 1.4225374 (1349)\ttotal: 9.03s\tremaining: 1m 31s\n",
      "1400:\tlearn: 1.1032833\ttest: 1.4217705\tbest: 1.4208707 (1371)\ttotal: 9.36s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.0875296\ttest: 1.4135464\tbest: 1.4135464 (1450)\ttotal: 9.7s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0712505\ttest: 1.4097909\tbest: 1.4097909 (1500)\ttotal: 10s\tremaining: 1m 30s\n",
      "1550:\tlearn: 1.0538701\ttest: 1.4001832\tbest: 1.4001832 (1550)\ttotal: 10.4s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0395656\ttest: 1.3935540\tbest: 1.3935540 (1600)\ttotal: 10.7s\tremaining: 1m 29s\n",
      "1650:\tlearn: 1.0238518\ttest: 1.3820556\tbest: 1.3820556 (1650)\ttotal: 11s\tremaining: 1m 29s\n",
      "1700:\tlearn: 1.0079756\ttest: 1.3731952\tbest: 1.3731952 (1700)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1750:\tlearn: 0.9958194\ttest: 1.3685104\tbest: 1.3685104 (1750)\ttotal: 11.7s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9811860\ttest: 1.3644850\tbest: 1.3641310 (1787)\ttotal: 12s\tremaining: 1m 28s\n",
      "1850:\tlearn: 0.9659557\ttest: 1.3626374\tbest: 1.3616864 (1831)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9527705\ttest: 1.3589547\tbest: 1.3587155 (1896)\ttotal: 12.7s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9371895\ttest: 1.3495651\tbest: 1.3495651 (1950)\ttotal: 13s\tremaining: 1m 27s\n",
      "2000:\tlearn: 0.9232736\ttest: 1.3419963\tbest: 1.3414506 (1999)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.9091106\ttest: 1.3392436\tbest: 1.3392436 (2050)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.8935668\ttest: 1.3331646\tbest: 1.3324494 (2097)\ttotal: 14s\tremaining: 1m 26s\n",
      "2150:\tlearn: 0.8793140\ttest: 1.3259103\tbest: 1.3259103 (2150)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8653186\ttest: 1.3200914\tbest: 1.3200914 (2200)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8531612\ttest: 1.3150213\tbest: 1.3147700 (2240)\ttotal: 15s\tremaining: 1m 25s\n",
      "2300:\tlearn: 0.8404259\ttest: 1.3112540\tbest: 1.3112540 (2300)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8281260\ttest: 1.3068711\tbest: 1.3067511 (2346)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8154648\ttest: 1.3070600\tbest: 1.3049874 (2390)\ttotal: 16s\tremaining: 1m 24s\n",
      "2450:\tlearn: 0.8015068\ttest: 1.3018867\tbest: 1.3013547 (2446)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.7897106\ttest: 1.3003380\tbest: 1.2998479 (2491)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7780245\ttest: 1.3013823\tbest: 1.2998479 (2491)\ttotal: 17s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.7648317\ttest: 1.2974791\tbest: 1.2974791 (2600)\ttotal: 17.3s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7545280\ttest: 1.2971852\tbest: 1.2971852 (2650)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7453404\ttest: 1.2934780\tbest: 1.2933602 (2699)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "2750:\tlearn: 0.7324573\ttest: 1.2890785\tbest: 1.2890785 (2750)\ttotal: 18.4s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7196759\ttest: 1.2853227\tbest: 1.2853227 (2800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.7103873\ttest: 1.2851862\tbest: 1.2848324 (2826)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "2900:\tlearn: 0.7001985\ttest: 1.2875420\tbest: 1.2845825 (2859)\ttotal: 19.4s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.6897909\ttest: 1.2843488\tbest: 1.2839972 (2946)\ttotal: 19.7s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.6789424\ttest: 1.2826480\tbest: 1.2819020 (2984)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "3050:\tlearn: 0.6690595\ttest: 1.2807591\tbest: 1.2802712 (3030)\ttotal: 20.4s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6593126\ttest: 1.2782730\tbest: 1.2782730 (3100)\ttotal: 20.7s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6491280\ttest: 1.2766349\tbest: 1.2766349 (3150)\ttotal: 21.1s\tremaining: 1m 19s\n",
      "3200:\tlearn: 0.6386515\ttest: 1.2724571\tbest: 1.2724571 (3200)\ttotal: 21.4s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6290081\ttest: 1.2715320\tbest: 1.2701746 (3239)\ttotal: 21.7s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6188670\ttest: 1.2687854\tbest: 1.2681893 (3298)\ttotal: 22.1s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.6103221\ttest: 1.2694456\tbest: 1.2681893 (3298)\ttotal: 22.4s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.6017821\ttest: 1.2688216\tbest: 1.2681893 (3298)\ttotal: 22.7s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.5909621\ttest: 1.2712568\tbest: 1.2680805 (3405)\ttotal: 23.1s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.5819357\ttest: 1.2680936\tbest: 1.2680805 (3405)\ttotal: 23.4s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5735509\ttest: 1.2700186\tbest: 1.2664360 (3521)\ttotal: 23.7s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5648522\ttest: 1.2692717\tbest: 1.2664360 (3521)\ttotal: 24.1s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.5574439\ttest: 1.2672771\tbest: 1.2664360 (3521)\ttotal: 24.4s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5494208\ttest: 1.2684559\tbest: 1.2664360 (3521)\ttotal: 24.7s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5419810\ttest: 1.2640860\tbest: 1.2640860 (3750)\ttotal: 25.1s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5344757\ttest: 1.2635833\tbest: 1.2630020 (3782)\ttotal: 25.4s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5272144\ttest: 1.2610850\tbest: 1.2610657 (3849)\ttotal: 25.7s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5180421\ttest: 1.2576865\tbest: 1.2576865 (3900)\ttotal: 26.1s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.5099015\ttest: 1.2568549\tbest: 1.2567958 (3921)\ttotal: 26.4s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.5014835\ttest: 1.2552274\tbest: 1.2552274 (4000)\ttotal: 26.7s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.4927795\ttest: 1.2508956\tbest: 1.2508956 (4050)\ttotal: 27.1s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.4850365\ttest: 1.2490561\tbest: 1.2490561 (4100)\ttotal: 27.4s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4769651\ttest: 1.2476932\tbest: 1.2476932 (4150)\ttotal: 27.7s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4695421\ttest: 1.2476902\tbest: 1.2463283 (4180)\ttotal: 28.1s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4628472\ttest: 1.2476850\tbest: 1.2463283 (4180)\ttotal: 28.4s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4563789\ttest: 1.2490890\tbest: 1.2463283 (4180)\ttotal: 28.7s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4490319\ttest: 1.2480910\tbest: 1.2463283 (4180)\ttotal: 29.1s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4423969\ttest: 1.2476239\tbest: 1.2463283 (4180)\ttotal: 29.4s\tremaining: 1m 10s\n",
      "4450:\tlearn: 0.4355724\ttest: 1.2485621\tbest: 1.2463283 (4180)\ttotal: 29.7s\tremaining: 1m 10s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.246328292\n",
      "bestIteration = 4180\n",
      "\n",
      "Shrink model to first 4181 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скор для фолда(4) : 9.0 средний скор на префиксе = 9.0 это заняло = 30 сек.\n",
      "Фолд: 5\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.5858703\ttest: 3.5956380\tbest: 3.5956380 (0)\ttotal: 28.9ms\tremaining: 7m 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7208889\ttest: 2.8604563\tbest: 2.8604563 (50)\ttotal: 353ms\tremaining: 1m 43s\n",
      "100:\tlearn: 2.2457122\ttest: 2.5500245\tbest: 2.5500245 (100)\ttotal: 692ms\tremaining: 1m 42s\n",
      "150:\tlearn: 1.9819317\ttest: 2.3387223\tbest: 2.3387223 (150)\ttotal: 1.02s\tremaining: 1m 40s\n",
      "200:\tlearn: 1.8257709\ttest: 2.1860000\tbest: 2.1860000 (200)\ttotal: 1.35s\tremaining: 1m 39s\n",
      "250:\tlearn: 1.7216358\ttest: 2.1052514\tbest: 2.1052514 (250)\ttotal: 1.69s\tremaining: 1m 39s\n",
      "300:\tlearn: 1.6380875\ttest: 2.0542335\tbest: 2.0542335 (300)\ttotal: 2.02s\tremaining: 1m 38s\n",
      "350:\tlearn: 1.5757410\ttest: 2.0235214\tbest: 2.0235214 (350)\ttotal: 2.35s\tremaining: 1m 38s\n",
      "400:\tlearn: 1.5233471\ttest: 1.9975479\tbest: 1.9969738 (399)\ttotal: 2.69s\tremaining: 1m 38s\n",
      "450:\tlearn: 1.4813461\ttest: 1.9864297\tbest: 1.9864297 (450)\ttotal: 3.02s\tremaining: 1m 37s\n",
      "500:\tlearn: 1.4411739\ttest: 1.9562742\tbest: 1.9562742 (500)\ttotal: 3.35s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4088072\ttest: 1.9310778\tbest: 1.9299889 (549)\ttotal: 3.69s\tremaining: 1m 36s\n",
      "600:\tlearn: 1.3807743\ttest: 1.9114380\tbest: 1.9114380 (600)\ttotal: 4.02s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3548068\ttest: 1.8959027\tbest: 1.8959027 (650)\ttotal: 4.35s\tremaining: 1m 35s\n",
      "700:\tlearn: 1.3311343\ttest: 1.8855120\tbest: 1.8853691 (699)\ttotal: 4.68s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3091909\ttest: 1.8764343\tbest: 1.8761792 (749)\ttotal: 5.01s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.2862656\ttest: 1.8696053\tbest: 1.8689363 (795)\ttotal: 5.34s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.2657866\ttest: 1.8572621\tbest: 1.8572621 (850)\ttotal: 5.67s\tremaining: 1m 34s\n",
      "900:\tlearn: 1.2448686\ttest: 1.8486024\tbest: 1.8486024 (900)\ttotal: 5.99s\tremaining: 1m 33s\n",
      "950:\tlearn: 1.2268729\ttest: 1.8416985\tbest: 1.8409858 (943)\ttotal: 6.32s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2084957\ttest: 1.8345878\tbest: 1.8343641 (998)\ttotal: 6.66s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.1901926\ttest: 1.8260899\tbest: 1.8260899 (1050)\ttotal: 6.98s\tremaining: 1m 32s\n",
      "1100:\tlearn: 1.1726678\ttest: 1.8213196\tbest: 1.8211619 (1090)\ttotal: 7.31s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.1572011\ttest: 1.8194356\tbest: 1.8193750 (1149)\ttotal: 7.64s\tremaining: 1m 31s\n",
      "1200:\tlearn: 1.1388648\ttest: 1.8147321\tbest: 1.8142069 (1199)\ttotal: 7.96s\tremaining: 1m 31s\n",
      "1250:\tlearn: 1.1220808\ttest: 1.8114973\tbest: 1.8108003 (1241)\ttotal: 8.29s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1058509\ttest: 1.8073697\tbest: 1.8064169 (1293)\ttotal: 8.63s\tremaining: 1m 30s\n",
      "1350:\tlearn: 1.0872178\ttest: 1.8053515\tbest: 1.8040685 (1339)\ttotal: 8.95s\tremaining: 1m 30s\n",
      "1400:\tlearn: 1.0728714\ttest: 1.8008053\tbest: 1.8003345 (1396)\ttotal: 9.29s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.0594481\ttest: 1.7959010\tbest: 1.7959010 (1450)\ttotal: 9.62s\tremaining: 1m 29s\n",
      "1500:\tlearn: 1.0438114\ttest: 1.7897993\tbest: 1.7897993 (1500)\ttotal: 9.95s\tremaining: 1m 29s\n",
      "1550:\tlearn: 1.0285075\ttest: 1.7866855\tbest: 1.7866855 (1550)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0129091\ttest: 1.7811501\tbest: 1.7811501 (1600)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1650:\tlearn: 0.9983518\ttest: 1.7787644\tbest: 1.7772523 (1642)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1700:\tlearn: 0.9811758\ttest: 1.7737076\tbest: 1.7730896 (1692)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 0.9656474\ttest: 1.7694194\tbest: 1.7682371 (1741)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1800:\tlearn: 0.9512995\ttest: 1.7633396\tbest: 1.7632657 (1799)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9386483\ttest: 1.7584122\tbest: 1.7583914 (1849)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9262242\ttest: 1.7576911\tbest: 1.7560028 (1887)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1950:\tlearn: 0.9135880\ttest: 1.7544993\tbest: 1.7537185 (1939)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "2000:\tlearn: 0.9001593\ttest: 1.7511055\tbest: 1.7511055 (2000)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.8865280\ttest: 1.7463713\tbest: 1.7463593 (2049)\ttotal: 13.6s\tremaining: 1m 25s\n",
      "2100:\tlearn: 0.8743315\ttest: 1.7428493\tbest: 1.7428199 (2098)\ttotal: 13.9s\tremaining: 1m 25s\n",
      "2150:\tlearn: 0.8594356\ttest: 1.7393532\tbest: 1.7389083 (2147)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8488309\ttest: 1.7344909\tbest: 1.7344693 (2197)\ttotal: 14.6s\tremaining: 1m 24s\n",
      "2250:\tlearn: 0.8370684\ttest: 1.7315231\tbest: 1.7312564 (2242)\ttotal: 14.9s\tremaining: 1m 24s\n",
      "2300:\tlearn: 0.8257296\ttest: 1.7299038\tbest: 1.7298692 (2298)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8141963\ttest: 1.7232047\tbest: 1.7232047 (2350)\ttotal: 15.6s\tremaining: 1m 23s\n",
      "2400:\tlearn: 0.8032777\ttest: 1.7195901\tbest: 1.7195901 (2400)\ttotal: 15.9s\tremaining: 1m 23s\n",
      "2450:\tlearn: 0.7922928\ttest: 1.7150174\tbest: 1.7150174 (2450)\ttotal: 16.2s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.7801661\ttest: 1.7110209\tbest: 1.7107742 (2496)\ttotal: 16.6s\tremaining: 1m 22s\n",
      "2550:\tlearn: 0.7682682\ttest: 1.7076467\tbest: 1.7065003 (2539)\ttotal: 16.9s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.7582557\ttest: 1.7026894\tbest: 1.7026894 (2600)\ttotal: 17.2s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7469262\ttest: 1.6977737\tbest: 1.6977416 (2648)\ttotal: 17.6s\tremaining: 1m 21s\n",
      "2700:\tlearn: 0.7352620\ttest: 1.6967731\tbest: 1.6963046 (2679)\ttotal: 17.9s\tremaining: 1m 21s\n",
      "2750:\tlearn: 0.7261866\ttest: 1.6914352\tbest: 1.6914352 (2750)\ttotal: 18.2s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7149931\ttest: 1.6892203\tbest: 1.6888899 (2790)\ttotal: 18.6s\tremaining: 1m 20s\n",
      "2850:\tlearn: 0.7040947\ttest: 1.6827702\tbest: 1.6827702 (2850)\ttotal: 18.9s\tremaining: 1m 20s\n",
      "2900:\tlearn: 0.6938433\ttest: 1.6778228\tbest: 1.6778228 (2900)\ttotal: 19.2s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.6827650\ttest: 1.6760741\tbest: 1.6753922 (2944)\ttotal: 19.6s\tremaining: 1m 19s\n",
      "3000:\tlearn: 0.6723506\ttest: 1.6717391\tbest: 1.6717391 (3000)\ttotal: 19.9s\tremaining: 1m 19s\n",
      "3050:\tlearn: 0.6619141\ttest: 1.6699082\tbest: 1.6699082 (3050)\ttotal: 20.2s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6502249\ttest: 1.6652074\tbest: 1.6652074 (3100)\ttotal: 20.6s\tremaining: 1m 18s\n",
      "3150:\tlearn: 0.6416414\ttest: 1.6622472\tbest: 1.6621810 (3149)\ttotal: 20.9s\tremaining: 1m 18s\n",
      "3200:\tlearn: 0.6308056\ttest: 1.6604072\tbest: 1.6592198 (3184)\ttotal: 21.2s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6221478\ttest: 1.6557580\tbest: 1.6557497 (3249)\ttotal: 21.6s\tremaining: 1m 17s\n",
      "3300:\tlearn: 0.6132351\ttest: 1.6512114\tbest: 1.6512114 (3300)\ttotal: 21.9s\tremaining: 1m 17s\n",
      "3350:\tlearn: 0.6029189\ttest: 1.6495951\tbest: 1.6491006 (3336)\ttotal: 22.2s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.5939115\ttest: 1.6468073\tbest: 1.6464382 (3398)\ttotal: 22.6s\tremaining: 1m 16s\n",
      "3450:\tlearn: 0.5843349\ttest: 1.6482167\tbest: 1.6464382 (3398)\ttotal: 22.9s\tremaining: 1m 16s\n",
      "3500:\tlearn: 0.5762903\ttest: 1.6471405\tbest: 1.6464382 (3398)\ttotal: 23.2s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5665068\ttest: 1.6456588\tbest: 1.6446427 (3525)\ttotal: 23.6s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5594465\ttest: 1.6449023\tbest: 1.6445117 (3593)\ttotal: 23.9s\tremaining: 1m 15s\n",
      "3650:\tlearn: 0.5518779\ttest: 1.6425460\tbest: 1.6425460 (3650)\ttotal: 24.2s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5435609\ttest: 1.6419122\tbest: 1.6411200 (3687)\ttotal: 24.6s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5357429\ttest: 1.6390885\tbest: 1.6386479 (3743)\ttotal: 24.9s\tremaining: 1m 14s\n",
      "3800:\tlearn: 0.5276501\ttest: 1.6384837\tbest: 1.6380767 (3793)\ttotal: 25.2s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5199432\ttest: 1.6341134\tbest: 1.6341134 (3850)\ttotal: 25.6s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5123217\ttest: 1.6330843\tbest: 1.6330843 (3900)\ttotal: 25.9s\tremaining: 1m 13s\n",
      "3950:\tlearn: 0.5036141\ttest: 1.6284840\tbest: 1.6284425 (3948)\ttotal: 26.2s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.4956264\ttest: 1.6305696\tbest: 1.6284425 (3948)\ttotal: 26.6s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.4884880\ttest: 1.6263709\tbest: 1.6260865 (4048)\ttotal: 26.9s\tremaining: 1m 12s\n",
      "4100:\tlearn: 0.4805002\ttest: 1.6253645\tbest: 1.6252085 (4099)\ttotal: 27.2s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4729622\ttest: 1.6233029\tbest: 1.6227405 (4142)\ttotal: 27.6s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4663740\ttest: 1.6223674\tbest: 1.6223674 (4200)\ttotal: 27.9s\tremaining: 1m 11s\n",
      "4250:\tlearn: 0.4589138\ttest: 1.6220914\tbest: 1.6215382 (4218)\ttotal: 28.2s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4515403\ttest: 1.6203281\tbest: 1.6202744 (4298)\ttotal: 28.6s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4455210\ttest: 1.6177800\tbest: 1.6173665 (4343)\ttotal: 28.9s\tremaining: 1m 10s\n",
      "4400:\tlearn: 0.4393631\ttest: 1.6191803\tbest: 1.6173665 (4343)\ttotal: 29.2s\tremaining: 1m 10s\n",
      "4450:\tlearn: 0.4319543\ttest: 1.6191231\tbest: 1.6173665 (4343)\ttotal: 29.6s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4253636\ttest: 1.6180690\tbest: 1.6173665 (4343)\ttotal: 29.9s\tremaining: 1m 9s\n",
      "4550:\tlearn: 0.4189750\ttest: 1.6164131\tbest: 1.6163258 (4548)\ttotal: 30.3s\tremaining: 1m 9s\n",
      "4600:\tlearn: 0.4123833\ttest: 1.6148357\tbest: 1.6141738 (4578)\ttotal: 30.6s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4058444\ttest: 1.6144095\tbest: 1.6141738 (4578)\ttotal: 30.9s\tremaining: 1m 8s\n",
      "4700:\tlearn: 0.3999835\ttest: 1.6120067\tbest: 1.6118771 (4686)\ttotal: 31.3s\tremaining: 1m 8s\n",
      "4750:\tlearn: 0.3945924\ttest: 1.6115829\tbest: 1.6115607 (4704)\ttotal: 31.6s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.3888594\ttest: 1.6110266\tbest: 1.6094636 (4787)\ttotal: 31.9s\tremaining: 1m 7s\n",
      "4850:\tlearn: 0.3832042\ttest: 1.6112185\tbest: 1.6094636 (4787)\ttotal: 32.3s\tremaining: 1m 7s\n",
      "4900:\tlearn: 0.3764674\ttest: 1.6089589\tbest: 1.6089446 (4882)\ttotal: 32.6s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3712317\ttest: 1.6058556\tbest: 1.6052870 (4943)\ttotal: 32.9s\tremaining: 1m 6s\n",
      "5000:\tlearn: 0.3653888\ttest: 1.6061346\tbest: 1.6044706 (4972)\ttotal: 33.3s\tremaining: 1m 6s\n",
      "5050:\tlearn: 0.3596460\ttest: 1.6052959\tbest: 1.6044706 (4972)\ttotal: 33.6s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3544370\ttest: 1.6020947\tbest: 1.6016941 (5088)\ttotal: 33.9s\tremaining: 1m 5s\n",
      "5150:\tlearn: 0.3479795\ttest: 1.5981804\tbest: 1.5975789 (5145)\ttotal: 34.3s\tremaining: 1m 5s\n",
      "5200:\tlearn: 0.3425431\ttest: 1.5958670\tbest: 1.5952584 (5191)\ttotal: 34.6s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3373480\ttest: 1.5969170\tbest: 1.5949569 (5220)\ttotal: 34.9s\tremaining: 1m 4s\n",
      "5300:\tlearn: 0.3312740\ttest: 1.5956476\tbest: 1.5949569 (5220)\ttotal: 35.3s\tremaining: 1m 4s\n",
      "5350:\tlearn: 0.3268664\ttest: 1.5964057\tbest: 1.5949569 (5220)\ttotal: 35.6s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3224560\ttest: 1.5957231\tbest: 1.5949569 (5220)\ttotal: 35.9s\tremaining: 1m 3s\n",
      "5450:\tlearn: 0.3166816\ttest: 1.5948544\tbest: 1.5938208 (5436)\ttotal: 36.3s\tremaining: 1m 3s\n",
      "5500:\tlearn: 0.3116571\ttest: 1.5961597\tbest: 1.5938208 (5436)\ttotal: 36.6s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3067342\ttest: 1.5937333\tbest: 1.5935885 (5549)\ttotal: 37s\tremaining: 1m 2s\n",
      "5600:\tlearn: 0.3020285\ttest: 1.5930143\tbest: 1.5927433 (5580)\ttotal: 37.3s\tremaining: 1m 2s\n",
      "5650:\tlearn: 0.2971745\ttest: 1.5940387\tbest: 1.5927433 (5580)\ttotal: 37.6s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.2916512\ttest: 1.5930784\tbest: 1.5927433 (5580)\ttotal: 38s\tremaining: 1m 1s\n",
      "5750:\tlearn: 0.2870161\ttest: 1.5920354\tbest: 1.5919693 (5749)\ttotal: 38.3s\tremaining: 1m 1s\n",
      "5800:\tlearn: 0.2818676\ttest: 1.5941619\tbest: 1.5917601 (5753)\ttotal: 38.6s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2773703\ttest: 1.5915588\tbest: 1.5915588 (5850)\ttotal: 39s\tremaining: 1m\n",
      "5900:\tlearn: 0.2737141\ttest: 1.5912733\tbest: 1.5905581 (5884)\ttotal: 39.3s\tremaining: 1m\n",
      "5950:\tlearn: 0.2695627\ttest: 1.5895917\tbest: 1.5895516 (5949)\ttotal: 39.7s\tremaining: 1m\n",
      "6000:\tlearn: 0.2650516\ttest: 1.5873386\tbest: 1.5873386 (6000)\ttotal: 40s\tremaining: 60s\n",
      "6050:\tlearn: 0.2613785\ttest: 1.5851216\tbest: 1.5851084 (6048)\ttotal: 40.3s\tremaining: 59.6s\n",
      "6100:\tlearn: 0.2571206\ttest: 1.5851182\tbest: 1.5848010 (6068)\ttotal: 40.7s\tremaining: 59.3s\n",
      "6150:\tlearn: 0.2528238\ttest: 1.5849922\tbest: 1.5843812 (6146)\ttotal: 41s\tremaining: 59s\n",
      "6200:\tlearn: 0.2492824\ttest: 1.5842196\tbest: 1.5842196 (6200)\ttotal: 41.4s\tremaining: 58.7s\n",
      "6250:\tlearn: 0.2449934\ttest: 1.5834910\tbest: 1.5830325 (6232)\ttotal: 41.7s\tremaining: 58.3s\n",
      "6300:\tlearn: 0.2415703\ttest: 1.5832318\tbest: 1.5829344 (6259)\ttotal: 42s\tremaining: 58s\n",
      "6350:\tlearn: 0.2372915\ttest: 1.5835686\tbest: 1.5829344 (6259)\ttotal: 42.4s\tremaining: 57.7s\n",
      "6400:\tlearn: 0.2328516\ttest: 1.5792910\tbest: 1.5788155 (6397)\ttotal: 42.7s\tremaining: 57.4s\n",
      "6450:\tlearn: 0.2296946\ttest: 1.5792499\tbest: 1.5786655 (6418)\ttotal: 43s\tremaining: 57s\n",
      "6500:\tlearn: 0.2260728\ttest: 1.5779224\tbest: 1.5777903 (6469)\ttotal: 43.4s\tremaining: 56.7s\n",
      "6550:\tlearn: 0.2231537\ttest: 1.5777400\tbest: 1.5775320 (6541)\ttotal: 43.7s\tremaining: 56.4s\n",
      "6600:\tlearn: 0.2201275\ttest: 1.5771897\tbest: 1.5768692 (6586)\ttotal: 44s\tremaining: 56s\n",
      "6650:\tlearn: 0.2164316\ttest: 1.5748779\tbest: 1.5748779 (6650)\ttotal: 44.4s\tremaining: 55.7s\n",
      "6700:\tlearn: 0.2129460\ttest: 1.5731155\tbest: 1.5731155 (6700)\ttotal: 44.7s\tremaining: 55.4s\n",
      "6750:\tlearn: 0.2094894\ttest: 1.5735038\tbest: 1.5725630 (6704)\ttotal: 45.1s\tremaining: 55.1s\n",
      "6800:\tlearn: 0.2064108\ttest: 1.5728769\tbest: 1.5720036 (6781)\ttotal: 45.4s\tremaining: 54.7s\n",
      "6850:\tlearn: 0.2029797\ttest: 1.5725904\tbest: 1.5720036 (6781)\ttotal: 45.7s\tremaining: 54.4s\n",
      "6900:\tlearn: 0.2001080\ttest: 1.5740828\tbest: 1.5720036 (6781)\ttotal: 46.1s\tremaining: 54.1s\n",
      "6950:\tlearn: 0.1965286\ttest: 1.5740391\tbest: 1.5720036 (6781)\ttotal: 46.4s\tremaining: 53.7s\n",
      "7000:\tlearn: 0.1932134\ttest: 1.5718537\tbest: 1.5718495 (6999)\ttotal: 46.7s\tremaining: 53.4s\n",
      "7050:\tlearn: 0.1900933\ttest: 1.5726255\tbest: 1.5715606 (7026)\ttotal: 47.1s\tremaining: 53.1s\n",
      "7100:\tlearn: 0.1872020\ttest: 1.5712164\tbest: 1.5706678 (7088)\ttotal: 47.4s\tremaining: 52.8s\n",
      "7150:\tlearn: 0.1843929\ttest: 1.5710442\tbest: 1.5698709 (7124)\ttotal: 47.8s\tremaining: 52.4s\n",
      "7200:\tlearn: 0.1816001\ttest: 1.5704343\tbest: 1.5698709 (7124)\ttotal: 48.1s\tremaining: 52.1s\n",
      "7250:\tlearn: 0.1790183\ttest: 1.5680946\tbest: 1.5676722 (7245)\ttotal: 48.5s\tremaining: 51.8s\n",
      "7300:\tlearn: 0.1759697\ttest: 1.5670346\tbest: 1.5666564 (7293)\ttotal: 48.8s\tremaining: 51.4s\n",
      "7350:\tlearn: 0.1731910\ttest: 1.5660825\tbest: 1.5654404 (7324)\ttotal: 49.1s\tremaining: 51.1s\n",
      "7400:\tlearn: 0.1704960\ttest: 1.5664761\tbest: 1.5654404 (7324)\ttotal: 49.5s\tremaining: 50.8s\n",
      "7450:\tlearn: 0.1679447\ttest: 1.5674962\tbest: 1.5654404 (7324)\ttotal: 49.8s\tremaining: 50.4s\n",
      "7500:\tlearn: 0.1652944\ttest: 1.5672062\tbest: 1.5654404 (7324)\ttotal: 50.1s\tremaining: 50.1s\n",
      "7550:\tlearn: 0.1628194\ttest: 1.5670855\tbest: 1.5654404 (7324)\ttotal: 50.5s\tremaining: 49.8s\n",
      "7600:\tlearn: 0.1600697\ttest: 1.5662628\tbest: 1.5654404 (7324)\ttotal: 50.8s\tremaining: 49.5s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.565440442\n",
      "bestIteration = 7324\n",
      "\n",
      "Shrink model to first 7325 iterations.\n",
      "Скор для фолда(5) : 9.0 средний скор на префиксе = 9.0 это заняло = 51 сек.\n",
      "Фолд: 6\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.5997946\ttest: 3.7303716\tbest: 3.7303716 (0)\ttotal: 27.5ms\tremaining: 6m 52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7568062\ttest: 2.8985925\tbest: 2.8985925 (50)\ttotal: 364ms\tremaining: 1m 46s\n",
      "100:\tlearn: 2.2935339\ttest: 2.3024308\tbest: 2.3024308 (100)\ttotal: 695ms\tremaining: 1m 42s\n",
      "150:\tlearn: 2.0358189\ttest: 1.9186323\tbest: 1.9186323 (150)\ttotal: 1.02s\tremaining: 1m 40s\n",
      "200:\tlearn: 1.8666967\ttest: 1.7099027\tbest: 1.7099027 (200)\ttotal: 1.36s\tremaining: 1m 40s\n",
      "250:\tlearn: 1.7550958\ttest: 1.5955988\tbest: 1.5955988 (250)\ttotal: 1.69s\tremaining: 1m 39s\n",
      "300:\tlearn: 1.6745830\ttest: 1.5110080\tbest: 1.5110080 (300)\ttotal: 2.02s\tremaining: 1m 38s\n",
      "350:\tlearn: 1.6034677\ttest: 1.4485788\tbest: 1.4485788 (350)\ttotal: 2.37s\tremaining: 1m 38s\n",
      "400:\tlearn: 1.5505322\ttest: 1.4218815\tbest: 1.4218815 (400)\ttotal: 2.7s\tremaining: 1m 38s\n",
      "450:\tlearn: 1.5023123\ttest: 1.3890677\tbest: 1.3890677 (450)\ttotal: 3.03s\tremaining: 1m 37s\n",
      "500:\tlearn: 1.4614178\ttest: 1.3637347\tbest: 1.3637347 (500)\ttotal: 3.37s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4274443\ttest: 1.3453946\tbest: 1.3452837 (549)\ttotal: 3.71s\tremaining: 1m 37s\n",
      "600:\tlearn: 1.3991488\ttest: 1.3299564\tbest: 1.3299564 (600)\ttotal: 4.04s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3745181\ttest: 1.3172968\tbest: 1.3172968 (650)\ttotal: 4.38s\tremaining: 1m 36s\n",
      "700:\tlearn: 1.3513996\ttest: 1.3059664\tbest: 1.3059664 (700)\ttotal: 4.71s\tremaining: 1m 36s\n",
      "750:\tlearn: 1.3303763\ttest: 1.2961849\tbest: 1.2961518 (749)\ttotal: 5.04s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.3096627\ttest: 1.2883286\tbest: 1.2881875 (789)\ttotal: 5.38s\tremaining: 1m 35s\n",
      "850:\tlearn: 1.2905176\ttest: 1.2842294\tbest: 1.2841582 (843)\ttotal: 5.71s\tremaining: 1m 34s\n",
      "900:\tlearn: 1.2720812\ttest: 1.2809859\tbest: 1.2803020 (885)\ttotal: 6.04s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2531464\ttest: 1.2720682\tbest: 1.2716442 (948)\ttotal: 6.38s\tremaining: 1m 34s\n",
      "1000:\tlearn: 1.2345371\ttest: 1.2683284\tbest: 1.2677845 (990)\ttotal: 6.7s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2168208\ttest: 1.2645899\tbest: 1.2645295 (1048)\ttotal: 7.03s\tremaining: 1m 33s\n",
      "1100:\tlearn: 1.1984235\ttest: 1.2621607\tbest: 1.2621442 (1099)\ttotal: 7.36s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.1833851\ttest: 1.2605771\tbest: 1.2597970 (1148)\ttotal: 7.7s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1660919\ttest: 1.2539239\tbest: 1.2539239 (1200)\ttotal: 8.03s\tremaining: 1m 32s\n",
      "1250:\tlearn: 1.1481920\ttest: 1.2482685\tbest: 1.2482519 (1249)\ttotal: 8.36s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1302345\ttest: 1.2474759\tbest: 1.2456216 (1284)\ttotal: 8.69s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.1149807\ttest: 1.2441391\tbest: 1.2435978 (1344)\ttotal: 9.01s\tremaining: 1m 31s\n",
      "1400:\tlearn: 1.1004403\ttest: 1.2381997\tbest: 1.2378954 (1394)\ttotal: 9.35s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.0839943\ttest: 1.2319458\tbest: 1.2319458 (1450)\ttotal: 9.68s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0697422\ttest: 1.2317436\tbest: 1.2279950 (1488)\ttotal: 10s\tremaining: 1m 30s\n",
      "1550:\tlearn: 1.0546424\ttest: 1.2325702\tbest: 1.2279950 (1488)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0394716\ttest: 1.2283684\tbest: 1.2279950 (1488)\ttotal: 10.7s\tremaining: 1m 29s\n",
      "1650:\tlearn: 1.0215393\ttest: 1.2215389\tbest: 1.2213114 (1648)\ttotal: 11s\tremaining: 1m 29s\n",
      "1700:\tlearn: 1.0065084\ttest: 1.2188769\tbest: 1.2181760 (1695)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 0.9929932\ttest: 1.2146971\tbest: 1.2146971 (1750)\ttotal: 11.7s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9782112\ttest: 1.2156822\tbest: 1.2143442 (1753)\ttotal: 12s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9628961\ttest: 1.2103711\tbest: 1.2103711 (1850)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9483658\ttest: 1.2064319\tbest: 1.2062687 (1899)\ttotal: 12.7s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9344995\ttest: 1.2073876\tbest: 1.2058758 (1929)\ttotal: 13s\tremaining: 1m 27s\n",
      "2000:\tlearn: 0.9184029\ttest: 1.2030477\tbest: 1.2030477 (2000)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.9034772\ttest: 1.1988396\tbest: 1.1988118 (2048)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.8904353\ttest: 1.1957740\tbest: 1.1957740 (2100)\ttotal: 14s\tremaining: 1m 26s\n",
      "2150:\tlearn: 0.8749986\ttest: 1.1956909\tbest: 1.1937504 (2120)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8630078\ttest: 1.1946972\tbest: 1.1937504 (2120)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8493748\ttest: 1.1928268\tbest: 1.1927085 (2249)\ttotal: 15s\tremaining: 1m 25s\n",
      "2300:\tlearn: 0.8349841\ttest: 1.1909199\tbest: 1.1909199 (2300)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8208784\ttest: 1.1904809\tbest: 1.1894617 (2329)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8067584\ttest: 1.1898590\tbest: 1.1888304 (2373)\ttotal: 16s\tremaining: 1m 24s\n",
      "2450:\tlearn: 0.7940732\ttest: 1.1871196\tbest: 1.1871116 (2449)\ttotal: 16.4s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.7800526\ttest: 1.1848798\tbest: 1.1844207 (2499)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7662792\ttest: 1.1856942\tbest: 1.1834922 (2507)\ttotal: 17s\tremaining: 1m 23s\n",
      "2600:\tlearn: 0.7555732\ttest: 1.1822557\tbest: 1.1821836 (2596)\ttotal: 17.4s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7407471\ttest: 1.1803660\tbest: 1.1801627 (2649)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7283390\ttest: 1.1793983\tbest: 1.1790332 (2694)\ttotal: 18s\tremaining: 1m 22s\n",
      "2750:\tlearn: 0.7171403\ttest: 1.1826336\tbest: 1.1790332 (2694)\ttotal: 18.4s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7052494\ttest: 1.1820904\tbest: 1.1790332 (2694)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.6962453\ttest: 1.1818104\tbest: 1.1790332 (2694)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "2900:\tlearn: 0.6858058\ttest: 1.1819096\tbest: 1.1790332 (2694)\ttotal: 19.4s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.6739731\ttest: 1.1795937\tbest: 1.1790332 (2694)\ttotal: 19.7s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.6640689\ttest: 1.1778631\tbest: 1.1775761 (2998)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "3050:\tlearn: 0.6533618\ttest: 1.1798577\tbest: 1.1775761 (2998)\ttotal: 20.4s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6424576\ttest: 1.1773041\tbest: 1.1759133 (3080)\ttotal: 20.7s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6326835\ttest: 1.1772189\tbest: 1.1759133 (3080)\ttotal: 21.1s\tremaining: 1m 19s\n",
      "3200:\tlearn: 0.6218535\ttest: 1.1763952\tbest: 1.1757413 (3192)\ttotal: 21.4s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6119744\ttest: 1.1735532\tbest: 1.1735462 (3249)\ttotal: 21.8s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6024058\ttest: 1.1743454\tbest: 1.1722769 (3282)\ttotal: 22.1s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.5934831\ttest: 1.1732952\tbest: 1.1722769 (3282)\ttotal: 22.4s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.5829099\ttest: 1.1724932\tbest: 1.1719212 (3377)\ttotal: 22.8s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.5731544\ttest: 1.1695442\tbest: 1.1694744 (3448)\ttotal: 23.1s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.5638652\ttest: 1.1696055\tbest: 1.1686853 (3463)\ttotal: 23.4s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5549189\ttest: 1.1662015\tbest: 1.1655926 (3544)\ttotal: 23.8s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5462625\ttest: 1.1636024\tbest: 1.1630370 (3595)\ttotal: 24.1s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.5365881\ttest: 1.1638026\tbest: 1.1629857 (3620)\ttotal: 24.4s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5280408\ttest: 1.1620087\tbest: 1.1619147 (3699)\ttotal: 24.8s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5198965\ttest: 1.1581315\tbest: 1.1581315 (3750)\ttotal: 25.1s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5109819\ttest: 1.1587922\tbest: 1.1577311 (3779)\ttotal: 25.4s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5020731\ttest: 1.1568958\tbest: 1.1568958 (3850)\ttotal: 25.8s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.4929699\ttest: 1.1567925\tbest: 1.1560484 (3871)\ttotal: 26.1s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.4846185\ttest: 1.1528254\tbest: 1.1528254 (3950)\ttotal: 26.5s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.4762960\ttest: 1.1500830\tbest: 1.1500191 (3997)\ttotal: 26.8s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.4689665\ttest: 1.1498390\tbest: 1.1488473 (4016)\ttotal: 27.1s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.4610811\ttest: 1.1497434\tbest: 1.1488473 (4016)\ttotal: 27.5s\tremaining: 1m 13s\n",
      "4150:\tlearn: 0.4538157\ttest: 1.1504069\tbest: 1.1488473 (4016)\ttotal: 27.8s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4455015\ttest: 1.1514983\tbest: 1.1488473 (4016)\ttotal: 28.2s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4387552\ttest: 1.1542374\tbest: 1.1488473 (4016)\ttotal: 28.5s\tremaining: 1m 12s\n",
      "4300:\tlearn: 0.4318751\ttest: 1.1514427\tbest: 1.1488473 (4016)\ttotal: 28.8s\tremaining: 1m 11s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.148847299\n",
      "bestIteration = 4016\n",
      "\n",
      "Shrink model to first 4017 iterations.\n",
      "Скор для фолда(6) : 9.0 средний скор на префиксе = 9.0 это заняло = 29 сек.\n",
      "Фолд: 7\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.5959039\ttest: 4.1806536\tbest: 4.1806536 (0)\ttotal: 28.8ms\tremaining: 7m 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7289307\ttest: 3.2713227\tbest: 3.2713227 (50)\ttotal: 353ms\tremaining: 1m 43s\n",
      "100:\tlearn: 2.2686827\ttest: 2.6919867\tbest: 2.6919867 (100)\ttotal: 693ms\tremaining: 1m 42s\n",
      "150:\tlearn: 2.0078770\ttest: 2.3860483\tbest: 2.3860483 (150)\ttotal: 1.03s\tremaining: 1m 41s\n",
      "200:\tlearn: 1.8506973\ttest: 2.2035881\tbest: 2.2035881 (200)\ttotal: 1.35s\tremaining: 1m 39s\n",
      "250:\tlearn: 1.7511698\ttest: 2.1061869\tbest: 2.1061869 (250)\ttotal: 1.69s\tremaining: 1m 39s\n",
      "300:\tlearn: 1.6938270\ttest: 2.0506217\tbest: 2.0502260 (297)\ttotal: 1.99s\tremaining: 1m 37s\n",
      "350:\tlearn: 1.6381716\ttest: 1.9973194\tbest: 1.9973194 (350)\ttotal: 2.3s\tremaining: 1m 36s\n",
      "400:\tlearn: 1.5969712\ttest: 1.9600212\tbest: 1.9600212 (400)\ttotal: 2.63s\tremaining: 1m 35s\n",
      "450:\tlearn: 1.5604501\ttest: 1.9324134\tbest: 1.9324134 (450)\ttotal: 2.95s\tremaining: 1m 35s\n",
      "500:\tlearn: 1.5236034\ttest: 1.8927839\tbest: 1.8927839 (500)\ttotal: 3.27s\tremaining: 1m 34s\n",
      "550:\tlearn: 1.4915193\ttest: 1.8629810\tbest: 1.8629810 (550)\ttotal: 3.6s\tremaining: 1m 34s\n",
      "600:\tlearn: 1.4670116\ttest: 1.8425720\tbest: 1.8425720 (600)\ttotal: 3.91s\tremaining: 1m 33s\n",
      "650:\tlearn: 1.4454825\ttest: 1.8190586\tbest: 1.8190586 (650)\ttotal: 4.22s\tremaining: 1m 33s\n",
      "700:\tlearn: 1.4258447\ttest: 1.8041174\tbest: 1.8034048 (697)\ttotal: 4.55s\tremaining: 1m 32s\n",
      "750:\tlearn: 1.4083339\ttest: 1.7861199\tbest: 1.7861199 (750)\ttotal: 4.86s\tremaining: 1m 32s\n",
      "800:\tlearn: 1.3848105\ttest: 1.7714725\tbest: 1.7714725 (800)\ttotal: 5.19s\tremaining: 1m 31s\n",
      "850:\tlearn: 1.3710990\ttest: 1.7634135\tbest: 1.7633725 (849)\ttotal: 5.52s\tremaining: 1m 31s\n",
      "900:\tlearn: 1.3542926\ttest: 1.7541187\tbest: 1.7525683 (899)\ttotal: 5.85s\tremaining: 1m 31s\n",
      "950:\tlearn: 1.3357671\ttest: 1.7380404\tbest: 1.7379793 (949)\ttotal: 6.18s\tremaining: 1m 31s\n",
      "1000:\tlearn: 1.3198406\ttest: 1.7261654\tbest: 1.7261654 (1000)\ttotal: 6.5s\tremaining: 1m 30s\n",
      "1050:\tlearn: 1.3023182\ttest: 1.7170907\tbest: 1.7170907 (1050)\ttotal: 6.83s\tremaining: 1m 30s\n",
      "1100:\tlearn: 1.2864958\ttest: 1.7090228\tbest: 1.7086564 (1099)\ttotal: 7.15s\tremaining: 1m 30s\n",
      "1150:\tlearn: 1.2679564\ttest: 1.7047369\tbest: 1.7047369 (1150)\ttotal: 7.47s\tremaining: 1m 29s\n",
      "1200:\tlearn: 1.2491649\ttest: 1.6977583\tbest: 1.6977583 (1200)\ttotal: 7.8s\tremaining: 1m 29s\n",
      "1250:\tlearn: 1.2302145\ttest: 1.6886861\tbest: 1.6886377 (1249)\ttotal: 8.13s\tremaining: 1m 29s\n",
      "1300:\tlearn: 1.2117006\ttest: 1.6880977\tbest: 1.6854293 (1277)\ttotal: 8.46s\tremaining: 1m 29s\n",
      "1350:\tlearn: 1.1924698\ttest: 1.6848263\tbest: 1.6832338 (1348)\ttotal: 8.78s\tremaining: 1m 28s\n",
      "1400:\tlearn: 1.1744678\ttest: 1.6857128\tbest: 1.6813908 (1379)\ttotal: 9.11s\tremaining: 1m 28s\n",
      "1450:\tlearn: 1.1531023\ttest: 1.6765593\tbest: 1.6765593 (1450)\ttotal: 9.44s\tremaining: 1m 28s\n",
      "1500:\tlearn: 1.1332153\ttest: 1.6684553\tbest: 1.6680277 (1496)\ttotal: 9.77s\tremaining: 1m 27s\n",
      "1550:\tlearn: 1.1139356\ttest: 1.6568960\tbest: 1.6568960 (1550)\ttotal: 10.1s\tremaining: 1m 27s\n",
      "1600:\tlearn: 1.0946228\ttest: 1.6547437\tbest: 1.6543826 (1595)\ttotal: 10.4s\tremaining: 1m 27s\n",
      "1650:\tlearn: 1.0788954\ttest: 1.6508294\tbest: 1.6486593 (1640)\ttotal: 10.8s\tremaining: 1m 26s\n",
      "1700:\tlearn: 1.0601493\ttest: 1.6457925\tbest: 1.6457925 (1700)\ttotal: 11.1s\tremaining: 1m 26s\n",
      "1750:\tlearn: 1.0452564\ttest: 1.6376514\tbest: 1.6375985 (1749)\ttotal: 11.4s\tremaining: 1m 26s\n",
      "1800:\tlearn: 1.0301344\ttest: 1.6312072\tbest: 1.6310889 (1797)\ttotal: 11.8s\tremaining: 1m 26s\n",
      "1850:\tlearn: 1.0123069\ttest: 1.6250843\tbest: 1.6241236 (1846)\ttotal: 12.1s\tremaining: 1m 25s\n",
      "1900:\tlearn: 0.9974438\ttest: 1.6178597\tbest: 1.6176089 (1899)\ttotal: 12.4s\tremaining: 1m 25s\n",
      "1950:\tlearn: 0.9816978\ttest: 1.6116934\tbest: 1.6116934 (1950)\ttotal: 12.7s\tremaining: 1m 25s\n",
      "2000:\tlearn: 0.9674940\ttest: 1.6059346\tbest: 1.6047253 (1994)\ttotal: 13.1s\tremaining: 1m 25s\n",
      "2050:\tlearn: 0.9529218\ttest: 1.5987962\tbest: 1.5987962 (2050)\ttotal: 13.4s\tremaining: 1m 24s\n",
      "2100:\tlearn: 0.9401975\ttest: 1.5902434\tbest: 1.5902434 (2100)\ttotal: 13.7s\tremaining: 1m 24s\n",
      "2150:\tlearn: 0.9272515\ttest: 1.5864296\tbest: 1.5864296 (2150)\ttotal: 14.1s\tremaining: 1m 24s\n",
      "2200:\tlearn: 0.9115118\ttest: 1.5834655\tbest: 1.5831571 (2194)\ttotal: 14.4s\tremaining: 1m 23s\n",
      "2250:\tlearn: 0.8986852\ttest: 1.5758000\tbest: 1.5755224 (2249)\ttotal: 14.7s\tremaining: 1m 23s\n",
      "2300:\tlearn: 0.8844897\ttest: 1.5670488\tbest: 1.5670488 (2300)\ttotal: 15.1s\tremaining: 1m 23s\n",
      "2350:\tlearn: 0.8705784\ttest: 1.5635706\tbest: 1.5628929 (2349)\ttotal: 15.4s\tremaining: 1m 22s\n",
      "2400:\tlearn: 0.8582378\ttest: 1.5541019\tbest: 1.5541019 (2400)\ttotal: 15.7s\tremaining: 1m 22s\n",
      "2450:\tlearn: 0.8446761\ttest: 1.5477080\tbest: 1.5477080 (2450)\ttotal: 16.1s\tremaining: 1m 22s\n",
      "2500:\tlearn: 0.8302920\ttest: 1.5433847\tbest: 1.5416811 (2497)\ttotal: 16.4s\tremaining: 1m 21s\n",
      "2550:\tlearn: 0.8171881\ttest: 1.5363287\tbest: 1.5361836 (2547)\ttotal: 16.7s\tremaining: 1m 21s\n",
      "2600:\tlearn: 0.8064773\ttest: 1.5326604\tbest: 1.5326350 (2599)\ttotal: 17.1s\tremaining: 1m 21s\n",
      "2650:\tlearn: 0.7982802\ttest: 1.5308729\tbest: 1.5305343 (2617)\ttotal: 17.4s\tremaining: 1m 21s\n",
      "2700:\tlearn: 0.7867044\ttest: 1.5262051\tbest: 1.5262051 (2700)\ttotal: 17.7s\tremaining: 1m 20s\n",
      "2750:\tlearn: 0.7769464\ttest: 1.5255350\tbest: 1.5250065 (2743)\ttotal: 18.1s\tremaining: 1m 20s\n",
      "2800:\tlearn: 0.7640444\ttest: 1.5232799\tbest: 1.5226768 (2791)\ttotal: 18.4s\tremaining: 1m 20s\n",
      "2850:\tlearn: 0.7515760\ttest: 1.5160495\tbest: 1.5160495 (2850)\ttotal: 18.7s\tremaining: 1m 19s\n",
      "2900:\tlearn: 0.7411201\ttest: 1.5113655\tbest: 1.5107051 (2889)\ttotal: 19.1s\tremaining: 1m 19s\n",
      "2950:\tlearn: 0.7304750\ttest: 1.5032166\tbest: 1.5032166 (2950)\ttotal: 19.4s\tremaining: 1m 19s\n",
      "3000:\tlearn: 0.7188287\ttest: 1.4983622\tbest: 1.4981416 (2999)\ttotal: 19.7s\tremaining: 1m 18s\n",
      "3050:\tlearn: 0.7071017\ttest: 1.4937529\tbest: 1.4932786 (3047)\ttotal: 20.1s\tremaining: 1m 18s\n",
      "3100:\tlearn: 0.6961802\ttest: 1.4866861\tbest: 1.4866861 (3100)\ttotal: 20.4s\tremaining: 1m 18s\n",
      "3150:\tlearn: 0.6866119\ttest: 1.4827222\tbest: 1.4826062 (3147)\ttotal: 20.7s\tremaining: 1m 17s\n",
      "3200:\tlearn: 0.6772147\ttest: 1.4768440\tbest: 1.4767022 (3197)\ttotal: 21s\tremaining: 1m 17s\n",
      "3250:\tlearn: 0.6668905\ttest: 1.4726966\tbest: 1.4722540 (3247)\ttotal: 21.4s\tremaining: 1m 17s\n",
      "3300:\tlearn: 0.6560209\ttest: 1.4676448\tbest: 1.4675362 (3293)\ttotal: 21.7s\tremaining: 1m 16s\n",
      "3350:\tlearn: 0.6443144\ttest: 1.4570124\tbest: 1.4570124 (3350)\ttotal: 22s\tremaining: 1m 16s\n",
      "3400:\tlearn: 0.6330708\ttest: 1.4498240\tbest: 1.4496656 (3399)\ttotal: 22.4s\tremaining: 1m 16s\n",
      "3450:\tlearn: 0.6248215\ttest: 1.4476870\tbest: 1.4473887 (3438)\ttotal: 22.7s\tremaining: 1m 16s\n",
      "3500:\tlearn: 0.6149404\ttest: 1.4386346\tbest: 1.4381704 (3498)\ttotal: 23s\tremaining: 1m 15s\n",
      "3550:\tlearn: 0.6037789\ttest: 1.4345558\tbest: 1.4342515 (3548)\ttotal: 23.4s\tremaining: 1m 15s\n",
      "3600:\tlearn: 0.5944109\ttest: 1.4272193\tbest: 1.4272193 (3600)\ttotal: 23.7s\tremaining: 1m 15s\n",
      "3650:\tlearn: 0.5840486\ttest: 1.4182026\tbest: 1.4182026 (3650)\ttotal: 24.1s\tremaining: 1m 14s\n",
      "3700:\tlearn: 0.5751835\ttest: 1.4153469\tbest: 1.4140917 (3693)\ttotal: 24.4s\tremaining: 1m 14s\n",
      "3750:\tlearn: 0.5660707\ttest: 1.4120197\tbest: 1.4120031 (3749)\ttotal: 24.7s\tremaining: 1m 14s\n",
      "3800:\tlearn: 0.5578263\ttest: 1.4072050\tbest: 1.4072050 (3800)\ttotal: 25.1s\tremaining: 1m 13s\n",
      "3850:\tlearn: 0.5484836\ttest: 1.4055838\tbest: 1.4055675 (3822)\ttotal: 25.4s\tremaining: 1m 13s\n",
      "3900:\tlearn: 0.5393813\ttest: 1.4005606\tbest: 1.4005606 (3900)\ttotal: 25.7s\tremaining: 1m 13s\n",
      "3950:\tlearn: 0.5297736\ttest: 1.3970449\tbest: 1.3970449 (3950)\ttotal: 26s\tremaining: 1m 12s\n",
      "4000:\tlearn: 0.5204393\ttest: 1.3934691\tbest: 1.3934691 (4000)\ttotal: 26.4s\tremaining: 1m 12s\n",
      "4050:\tlearn: 0.5112827\ttest: 1.3916740\tbest: 1.3914753 (4049)\ttotal: 26.7s\tremaining: 1m 12s\n",
      "4100:\tlearn: 0.5026702\ttest: 1.3855120\tbest: 1.3854203 (4098)\ttotal: 27.1s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4924927\ttest: 1.3797170\tbest: 1.3789330 (4140)\ttotal: 27.4s\tremaining: 1m 11s\n",
      "4200:\tlearn: 0.4855013\ttest: 1.3759642\tbest: 1.3757771 (4194)\ttotal: 27.8s\tremaining: 1m 11s\n",
      "4250:\tlearn: 0.4771343\ttest: 1.3720518\tbest: 1.3716388 (4247)\ttotal: 28.1s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4686915\ttest: 1.3694978\tbest: 1.3690515 (4298)\ttotal: 28.4s\tremaining: 1m 10s\n",
      "4350:\tlearn: 0.4612062\ttest: 1.3681974\tbest: 1.3681974 (4350)\ttotal: 28.8s\tremaining: 1m 10s\n",
      "4400:\tlearn: 0.4546045\ttest: 1.3649775\tbest: 1.3649775 (4400)\ttotal: 29.1s\tremaining: 1m 10s\n",
      "4450:\tlearn: 0.4471794\ttest: 1.3626083\tbest: 1.3623425 (4447)\ttotal: 29.5s\tremaining: 1m 9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4399320\ttest: 1.3583570\tbest: 1.3582040 (4498)\ttotal: 29.8s\tremaining: 1m 9s\n",
      "4550:\tlearn: 0.4319736\ttest: 1.3548666\tbest: 1.3544470 (4548)\ttotal: 30.1s\tremaining: 1m 9s\n",
      "4600:\tlearn: 0.4254531\ttest: 1.3501160\tbest: 1.3501160 (4600)\ttotal: 30.5s\tremaining: 1m 8s\n",
      "4650:\tlearn: 0.4190900\ttest: 1.3470746\tbest: 1.3468976 (4646)\ttotal: 30.8s\tremaining: 1m 8s\n",
      "4700:\tlearn: 0.4110118\ttest: 1.3429336\tbest: 1.3428857 (4699)\ttotal: 31.1s\tremaining: 1m 8s\n",
      "4750:\tlearn: 0.4054865\ttest: 1.3418630\tbest: 1.3418630 (4750)\ttotal: 31.5s\tremaining: 1m 7s\n",
      "4800:\tlearn: 0.3990438\ttest: 1.3389386\tbest: 1.3389386 (4800)\ttotal: 31.8s\tremaining: 1m 7s\n",
      "4850:\tlearn: 0.3924159\ttest: 1.3356634\tbest: 1.3356634 (4850)\ttotal: 32.1s\tremaining: 1m 7s\n",
      "4900:\tlearn: 0.3864086\ttest: 1.3370605\tbest: 1.3354108 (4855)\ttotal: 32.5s\tremaining: 1m 6s\n",
      "4950:\tlearn: 0.3800022\ttest: 1.3353895\tbest: 1.3352523 (4947)\ttotal: 32.8s\tremaining: 1m 6s\n",
      "5000:\tlearn: 0.3725809\ttest: 1.3287249\tbest: 1.3286220 (4996)\ttotal: 33.1s\tremaining: 1m 6s\n",
      "5050:\tlearn: 0.3663711\ttest: 1.3272768\tbest: 1.3260918 (5025)\ttotal: 33.5s\tremaining: 1m 5s\n",
      "5100:\tlearn: 0.3609651\ttest: 1.3263010\tbest: 1.3260918 (5025)\ttotal: 33.8s\tremaining: 1m 5s\n",
      "5150:\tlearn: 0.3549156\ttest: 1.3217712\tbest: 1.3216298 (5149)\ttotal: 34.2s\tremaining: 1m 5s\n",
      "5200:\tlearn: 0.3491106\ttest: 1.3194463\tbest: 1.3187830 (5192)\ttotal: 34.5s\tremaining: 1m 4s\n",
      "5250:\tlearn: 0.3435620\ttest: 1.3189556\tbest: 1.3187077 (5210)\ttotal: 34.8s\tremaining: 1m 4s\n",
      "5300:\tlearn: 0.3375858\ttest: 1.3176972\tbest: 1.3165434 (5275)\ttotal: 35.2s\tremaining: 1m 4s\n",
      "5350:\tlearn: 0.3323367\ttest: 1.3159187\tbest: 1.3159187 (5350)\ttotal: 35.5s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3268464\ttest: 1.3143980\tbest: 1.3142849 (5397)\ttotal: 35.8s\tremaining: 1m 3s\n",
      "5450:\tlearn: 0.3224600\ttest: 1.3099535\tbest: 1.3099473 (5449)\ttotal: 36.2s\tremaining: 1m 3s\n",
      "5500:\tlearn: 0.3171547\ttest: 1.3068376\tbest: 1.3068376 (5500)\ttotal: 36.5s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3116467\ttest: 1.3032306\tbest: 1.3029834 (5549)\ttotal: 36.8s\tremaining: 1m 2s\n",
      "5600:\tlearn: 0.3066136\ttest: 1.2998957\tbest: 1.2998957 (5600)\ttotal: 37.2s\tremaining: 1m 2s\n",
      "5650:\tlearn: 0.3017493\ttest: 1.2960800\tbest: 1.2959731 (5644)\ttotal: 37.5s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.2975572\ttest: 1.2949906\tbest: 1.2944826 (5698)\ttotal: 37.8s\tremaining: 1m 1s\n",
      "5750:\tlearn: 0.2934422\ttest: 1.2913640\tbest: 1.2907832 (5745)\ttotal: 38.2s\tremaining: 1m 1s\n",
      "5800:\tlearn: 0.2884127\ttest: 1.2883532\tbest: 1.2883366 (5798)\ttotal: 38.5s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2838559\ttest: 1.2885829\tbest: 1.2880030 (5806)\ttotal: 38.8s\tremaining: 1m\n",
      "5900:\tlearn: 0.2797307\ttest: 1.2865977\tbest: 1.2865977 (5900)\ttotal: 39.2s\tremaining: 1m\n",
      "5950:\tlearn: 0.2755109\ttest: 1.2840365\tbest: 1.2835788 (5928)\ttotal: 39.5s\tremaining: 1m\n",
      "6000:\tlearn: 0.2712900\ttest: 1.2823445\tbest: 1.2821063 (5993)\ttotal: 39.9s\tremaining: 59.8s\n",
      "6050:\tlearn: 0.2675106\ttest: 1.2812951\tbest: 1.2808369 (6038)\ttotal: 40.2s\tremaining: 59.4s\n",
      "6100:\tlearn: 0.2632016\ttest: 1.2779443\tbest: 1.2779443 (6100)\ttotal: 40.5s\tremaining: 59.1s\n",
      "6150:\tlearn: 0.2590056\ttest: 1.2770666\tbest: 1.2770404 (6148)\ttotal: 40.9s\tremaining: 58.8s\n",
      "6200:\tlearn: 0.2553508\ttest: 1.2777917\tbest: 1.2770182 (6152)\ttotal: 41.2s\tremaining: 58.4s\n",
      "6250:\tlearn: 0.2512723\ttest: 1.2756674\tbest: 1.2754830 (6246)\ttotal: 41.5s\tremaining: 58.1s\n",
      "6300:\tlearn: 0.2471301\ttest: 1.2753341\tbest: 1.2751823 (6298)\ttotal: 41.9s\tremaining: 57.8s\n",
      "6350:\tlearn: 0.2436292\ttest: 1.2737819\tbest: 1.2737819 (6350)\ttotal: 42.2s\tremaining: 57.4s\n",
      "6400:\tlearn: 0.2399566\ttest: 1.2712379\tbest: 1.2708489 (6384)\ttotal: 42.5s\tremaining: 57.1s\n",
      "6450:\tlearn: 0.2359043\ttest: 1.2704467\tbest: 1.2696274 (6428)\ttotal: 42.9s\tremaining: 56.8s\n",
      "6500:\tlearn: 0.2323575\ttest: 1.2706919\tbest: 1.2696274 (6428)\ttotal: 43.2s\tremaining: 56.5s\n",
      "6550:\tlearn: 0.2283223\ttest: 1.2669513\tbest: 1.2669513 (6550)\ttotal: 43.5s\tremaining: 56.2s\n",
      "6600:\tlearn: 0.2245281\ttest: 1.2652020\tbest: 1.2650726 (6597)\ttotal: 43.9s\tremaining: 55.8s\n",
      "6650:\tlearn: 0.2207375\ttest: 1.2648919\tbest: 1.2638600 (6613)\ttotal: 44.2s\tremaining: 55.5s\n",
      "6700:\tlearn: 0.2171363\ttest: 1.2646400\tbest: 1.2638600 (6613)\ttotal: 44.5s\tremaining: 55.2s\n",
      "6750:\tlearn: 0.2137864\ttest: 1.2632755\tbest: 1.2630391 (6749)\ttotal: 44.9s\tremaining: 54.8s\n",
      "6800:\tlearn: 0.2104262\ttest: 1.2609502\tbest: 1.2609502 (6800)\ttotal: 45.2s\tremaining: 54.5s\n",
      "6850:\tlearn: 0.2075659\ttest: 1.2591276\tbest: 1.2591276 (6850)\ttotal: 45.5s\tremaining: 54.2s\n",
      "6900:\tlearn: 0.2043300\ttest: 1.2582490\tbest: 1.2579985 (6899)\ttotal: 45.9s\tremaining: 53.8s\n",
      "6950:\tlearn: 0.2014908\ttest: 1.2588557\tbest: 1.2579900 (6906)\ttotal: 46.2s\tremaining: 53.5s\n",
      "7000:\tlearn: 0.1989122\ttest: 1.2576412\tbest: 1.2573876 (6990)\ttotal: 46.5s\tremaining: 53.2s\n",
      "7050:\tlearn: 0.1960258\ttest: 1.2554896\tbest: 1.2553268 (7046)\ttotal: 46.9s\tremaining: 52.9s\n",
      "7100:\tlearn: 0.1931753\ttest: 1.2541427\tbest: 1.2538758 (7075)\ttotal: 47.2s\tremaining: 52.5s\n",
      "7150:\tlearn: 0.1903674\ttest: 1.2524493\tbest: 1.2524493 (7150)\ttotal: 47.5s\tremaining: 52.2s\n",
      "7200:\tlearn: 0.1872300\ttest: 1.2497673\tbest: 1.2494243 (7198)\ttotal: 47.9s\tremaining: 51.9s\n",
      "7250:\tlearn: 0.1843624\ttest: 1.2514997\tbest: 1.2494243 (7198)\ttotal: 48.2s\tremaining: 51.5s\n",
      "7300:\tlearn: 0.1815901\ttest: 1.2500913\tbest: 1.2494243 (7198)\ttotal: 48.6s\tremaining: 51.2s\n",
      "7350:\tlearn: 0.1786586\ttest: 1.2492205\tbest: 1.2486370 (7334)\ttotal: 48.9s\tremaining: 50.9s\n",
      "7400:\tlearn: 0.1759271\ttest: 1.2482829\tbest: 1.2482829 (7400)\ttotal: 49.2s\tremaining: 50.5s\n",
      "7450:\tlearn: 0.1735399\ttest: 1.2453459\tbest: 1.2453459 (7450)\ttotal: 49.5s\tremaining: 50.2s\n",
      "7500:\tlearn: 0.1711134\ttest: 1.2433246\tbest: 1.2432584 (7495)\ttotal: 49.9s\tremaining: 49.9s\n",
      "7550:\tlearn: 0.1684994\ttest: 1.2434183\tbest: 1.2429991 (7506)\ttotal: 50.2s\tremaining: 49.5s\n",
      "7600:\tlearn: 0.1656945\ttest: 1.2432845\tbest: 1.2421611 (7577)\ttotal: 50.5s\tremaining: 49.2s\n",
      "7650:\tlearn: 0.1633237\ttest: 1.2431482\tbest: 1.2421611 (7577)\ttotal: 50.9s\tremaining: 48.9s\n",
      "7700:\tlearn: 0.1608347\ttest: 1.2425808\tbest: 1.2421611 (7577)\ttotal: 51.2s\tremaining: 48.5s\n",
      "7750:\tlearn: 0.1589726\ttest: 1.2425882\tbest: 1.2418254 (7722)\ttotal: 51.5s\tremaining: 48.2s\n",
      "7800:\tlearn: 0.1560843\ttest: 1.2405666\tbest: 1.2400298 (7784)\ttotal: 51.9s\tremaining: 47.9s\n",
      "7850:\tlearn: 0.1538611\ttest: 1.2396694\tbest: 1.2396650 (7849)\ttotal: 52.2s\tremaining: 47.5s\n",
      "7900:\tlearn: 0.1519411\ttest: 1.2383349\tbest: 1.2380446 (7875)\ttotal: 52.5s\tremaining: 47.2s\n",
      "7950:\tlearn: 0.1493961\ttest: 1.2395789\tbest: 1.2380446 (7875)\ttotal: 52.9s\tremaining: 46.9s\n",
      "8000:\tlearn: 0.1468690\ttest: 1.2376506\tbest: 1.2376506 (8000)\ttotal: 53.2s\tremaining: 46.5s\n",
      "8050:\tlearn: 0.1444758\ttest: 1.2374578\tbest: 1.2369567 (8039)\ttotal: 53.6s\tremaining: 46.2s\n",
      "8100:\tlearn: 0.1422540\ttest: 1.2363092\tbest: 1.2363092 (8100)\ttotal: 53.9s\tremaining: 45.9s\n",
      "8150:\tlearn: 0.1399996\ttest: 1.2368508\tbest: 1.2360289 (8125)\ttotal: 54.2s\tremaining: 45.6s\n",
      "8200:\tlearn: 0.1379006\ttest: 1.2368822\tbest: 1.2360289 (8125)\ttotal: 54.6s\tremaining: 45.2s\n",
      "8250:\tlearn: 0.1357649\ttest: 1.2379173\tbest: 1.2360289 (8125)\ttotal: 54.9s\tremaining: 44.9s\n",
      "8300:\tlearn: 0.1336861\ttest: 1.2370408\tbest: 1.2360289 (8125)\ttotal: 55.2s\tremaining: 44.6s\n",
      "8350:\tlearn: 0.1318204\ttest: 1.2364904\tbest: 1.2360289 (8125)\ttotal: 55.6s\tremaining: 44.2s\n",
      "8400:\tlearn: 0.1300213\ttest: 1.2356738\tbest: 1.2353641 (8388)\ttotal: 55.9s\tremaining: 43.9s\n",
      "8450:\tlearn: 0.1278993\ttest: 1.2347616\tbest: 1.2347616 (8450)\ttotal: 56.2s\tremaining: 43.6s\n",
      "8500:\tlearn: 0.1260586\ttest: 1.2331583\tbest: 1.2331583 (8500)\ttotal: 56.6s\tremaining: 43.3s\n",
      "8550:\tlearn: 0.1244083\ttest: 1.2342770\tbest: 1.2326838 (8503)\ttotal: 56.9s\tremaining: 42.9s\n",
      "8600:\tlearn: 0.1224600\ttest: 1.2329192\tbest: 1.2326838 (8503)\ttotal: 57.2s\tremaining: 42.6s\n",
      "8650:\tlearn: 0.1203138\ttest: 1.2323296\tbest: 1.2319245 (8642)\ttotal: 57.6s\tremaining: 42.3s\n",
      "8700:\tlearn: 0.1184102\ttest: 1.2318822\tbest: 1.2311539 (8691)\ttotal: 57.9s\tremaining: 41.9s\n",
      "8750:\tlearn: 0.1162493\ttest: 1.2298652\tbest: 1.2298142 (8749)\ttotal: 58.3s\tremaining: 41.6s\n",
      "8800:\tlearn: 0.1139495\ttest: 1.2274121\tbest: 1.2274121 (8800)\ttotal: 58.6s\tremaining: 41.3s\n",
      "8850:\tlearn: 0.1123664\ttest: 1.2263297\tbest: 1.2261135 (8842)\ttotal: 58.9s\tremaining: 40.9s\n",
      "8900:\tlearn: 0.1106184\ttest: 1.2242631\tbest: 1.2240686 (8889)\ttotal: 59.3s\tremaining: 40.6s\n",
      "8950:\tlearn: 0.1088497\ttest: 1.2244217\tbest: 1.2237874 (8915)\ttotal: 59.6s\tremaining: 40.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000:\tlearn: 0.1067966\ttest: 1.2234220\tbest: 1.2229912 (8988)\ttotal: 59.9s\tremaining: 40s\n",
      "9050:\tlearn: 0.1053647\ttest: 1.2239537\tbest: 1.2229912 (8988)\ttotal: 1m\tremaining: 39.6s\n",
      "9100:\tlearn: 0.1037603\ttest: 1.2223958\tbest: 1.2222169 (9097)\ttotal: 1m\tremaining: 39.3s\n",
      "9150:\tlearn: 0.1022802\ttest: 1.2221124\tbest: 1.2221124 (9150)\ttotal: 1m\tremaining: 39s\n",
      "9200:\tlearn: 0.1005302\ttest: 1.2210805\tbest: 1.2205126 (9193)\ttotal: 1m 1s\tremaining: 38.6s\n",
      "9250:\tlearn: 0.0989087\ttest: 1.2195518\tbest: 1.2195094 (9245)\ttotal: 1m 1s\tremaining: 38.3s\n",
      "9300:\tlearn: 0.0973834\ttest: 1.2185448\tbest: 1.2183966 (9297)\ttotal: 1m 1s\tremaining: 38s\n",
      "9350:\tlearn: 0.0958162\ttest: 1.2166454\tbest: 1.2164073 (9346)\ttotal: 1m 2s\tremaining: 37.6s\n",
      "9400:\tlearn: 0.0945618\ttest: 1.2155741\tbest: 1.2155644 (9396)\ttotal: 1m 2s\tremaining: 37.3s\n",
      "9450:\tlearn: 0.0930144\ttest: 1.2170025\tbest: 1.2153821 (9407)\ttotal: 1m 2s\tremaining: 37s\n",
      "9500:\tlearn: 0.0915226\ttest: 1.2164237\tbest: 1.2153821 (9407)\ttotal: 1m 3s\tremaining: 36.6s\n",
      "9550:\tlearn: 0.0899334\ttest: 1.2158197\tbest: 1.2153821 (9407)\ttotal: 1m 3s\tremaining: 36.3s\n",
      "9600:\tlearn: 0.0885237\ttest: 1.2155552\tbest: 1.2153821 (9407)\ttotal: 1m 3s\tremaining: 36s\n",
      "9650:\tlearn: 0.0869468\ttest: 1.2147538\tbest: 1.2145329 (9641)\ttotal: 1m 4s\tremaining: 35.6s\n",
      "9700:\tlearn: 0.0855334\ttest: 1.2142289\tbest: 1.2139886 (9696)\ttotal: 1m 4s\tremaining: 35.3s\n",
      "9750:\tlearn: 0.0841273\ttest: 1.2136848\tbest: 1.2133501 (9749)\ttotal: 1m 4s\tremaining: 35s\n",
      "9800:\tlearn: 0.0828763\ttest: 1.2142445\tbest: 1.2130245 (9760)\ttotal: 1m 5s\tremaining: 34.6s\n",
      "9850:\tlearn: 0.0815114\ttest: 1.2153271\tbest: 1.2130245 (9760)\ttotal: 1m 5s\tremaining: 34.3s\n",
      "9900:\tlearn: 0.0802611\ttest: 1.2149409\tbest: 1.2130245 (9760)\ttotal: 1m 5s\tremaining: 34s\n",
      "9950:\tlearn: 0.0788269\ttest: 1.2154046\tbest: 1.2130245 (9760)\ttotal: 1m 6s\tremaining: 33.7s\n",
      "10000:\tlearn: 0.0776131\ttest: 1.2135860\tbest: 1.2130245 (9760)\ttotal: 1m 6s\tremaining: 33.3s\n",
      "10050:\tlearn: 0.0764174\ttest: 1.2127254\tbest: 1.2126356 (10049)\ttotal: 1m 6s\tremaining: 33s\n",
      "10100:\tlearn: 0.0752665\ttest: 1.2121760\tbest: 1.2118636 (10069)\ttotal: 1m 7s\tremaining: 32.7s\n",
      "10150:\tlearn: 0.0742039\ttest: 1.2126947\tbest: 1.2118636 (10069)\ttotal: 1m 7s\tremaining: 32.3s\n",
      "10200:\tlearn: 0.0729273\ttest: 1.2142632\tbest: 1.2118636 (10069)\ttotal: 1m 7s\tremaining: 32s\n",
      "10250:\tlearn: 0.0717619\ttest: 1.2145820\tbest: 1.2118636 (10069)\ttotal: 1m 8s\tremaining: 31.7s\n",
      "10300:\tlearn: 0.0704291\ttest: 1.2140806\tbest: 1.2118636 (10069)\ttotal: 1m 8s\tremaining: 31.3s\n",
      "10350:\tlearn: 0.0692423\ttest: 1.2142940\tbest: 1.2118636 (10069)\ttotal: 1m 9s\tremaining: 31s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.211863553\n",
      "bestIteration = 10069\n",
      "\n",
      "Shrink model to first 10070 iterations.\n",
      "Скор для фолда(7) : 9.0 средний скор на префиксе = 9.0 это заняло = 69 сек.\n",
      "Фолд: 8\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.6208332\ttest: 3.4494664\tbest: 3.4494664 (0)\ttotal: 94.2ms\tremaining: 23m 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7574633\ttest: 2.5146981\tbest: 2.5146981 (50)\ttotal: 431ms\tremaining: 2m 6s\n",
      "100:\tlearn: 2.2932395\ttest: 2.0000594\tbest: 2.0000594 (100)\ttotal: 761ms\tremaining: 1m 52s\n",
      "150:\tlearn: 2.0436981\ttest: 1.7300870\tbest: 1.7300870 (150)\ttotal: 1.1s\tremaining: 1m 48s\n",
      "200:\tlearn: 1.8818438\ttest: 1.5817109\tbest: 1.5817109 (200)\ttotal: 1.44s\tremaining: 1m 45s\n",
      "250:\tlearn: 1.7760437\ttest: 1.4935886\tbest: 1.4935886 (250)\ttotal: 1.77s\tremaining: 1m 44s\n",
      "300:\tlearn: 1.6955742\ttest: 1.4302074\tbest: 1.4302074 (300)\ttotal: 2.11s\tremaining: 1m 43s\n",
      "350:\tlearn: 1.6330714\ttest: 1.3924927\tbest: 1.3924927 (350)\ttotal: 2.46s\tremaining: 1m 42s\n",
      "400:\tlearn: 1.5850729\ttest: 1.3607099\tbest: 1.3607099 (400)\ttotal: 2.79s\tremaining: 1m 41s\n",
      "450:\tlearn: 1.5451374\ttest: 1.3418963\tbest: 1.3418343 (448)\ttotal: 3.12s\tremaining: 1m 40s\n",
      "500:\tlearn: 1.5084068\ttest: 1.3148962\tbest: 1.3148962 (500)\ttotal: 3.46s\tremaining: 1m 40s\n",
      "550:\tlearn: 1.4745476\ttest: 1.3070704\tbest: 1.3062523 (545)\ttotal: 3.79s\tremaining: 1m 39s\n",
      "600:\tlearn: 1.4467619\ttest: 1.2967919\tbest: 1.2967919 (600)\ttotal: 4.12s\tremaining: 1m 38s\n",
      "650:\tlearn: 1.4209298\ttest: 1.2830909\tbest: 1.2829893 (647)\ttotal: 4.46s\tremaining: 1m 38s\n",
      "700:\tlearn: 1.3985486\ttest: 1.2747928\tbest: 1.2747830 (698)\ttotal: 4.79s\tremaining: 1m 37s\n",
      "750:\tlearn: 1.3781989\ttest: 1.2692351\tbest: 1.2692351 (750)\ttotal: 5.13s\tremaining: 1m 37s\n",
      "800:\tlearn: 1.3580937\ttest: 1.2673477\tbest: 1.2639537 (773)\ttotal: 5.46s\tremaining: 1m 36s\n",
      "850:\tlearn: 1.3370211\ttest: 1.2614340\tbest: 1.2589054 (840)\ttotal: 5.79s\tremaining: 1m 36s\n",
      "900:\tlearn: 1.3187601\ttest: 1.2661899\tbest: 1.2589054 (840)\ttotal: 6.13s\tremaining: 1m 35s\n",
      "950:\tlearn: 1.3003910\ttest: 1.2608446\tbest: 1.2589054 (840)\ttotal: 6.46s\tremaining: 1m 35s\n",
      "1000:\tlearn: 1.2828613\ttest: 1.2571026\tbest: 1.2561146 (988)\ttotal: 6.78s\tremaining: 1m 34s\n",
      "1050:\tlearn: 1.2633137\ttest: 1.2518110\tbest: 1.2515231 (1045)\ttotal: 7.12s\tremaining: 1m 34s\n",
      "1100:\tlearn: 1.2451215\ttest: 1.2489085\tbest: 1.2476079 (1097)\ttotal: 7.45s\tremaining: 1m 34s\n",
      "1150:\tlearn: 1.2251159\ttest: 1.2468637\tbest: 1.2457459 (1130)\ttotal: 7.78s\tremaining: 1m 33s\n",
      "1200:\tlearn: 1.2047309\ttest: 1.2465432\tbest: 1.2455707 (1168)\ttotal: 8.12s\tremaining: 1m 33s\n",
      "1250:\tlearn: 1.1891786\ttest: 1.2401258\tbest: 1.2397798 (1248)\ttotal: 8.45s\tremaining: 1m 32s\n",
      "1300:\tlearn: 1.1711446\ttest: 1.2330519\tbest: 1.2330519 (1300)\ttotal: 8.77s\tremaining: 1m 32s\n",
      "1350:\tlearn: 1.1554644\ttest: 1.2269010\tbest: 1.2268017 (1349)\ttotal: 9.11s\tremaining: 1m 32s\n",
      "1400:\tlearn: 1.1413594\ttest: 1.2187154\tbest: 1.2186934 (1399)\ttotal: 9.44s\tremaining: 1m 31s\n",
      "1450:\tlearn: 1.1245802\ttest: 1.2185766\tbest: 1.2154966 (1438)\ttotal: 9.77s\tremaining: 1m 31s\n",
      "1500:\tlearn: 1.1102278\ttest: 1.2166911\tbest: 1.2154966 (1438)\ttotal: 10.1s\tremaining: 1m 30s\n",
      "1550:\tlearn: 1.0946076\ttest: 1.2089235\tbest: 1.2088548 (1549)\ttotal: 10.4s\tremaining: 1m 30s\n",
      "1600:\tlearn: 1.0798037\ttest: 1.2062232\tbest: 1.2048865 (1595)\ttotal: 10.8s\tremaining: 1m 30s\n",
      "1650:\tlearn: 1.0649295\ttest: 1.1988780\tbest: 1.1988780 (1650)\ttotal: 11.1s\tremaining: 1m 29s\n",
      "1700:\tlearn: 1.0514345\ttest: 1.1925862\tbest: 1.1921386 (1696)\ttotal: 11.4s\tremaining: 1m 29s\n",
      "1750:\tlearn: 1.0373542\ttest: 1.1879119\tbest: 1.1878942 (1749)\ttotal: 11.8s\tremaining: 1m 28s\n",
      "1800:\tlearn: 1.0229174\ttest: 1.1853860\tbest: 1.1846986 (1797)\ttotal: 12.1s\tremaining: 1m 28s\n",
      "1850:\tlearn: 1.0082617\ttest: 1.1873587\tbest: 1.1840848 (1812)\ttotal: 12.4s\tremaining: 1m 28s\n",
      "1900:\tlearn: 0.9947539\ttest: 1.1881303\tbest: 1.1840848 (1812)\ttotal: 12.8s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9807841\ttest: 1.1867240\tbest: 1.1840848 (1812)\ttotal: 13.1s\tremaining: 1m 27s\n",
      "2000:\tlearn: 0.9674615\ttest: 1.1855504\tbest: 1.1840848 (1812)\ttotal: 13.4s\tremaining: 1m 27s\n",
      "2050:\tlearn: 0.9547756\ttest: 1.1841521\tbest: 1.1840848 (1812)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.9411649\ttest: 1.1813249\tbest: 1.1811979 (2098)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "2150:\tlearn: 0.9273820\ttest: 1.1784236\tbest: 1.1782215 (2149)\ttotal: 14.4s\tremaining: 1m 26s\n",
      "2200:\tlearn: 0.9151341\ttest: 1.1776040\tbest: 1.1762981 (2172)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.9006652\ttest: 1.1728559\tbest: 1.1728559 (2250)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "2300:\tlearn: 0.8862803\ttest: 1.1722700\tbest: 1.1722641 (2299)\ttotal: 15.4s\tremaining: 1m 25s\n",
      "2350:\tlearn: 0.8738893\ttest: 1.1702864\tbest: 1.1701633 (2345)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8610874\ttest: 1.1653423\tbest: 1.1652577 (2396)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "2450:\tlearn: 0.8511805\ttest: 1.1631083\tbest: 1.1621819 (2446)\ttotal: 16.4s\tremaining: 1m 24s\n",
      "2500:\tlearn: 0.8410080\ttest: 1.1600605\tbest: 1.1599614 (2489)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.8284580\ttest: 1.1599360\tbest: 1.1583716 (2538)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "2600:\tlearn: 0.8161423\ttest: 1.1616877\tbest: 1.1583716 (2538)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "2650:\tlearn: 0.8052147\ttest: 1.1585496\tbest: 1.1583716 (2538)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7922356\ttest: 1.1569630\tbest: 1.1568432 (2699)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "2750:\tlearn: 0.7804199\ttest: 1.1530419\tbest: 1.1530419 (2750)\ttotal: 18.5s\tremaining: 1m 22s\n",
      "2800:\tlearn: 0.7703259\ttest: 1.1490495\tbest: 1.1490086 (2798)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.7587506\ttest: 1.1492165\tbest: 1.1470137 (2831)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "2900:\tlearn: 0.7480658\ttest: 1.1480366\tbest: 1.1470137 (2831)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "2950:\tlearn: 0.7371069\ttest: 1.1459620\tbest: 1.1456228 (2936)\ttotal: 19.8s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.7281312\ttest: 1.1465122\tbest: 1.1455026 (2980)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "3050:\tlearn: 0.7172938\ttest: 1.1445464\tbest: 1.1444693 (3049)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "3100:\tlearn: 0.7070322\ttest: 1.1419802\tbest: 1.1418397 (3097)\ttotal: 20.8s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6976793\ttest: 1.1414364\tbest: 1.1400425 (3135)\ttotal: 21.1s\tremaining: 1m 19s\n",
      "3200:\tlearn: 0.6887727\ttest: 1.1392427\tbest: 1.1388834 (3196)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "3250:\tlearn: 0.6791751\ttest: 1.1376448\tbest: 1.1376448 (3250)\ttotal: 21.8s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6696853\ttest: 1.1358439\tbest: 1.1358439 (3300)\ttotal: 22.1s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.6606290\ttest: 1.1343139\tbest: 1.1343139 (3350)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "3400:\tlearn: 0.6510885\ttest: 1.1320572\tbest: 1.1319236 (3397)\ttotal: 22.8s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.6413942\ttest: 1.1329781\tbest: 1.1319236 (3397)\ttotal: 23.2s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.6329791\ttest: 1.1343542\tbest: 1.1318864 (3467)\ttotal: 23.5s\tremaining: 1m 17s\n",
      "3550:\tlearn: 0.6225161\ttest: 1.1302758\tbest: 1.1301181 (3547)\ttotal: 23.8s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.6119763\ttest: 1.1292436\tbest: 1.1285023 (3593)\ttotal: 24.2s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.6022176\ttest: 1.1273372\tbest: 1.1272820 (3644)\ttotal: 24.5s\tremaining: 1m 16s\n",
      "3700:\tlearn: 0.5936035\ttest: 1.1254058\tbest: 1.1253831 (3699)\ttotal: 24.8s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5854255\ttest: 1.1238575\tbest: 1.1235608 (3723)\ttotal: 25.2s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5775357\ttest: 1.1240943\tbest: 1.1235608 (3723)\ttotal: 25.5s\tremaining: 1m 15s\n",
      "3850:\tlearn: 0.5680757\ttest: 1.1219406\tbest: 1.1218604 (3845)\ttotal: 25.8s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5600902\ttest: 1.1203291\tbest: 1.1194272 (3885)\ttotal: 26.2s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.5509012\ttest: 1.1169465\tbest: 1.1169465 (3950)\ttotal: 26.5s\tremaining: 1m 14s\n",
      "4000:\tlearn: 0.5426643\ttest: 1.1162062\tbest: 1.1159360 (3997)\ttotal: 26.8s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.5350348\ttest: 1.1133944\tbest: 1.1132719 (4048)\ttotal: 27.2s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.5279928\ttest: 1.1119110\tbest: 1.1118278 (4087)\ttotal: 27.5s\tremaining: 1m 13s\n",
      "4150:\tlearn: 0.5203281\ttest: 1.1114946\tbest: 1.1109665 (4138)\ttotal: 27.9s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.5126830\ttest: 1.1088783\tbest: 1.1088783 (4200)\ttotal: 28.2s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.5050292\ttest: 1.1110809\tbest: 1.1083282 (4214)\ttotal: 28.5s\tremaining: 1m 12s\n",
      "4300:\tlearn: 0.4982166\ttest: 1.1113205\tbest: 1.1083282 (4214)\ttotal: 28.9s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4911615\ttest: 1.1101686\tbest: 1.1083282 (4214)\ttotal: 29.2s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4847910\ttest: 1.1086790\tbest: 1.1083282 (4214)\ttotal: 29.5s\tremaining: 1m 11s\n",
      "4450:\tlearn: 0.4771040\ttest: 1.1068800\tbest: 1.1067722 (4448)\ttotal: 29.9s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4703634\ttest: 1.1053717\tbest: 1.1050284 (4487)\ttotal: 30.2s\tremaining: 1m 10s\n",
      "4550:\tlearn: 0.4638732\ttest: 1.1021753\tbest: 1.1021331 (4545)\ttotal: 30.5s\tremaining: 1m 10s\n",
      "4600:\tlearn: 0.4582376\ttest: 1.1022477\tbest: 1.1017428 (4576)\ttotal: 30.9s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4517660\ttest: 1.1014398\tbest: 1.1014398 (4650)\ttotal: 31.2s\tremaining: 1m 9s\n",
      "4700:\tlearn: 0.4446237\ttest: 1.1028289\tbest: 1.1010505 (4672)\ttotal: 31.5s\tremaining: 1m 9s\n",
      "4750:\tlearn: 0.4373838\ttest: 1.1014304\tbest: 1.1006578 (4743)\ttotal: 31.9s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.4316617\ttest: 1.0993578\tbest: 1.0993578 (4800)\ttotal: 32.2s\tremaining: 1m 8s\n",
      "4850:\tlearn: 0.4249985\ttest: 1.0963521\tbest: 1.0963521 (4850)\ttotal: 32.5s\tremaining: 1m 8s\n",
      "4900:\tlearn: 0.4197808\ttest: 1.0962184\tbest: 1.0954658 (4880)\ttotal: 32.9s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.4135512\ttest: 1.0965588\tbest: 1.0954658 (4880)\ttotal: 33.2s\tremaining: 1m 7s\n",
      "5000:\tlearn: 0.4080907\ttest: 1.0962824\tbest: 1.0954658 (4880)\ttotal: 33.5s\tremaining: 1m 7s\n",
      "5050:\tlearn: 0.4009673\ttest: 1.0973316\tbest: 1.0954658 (4880)\ttotal: 33.9s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3951872\ttest: 1.0964720\tbest: 1.0954658 (4880)\ttotal: 34.2s\tremaining: 1m 6s\n",
      "5150:\tlearn: 0.3899311\ttest: 1.0940239\tbest: 1.0937916 (5145)\ttotal: 34.5s\tremaining: 1m 6s\n",
      "5200:\tlearn: 0.3834763\ttest: 1.0938265\tbest: 1.0936921 (5182)\ttotal: 34.9s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3785919\ttest: 1.0933393\tbest: 1.0927518 (5216)\ttotal: 35.2s\tremaining: 1m 5s\n",
      "5300:\tlearn: 0.3730616\ttest: 1.0921480\tbest: 1.0911217 (5286)\ttotal: 35.5s\tremaining: 1m 5s\n",
      "5350:\tlearn: 0.3678595\ttest: 1.0917563\tbest: 1.0911217 (5286)\ttotal: 35.9s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3628805\ttest: 1.0907168\tbest: 1.0905014 (5389)\ttotal: 36.2s\tremaining: 1m 4s\n",
      "5450:\tlearn: 0.3580903\ttest: 1.0914859\tbest: 1.0905014 (5389)\ttotal: 36.5s\tremaining: 1m 4s\n",
      "5500:\tlearn: 0.3527198\ttest: 1.0897668\tbest: 1.0895471 (5486)\ttotal: 36.9s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3480225\ttest: 1.0886532\tbest: 1.0880788 (5519)\ttotal: 37.2s\tremaining: 1m 3s\n",
      "5600:\tlearn: 0.3426749\ttest: 1.0866119\tbest: 1.0860948 (5589)\ttotal: 37.6s\tremaining: 1m 3s\n",
      "5650:\tlearn: 0.3369873\ttest: 1.0845397\tbest: 1.0845397 (5650)\ttotal: 37.9s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.3322244\ttest: 1.0845558\tbest: 1.0832396 (5685)\ttotal: 38.2s\tremaining: 1m 2s\n",
      "5750:\tlearn: 0.3272356\ttest: 1.0848417\tbest: 1.0832396 (5685)\ttotal: 38.6s\tremaining: 1m 2s\n",
      "5800:\tlearn: 0.3219188\ttest: 1.0859267\tbest: 1.0832396 (5685)\ttotal: 38.9s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.3173311\ttest: 1.0849187\tbest: 1.0832396 (5685)\ttotal: 39.2s\tremaining: 1m 1s\n",
      "5900:\tlearn: 0.3126561\ttest: 1.0843432\tbest: 1.0832396 (5685)\ttotal: 39.6s\tremaining: 1m 1s\n",
      "5950:\tlearn: 0.3080828\ttest: 1.0825982\tbest: 1.0821261 (5947)\ttotal: 39.9s\tremaining: 1m\n",
      "6000:\tlearn: 0.3037196\ttest: 1.0823090\tbest: 1.0818135 (5996)\ttotal: 40.3s\tremaining: 1m\n",
      "6050:\tlearn: 0.2989030\ttest: 1.0807175\tbest: 1.0807034 (6039)\ttotal: 40.6s\tremaining: 1m\n",
      "6100:\tlearn: 0.2943712\ttest: 1.0804819\tbest: 1.0796259 (6085)\ttotal: 40.9s\tremaining: 59.7s\n",
      "6150:\tlearn: 0.2898964\ttest: 1.0815303\tbest: 1.0796259 (6085)\ttotal: 41.3s\tremaining: 59.4s\n",
      "6200:\tlearn: 0.2855764\ttest: 1.0789414\tbest: 1.0789414 (6200)\ttotal: 41.6s\tremaining: 59s\n",
      "6250:\tlearn: 0.2809341\ttest: 1.0793751\tbest: 1.0789141 (6247)\ttotal: 42s\tremaining: 58.7s\n",
      "6300:\tlearn: 0.2768470\ttest: 1.0782069\tbest: 1.0777495 (6292)\ttotal: 42.3s\tremaining: 58.4s\n",
      "6350:\tlearn: 0.2734511\ttest: 1.0802734\tbest: 1.0777495 (6292)\ttotal: 42.6s\tremaining: 58s\n",
      "6400:\tlearn: 0.2692277\ttest: 1.0780190\tbest: 1.0777495 (6292)\ttotal: 43s\tremaining: 57.7s\n",
      "6450:\tlearn: 0.2647016\ttest: 1.0765602\tbest: 1.0765602 (6450)\ttotal: 43.3s\tremaining: 57.4s\n",
      "6500:\tlearn: 0.2602189\ttest: 1.0774696\tbest: 1.0762082 (6476)\ttotal: 43.6s\tremaining: 57s\n",
      "6550:\tlearn: 0.2564405\ttest: 1.0783439\tbest: 1.0762082 (6476)\ttotal: 44s\tremaining: 56.7s\n",
      "6600:\tlearn: 0.2526830\ttest: 1.0780822\tbest: 1.0762082 (6476)\ttotal: 44.3s\tremaining: 56.4s\n",
      "6650:\tlearn: 0.2485559\ttest: 1.0767896\tbest: 1.0762082 (6476)\ttotal: 44.6s\tremaining: 56s\n",
      "6700:\tlearn: 0.2448897\ttest: 1.0767252\tbest: 1.0760147 (6666)\ttotal: 45s\tremaining: 55.7s\n",
      "6750:\tlearn: 0.2405551\ttest: 1.0762078\tbest: 1.0760147 (6666)\ttotal: 45.3s\tremaining: 55.4s\n",
      "6800:\tlearn: 0.2366041\ttest: 1.0766225\tbest: 1.0751023 (6763)\ttotal: 45.7s\tremaining: 55s\n",
      "6850:\tlearn: 0.2336423\ttest: 1.0768623\tbest: 1.0751023 (6763)\ttotal: 46s\tremaining: 54.7s\n",
      "6900:\tlearn: 0.2304385\ttest: 1.0767721\tbest: 1.0751023 (6763)\ttotal: 46.3s\tremaining: 54.4s\n",
      "6950:\tlearn: 0.2269370\ttest: 1.0768576\tbest: 1.0751023 (6763)\ttotal: 46.7s\tremaining: 54s\n",
      "7000:\tlearn: 0.2241354\ttest: 1.0765825\tbest: 1.0751023 (6763)\ttotal: 47s\tremaining: 53.7s\n",
      "7050:\tlearn: 0.2212014\ttest: 1.0787710\tbest: 1.0751023 (6763)\ttotal: 47.3s\tremaining: 53.4s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.075102343\n",
      "bestIteration = 6763\n",
      "\n",
      "Shrink model to first 6764 iterations.\n",
      "Скор для фолда(8) : 9.0 средний скор на префиксе = 9.0 это заняло = 47 сек.\n",
      "Фолд: 9\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.5856830\ttest: 3.7247991\tbest: 3.7247991 (0)\ttotal: 26ms\tremaining: 6m 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7209749\ttest: 2.7966431\tbest: 2.7966431 (50)\ttotal: 361ms\tremaining: 1m 45s\n",
      "100:\tlearn: 2.2645992\ttest: 2.2427081\tbest: 2.2427081 (100)\ttotal: 697ms\tremaining: 1m 42s\n",
      "150:\tlearn: 2.0108544\ttest: 1.9295393\tbest: 1.9295393 (150)\ttotal: 1.04s\tremaining: 1m 41s\n",
      "200:\tlearn: 1.8523697\ttest: 1.7476312\tbest: 1.7476312 (200)\ttotal: 1.37s\tremaining: 1m 40s\n",
      "250:\tlearn: 1.7517706\ttest: 1.6466343\tbest: 1.6466343 (250)\ttotal: 1.71s\tremaining: 1m 40s\n",
      "300:\tlearn: 1.6786582\ttest: 1.6031620\tbest: 1.6031620 (300)\ttotal: 2.05s\tremaining: 1m 39s\n",
      "350:\tlearn: 1.6160879\ttest: 1.5702485\tbest: 1.5701016 (349)\ttotal: 2.38s\tremaining: 1m 39s\n",
      "400:\tlearn: 1.5665979\ttest: 1.5416398\tbest: 1.5416398 (400)\ttotal: 2.71s\tremaining: 1m 38s\n",
      "450:\tlearn: 1.5239921\ttest: 1.5063761\tbest: 1.5063761 (450)\ttotal: 3.05s\tremaining: 1m 38s\n",
      "500:\tlearn: 1.4861580\ttest: 1.4641763\tbest: 1.4641763 (500)\ttotal: 3.37s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4534712\ttest: 1.4305982\tbest: 1.4305982 (550)\ttotal: 3.71s\tremaining: 1m 37s\n",
      "600:\tlearn: 1.4230708\ttest: 1.4059105\tbest: 1.4047010 (596)\ttotal: 4.04s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.4000374\ttest: 1.3937749\tbest: 1.3929717 (647)\ttotal: 4.35s\tremaining: 1m 35s\n",
      "700:\tlearn: 1.3801153\ttest: 1.3856411\tbest: 1.3855923 (699)\ttotal: 4.68s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3582435\ttest: 1.3738197\tbest: 1.3736089 (749)\ttotal: 5.01s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.3388330\ttest: 1.3623290\tbest: 1.3623290 (800)\ttotal: 5.34s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.3176151\ttest: 1.3458353\tbest: 1.3458353 (850)\ttotal: 5.67s\tremaining: 1m 34s\n",
      "900:\tlearn: 1.2977707\ttest: 1.3305916\tbest: 1.3305916 (900)\ttotal: 6s\tremaining: 1m 33s\n",
      "950:\tlearn: 1.2813171\ttest: 1.3226763\tbest: 1.3226763 (950)\ttotal: 6.33s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2648141\ttest: 1.3118733\tbest: 1.3118733 (1000)\ttotal: 6.66s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2474273\ttest: 1.3025149\tbest: 1.3025149 (1050)\ttotal: 7s\tremaining: 1m 32s\n",
      "1100:\tlearn: 1.2317793\ttest: 1.2929009\tbest: 1.2929009 (1100)\ttotal: 7.33s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.2125311\ttest: 1.2869871\tbest: 1.2869871 (1150)\ttotal: 7.67s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1931381\ttest: 1.2795065\tbest: 1.2795065 (1200)\ttotal: 8s\tremaining: 1m 31s\n",
      "1250:\tlearn: 1.1751093\ttest: 1.2716732\tbest: 1.2716681 (1246)\ttotal: 8.32s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1572382\ttest: 1.2667639\tbest: 1.2667639 (1300)\ttotal: 8.65s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.1399134\ttest: 1.2594138\tbest: 1.2592640 (1344)\ttotal: 9s\tremaining: 1m 30s\n",
      "1400:\tlearn: 1.1241731\ttest: 1.2562521\tbest: 1.2562521 (1400)\ttotal: 9.33s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.1088324\ttest: 1.2555440\tbest: 1.2544383 (1429)\ttotal: 9.66s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0912797\ttest: 1.2498112\tbest: 1.2498112 (1500)\ttotal: 10s\tremaining: 1m 29s\n",
      "1550:\tlearn: 1.0746835\ttest: 1.2473613\tbest: 1.2467166 (1546)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0607937\ttest: 1.2452706\tbest: 1.2444962 (1574)\ttotal: 10.7s\tremaining: 1m 29s\n",
      "1650:\tlearn: 1.0431102\ttest: 1.2400886\tbest: 1.2400886 (1650)\ttotal: 11s\tremaining: 1m 28s\n",
      "1700:\tlearn: 1.0273411\ttest: 1.2318514\tbest: 1.2318514 (1700)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 1.0116908\ttest: 1.2293458\tbest: 1.2286578 (1746)\ttotal: 11.7s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9964462\ttest: 1.2261336\tbest: 1.2257482 (1796)\ttotal: 12s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9798925\ttest: 1.2231975\tbest: 1.2231912 (1849)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9656913\ttest: 1.2200221\tbest: 1.2196451 (1896)\ttotal: 12.7s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9503231\ttest: 1.2200808\tbest: 1.2190417 (1945)\ttotal: 13s\tremaining: 1m 26s\n",
      "2000:\tlearn: 0.9373375\ttest: 1.2178310\tbest: 1.2167286 (1977)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.9222257\ttest: 1.2145768\tbest: 1.2145178 (2043)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.9103639\ttest: 1.2106369\tbest: 1.2106369 (2100)\ttotal: 14s\tremaining: 1m 26s\n",
      "2150:\tlearn: 0.8983379\ttest: 1.2074754\tbest: 1.2071104 (2148)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8860183\ttest: 1.2029396\tbest: 1.2029396 (2200)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8730698\ttest: 1.2001107\tbest: 1.1999951 (2249)\ttotal: 15s\tremaining: 1m 25s\n",
      "2300:\tlearn: 0.8600168\ttest: 1.1990005\tbest: 1.1982398 (2281)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8463804\ttest: 1.1936605\tbest: 1.1936605 (2350)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8324714\ttest: 1.1870347\tbest: 1.1868466 (2399)\ttotal: 16s\tremaining: 1m 23s\n",
      "2450:\tlearn: 0.8199195\ttest: 1.1803261\tbest: 1.1800316 (2446)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.8083754\ttest: 1.1778011\tbest: 1.1778011 (2500)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7968084\ttest: 1.1713188\tbest: 1.1713188 (2550)\ttotal: 17s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.7866987\ttest: 1.1672164\tbest: 1.1662400 (2592)\ttotal: 17.3s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7768255\ttest: 1.1650187\tbest: 1.1649046 (2645)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7649465\ttest: 1.1616860\tbest: 1.1614828 (2699)\ttotal: 18s\tremaining: 1m 21s\n",
      "2750:\tlearn: 0.7549123\ttest: 1.1597207\tbest: 1.1597207 (2750)\ttotal: 18.3s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7439582\ttest: 1.1557384\tbest: 1.1557384 (2800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.7342082\ttest: 1.1542064\tbest: 1.1542064 (2850)\ttotal: 19s\tremaining: 1m 21s\n",
      "2900:\tlearn: 0.7240654\ttest: 1.1542136\tbest: 1.1538707 (2884)\ttotal: 19.3s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.7144638\ttest: 1.1519619\tbest: 1.1514303 (2936)\ttotal: 19.7s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.7057658\ttest: 1.1504439\tbest: 1.1504439 (3000)\ttotal: 20s\tremaining: 1m 20s\n",
      "3050:\tlearn: 0.6964928\ttest: 1.1489747\tbest: 1.1486749 (3040)\ttotal: 20.4s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6858842\ttest: 1.1453215\tbest: 1.1453119 (3099)\ttotal: 20.7s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6771144\ttest: 1.1442324\tbest: 1.1442324 (3150)\ttotal: 21s\tremaining: 1m 19s\n",
      "3200:\tlearn: 0.6646463\ttest: 1.1411427\tbest: 1.1411427 (3200)\ttotal: 21.4s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6545756\ttest: 1.1399198\tbest: 1.1399057 (3220)\ttotal: 21.7s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6436319\ttest: 1.1359490\tbest: 1.1359486 (3299)\ttotal: 22s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.6340101\ttest: 1.1339765\tbest: 1.1338905 (3338)\ttotal: 22.4s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.6242068\ttest: 1.1304602\tbest: 1.1304602 (3400)\ttotal: 22.7s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.6154228\ttest: 1.1285180\tbest: 1.1285180 (3450)\ttotal: 23s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.6073286\ttest: 1.1258497\tbest: 1.1251374 (3494)\ttotal: 23.4s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5969973\ttest: 1.1231206\tbest: 1.1231199 (3539)\ttotal: 23.7s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5876419\ttest: 1.1214820\tbest: 1.1214820 (3600)\ttotal: 24.1s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.5781798\ttest: 1.1198100\tbest: 1.1195331 (3646)\ttotal: 24.4s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5697242\ttest: 1.1180883\tbest: 1.1176377 (3699)\ttotal: 24.7s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5614002\ttest: 1.1153576\tbest: 1.1147620 (3747)\ttotal: 25.1s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5529984\ttest: 1.1134837\tbest: 1.1126670 (3793)\ttotal: 25.4s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5442274\ttest: 1.1107482\tbest: 1.1106253 (3849)\ttotal: 25.7s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5359197\ttest: 1.1114085\tbest: 1.1105851 (3887)\ttotal: 26.1s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.5280836\ttest: 1.1082144\tbest: 1.1081906 (3949)\ttotal: 26.4s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.5200977\ttest: 1.1051827\tbest: 1.1051827 (4000)\ttotal: 26.7s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.5128305\ttest: 1.1031727\tbest: 1.1031727 (4050)\ttotal: 27.1s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.5056729\ttest: 1.1022330\tbest: 1.1020137 (4090)\ttotal: 27.4s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4972530\ttest: 1.0996585\tbest: 1.0996585 (4150)\ttotal: 27.8s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4906551\ttest: 1.1000572\tbest: 1.0989983 (4155)\ttotal: 28.1s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4831023\ttest: 1.0978370\tbest: 1.0977450 (4238)\ttotal: 28.4s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4760711\ttest: 1.0969886\tbest: 1.0969886 (4300)\ttotal: 28.8s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4698697\ttest: 1.0958913\tbest: 1.0957133 (4345)\ttotal: 29.1s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4633197\ttest: 1.0954225\tbest: 1.0951815 (4395)\ttotal: 29.5s\tremaining: 1m 10s\n",
      "4450:\tlearn: 0.4564967\ttest: 1.0961106\tbest: 1.0948504 (4405)\ttotal: 29.8s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4502927\ttest: 1.0956104\tbest: 1.0948504 (4405)\ttotal: 30.2s\tremaining: 1m 10s\n",
      "4550:\tlearn: 0.4436833\ttest: 1.0964738\tbest: 1.0948504 (4405)\ttotal: 30.5s\tremaining: 1m 10s\n",
      "4600:\tlearn: 0.4380536\ttest: 1.0959285\tbest: 1.0948504 (4405)\ttotal: 30.8s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4308214\ttest: 1.0960134\tbest: 1.0948504 (4405)\ttotal: 31.2s\tremaining: 1m 9s\n",
      "4700:\tlearn: 0.4241165\ttest: 1.0947318\tbest: 1.0946398 (4697)\ttotal: 31.5s\tremaining: 1m 9s\n",
      "4750:\tlearn: 0.4167658\ttest: 1.0935960\tbest: 1.0930316 (4745)\ttotal: 31.8s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.4107066\ttest: 1.0930704\tbest: 1.0926820 (4783)\ttotal: 32.2s\tremaining: 1m 8s\n",
      "4850:\tlearn: 0.4045013\ttest: 1.0936904\tbest: 1.0920908 (4808)\ttotal: 32.5s\tremaining: 1m 8s\n",
      "4900:\tlearn: 0.3986883\ttest: 1.0926729\tbest: 1.0920908 (4808)\ttotal: 32.9s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3929710\ttest: 1.0922099\tbest: 1.0920908 (4808)\ttotal: 33.2s\tremaining: 1m 7s\n",
      "5000:\tlearn: 0.3866853\ttest: 1.0924624\tbest: 1.0919439 (4973)\ttotal: 33.5s\tremaining: 1m 7s\n",
      "5050:\tlearn: 0.3814464\ttest: 1.0918657\tbest: 1.0914624 (5048)\ttotal: 33.9s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3761919\ttest: 1.0918402\tbest: 1.0914624 (5048)\ttotal: 34.2s\tremaining: 1m 6s\n",
      "5150:\tlearn: 0.3702447\ttest: 1.0914742\tbest: 1.0911868 (5122)\ttotal: 34.6s\tremaining: 1m 6s\n",
      "5200:\tlearn: 0.3642644\ttest: 1.0925560\tbest: 1.0911868 (5122)\ttotal: 34.9s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3584256\ttest: 1.0917113\tbest: 1.0911868 (5122)\ttotal: 35.2s\tremaining: 1m 5s\n",
      "5300:\tlearn: 0.3530505\ttest: 1.0912674\tbest: 1.0907702 (5291)\ttotal: 35.6s\tremaining: 1m 5s\n",
      "5350:\tlearn: 0.3473884\ttest: 1.0919359\tbest: 1.0907702 (5291)\ttotal: 35.9s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3427999\ttest: 1.0919698\tbest: 1.0907702 (5291)\ttotal: 36.2s\tremaining: 1m 4s\n",
      "5450:\tlearn: 0.3386675\ttest: 1.0925263\tbest: 1.0907702 (5291)\ttotal: 36.6s\tremaining: 1m 4s\n",
      "5500:\tlearn: 0.3331403\ttest: 1.0939347\tbest: 1.0907702 (5291)\ttotal: 36.9s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3282918\ttest: 1.0950414\tbest: 1.0907702 (5291)\ttotal: 37.3s\tremaining: 1m 3s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.090770184\n",
      "bestIteration = 5291\n",
      "\n",
      "Shrink model to first 5292 iterations.\n",
      "Скор для фолда(9) : 9.0 средний скор на префиксе = 9.0 это заняло = 37 сек.\n",
      "Фолд: 10\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.6091797\ttest: 3.6583250\tbest: 3.6583250 (0)\ttotal: 28.1ms\tremaining: 7m 1s\n",
      "50:\tlearn: 2.7412148\ttest: 2.9359654\tbest: 2.9359654 (50)\ttotal: 358ms\tremaining: 1m 44s\n",
      "100:\tlearn: 2.2687957\ttest: 2.4481191\tbest: 2.4481191 (100)\ttotal: 692ms\tremaining: 1m 42s\n",
      "150:\tlearn: 2.0109336\ttest: 2.1563091\tbest: 2.1563091 (150)\ttotal: 1.02s\tremaining: 1m 40s\n",
      "200:\tlearn: 1.8487516\ttest: 1.9778194\tbest: 1.9778194 (200)\ttotal: 1.37s\tremaining: 1m 40s\n",
      "250:\tlearn: 1.7430104\ttest: 1.8640392\tbest: 1.8640392 (250)\ttotal: 1.7s\tremaining: 1m 40s\n",
      "300:\tlearn: 1.6661264\ttest: 1.8002699\tbest: 1.8002699 (300)\ttotal: 2.03s\tremaining: 1m 39s\n",
      "350:\tlearn: 1.6017591\ttest: 1.7452018\tbest: 1.7451955 (348)\ttotal: 2.37s\tremaining: 1m 38s\n",
      "400:\tlearn: 1.5481667\ttest: 1.7168769\tbest: 1.7168769 (400)\ttotal: 2.71s\tremaining: 1m 38s\n",
      "450:\tlearn: 1.5022760\ttest: 1.6805995\tbest: 1.6805995 (450)\ttotal: 3.03s\tremaining: 1m 37s\n",
      "500:\tlearn: 1.4627135\ttest: 1.6512556\tbest: 1.6512556 (500)\ttotal: 3.37s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4284357\ttest: 1.6267622\tbest: 1.6267622 (550)\ttotal: 3.7s\tremaining: 1m 36s\n",
      "600:\tlearn: 1.3992372\ttest: 1.6117883\tbest: 1.6117883 (600)\ttotal: 4.03s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3738371\ttest: 1.6046131\tbest: 1.6041887 (647)\ttotal: 4.36s\tremaining: 1m 36s\n",
      "700:\tlearn: 1.3487432\ttest: 1.5925438\tbest: 1.5923942 (696)\ttotal: 4.69s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3252705\ttest: 1.5818564\tbest: 1.5818564 (750)\ttotal: 5.02s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.3015672\ttest: 1.5740044\tbest: 1.5739724 (799)\ttotal: 5.35s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.2784051\ttest: 1.5736115\tbest: 1.5714130 (819)\ttotal: 5.68s\tremaining: 1m 34s\n",
      "900:\tlearn: 1.2568683\ttest: 1.5747031\tbest: 1.5706849 (868)\ttotal: 6.01s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2357784\ttest: 1.5633573\tbest: 1.5633573 (950)\ttotal: 6.34s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2134989\ttest: 1.5547445\tbest: 1.5544547 (994)\ttotal: 6.68s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.1928260\ttest: 1.5533065\tbest: 1.5527744 (1038)\ttotal: 7s\tremaining: 1m 32s\n",
      "1100:\tlearn: 1.1735568\ttest: 1.5503232\tbest: 1.5495835 (1094)\ttotal: 7.33s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.1535435\ttest: 1.5451035\tbest: 1.5450891 (1149)\ttotal: 7.66s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1335410\ttest: 1.5396068\tbest: 1.5396068 (1200)\ttotal: 7.99s\tremaining: 1m 31s\n",
      "1250:\tlearn: 1.1136223\ttest: 1.5365479\tbest: 1.5349811 (1213)\ttotal: 8.32s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.0968673\ttest: 1.5367873\tbest: 1.5349811 (1213)\ttotal: 8.66s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.0836638\ttest: 1.5377114\tbest: 1.5349811 (1213)\ttotal: 8.98s\tremaining: 1m 30s\n",
      "1400:\tlearn: 1.0667117\ttest: 1.5309746\tbest: 1.5309746 (1400)\ttotal: 9.32s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.0491157\ttest: 1.5328223\tbest: 1.5294705 (1415)\ttotal: 9.65s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0314626\ttest: 1.5309567\tbest: 1.5294705 (1415)\ttotal: 9.97s\tremaining: 1m 29s\n",
      "1550:\tlearn: 1.0163066\ttest: 1.5296527\tbest: 1.5287948 (1539)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 0.9982303\ttest: 1.5280304\tbest: 1.5270364 (1595)\ttotal: 10.6s\tremaining: 1m 29s\n",
      "1650:\tlearn: 0.9813355\ttest: 1.5274141\tbest: 1.5263878 (1634)\ttotal: 11s\tremaining: 1m 28s\n",
      "1700:\tlearn: 0.9655140\ttest: 1.5241333\tbest: 1.5241333 (1700)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 0.9515117\ttest: 1.5228940\tbest: 1.5223384 (1745)\ttotal: 11.6s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9345819\ttest: 1.5188865\tbest: 1.5173349 (1775)\ttotal: 12s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9171682\ttest: 1.5190364\tbest: 1.5173349 (1775)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9022556\ttest: 1.5179915\tbest: 1.5173349 (1775)\ttotal: 12.7s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.8888655\ttest: 1.5156216\tbest: 1.5156216 (1950)\ttotal: 13s\tremaining: 1m 26s\n",
      "2000:\tlearn: 0.8713102\ttest: 1.5158620\tbest: 1.5142920 (1955)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.8591607\ttest: 1.5160277\tbest: 1.5142920 (1955)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.8458994\ttest: 1.5183931\tbest: 1.5142920 (1955)\ttotal: 14s\tremaining: 1m 25s\n",
      "2150:\tlearn: 0.8327372\ttest: 1.5188442\tbest: 1.5142920 (1955)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8183702\ttest: 1.5158657\tbest: 1.5142920 (1955)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8067601\ttest: 1.5161054\tbest: 1.5142920 (1955)\ttotal: 15s\tremaining: 1m 24s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.514292039\n",
      "bestIteration = 1955\n",
      "\n",
      "Shrink model to first 1956 iterations.\n",
      "Скор для фолда(10) : 9.0 средний скор на префиксе = 9.0 это заняло = 15 сек.\n",
      "Фолд: 11\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "0:\tlearn: 3.6078656\ttest: 3.7042164\tbest: 3.7042164 (0)\ttotal: 27.9ms\tremaining: 6m 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7632634\ttest: 2.9259256\tbest: 2.9259256 (50)\ttotal: 359ms\tremaining: 1m 45s\n",
      "100:\tlearn: 2.2811047\ttest: 2.5691309\tbest: 2.5691309 (100)\ttotal: 692ms\tremaining: 1m 42s\n",
      "150:\tlearn: 2.0151758\ttest: 2.4486433\tbest: 2.4486433 (150)\ttotal: 1.03s\tremaining: 1m 41s\n",
      "200:\tlearn: 1.8501299\ttest: 2.3378323\tbest: 2.3378323 (200)\ttotal: 1.35s\tremaining: 1m 39s\n",
      "250:\tlearn: 1.7412284\ttest: 2.2432314\tbest: 2.2432314 (250)\ttotal: 1.69s\tremaining: 1m 39s\n",
      "300:\tlearn: 1.6623682\ttest: 2.1780114\tbest: 2.1780114 (300)\ttotal: 2.03s\tremaining: 1m 39s\n",
      "350:\tlearn: 1.5997388\ttest: 2.1038930\tbest: 2.1038930 (350)\ttotal: 2.36s\tremaining: 1m 38s\n",
      "400:\tlearn: 1.5529672\ttest: 2.0480277\tbest: 2.0480277 (400)\ttotal: 2.69s\tremaining: 1m 38s\n",
      "450:\tlearn: 1.5115067\ttest: 2.0008112\tbest: 2.0008112 (450)\ttotal: 3.03s\tremaining: 1m 37s\n",
      "500:\tlearn: 1.4733879\ttest: 1.9626172\tbest: 1.9626172 (500)\ttotal: 3.36s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4381271\ttest: 1.9290003\tbest: 1.9289194 (549)\ttotal: 3.69s\tremaining: 1m 36s\n",
      "600:\tlearn: 1.4115831\ttest: 1.9082938\tbest: 1.9082938 (600)\ttotal: 4.02s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3826368\ttest: 1.8820855\tbest: 1.8820855 (650)\ttotal: 4.35s\tremaining: 1m 35s\n",
      "700:\tlearn: 1.3603627\ttest: 1.8624359\tbest: 1.8624359 (700)\ttotal: 4.68s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3400916\ttest: 1.8382422\tbest: 1.8382422 (750)\ttotal: 5.02s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.3164394\ttest: 1.8193642\tbest: 1.8193642 (800)\ttotal: 5.34s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.2960613\ttest: 1.8055008\tbest: 1.8055008 (850)\ttotal: 5.68s\tremaining: 1m 34s\n",
      "900:\tlearn: 1.2761480\ttest: 1.7865300\tbest: 1.7865300 (900)\ttotal: 6.03s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2568338\ttest: 1.7744611\tbest: 1.7744610 (948)\ttotal: 6.34s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2383862\ttest: 1.7627141\tbest: 1.7627141 (1000)\ttotal: 6.68s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2206303\ttest: 1.7508363\tbest: 1.7504765 (1043)\ttotal: 7.01s\tremaining: 1m 33s\n",
      "1100:\tlearn: 1.2030862\ttest: 1.7421673\tbest: 1.7417313 (1098)\ttotal: 7.34s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.1856807\ttest: 1.7319566\tbest: 1.7319566 (1150)\ttotal: 7.68s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1669176\ttest: 1.7283375\tbest: 1.7282418 (1198)\ttotal: 8.02s\tremaining: 1m 32s\n",
      "1250:\tlearn: 1.1494886\ttest: 1.7214614\tbest: 1.7214614 (1250)\ttotal: 8.34s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1322901\ttest: 1.7173144\tbest: 1.7171792 (1296)\ttotal: 8.67s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.1145514\ttest: 1.7088481\tbest: 1.7088311 (1347)\ttotal: 9s\tremaining: 1m 30s\n",
      "1400:\tlearn: 1.0994948\ttest: 1.7011814\tbest: 1.7011472 (1399)\ttotal: 9.32s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.0832277\ttest: 1.6962758\tbest: 1.6962210 (1449)\ttotal: 9.66s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0663469\ttest: 1.6925243\tbest: 1.6919651 (1491)\ttotal: 9.99s\tremaining: 1m 29s\n",
      "1550:\tlearn: 1.0507457\ttest: 1.6841304\tbest: 1.6841304 (1550)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0354324\ttest: 1.6767486\tbest: 1.6765078 (1598)\ttotal: 10.7s\tremaining: 1m 29s\n",
      "1650:\tlearn: 1.0209330\ttest: 1.6721900\tbest: 1.6721900 (1650)\ttotal: 11s\tremaining: 1m 28s\n",
      "1700:\tlearn: 1.0043600\ttest: 1.6669710\tbest: 1.6668533 (1698)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 0.9881172\ttest: 1.6616954\tbest: 1.6616820 (1748)\ttotal: 11.6s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9738355\ttest: 1.6538531\tbest: 1.6536660 (1799)\ttotal: 12s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9593094\ttest: 1.6497822\tbest: 1.6497653 (1849)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9446585\ttest: 1.6457921\tbest: 1.6457830 (1899)\ttotal: 12.6s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9303557\ttest: 1.6393800\tbest: 1.6393410 (1949)\ttotal: 13s\tremaining: 1m 26s\n",
      "2000:\tlearn: 0.9147421\ttest: 1.6337057\tbest: 1.6334606 (1997)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.9004872\ttest: 1.6259046\tbest: 1.6256032 (2048)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.8854532\ttest: 1.6198054\tbest: 1.6198054 (2100)\ttotal: 14s\tremaining: 1m 25s\n",
      "2150:\tlearn: 0.8697301\ttest: 1.6174188\tbest: 1.6173003 (2148)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8560406\ttest: 1.6136760\tbest: 1.6133434 (2186)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8411164\ttest: 1.6087082\tbest: 1.6084378 (2249)\ttotal: 15s\tremaining: 1m 24s\n",
      "2300:\tlearn: 0.8259900\ttest: 1.6028641\tbest: 1.6028641 (2300)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8119245\ttest: 1.6005402\tbest: 1.6002015 (2327)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.7977891\ttest: 1.5983586\tbest: 1.5983586 (2400)\ttotal: 16s\tremaining: 1m 23s\n",
      "2450:\tlearn: 0.7856763\ttest: 1.5926032\tbest: 1.5926032 (2450)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.7722828\ttest: 1.5874633\tbest: 1.5874633 (2500)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7604645\ttest: 1.5832937\tbest: 1.5832937 (2550)\ttotal: 17s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.7477410\ttest: 1.5816329\tbest: 1.5815573 (2587)\ttotal: 17.3s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7359301\ttest: 1.5810896\tbest: 1.5803353 (2637)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7261655\ttest: 1.5795937\tbest: 1.5795937 (2700)\ttotal: 18s\tremaining: 1m 21s\n",
      "2750:\tlearn: 0.7148701\ttest: 1.5783147\tbest: 1.5770548 (2727)\ttotal: 18.3s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7051378\ttest: 1.5766885\tbest: 1.5766885 (2800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.6949462\ttest: 1.5736097\tbest: 1.5731234 (2841)\ttotal: 19s\tremaining: 1m 20s\n",
      "2900:\tlearn: 0.6856361\ttest: 1.5732992\tbest: 1.5731076 (2866)\ttotal: 19.3s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.6764482\ttest: 1.5712852\tbest: 1.5712852 (2950)\ttotal: 19.7s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.6675821\ttest: 1.5684840\tbest: 1.5683901 (2995)\ttotal: 20s\tremaining: 1m 19s\n",
      "3050:\tlearn: 0.6569701\ttest: 1.5694315\tbest: 1.5683901 (2995)\ttotal: 20.3s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6484661\ttest: 1.5652652\tbest: 1.5652652 (3100)\ttotal: 20.6s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6382484\ttest: 1.5648914\tbest: 1.5641244 (3144)\ttotal: 21s\tremaining: 1m 18s\n",
      "3200:\tlearn: 0.6278515\ttest: 1.5619801\tbest: 1.5613526 (3196)\ttotal: 21.3s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6177521\ttest: 1.5618343\tbest: 1.5609155 (3215)\ttotal: 21.7s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6076454\ttest: 1.5597628\tbest: 1.5579417 (3289)\ttotal: 22s\tremaining: 1m 17s\n",
      "3350:\tlearn: 0.5980646\ttest: 1.5569164\tbest: 1.5569164 (3350)\ttotal: 22.3s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.5898326\ttest: 1.5551123\tbest: 1.5551123 (3400)\ttotal: 22.7s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.5816147\ttest: 1.5525229\tbest: 1.5523063 (3448)\ttotal: 23s\tremaining: 1m 16s\n",
      "3500:\tlearn: 0.5718761\ttest: 1.5510045\tbest: 1.5506978 (3470)\ttotal: 23.3s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5631564\ttest: 1.5500482\tbest: 1.5496961 (3530)\ttotal: 23.7s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5545811\ttest: 1.5490710\tbest: 1.5484255 (3596)\ttotal: 24s\tremaining: 1m 15s\n",
      "3650:\tlearn: 0.5451943\ttest: 1.5469413\tbest: 1.5464079 (3647)\ttotal: 24.3s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5354309\ttest: 1.5449841\tbest: 1.5446344 (3699)\ttotal: 24.7s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5282959\ttest: 1.5443760\tbest: 1.5439561 (3742)\ttotal: 25s\tremaining: 1m 14s\n",
      "3800:\tlearn: 0.5217163\ttest: 1.5444301\tbest: 1.5439561 (3742)\ttotal: 25.3s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5133019\ttest: 1.5446349\tbest: 1.5439561 (3742)\ttotal: 25.7s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5041333\ttest: 1.5441977\tbest: 1.5436656 (3885)\ttotal: 26s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.4959909\ttest: 1.5445940\tbest: 1.5436656 (3885)\ttotal: 26.3s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.4877524\ttest: 1.5449834\tbest: 1.5436656 (3885)\ttotal: 26.7s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.4795347\ttest: 1.5474113\tbest: 1.5436656 (3885)\ttotal: 27s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.4708974\ttest: 1.5485027\tbest: 1.5436656 (3885)\ttotal: 27.3s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4640227\ttest: 1.5499957\tbest: 1.5436656 (3885)\ttotal: 27.7s\tremaining: 1m 12s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.543665636\n",
      "bestIteration = 3885\n",
      "\n",
      "Shrink model to first 3886 iterations.\n",
      "Скор для фолда(11) : 9.0 средний скор на префиксе = 9.0 это заняло = 28 сек.\n",
      "Фолд: 12\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.5973187\ttest: 3.5874154\tbest: 3.5874154 (0)\ttotal: 28.3ms\tremaining: 7m 4s\n",
      "50:\tlearn: 2.7387931\ttest: 2.5339573\tbest: 2.5339573 (50)\ttotal: 363ms\tremaining: 1m 46s\n",
      "100:\tlearn: 2.2828259\ttest: 2.1351829\tbest: 2.1351829 (100)\ttotal: 686ms\tremaining: 1m 41s\n",
      "150:\tlearn: 2.0351074\ttest: 1.9703081\tbest: 1.9703081 (150)\ttotal: 1.02s\tremaining: 1m 40s\n",
      "200:\tlearn: 1.8731067\ttest: 1.9052839\tbest: 1.9052839 (200)\ttotal: 1.36s\tremaining: 1m 40s\n",
      "250:\tlearn: 1.7611808\ttest: 1.8784553\tbest: 1.8784553 (250)\ttotal: 1.69s\tremaining: 1m 39s\n",
      "300:\tlearn: 1.6801561\ttest: 1.8625497\tbest: 1.8618669 (298)\ttotal: 2.03s\tremaining: 1m 39s\n",
      "350:\tlearn: 1.6111937\ttest: 1.8464154\tbest: 1.8458554 (349)\ttotal: 2.37s\tremaining: 1m 38s\n",
      "400:\tlearn: 1.5554273\ttest: 1.8304085\tbest: 1.8294953 (393)\ttotal: 2.69s\tremaining: 1m 37s\n",
      "450:\tlearn: 1.5115156\ttest: 1.8141879\tbest: 1.8141879 (450)\ttotal: 3.03s\tremaining: 1m 37s\n",
      "500:\tlearn: 1.4784686\ttest: 1.7998452\tbest: 1.7998452 (500)\ttotal: 3.36s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4477790\ttest: 1.7868572\tbest: 1.7868572 (550)\ttotal: 3.68s\tremaining: 1m 36s\n",
      "600:\tlearn: 1.4194166\ttest: 1.7681944\tbest: 1.7681944 (600)\ttotal: 4.02s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3936415\ttest: 1.7565714\tbest: 1.7561860 (641)\ttotal: 4.35s\tremaining: 1m 35s\n",
      "700:\tlearn: 1.3730797\ttest: 1.7478532\tbest: 1.7469826 (692)\ttotal: 4.67s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3555759\ttest: 1.7406701\tbest: 1.7402805 (745)\ttotal: 5s\tremaining: 1m 34s\n",
      "800:\tlearn: 1.3391721\ttest: 1.7337673\tbest: 1.7337673 (800)\ttotal: 5.33s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.3211072\ttest: 1.7313059\tbest: 1.7313059 (850)\ttotal: 5.65s\tremaining: 1m 33s\n",
      "900:\tlearn: 1.3026263\ttest: 1.7223403\tbest: 1.7223403 (900)\ttotal: 6s\tremaining: 1m 33s\n",
      "950:\tlearn: 1.2837660\ttest: 1.7205416\tbest: 1.7205416 (950)\ttotal: 6.34s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2668287\ttest: 1.7124292\tbest: 1.7123576 (999)\ttotal: 6.66s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2501328\ttest: 1.7053724\tbest: 1.7043997 (1033)\ttotal: 6.99s\tremaining: 1m 32s\n",
      "1100:\tlearn: 1.2333515\ttest: 1.6981045\tbest: 1.6981045 (1100)\ttotal: 7.33s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.2192977\ttest: 1.6936321\tbest: 1.6936062 (1149)\ttotal: 7.66s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.2031967\ttest: 1.6858378\tbest: 1.6857082 (1199)\ttotal: 8s\tremaining: 1m 31s\n",
      "1250:\tlearn: 1.1859625\ttest: 1.6819013\tbest: 1.6812695 (1247)\ttotal: 8.34s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1707715\ttest: 1.6771428\tbest: 1.6771428 (1300)\ttotal: 8.66s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.1529887\ttest: 1.6682052\tbest: 1.6682052 (1350)\ttotal: 9s\tremaining: 1m 30s\n",
      "1400:\tlearn: 1.1343899\ttest: 1.6615886\tbest: 1.6615886 (1400)\ttotal: 9.33s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.1188500\ttest: 1.6560589\tbest: 1.6555758 (1447)\ttotal: 9.65s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0993781\ttest: 1.6485402\tbest: 1.6485402 (1500)\ttotal: 9.99s\tremaining: 1m 29s\n",
      "1550:\tlearn: 1.0828181\ttest: 1.6411266\tbest: 1.6410439 (1549)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0679348\ttest: 1.6326261\tbest: 1.6324249 (1599)\ttotal: 10.7s\tremaining: 1m 29s\n",
      "1650:\tlearn: 1.0528554\ttest: 1.6266178\tbest: 1.6266178 (1650)\ttotal: 11s\tremaining: 1m 28s\n",
      "1700:\tlearn: 1.0376208\ttest: 1.6222375\tbest: 1.6222375 (1700)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 1.0207696\ttest: 1.6129146\tbest: 1.6122890 (1748)\ttotal: 11.7s\tremaining: 1m 28s\n",
      "1800:\tlearn: 1.0061465\ttest: 1.6053528\tbest: 1.6053528 (1800)\ttotal: 12s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9905565\ttest: 1.5976874\tbest: 1.5971354 (1848)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9766204\ttest: 1.5910711\tbest: 1.5910711 (1900)\ttotal: 12.7s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9600191\ttest: 1.5836831\tbest: 1.5836831 (1950)\ttotal: 13s\tremaining: 1m 26s\n",
      "2000:\tlearn: 0.9450655\ttest: 1.5769035\tbest: 1.5769035 (2000)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.9288389\ttest: 1.5714938\tbest: 1.5707176 (2045)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.9129204\ttest: 1.5638036\tbest: 1.5637709 (2099)\ttotal: 14s\tremaining: 1m 26s\n",
      "2150:\tlearn: 0.8968748\ttest: 1.5596190\tbest: 1.5593668 (2149)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8827102\ttest: 1.5554878\tbest: 1.5554878 (2200)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8701643\ttest: 1.5534173\tbest: 1.5531991 (2244)\ttotal: 15s\tremaining: 1m 25s\n",
      "2300:\tlearn: 0.8579411\ttest: 1.5504453\tbest: 1.5502927 (2297)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8453511\ttest: 1.5428887\tbest: 1.5426595 (2348)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8339623\ttest: 1.5374828\tbest: 1.5374828 (2400)\ttotal: 16s\tremaining: 1m 23s\n",
      "2450:\tlearn: 0.8209928\ttest: 1.5318390\tbest: 1.5311189 (2446)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.8072108\ttest: 1.5288892\tbest: 1.5281890 (2484)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7964846\ttest: 1.5261131\tbest: 1.5261131 (2550)\ttotal: 17s\tremaining: 1m 23s\n",
      "2600:\tlearn: 0.7851571\ttest: 1.5234847\tbest: 1.5234847 (2600)\ttotal: 17.4s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7729006\ttest: 1.5189404\tbest: 1.5188635 (2649)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7641017\ttest: 1.5163506\tbest: 1.5163506 (2700)\ttotal: 18s\tremaining: 1m 22s\n",
      "2750:\tlearn: 0.7537251\ttest: 1.5125147\tbest: 1.5123965 (2744)\ttotal: 18.4s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7434920\ttest: 1.5111951\tbest: 1.5111951 (2800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.7338546\ttest: 1.5102864\tbest: 1.5092217 (2819)\ttotal: 19s\tremaining: 1m 21s\n",
      "2900:\tlearn: 0.7234382\ttest: 1.5081666\tbest: 1.5081666 (2900)\ttotal: 19.4s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.7138299\ttest: 1.5044169\tbest: 1.5043031 (2949)\ttotal: 19.7s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.7032407\ttest: 1.5023290\tbest: 1.5023217 (2999)\ttotal: 20s\tremaining: 1m 20s\n",
      "3050:\tlearn: 0.6933765\ttest: 1.5017482\tbest: 1.5012482 (3038)\ttotal: 20.4s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6844532\ttest: 1.4979943\tbest: 1.4979943 (3100)\ttotal: 20.7s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6754723\ttest: 1.4955667\tbest: 1.4953946 (3149)\ttotal: 21s\tremaining: 1m 19s\n",
      "3200:\tlearn: 0.6637809\ttest: 1.4918279\tbest: 1.4911361 (3198)\ttotal: 21.4s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6527599\ttest: 1.4896943\tbest: 1.4892520 (3248)\ttotal: 21.7s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6436945\ttest: 1.4867316\tbest: 1.4864845 (3299)\ttotal: 22s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.6345468\ttest: 1.4837011\tbest: 1.4835428 (3341)\ttotal: 22.4s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.6247059\ttest: 1.4802866\tbest: 1.4801462 (3393)\ttotal: 22.7s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.6153346\ttest: 1.4770647\tbest: 1.4766286 (3448)\ttotal: 23s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.6066405\ttest: 1.4749815\tbest: 1.4740664 (3483)\ttotal: 23.4s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5982998\ttest: 1.4738384\tbest: 1.4738384 (3550)\ttotal: 23.7s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5878009\ttest: 1.4702524\tbest: 1.4701887 (3586)\ttotal: 24s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.5773278\ttest: 1.4675015\tbest: 1.4675015 (3650)\ttotal: 24.4s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5694736\ttest: 1.4626035\tbest: 1.4626035 (3700)\ttotal: 24.7s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5594802\ttest: 1.4604344\tbest: 1.4599158 (3743)\ttotal: 25.1s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5499920\ttest: 1.4577746\tbest: 1.4577746 (3800)\ttotal: 25.4s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5424782\ttest: 1.4551522\tbest: 1.4551522 (3850)\ttotal: 25.7s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5333462\ttest: 1.4534068\tbest: 1.4527493 (3890)\ttotal: 26.1s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.5252250\ttest: 1.4493303\tbest: 1.4493303 (3950)\ttotal: 26.4s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.5191075\ttest: 1.4473177\tbest: 1.4471102 (3991)\ttotal: 26.7s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.5110236\ttest: 1.4464186\tbest: 1.4459436 (4039)\ttotal: 27.1s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.5030456\ttest: 1.4443421\tbest: 1.4442215 (4094)\ttotal: 27.4s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4951399\ttest: 1.4417413\tbest: 1.4417413 (4150)\ttotal: 27.7s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4882695\ttest: 1.4386313\tbest: 1.4384101 (4198)\ttotal: 28.1s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4812597\ttest: 1.4351358\tbest: 1.4351358 (4250)\ttotal: 28.4s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4738559\ttest: 1.4328372\tbest: 1.4325162 (4281)\ttotal: 28.7s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4660736\ttest: 1.4331791\tbest: 1.4318804 (4311)\ttotal: 29.1s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4582562\ttest: 1.4302471\tbest: 1.4299521 (4391)\ttotal: 29.4s\tremaining: 1m 10s\n",
      "4450:\tlearn: 0.4512065\ttest: 1.4296132\tbest: 1.4296132 (4450)\ttotal: 29.7s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4436170\ttest: 1.4282931\tbest: 1.4280627 (4484)\ttotal: 30.1s\tremaining: 1m 10s\n",
      "4550:\tlearn: 0.4365413\ttest: 1.4270224\tbest: 1.4270224 (4550)\ttotal: 30.4s\tremaining: 1m 9s\n",
      "4600:\tlearn: 0.4297440\ttest: 1.4240897\tbest: 1.4240537 (4597)\ttotal: 30.7s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4237479\ttest: 1.4210284\tbest: 1.4209354 (4647)\ttotal: 31.1s\tremaining: 1m 9s\n",
      "4700:\tlearn: 0.4170176\ttest: 1.4183433\tbest: 1.4183433 (4700)\ttotal: 31.4s\tremaining: 1m 8s\n",
      "4750:\tlearn: 0.4106183\ttest: 1.4144807\tbest: 1.4144807 (4750)\ttotal: 31.7s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.4034250\ttest: 1.4125931\tbest: 1.4123911 (4794)\ttotal: 32.1s\tremaining: 1m 8s\n",
      "4850:\tlearn: 0.3980018\ttest: 1.4119291\tbest: 1.4115933 (4840)\ttotal: 32.4s\tremaining: 1m 7s\n",
      "4900:\tlearn: 0.3911952\ttest: 1.4087020\tbest: 1.4080502 (4897)\ttotal: 32.8s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3849735\ttest: 1.4081756\tbest: 1.4080502 (4897)\ttotal: 33.1s\tremaining: 1m 7s\n",
      "5000:\tlearn: 0.3796888\ttest: 1.4066668\tbest: 1.4063798 (4996)\ttotal: 33.4s\tremaining: 1m 6s\n",
      "5050:\tlearn: 0.3741648\ttest: 1.4059578\tbest: 1.4058500 (5044)\ttotal: 33.8s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3679324\ttest: 1.4038983\tbest: 1.4037742 (5098)\ttotal: 34.1s\tremaining: 1m 6s\n",
      "5150:\tlearn: 0.3610254\ttest: 1.4018224\tbest: 1.4018224 (5150)\ttotal: 34.4s\tremaining: 1m 5s\n",
      "5200:\tlearn: 0.3548775\ttest: 1.3996161\tbest: 1.3995680 (5192)\ttotal: 34.8s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3488828\ttest: 1.3990789\tbest: 1.3989549 (5248)\ttotal: 35.1s\tremaining: 1m 5s\n",
      "5300:\tlearn: 0.3435775\ttest: 1.3971127\tbest: 1.3970006 (5295)\ttotal: 35.4s\tremaining: 1m 4s\n",
      "5350:\tlearn: 0.3380981\ttest: 1.3963370\tbest: 1.3959415 (5337)\ttotal: 35.8s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3326759\ttest: 1.3942135\tbest: 1.3939047 (5394)\ttotal: 36.1s\tremaining: 1m 4s\n",
      "5450:\tlearn: 0.3276411\ttest: 1.3929706\tbest: 1.3927852 (5443)\ttotal: 36.4s\tremaining: 1m 3s\n",
      "5500:\tlearn: 0.3225530\ttest: 1.3922149\tbest: 1.3922149 (5500)\ttotal: 36.8s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3176714\ttest: 1.3906854\tbest: 1.3906031 (5549)\ttotal: 37.1s\tremaining: 1m 3s\n",
      "5600:\tlearn: 0.3133376\ttest: 1.3893244\tbest: 1.3893244 (5600)\ttotal: 37.4s\tremaining: 1m 2s\n",
      "5650:\tlearn: 0.3088761\ttest: 1.3889711\tbest: 1.3889204 (5623)\ttotal: 37.8s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.3035592\ttest: 1.3878479\tbest: 1.3876133 (5694)\ttotal: 38.1s\tremaining: 1m 2s\n",
      "5750:\tlearn: 0.2993349\ttest: 1.3863779\tbest: 1.3863779 (5750)\ttotal: 38.4s\tremaining: 1m 1s\n",
      "5800:\tlearn: 0.2944754\ttest: 1.3847044\tbest: 1.3841694 (5789)\ttotal: 38.8s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2893265\ttest: 1.3843895\tbest: 1.3839532 (5837)\ttotal: 39.1s\tremaining: 1m 1s\n",
      "5900:\tlearn: 0.2849414\ttest: 1.3830214\tbest: 1.3830214 (5900)\ttotal: 39.4s\tremaining: 1m\n",
      "5950:\tlearn: 0.2805549\ttest: 1.3806577\tbest: 1.3805646 (5949)\ttotal: 39.8s\tremaining: 1m\n",
      "6000:\tlearn: 0.2757012\ttest: 1.3780730\tbest: 1.3780730 (6000)\ttotal: 40.1s\tremaining: 1m\n",
      "6050:\tlearn: 0.2716279\ttest: 1.3764530\tbest: 1.3763051 (6047)\ttotal: 40.4s\tremaining: 59.8s\n",
      "6100:\tlearn: 0.2683402\ttest: 1.3752375\tbest: 1.3752375 (6100)\ttotal: 40.8s\tremaining: 59.5s\n",
      "6150:\tlearn: 0.2637373\ttest: 1.3744845\tbest: 1.3744845 (6150)\ttotal: 41.1s\tremaining: 59.1s\n",
      "6200:\tlearn: 0.2591426\ttest: 1.3719225\tbest: 1.3718037 (6198)\ttotal: 41.4s\tremaining: 58.8s\n",
      "6250:\tlearn: 0.2554343\ttest: 1.3706935\tbest: 1.3703493 (6241)\ttotal: 41.8s\tremaining: 58.5s\n",
      "6300:\tlearn: 0.2521528\ttest: 1.3703023\tbest: 1.3701293 (6264)\ttotal: 42.1s\tremaining: 58.1s\n",
      "6350:\tlearn: 0.2486794\ttest: 1.3688470\tbest: 1.3688470 (6350)\ttotal: 42.4s\tremaining: 57.8s\n",
      "6400:\tlearn: 0.2443200\ttest: 1.3665526\tbest: 1.3664372 (6391)\ttotal: 42.8s\tremaining: 57.5s\n",
      "6450:\tlearn: 0.2402921\ttest: 1.3643698\tbest: 1.3642905 (6445)\ttotal: 43.1s\tremaining: 57.1s\n",
      "6500:\tlearn: 0.2368382\ttest: 1.3642938\tbest: 1.3641594 (6499)\ttotal: 43.4s\tremaining: 56.8s\n",
      "6550:\tlearn: 0.2327539\ttest: 1.3626487\tbest: 1.3624567 (6548)\ttotal: 43.8s\tremaining: 56.5s\n",
      "6600:\tlearn: 0.2296539\ttest: 1.3614619\tbest: 1.3614465 (6599)\ttotal: 44.1s\tremaining: 56.1s\n",
      "6650:\tlearn: 0.2258199\ttest: 1.3602816\tbest: 1.3602621 (6648)\ttotal: 44.4s\tremaining: 55.8s\n",
      "6700:\tlearn: 0.2228936\ttest: 1.3595121\tbest: 1.3591860 (6688)\ttotal: 44.8s\tremaining: 55.4s\n",
      "6750:\tlearn: 0.2188392\ttest: 1.3585243\tbest: 1.3585243 (6750)\ttotal: 45.1s\tremaining: 55.1s\n",
      "6800:\tlearn: 0.2154525\ttest: 1.3573251\tbest: 1.3572371 (6799)\ttotal: 45.4s\tremaining: 54.8s\n",
      "6850:\tlearn: 0.2121118\ttest: 1.3565038\tbest: 1.3562021 (6843)\ttotal: 45.8s\tremaining: 54.5s\n",
      "6900:\tlearn: 0.2087574\ttest: 1.3539047\tbest: 1.3538296 (6899)\ttotal: 46.1s\tremaining: 54.1s\n",
      "6950:\tlearn: 0.2056412\ttest: 1.3531388\tbest: 1.3528515 (6948)\ttotal: 46.4s\tremaining: 53.8s\n",
      "7000:\tlearn: 0.2025428\ttest: 1.3516381\tbest: 1.3515934 (6991)\ttotal: 46.8s\tremaining: 53.5s\n",
      "7050:\tlearn: 0.1989056\ttest: 1.3510696\tbest: 1.3507867 (7030)\ttotal: 47.1s\tremaining: 53.1s\n",
      "7100:\tlearn: 0.1956140\ttest: 1.3511858\tbest: 1.3506833 (7056)\ttotal: 47.5s\tremaining: 52.8s\n",
      "7150:\tlearn: 0.1924694\ttest: 1.3515148\tbest: 1.3506833 (7056)\ttotal: 47.8s\tremaining: 52.5s\n",
      "7200:\tlearn: 0.1894173\ttest: 1.3494349\tbest: 1.3492671 (7197)\ttotal: 48.1s\tremaining: 52.1s\n",
      "7250:\tlearn: 0.1860809\ttest: 1.3478962\tbest: 1.3478962 (7250)\ttotal: 48.5s\tremaining: 51.8s\n",
      "7300:\tlearn: 0.1830602\ttest: 1.3467533\tbest: 1.3463114 (7279)\ttotal: 48.8s\tremaining: 51.5s\n",
      "7350:\tlearn: 0.1802271\ttest: 1.3455161\tbest: 1.3451520 (7340)\ttotal: 49.1s\tremaining: 51.1s\n",
      "7400:\tlearn: 0.1770152\ttest: 1.3444088\tbest: 1.3443608 (7399)\ttotal: 49.5s\tremaining: 50.8s\n",
      "7450:\tlearn: 0.1737586\ttest: 1.3444752\tbest: 1.3437688 (7414)\ttotal: 49.8s\tremaining: 50.5s\n",
      "7500:\tlearn: 0.1712730\ttest: 1.3439540\tbest: 1.3437688 (7414)\ttotal: 50.1s\tremaining: 50.1s\n",
      "7550:\tlearn: 0.1681147\ttest: 1.3432254\tbest: 1.3432246 (7549)\ttotal: 50.5s\tremaining: 49.8s\n",
      "7600:\tlearn: 0.1657023\ttest: 1.3417354\tbest: 1.3417354 (7600)\ttotal: 50.8s\tremaining: 49.5s\n",
      "7650:\tlearn: 0.1632969\ttest: 1.3410089\tbest: 1.3407225 (7645)\ttotal: 51.2s\tremaining: 49.1s\n",
      "7700:\tlearn: 0.1605634\ttest: 1.3389681\tbest: 1.3387862 (7686)\ttotal: 51.5s\tremaining: 48.8s\n",
      "7750:\tlearn: 0.1580138\ttest: 1.3378554\tbest: 1.3375788 (7738)\ttotal: 51.8s\tremaining: 48.5s\n",
      "7800:\tlearn: 0.1551694\ttest: 1.3368734\tbest: 1.3367541 (7795)\ttotal: 52.2s\tremaining: 48.1s\n",
      "7850:\tlearn: 0.1530878\ttest: 1.3369502\tbest: 1.3367036 (7808)\ttotal: 52.5s\tremaining: 47.8s\n",
      "7900:\tlearn: 0.1507366\ttest: 1.3358120\tbest: 1.3357623 (7898)\ttotal: 52.8s\tremaining: 47.5s\n",
      "7950:\tlearn: 0.1481164\ttest: 1.3348471\tbest: 1.3345327 (7937)\ttotal: 53.2s\tremaining: 47.2s\n",
      "8000:\tlearn: 0.1457857\ttest: 1.3329274\tbest: 1.3329258 (7999)\ttotal: 53.5s\tremaining: 46.8s\n",
      "8050:\tlearn: 0.1432644\ttest: 1.3304304\tbest: 1.3302735 (8047)\ttotal: 53.9s\tremaining: 46.5s\n",
      "8100:\tlearn: 0.1406330\ttest: 1.3279794\tbest: 1.3279794 (8100)\ttotal: 54.2s\tremaining: 46.2s\n",
      "8150:\tlearn: 0.1385556\ttest: 1.3265432\tbest: 1.3265432 (8150)\ttotal: 54.5s\tremaining: 45.8s\n",
      "8200:\tlearn: 0.1363340\ttest: 1.3245282\tbest: 1.3245233 (8194)\ttotal: 54.9s\tremaining: 45.5s\n",
      "8250:\tlearn: 0.1342038\ttest: 1.3230687\tbest: 1.3230638 (8249)\ttotal: 55.2s\tremaining: 45.2s\n",
      "8300:\tlearn: 0.1319362\ttest: 1.3205426\tbest: 1.3205426 (8300)\ttotal: 55.5s\tremaining: 44.8s\n",
      "8350:\tlearn: 0.1300225\ttest: 1.3180687\tbest: 1.3180457 (8348)\ttotal: 55.9s\tremaining: 44.5s\n",
      "8400:\tlearn: 0.1279333\ttest: 1.3169575\tbest: 1.3169575 (8400)\ttotal: 56.2s\tremaining: 44.1s\n",
      "8450:\tlearn: 0.1260389\ttest: 1.3154128\tbest: 1.3153887 (8449)\ttotal: 56.5s\tremaining: 43.8s\n",
      "8500:\tlearn: 0.1241734\ttest: 1.3155468\tbest: 1.3151922 (8494)\ttotal: 56.9s\tremaining: 43.5s\n",
      "8550:\tlearn: 0.1223074\ttest: 1.3148806\tbest: 1.3145928 (8540)\ttotal: 57.2s\tremaining: 43.1s\n",
      "8600:\tlearn: 0.1206623\ttest: 1.3136591\tbest: 1.3136591 (8600)\ttotal: 57.5s\tremaining: 42.8s\n",
      "8650:\tlearn: 0.1184652\ttest: 1.3121864\tbest: 1.3121294 (8647)\ttotal: 57.9s\tremaining: 42.5s\n",
      "8700:\tlearn: 0.1166055\ttest: 1.3110215\tbest: 1.3108187 (8689)\ttotal: 58.2s\tremaining: 42.1s\n",
      "8750:\tlearn: 0.1145243\ttest: 1.3102547\tbest: 1.3101036 (8749)\ttotal: 58.6s\tremaining: 41.8s\n",
      "8800:\tlearn: 0.1124856\ttest: 1.3084396\tbest: 1.3084396 (8800)\ttotal: 58.9s\tremaining: 41.5s\n",
      "8850:\tlearn: 0.1105589\ttest: 1.3060411\tbest: 1.3060411 (8850)\ttotal: 59.2s\tremaining: 41.2s\n",
      "8900:\tlearn: 0.1088964\ttest: 1.3036514\tbest: 1.3034856 (8897)\ttotal: 59.6s\tremaining: 40.8s\n",
      "8950:\tlearn: 0.1075902\ttest: 1.3022762\tbest: 1.3019634 (8946)\ttotal: 59.9s\tremaining: 40.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000:\tlearn: 0.1058896\ttest: 1.3019045\tbest: 1.3017227 (8998)\ttotal: 1m\tremaining: 40.1s\n",
      "9050:\tlearn: 0.1041049\ttest: 1.3014829\tbest: 1.3014119 (9008)\ttotal: 1m\tremaining: 39.8s\n",
      "9100:\tlearn: 0.1025374\ttest: 1.3012437\tbest: 1.3006301 (9069)\ttotal: 1m\tremaining: 39.5s\n",
      "9150:\tlearn: 0.1010275\ttest: 1.3003159\tbest: 1.3002980 (9148)\ttotal: 1m 1s\tremaining: 39.1s\n",
      "9200:\tlearn: 0.0990231\ttest: 1.2985733\tbest: 1.2985733 (9200)\ttotal: 1m 1s\tremaining: 38.8s\n",
      "9250:\tlearn: 0.0974582\ttest: 1.2964967\tbest: 1.2964967 (9250)\ttotal: 1m 1s\tremaining: 38.5s\n",
      "9300:\tlearn: 0.0958878\ttest: 1.2966169\tbest: 1.2964156 (9252)\ttotal: 1m 2s\tremaining: 38.1s\n",
      "9350:\tlearn: 0.0943622\ttest: 1.2950593\tbest: 1.2950593 (9350)\ttotal: 1m 2s\tremaining: 37.8s\n",
      "9400:\tlearn: 0.0929504\ttest: 1.2941308\tbest: 1.2940499 (9398)\ttotal: 1m 2s\tremaining: 37.5s\n",
      "9450:\tlearn: 0.0916123\ttest: 1.2938381\tbest: 1.2938381 (9450)\ttotal: 1m 3s\tremaining: 37.1s\n",
      "9500:\tlearn: 0.0903339\ttest: 1.2920957\tbest: 1.2920957 (9500)\ttotal: 1m 3s\tremaining: 36.8s\n",
      "9550:\tlearn: 0.0891587\ttest: 1.2911662\tbest: 1.2911330 (9528)\ttotal: 1m 3s\tremaining: 36.5s\n",
      "9600:\tlearn: 0.0878176\ttest: 1.2900044\tbest: 1.2898723 (9599)\ttotal: 1m 4s\tremaining: 36.1s\n",
      "9650:\tlearn: 0.0863678\ttest: 1.2901078\tbest: 1.2898723 (9599)\ttotal: 1m 4s\tremaining: 35.8s\n",
      "9700:\tlearn: 0.0849609\ttest: 1.2887610\tbest: 1.2887038 (9696)\ttotal: 1m 4s\tremaining: 35.5s\n",
      "9750:\tlearn: 0.0836638\ttest: 1.2877396\tbest: 1.2877396 (9750)\ttotal: 1m 5s\tremaining: 35.1s\n",
      "9800:\tlearn: 0.0825269\ttest: 1.2862407\tbest: 1.2861122 (9791)\ttotal: 1m 5s\tremaining: 34.8s\n",
      "9850:\tlearn: 0.0815400\ttest: 1.2851700\tbest: 1.2851700 (9850)\ttotal: 1m 5s\tremaining: 34.5s\n",
      "9900:\tlearn: 0.0803665\ttest: 1.2846306\tbest: 1.2843565 (9895)\ttotal: 1m 6s\tremaining: 34.1s\n",
      "9950:\tlearn: 0.0790499\ttest: 1.2849240\tbest: 1.2843565 (9895)\ttotal: 1m 6s\tremaining: 33.8s\n",
      "10000:\tlearn: 0.0777959\ttest: 1.2844181\tbest: 1.2839519 (9975)\ttotal: 1m 6s\tremaining: 33.5s\n",
      "10050:\tlearn: 0.0765983\ttest: 1.2850524\tbest: 1.2839519 (9975)\ttotal: 1m 7s\tremaining: 33.1s\n",
      "10100:\tlearn: 0.0754347\ttest: 1.2850548\tbest: 1.2839519 (9975)\ttotal: 1m 7s\tremaining: 32.8s\n",
      "10150:\tlearn: 0.0741011\ttest: 1.2844629\tbest: 1.2839519 (9975)\ttotal: 1m 7s\tremaining: 32.5s\n",
      "10200:\tlearn: 0.0731032\ttest: 1.2843192\tbest: 1.2839519 (9975)\ttotal: 1m 8s\tremaining: 32.1s\n",
      "10250:\tlearn: 0.0721070\ttest: 1.2843370\tbest: 1.2839519 (9975)\ttotal: 1m 8s\tremaining: 31.8s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.283951947\n",
      "bestIteration = 9975\n",
      "\n",
      "Shrink model to first 9976 iterations.\n",
      "Скор для фолда(12) : 9.0 средний скор на префиксе = 9.0 это заняло = 69 сек.\n",
      "Фолд: 13\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "0:\tlearn: 3.5703592\ttest: 3.8774906\tbest: 3.8774906 (0)\ttotal: 27.8ms\tremaining: 6m 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7102234\ttest: 3.0797101\tbest: 3.0797101 (50)\ttotal: 355ms\tremaining: 1m 44s\n",
      "100:\tlearn: 2.2437571\ttest: 2.6645917\tbest: 2.6645917 (100)\ttotal: 689ms\tremaining: 1m 41s\n",
      "150:\tlearn: 1.9829907\ttest: 2.4219449\tbest: 2.4219449 (150)\ttotal: 1.03s\tremaining: 1m 40s\n",
      "200:\tlearn: 1.8225498\ttest: 2.2704516\tbest: 2.2704516 (200)\ttotal: 1.36s\tremaining: 1m 40s\n",
      "250:\tlearn: 1.7141663\ttest: 2.1655358\tbest: 2.1655358 (250)\ttotal: 1.7s\tremaining: 1m 39s\n",
      "300:\tlearn: 1.6330833\ttest: 2.0892165\tbest: 2.0892165 (300)\ttotal: 2.04s\tremaining: 1m 39s\n",
      "350:\tlearn: 1.5713610\ttest: 2.0455655\tbest: 2.0455655 (350)\ttotal: 2.37s\tremaining: 1m 38s\n",
      "400:\tlearn: 1.5192310\ttest: 2.0033488\tbest: 2.0033488 (400)\ttotal: 2.7s\tremaining: 1m 38s\n",
      "450:\tlearn: 1.4747777\ttest: 1.9576663\tbest: 1.9576663 (450)\ttotal: 3.03s\tremaining: 1m 37s\n",
      "500:\tlearn: 1.4389311\ttest: 1.9063478\tbest: 1.9063478 (500)\ttotal: 3.36s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4096403\ttest: 1.8675984\tbest: 1.8675984 (550)\ttotal: 3.69s\tremaining: 1m 36s\n",
      "600:\tlearn: 1.3830354\ttest: 1.8311376\tbest: 1.8311376 (600)\ttotal: 4.02s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3574366\ttest: 1.7978626\tbest: 1.7978626 (650)\ttotal: 4.35s\tremaining: 1m 35s\n",
      "700:\tlearn: 1.3354064\ttest: 1.7759205\tbest: 1.7747742 (698)\ttotal: 4.68s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3130334\ttest: 1.7573273\tbest: 1.7573273 (750)\ttotal: 5.02s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.2923043\ttest: 1.7463218\tbest: 1.7448189 (792)\ttotal: 5.35s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.2713432\ttest: 1.7416124\tbest: 1.7416124 (850)\ttotal: 5.68s\tremaining: 1m 34s\n",
      "900:\tlearn: 1.2526944\ttest: 1.7328186\tbest: 1.7318081 (897)\ttotal: 6.01s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2358190\ttest: 1.7197242\tbest: 1.7197242 (950)\ttotal: 6.34s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2181049\ttest: 1.7084776\tbest: 1.7084776 (1000)\ttotal: 6.67s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2002414\ttest: 1.6962051\tbest: 1.6961680 (1049)\ttotal: 7.01s\tremaining: 1m 33s\n",
      "1100:\tlearn: 1.1829881\ttest: 1.6919339\tbest: 1.6919339 (1100)\ttotal: 7.34s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.1678533\ttest: 1.6818955\tbest: 1.6818955 (1150)\ttotal: 7.69s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1526472\ttest: 1.6717595\tbest: 1.6717595 (1200)\ttotal: 8.03s\tremaining: 1m 32s\n",
      "1250:\tlearn: 1.1341865\ttest: 1.6615325\tbest: 1.6614718 (1249)\ttotal: 8.36s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1166587\ttest: 1.6482415\tbest: 1.6482415 (1300)\ttotal: 8.69s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.0990618\ttest: 1.6386013\tbest: 1.6381744 (1349)\ttotal: 9.03s\tremaining: 1m 31s\n",
      "1400:\tlearn: 1.0837546\ttest: 1.6294778\tbest: 1.6294778 (1400)\ttotal: 9.35s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.0674723\ttest: 1.6214503\tbest: 1.6214503 (1450)\ttotal: 9.68s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0543161\ttest: 1.6154618\tbest: 1.6154618 (1500)\ttotal: 10s\tremaining: 1m 30s\n",
      "1550:\tlearn: 1.0402971\ttest: 1.6057965\tbest: 1.6057965 (1550)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0239987\ttest: 1.5979266\tbest: 1.5979266 (1600)\ttotal: 10.7s\tremaining: 1m 29s\n",
      "1650:\tlearn: 1.0090160\ttest: 1.5908957\tbest: 1.5903731 (1648)\ttotal: 11s\tremaining: 1m 29s\n",
      "1700:\tlearn: 0.9951299\ttest: 1.5868301\tbest: 1.5868301 (1700)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 0.9785560\ttest: 1.5789214\tbest: 1.5789214 (1750)\ttotal: 11.7s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9628344\ttest: 1.5751569\tbest: 1.5751462 (1799)\ttotal: 12s\tremaining: 1m 28s\n",
      "1850:\tlearn: 0.9478808\ttest: 1.5665664\tbest: 1.5663022 (1842)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9327354\ttest: 1.5568595\tbest: 1.5568595 (1900)\ttotal: 12.7s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9205303\ttest: 1.5511433\tbest: 1.5511433 (1950)\ttotal: 13s\tremaining: 1m 27s\n",
      "2000:\tlearn: 0.9045263\ttest: 1.5453528\tbest: 1.5450617 (1999)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.8900311\ttest: 1.5383195\tbest: 1.5382009 (2049)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.8758549\ttest: 1.5322567\tbest: 1.5322322 (2099)\ttotal: 14s\tremaining: 1m 25s\n",
      "2150:\tlearn: 0.8620128\ttest: 1.5251761\tbest: 1.5250390 (2147)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8471638\ttest: 1.5186405\tbest: 1.5186405 (2200)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8336061\ttest: 1.5125265\tbest: 1.5116548 (2244)\ttotal: 15s\tremaining: 1m 24s\n",
      "2300:\tlearn: 0.8207907\ttest: 1.5076193\tbest: 1.5073968 (2298)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8093379\ttest: 1.5033900\tbest: 1.5033900 (2350)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.7965165\ttest: 1.5004910\tbest: 1.5002117 (2390)\ttotal: 16s\tremaining: 1m 23s\n",
      "2450:\tlearn: 0.7836355\ttest: 1.4971914\tbest: 1.4955554 (2443)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.7722664\ttest: 1.4945498\tbest: 1.4941593 (2486)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7598086\ttest: 1.4856680\tbest: 1.4856680 (2550)\ttotal: 17s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.7451346\ttest: 1.4812626\tbest: 1.4812626 (2600)\ttotal: 17.3s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7324624\ttest: 1.4797234\tbest: 1.4794150 (2647)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7209858\ttest: 1.4757840\tbest: 1.4756507 (2692)\ttotal: 18s\tremaining: 1m 21s\n",
      "2750:\tlearn: 0.7099467\ttest: 1.4732533\tbest: 1.4732174 (2747)\ttotal: 18.3s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.6996058\ttest: 1.4714545\tbest: 1.4712274 (2799)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.6873336\ttest: 1.4706176\tbest: 1.4693177 (2828)\ttotal: 19s\tremaining: 1m 20s\n",
      "2900:\tlearn: 0.6770725\ttest: 1.4669543\tbest: 1.4669543 (2900)\ttotal: 19.3s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.6675663\ttest: 1.4651479\tbest: 1.4642381 (2913)\ttotal: 19.7s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.6576876\ttest: 1.4611309\tbest: 1.4611309 (3000)\ttotal: 20s\tremaining: 1m 19s\n",
      "3050:\tlearn: 0.6468381\ttest: 1.4606133\tbest: 1.4600371 (3012)\ttotal: 20.3s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6364298\ttest: 1.4601061\tbest: 1.4578717 (3069)\ttotal: 20.7s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6277076\ttest: 1.4596420\tbest: 1.4578717 (3069)\ttotal: 21s\tremaining: 1m 19s\n",
      "3200:\tlearn: 0.6186464\ttest: 1.4564315\tbest: 1.4552661 (3186)\ttotal: 21.3s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6093489\ttest: 1.4555222\tbest: 1.4552661 (3186)\ttotal: 21.7s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.5993663\ttest: 1.4527527\tbest: 1.4521255 (3294)\ttotal: 22s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.5891146\ttest: 1.4515366\tbest: 1.4513560 (3344)\ttotal: 22.4s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.5795975\ttest: 1.4474477\tbest: 1.4472346 (3397)\ttotal: 22.7s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.5696170\ttest: 1.4407952\tbest: 1.4405040 (3446)\ttotal: 23s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.5609412\ttest: 1.4379502\tbest: 1.4379502 (3500)\ttotal: 23.4s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5518234\ttest: 1.4342663\tbest: 1.4336761 (3546)\ttotal: 23.7s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5420500\ttest: 1.4302117\tbest: 1.4302117 (3600)\ttotal: 24s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.5339182\ttest: 1.4265163\tbest: 1.4265163 (3650)\ttotal: 24.4s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5245491\ttest: 1.4237195\tbest: 1.4237195 (3700)\ttotal: 24.7s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5149604\ttest: 1.4221761\tbest: 1.4218800 (3726)\ttotal: 25s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5062248\ttest: 1.4182365\tbest: 1.4182071 (3799)\ttotal: 25.4s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.4984961\ttest: 1.4152360\tbest: 1.4148928 (3839)\ttotal: 25.7s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.4903673\ttest: 1.4109615\tbest: 1.4107309 (3890)\ttotal: 26s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.4828190\ttest: 1.4101244\tbest: 1.4099973 (3948)\ttotal: 26.4s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.4747899\ttest: 1.4064360\tbest: 1.4061451 (3998)\ttotal: 26.7s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.4680119\ttest: 1.4052196\tbest: 1.4045972 (4047)\ttotal: 27s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.4606669\ttest: 1.4049606\tbest: 1.4039037 (4060)\ttotal: 27.4s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4541739\ttest: 1.4020820\tbest: 1.4018380 (4141)\ttotal: 27.7s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4464392\ttest: 1.3980169\tbest: 1.3974868 (4186)\ttotal: 28.1s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4378972\ttest: 1.3981853\tbest: 1.3965937 (4220)\ttotal: 28.4s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4315116\ttest: 1.3968052\tbest: 1.3961072 (4286)\ttotal: 28.7s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4258348\ttest: 1.3962659\tbest: 1.3956983 (4331)\ttotal: 29.1s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4191977\ttest: 1.3964641\tbest: 1.3956983 (4331)\ttotal: 29.4s\tremaining: 1m 10s\n",
      "4450:\tlearn: 0.4126301\ttest: 1.3945112\tbest: 1.3934151 (4443)\ttotal: 29.8s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4069580\ttest: 1.3908040\tbest: 1.3908040 (4500)\ttotal: 30.1s\tremaining: 1m 10s\n",
      "4550:\tlearn: 0.4008397\ttest: 1.3896549\tbest: 1.3889813 (4529)\ttotal: 30.4s\tremaining: 1m 9s\n",
      "4600:\tlearn: 0.3952136\ttest: 1.3899274\tbest: 1.3889813 (4529)\ttotal: 30.8s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.3893704\ttest: 1.3869591\tbest: 1.3864004 (4649)\ttotal: 31.1s\tremaining: 1m 9s\n",
      "4700:\tlearn: 0.3836881\ttest: 1.3862718\tbest: 1.3855922 (4687)\ttotal: 31.4s\tremaining: 1m 8s\n",
      "4750:\tlearn: 0.3778892\ttest: 1.3833993\tbest: 1.3833993 (4750)\ttotal: 31.8s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.3722125\ttest: 1.3850483\tbest: 1.3832941 (4758)\ttotal: 32.1s\tremaining: 1m 8s\n",
      "4850:\tlearn: 0.3656809\ttest: 1.3803047\tbest: 1.3798988 (4844)\ttotal: 32.4s\tremaining: 1m 7s\n",
      "4900:\tlearn: 0.3594217\ttest: 1.3781687\tbest: 1.3776408 (4897)\ttotal: 32.8s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3529049\ttest: 1.3743398\tbest: 1.3743287 (4949)\ttotal: 33.1s\tremaining: 1m 7s\n",
      "5000:\tlearn: 0.3468281\ttest: 1.3696416\tbest: 1.3696416 (5000)\ttotal: 33.5s\tremaining: 1m 6s\n",
      "5050:\tlearn: 0.3414359\ttest: 1.3683136\tbest: 1.3680730 (5045)\ttotal: 33.8s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3357914\ttest: 1.3648812\tbest: 1.3648812 (5100)\ttotal: 34.1s\tremaining: 1m 6s\n",
      "5150:\tlearn: 0.3305995\ttest: 1.3661741\tbest: 1.3648812 (5100)\ttotal: 34.5s\tremaining: 1m 5s\n",
      "5200:\tlearn: 0.3259936\ttest: 1.3642683\tbest: 1.3640451 (5191)\ttotal: 34.8s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3217055\ttest: 1.3613237\tbest: 1.3613237 (5250)\ttotal: 35.1s\tremaining: 1m 5s\n",
      "5300:\tlearn: 0.3174867\ttest: 1.3576066\tbest: 1.3576066 (5300)\ttotal: 35.5s\tremaining: 1m 4s\n",
      "5350:\tlearn: 0.3119284\ttest: 1.3559949\tbest: 1.3558503 (5327)\ttotal: 35.8s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3071000\ttest: 1.3531887\tbest: 1.3528145 (5397)\ttotal: 36.1s\tremaining: 1m 4s\n",
      "5450:\tlearn: 0.3018738\ttest: 1.3524785\tbest: 1.3524785 (5450)\ttotal: 36.5s\tremaining: 1m 3s\n",
      "5500:\tlearn: 0.2966869\ttest: 1.3523715\tbest: 1.3511834 (5464)\ttotal: 36.8s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.2924680\ttest: 1.3525429\tbest: 1.3511834 (5464)\ttotal: 37.1s\tremaining: 1m 3s\n",
      "5600:\tlearn: 0.2881408\ttest: 1.3522003\tbest: 1.3511834 (5464)\ttotal: 37.5s\tremaining: 1m 2s\n",
      "5650:\tlearn: 0.2834236\ttest: 1.3521155\tbest: 1.3511834 (5464)\ttotal: 37.8s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.2790655\ttest: 1.3504730\tbest: 1.3503137 (5697)\ttotal: 38.2s\tremaining: 1m 2s\n",
      "5750:\tlearn: 0.2745854\ttest: 1.3482303\tbest: 1.3482291 (5749)\ttotal: 38.5s\tremaining: 1m 1s\n",
      "5800:\tlearn: 0.2701691\ttest: 1.3482225\tbest: 1.3476537 (5780)\ttotal: 38.8s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2660853\ttest: 1.3463725\tbest: 1.3463018 (5846)\ttotal: 39.2s\tremaining: 1m 1s\n",
      "5900:\tlearn: 0.2622868\ttest: 1.3456520\tbest: 1.3455832 (5898)\ttotal: 39.5s\tremaining: 1m\n",
      "5950:\tlearn: 0.2586130\ttest: 1.3443908\tbest: 1.3443183 (5945)\ttotal: 39.8s\tremaining: 1m\n",
      "6000:\tlearn: 0.2539981\ttest: 1.3431605\tbest: 1.3429698 (5999)\ttotal: 40.2s\tremaining: 1m\n",
      "6050:\tlearn: 0.2503021\ttest: 1.3401682\tbest: 1.3401682 (6050)\ttotal: 40.5s\tremaining: 59.9s\n",
      "6100:\tlearn: 0.2465876\ttest: 1.3394345\tbest: 1.3387784 (6096)\ttotal: 40.8s\tremaining: 59.6s\n",
      "6150:\tlearn: 0.2426806\ttest: 1.3391502\tbest: 1.3387784 (6096)\ttotal: 41.2s\tremaining: 59.2s\n",
      "6200:\tlearn: 0.2387098\ttest: 1.3372571\tbest: 1.3371279 (6193)\ttotal: 41.5s\tremaining: 58.9s\n",
      "6250:\tlearn: 0.2349428\ttest: 1.3367161\tbest: 1.3366036 (6235)\ttotal: 41.8s\tremaining: 58.6s\n",
      "6300:\tlearn: 0.2315779\ttest: 1.3366456\tbest: 1.3348299 (6282)\ttotal: 42.2s\tremaining: 58.2s\n",
      "6350:\tlearn: 0.2280773\ttest: 1.3361588\tbest: 1.3348299 (6282)\ttotal: 42.5s\tremaining: 57.9s\n",
      "6400:\tlearn: 0.2241687\ttest: 1.3339004\tbest: 1.3335008 (6397)\ttotal: 42.9s\tremaining: 57.6s\n",
      "6450:\tlearn: 0.2202191\ttest: 1.3344381\tbest: 1.3335008 (6397)\ttotal: 43.2s\tremaining: 57.2s\n",
      "6500:\tlearn: 0.2156845\ttest: 1.3333260\tbest: 1.3333260 (6500)\ttotal: 43.5s\tremaining: 56.9s\n",
      "6550:\tlearn: 0.2114602\ttest: 1.3316743\tbest: 1.3313507 (6544)\ttotal: 43.9s\tremaining: 56.6s\n",
      "6600:\tlearn: 0.2082186\ttest: 1.3296232\tbest: 1.3291763 (6589)\ttotal: 44.2s\tremaining: 56.2s\n",
      "6650:\tlearn: 0.2043361\ttest: 1.3279672\tbest: 1.3279493 (6649)\ttotal: 44.5s\tremaining: 55.9s\n",
      "6700:\tlearn: 0.2007613\ttest: 1.3271765\tbest: 1.3270081 (6688)\ttotal: 44.9s\tremaining: 55.6s\n",
      "6750:\tlearn: 0.1974458\ttest: 1.3266904\tbest: 1.3263904 (6745)\ttotal: 45.2s\tremaining: 55.2s\n",
      "6800:\tlearn: 0.1941991\ttest: 1.3255592\tbest: 1.3255191 (6795)\ttotal: 45.5s\tremaining: 54.9s\n",
      "6850:\tlearn: 0.1911492\ttest: 1.3239362\tbest: 1.3236687 (6839)\ttotal: 45.9s\tremaining: 54.6s\n",
      "6900:\tlearn: 0.1881162\ttest: 1.3230721\tbest: 1.3229910 (6896)\ttotal: 46.2s\tremaining: 54.2s\n",
      "6950:\tlearn: 0.1854839\ttest: 1.3227207\tbest: 1.3221239 (6935)\ttotal: 46.5s\tremaining: 53.9s\n",
      "7000:\tlearn: 0.1829453\ttest: 1.3237028\tbest: 1.3221239 (6935)\ttotal: 46.9s\tremaining: 53.6s\n",
      "7050:\tlearn: 0.1807503\ttest: 1.3251702\tbest: 1.3221239 (6935)\ttotal: 47.2s\tremaining: 53.2s\n",
      "7100:\tlearn: 0.1782315\ttest: 1.3247944\tbest: 1.3221239 (6935)\ttotal: 47.5s\tremaining: 52.9s\n",
      "7150:\tlearn: 0.1756266\ttest: 1.3251162\tbest: 1.3221239 (6935)\ttotal: 47.9s\tremaining: 52.6s\n",
      "7200:\tlearn: 0.1727704\ttest: 1.3227175\tbest: 1.3221239 (6935)\ttotal: 48.2s\tremaining: 52.2s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.32212394\n",
      "bestIteration = 6935\n",
      "\n",
      "Shrink model to first 6936 iterations.\n",
      "Скор для фолда(13) : 9.0 средний скор на префиксе = 9.0 это заняло = 49 сек.\n",
      "Фолд: 14\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "0:\tlearn: 3.6212224\ttest: 3.3030188\tbest: 3.3030188 (0)\ttotal: 29.1ms\tremaining: 7m 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7586379\ttest: 2.4972727\tbest: 2.4972727 (50)\ttotal: 364ms\tremaining: 1m 46s\n",
      "100:\tlearn: 2.2980301\ttest: 1.9769083\tbest: 1.9769083 (100)\ttotal: 698ms\tremaining: 1m 42s\n",
      "150:\tlearn: 2.0472263\ttest: 1.7340799\tbest: 1.7340799 (150)\ttotal: 1.04s\tremaining: 1m 41s\n",
      "200:\tlearn: 1.8859843\ttest: 1.5835941\tbest: 1.5835941 (200)\ttotal: 1.36s\tremaining: 1m 40s\n",
      "250:\tlearn: 1.7755894\ttest: 1.5045761\tbest: 1.5045761 (250)\ttotal: 1.7s\tremaining: 1m 40s\n",
      "300:\tlearn: 1.6963564\ttest: 1.4601377\tbest: 1.4601377 (300)\ttotal: 2.04s\tremaining: 1m 39s\n",
      "350:\tlearn: 1.6289511\ttest: 1.4268650\tbest: 1.4268650 (350)\ttotal: 2.38s\tremaining: 1m 39s\n",
      "400:\tlearn: 1.5742862\ttest: 1.4159951\tbest: 1.4146121 (399)\ttotal: 2.71s\tremaining: 1m 38s\n",
      "450:\tlearn: 1.5310411\ttest: 1.4027300\tbest: 1.4023053 (443)\ttotal: 3.06s\tremaining: 1m 38s\n",
      "500:\tlearn: 1.4943126\ttest: 1.3911179\tbest: 1.3905242 (497)\ttotal: 3.39s\tremaining: 1m 38s\n",
      "550:\tlearn: 1.4637905\ttest: 1.3862903\tbest: 1.3860096 (549)\ttotal: 3.72s\tremaining: 1m 37s\n",
      "600:\tlearn: 1.4326829\ttest: 1.3808004\tbest: 1.3776523 (590)\ttotal: 4.06s\tremaining: 1m 37s\n",
      "650:\tlearn: 1.4065608\ttest: 1.3779899\tbest: 1.3769726 (647)\ttotal: 4.39s\tremaining: 1m 36s\n",
      "700:\tlearn: 1.3824555\ttest: 1.3752572\tbest: 1.3730662 (688)\ttotal: 4.72s\tremaining: 1m 36s\n",
      "750:\tlearn: 1.3610155\ttest: 1.3654059\tbest: 1.3654059 (750)\ttotal: 5.06s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.3401153\ttest: 1.3612284\tbest: 1.3605999 (794)\ttotal: 5.38s\tremaining: 1m 35s\n",
      "850:\tlearn: 1.3184987\ttest: 1.3558564\tbest: 1.3558111 (849)\ttotal: 5.71s\tremaining: 1m 35s\n",
      "900:\tlearn: 1.2985035\ttest: 1.3529996\tbest: 1.3488832 (891)\ttotal: 6.05s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2799181\ttest: 1.3535090\tbest: 1.3488832 (891)\ttotal: 6.38s\tremaining: 1m 34s\n",
      "1000:\tlearn: 1.2598356\ttest: 1.3490727\tbest: 1.3483278 (988)\ttotal: 6.71s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2400192\ttest: 1.3469954\tbest: 1.3459348 (1040)\ttotal: 7.04s\tremaining: 1m 33s\n",
      "1100:\tlearn: 1.2203635\ttest: 1.3433770\tbest: 1.3433703 (1099)\ttotal: 7.37s\tremaining: 1m 33s\n",
      "1150:\tlearn: 1.2026835\ttest: 1.3393817\tbest: 1.3393817 (1150)\ttotal: 7.7s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1842794\ttest: 1.3347514\tbest: 1.3347514 (1200)\ttotal: 8.04s\tremaining: 1m 32s\n",
      "1250:\tlearn: 1.1667499\ttest: 1.3354081\tbest: 1.3345015 (1239)\ttotal: 8.37s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1512059\ttest: 1.3343640\tbest: 1.3333857 (1288)\ttotal: 8.7s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.1356680\ttest: 1.3313824\tbest: 1.3309346 (1333)\ttotal: 9.04s\tremaining: 1m 31s\n",
      "1400:\tlearn: 1.1179414\ttest: 1.3280519\tbest: 1.3280519 (1400)\ttotal: 9.39s\tremaining: 1m 31s\n",
      "1450:\tlearn: 1.1014047\ttest: 1.3274502\tbest: 1.3265645 (1414)\ttotal: 9.72s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0841262\ttest: 1.3234929\tbest: 1.3226770 (1498)\ttotal: 10.1s\tremaining: 1m 30s\n",
      "1550:\tlearn: 1.0681214\ttest: 1.3178331\tbest: 1.3178331 (1550)\ttotal: 10.4s\tremaining: 1m 30s\n",
      "1600:\tlearn: 1.0512685\ttest: 1.3165791\tbest: 1.3165791 (1600)\ttotal: 10.7s\tremaining: 1m 29s\n",
      "1650:\tlearn: 1.0348648\ttest: 1.3106774\tbest: 1.3102905 (1649)\ttotal: 11s\tremaining: 1m 29s\n",
      "1700:\tlearn: 1.0185113\ttest: 1.3035022\tbest: 1.3035022 (1700)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1750:\tlearn: 1.0024225\ttest: 1.3017472\tbest: 1.3017301 (1745)\ttotal: 11.7s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9873409\ttest: 1.2980307\tbest: 1.2979400 (1795)\ttotal: 12s\tremaining: 1m 28s\n",
      "1850:\tlearn: 0.9726679\ttest: 1.2974059\tbest: 1.2971969 (1829)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9576334\ttest: 1.2935323\tbest: 1.2931760 (1896)\ttotal: 12.7s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9446374\ttest: 1.2917394\tbest: 1.2916136 (1942)\ttotal: 13s\tremaining: 1m 27s\n",
      "2000:\tlearn: 0.9304017\ttest: 1.2894078\tbest: 1.2879589 (1974)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.9150417\ttest: 1.2870938\tbest: 1.2867243 (2048)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.9022464\ttest: 1.2864030\tbest: 1.2851523 (2086)\ttotal: 14s\tremaining: 1m 26s\n",
      "2150:\tlearn: 0.8874473\ttest: 1.2817210\tbest: 1.2807767 (2139)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8745228\ttest: 1.2816204\tbest: 1.2803906 (2174)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8618776\ttest: 1.2801063\tbest: 1.2801063 (2250)\ttotal: 15s\tremaining: 1m 25s\n",
      "2300:\tlearn: 0.8480519\ttest: 1.2763750\tbest: 1.2763381 (2298)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8360368\ttest: 1.2723012\tbest: 1.2723012 (2350)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8259059\ttest: 1.2738888\tbest: 1.2714846 (2360)\ttotal: 16s\tremaining: 1m 24s\n",
      "2450:\tlearn: 0.8133416\ttest: 1.2684714\tbest: 1.2683275 (2444)\ttotal: 16.4s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.8009320\ttest: 1.2682523\tbest: 1.2682276 (2499)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7905230\ttest: 1.2639597\tbest: 1.2639597 (2550)\ttotal: 17s\tremaining: 1m 23s\n",
      "2600:\tlearn: 0.7794190\ttest: 1.2617094\tbest: 1.2617094 (2600)\ttotal: 17.4s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7677775\ttest: 1.2577822\tbest: 1.2563250 (2636)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7560925\ttest: 1.2519024\tbest: 1.2519024 (2700)\ttotal: 18s\tremaining: 1m 22s\n",
      "2750:\tlearn: 0.7439493\ttest: 1.2460379\tbest: 1.2460379 (2750)\ttotal: 18.4s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7325700\ttest: 1.2476197\tbest: 1.2447332 (2766)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.7223025\ttest: 1.2436355\tbest: 1.2431871 (2835)\ttotal: 19s\tremaining: 1m 21s\n",
      "2900:\tlearn: 0.7127338\ttest: 1.2421612\tbest: 1.2420261 (2892)\ttotal: 19.4s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.7011229\ttest: 1.2366782\tbest: 1.2366782 (2950)\ttotal: 19.7s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.6890522\ttest: 1.2327958\tbest: 1.2318433 (2986)\ttotal: 20s\tremaining: 1m 20s\n",
      "3050:\tlearn: 0.6801096\ttest: 1.2285051\tbest: 1.2285051 (3050)\ttotal: 20.4s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6708898\ttest: 1.2259263\tbest: 1.2259263 (3100)\ttotal: 20.7s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6616700\ttest: 1.2217716\tbest: 1.2217716 (3150)\ttotal: 21s\tremaining: 1m 19s\n",
      "3200:\tlearn: 0.6508698\ttest: 1.2199853\tbest: 1.2199853 (3200)\ttotal: 21.4s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6402090\ttest: 1.2162276\tbest: 1.2157834 (3245)\ttotal: 21.7s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6281980\ttest: 1.2143523\tbest: 1.2139953 (3298)\ttotal: 22s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.6192607\ttest: 1.2124766\tbest: 1.2121373 (3346)\ttotal: 22.4s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.6099934\ttest: 1.2113560\tbest: 1.2111565 (3391)\ttotal: 22.7s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.6019200\ttest: 1.2083218\tbest: 1.2082153 (3443)\ttotal: 23.1s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.5928935\ttest: 1.2058701\tbest: 1.2058701 (3500)\ttotal: 23.4s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5843258\ttest: 1.2041529\tbest: 1.2038331 (3520)\ttotal: 23.7s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5760257\ttest: 1.1990541\tbest: 1.1990541 (3600)\ttotal: 24.1s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.5659749\ttest: 1.1991825\tbest: 1.1964975 (3628)\ttotal: 24.4s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5574824\ttest: 1.1989702\tbest: 1.1964975 (3628)\ttotal: 24.7s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5488676\ttest: 1.1960521\tbest: 1.1960521 (3750)\ttotal: 25.1s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5414690\ttest: 1.1939159\tbest: 1.1939159 (3800)\ttotal: 25.4s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5336309\ttest: 1.1913154\tbest: 1.1911397 (3849)\ttotal: 25.7s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5272240\ttest: 1.1878376\tbest: 1.1878072 (3896)\ttotal: 26.1s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.5210963\ttest: 1.1861589\tbest: 1.1856838 (3933)\ttotal: 26.4s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.5125334\ttest: 1.1823856\tbest: 1.1823160 (3996)\ttotal: 26.7s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.5053955\ttest: 1.1811524\tbest: 1.1798809 (4036)\ttotal: 27.1s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.4974534\ttest: 1.1791344\tbest: 1.1789348 (4099)\ttotal: 27.4s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4896052\ttest: 1.1750718\tbest: 1.1750718 (4150)\ttotal: 27.7s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4823404\ttest: 1.1725037\tbest: 1.1720271 (4188)\ttotal: 28.1s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4758631\ttest: 1.1714552\tbest: 1.1706281 (4219)\ttotal: 28.4s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4693615\ttest: 1.1697382\tbest: 1.1695993 (4282)\ttotal: 28.7s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4619526\ttest: 1.1672862\tbest: 1.1672803 (4349)\ttotal: 29.1s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4548931\ttest: 1.1651064\tbest: 1.1648383 (4396)\ttotal: 29.4s\tremaining: 1m 10s\n",
      "4450:\tlearn: 0.4474093\ttest: 1.1642278\tbest: 1.1639797 (4411)\ttotal: 29.8s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4405997\ttest: 1.1636819\tbest: 1.1636113 (4499)\ttotal: 30.1s\tremaining: 1m 10s\n",
      "4550:\tlearn: 0.4336502\ttest: 1.1624895\tbest: 1.1624895 (4550)\ttotal: 30.5s\tremaining: 1m 9s\n",
      "4600:\tlearn: 0.4269592\ttest: 1.1606415\tbest: 1.1602748 (4581)\ttotal: 30.8s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4207473\ttest: 1.1609564\tbest: 1.1602748 (4581)\ttotal: 31.1s\tremaining: 1m 9s\n",
      "4700:\tlearn: 0.4137541\ttest: 1.1627772\tbest: 1.1602748 (4581)\ttotal: 31.5s\tremaining: 1m 8s\n",
      "4750:\tlearn: 0.4075168\ttest: 1.1619465\tbest: 1.1602748 (4581)\ttotal: 31.8s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.4009095\ttest: 1.1623569\tbest: 1.1602748 (4581)\ttotal: 32.1s\tremaining: 1m 8s\n",
      "4850:\tlearn: 0.3946751\ttest: 1.1607626\tbest: 1.1602748 (4581)\ttotal: 32.5s\tremaining: 1m 7s\n",
      "4900:\tlearn: 0.3891537\ttest: 1.1585586\tbest: 1.1585586 (4900)\ttotal: 32.8s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3830567\ttest: 1.1536027\tbest: 1.1535147 (4949)\ttotal: 33.2s\tremaining: 1m 7s\n",
      "5000:\tlearn: 0.3769997\ttest: 1.1549536\tbest: 1.1535147 (4949)\ttotal: 33.5s\tremaining: 1m 6s\n",
      "5050:\tlearn: 0.3710563\ttest: 1.1543395\tbest: 1.1535147 (4949)\ttotal: 33.8s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3669086\ttest: 1.1524781\tbest: 1.1524022 (5096)\ttotal: 34.2s\tremaining: 1m 6s\n",
      "5150:\tlearn: 0.3612511\ttest: 1.1508670\tbest: 1.1508670 (5150)\ttotal: 34.5s\tremaining: 1m 5s\n",
      "5200:\tlearn: 0.3550229\ttest: 1.1492975\tbest: 1.1492975 (5200)\ttotal: 34.8s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3495679\ttest: 1.1475223\tbest: 1.1473756 (5247)\ttotal: 35.2s\tremaining: 1m 5s\n",
      "5300:\tlearn: 0.3433322\ttest: 1.1453463\tbest: 1.1449439 (5296)\ttotal: 35.5s\tremaining: 1m 4s\n",
      "5350:\tlearn: 0.3377071\ttest: 1.1454321\tbest: 1.1448874 (5341)\ttotal: 35.8s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3332166\ttest: 1.1457080\tbest: 1.1447609 (5363)\ttotal: 36.2s\tremaining: 1m 4s\n",
      "5450:\tlearn: 0.3283041\ttest: 1.1456838\tbest: 1.1447609 (5363)\ttotal: 36.5s\tremaining: 1m 3s\n",
      "5500:\tlearn: 0.3239601\ttest: 1.1438231\tbest: 1.1435393 (5498)\ttotal: 36.8s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3197744\ttest: 1.1423200\tbest: 1.1419865 (5544)\ttotal: 37.2s\tremaining: 1m 3s\n",
      "5600:\tlearn: 0.3139455\ttest: 1.1406773\tbest: 1.1405890 (5593)\ttotal: 37.5s\tremaining: 1m 2s\n",
      "5650:\tlearn: 0.3087147\ttest: 1.1378671\tbest: 1.1378671 (5650)\ttotal: 37.8s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.3032859\ttest: 1.1364106\tbest: 1.1364106 (5700)\ttotal: 38.2s\tremaining: 1m 2s\n",
      "5750:\tlearn: 0.2991008\ttest: 1.1333828\tbest: 1.1328493 (5735)\ttotal: 38.5s\tremaining: 1m 1s\n",
      "5800:\tlearn: 0.2939970\ttest: 1.1322952\tbest: 1.1316438 (5788)\ttotal: 38.9s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2894596\ttest: 1.1318032\tbest: 1.1314917 (5838)\ttotal: 39.2s\tremaining: 1m 1s\n",
      "5900:\tlearn: 0.2855737\ttest: 1.1318282\tbest: 1.1309336 (5878)\ttotal: 39.5s\tremaining: 1m\n",
      "5950:\tlearn: 0.2806436\ttest: 1.1294062\tbest: 1.1294062 (5950)\ttotal: 39.9s\tremaining: 1m\n",
      "6000:\tlearn: 0.2769294\ttest: 1.1297301\tbest: 1.1294062 (5950)\ttotal: 40.2s\tremaining: 1m\n",
      "6050:\tlearn: 0.2726123\ttest: 1.1267402\tbest: 1.1267402 (6050)\ttotal: 40.5s\tremaining: 59.9s\n",
      "6100:\tlearn: 0.2681012\ttest: 1.1259924\tbest: 1.1259924 (6100)\ttotal: 40.9s\tremaining: 59.6s\n",
      "6150:\tlearn: 0.2643277\ttest: 1.1244253\tbest: 1.1244075 (6138)\ttotal: 41.2s\tremaining: 59.3s\n",
      "6200:\tlearn: 0.2599493\ttest: 1.1236436\tbest: 1.1227861 (6190)\ttotal: 41.5s\tremaining: 58.9s\n",
      "6250:\tlearn: 0.2559622\ttest: 1.1235873\tbest: 1.1221749 (6232)\ttotal: 41.9s\tremaining: 58.6s\n",
      "6300:\tlearn: 0.2519826\ttest: 1.1236905\tbest: 1.1221749 (6232)\ttotal: 42.2s\tremaining: 58.3s\n",
      "6350:\tlearn: 0.2480088\ttest: 1.1217510\tbest: 1.1211926 (6340)\ttotal: 42.5s\tremaining: 57.9s\n",
      "6400:\tlearn: 0.2438399\ttest: 1.1207621\tbest: 1.1202940 (6390)\ttotal: 42.9s\tremaining: 57.6s\n",
      "6450:\tlearn: 0.2399060\ttest: 1.1192434\tbest: 1.1192434 (6450)\ttotal: 43.2s\tremaining: 57.3s\n",
      "6500:\tlearn: 0.2361368\ttest: 1.1187703\tbest: 1.1184722 (6484)\ttotal: 43.6s\tremaining: 57s\n",
      "6550:\tlearn: 0.2324323\ttest: 1.1166755\tbest: 1.1166340 (6534)\ttotal: 43.9s\tremaining: 56.6s\n",
      "6600:\tlearn: 0.2289692\ttest: 1.1150728\tbest: 1.1150728 (6600)\ttotal: 44.2s\tremaining: 56.3s\n",
      "6650:\tlearn: 0.2253162\ttest: 1.1143905\tbest: 1.1141264 (6632)\ttotal: 44.6s\tremaining: 56s\n",
      "6700:\tlearn: 0.2218717\ttest: 1.1144818\tbest: 1.1139537 (6690)\ttotal: 44.9s\tremaining: 55.6s\n",
      "6750:\tlearn: 0.2187303\ttest: 1.1121715\tbest: 1.1121028 (6748)\ttotal: 45.3s\tremaining: 55.3s\n",
      "6800:\tlearn: 0.2153526\ttest: 1.1117384\tbest: 1.1117384 (6800)\ttotal: 45.6s\tremaining: 55s\n",
      "6850:\tlearn: 0.2121227\ttest: 1.1120569\tbest: 1.1106770 (6832)\ttotal: 45.9s\tremaining: 54.6s\n",
      "6900:\tlearn: 0.2089617\ttest: 1.1103934\tbest: 1.1103934 (6900)\ttotal: 46.3s\tremaining: 54.3s\n",
      "6950:\tlearn: 0.2058480\ttest: 1.1082522\tbest: 1.1082468 (6949)\ttotal: 46.6s\tremaining: 54s\n",
      "7000:\tlearn: 0.2028612\ttest: 1.1059864\tbest: 1.1056883 (6995)\ttotal: 46.9s\tremaining: 53.6s\n",
      "7050:\tlearn: 0.1996189\ttest: 1.1034780\tbest: 1.1034780 (7050)\ttotal: 47.3s\tremaining: 53.3s\n",
      "7100:\tlearn: 0.1963598\ttest: 1.1030163\tbest: 1.1025813 (7082)\ttotal: 47.6s\tremaining: 53s\n",
      "7150:\tlearn: 0.1934717\ttest: 1.1023189\tbest: 1.1019246 (7140)\ttotal: 47.9s\tremaining: 52.6s\n",
      "7200:\tlearn: 0.1908607\ttest: 1.1010116\tbest: 1.1010062 (7184)\ttotal: 48.3s\tremaining: 52.3s\n",
      "7250:\tlearn: 0.1879231\ttest: 1.1002847\tbest: 1.1002348 (7244)\ttotal: 48.6s\tremaining: 51.9s\n",
      "7300:\tlearn: 0.1854947\ttest: 1.0972285\tbest: 1.0972285 (7300)\ttotal: 49s\tremaining: 51.6s\n",
      "7350:\tlearn: 0.1829896\ttest: 1.0964700\tbest: 1.0963796 (7334)\ttotal: 49.3s\tremaining: 51.3s\n",
      "7400:\tlearn: 0.1799521\ttest: 1.0955694\tbest: 1.0952980 (7398)\ttotal: 49.6s\tremaining: 51s\n",
      "7450:\tlearn: 0.1773595\ttest: 1.0948397\tbest: 1.0948397 (7450)\ttotal: 50s\tremaining: 50.6s\n",
      "7500:\tlearn: 0.1748129\ttest: 1.0946843\tbest: 1.0943446 (7477)\ttotal: 50.3s\tremaining: 50.3s\n",
      "7550:\tlearn: 0.1720922\ttest: 1.0916825\tbest: 1.0916542 (7548)\ttotal: 50.6s\tremaining: 49.9s\n",
      "7600:\tlearn: 0.1697264\ttest: 1.0911719\tbest: 1.0911719 (7600)\ttotal: 51s\tremaining: 49.6s\n",
      "7650:\tlearn: 0.1671979\ttest: 1.0903871\tbest: 1.0903117 (7649)\ttotal: 51.3s\tremaining: 49.3s\n",
      "7700:\tlearn: 0.1648438\ttest: 1.0895558\tbest: 1.0892368 (7682)\ttotal: 51.6s\tremaining: 48.9s\n",
      "7750:\tlearn: 0.1626335\ttest: 1.0885516\tbest: 1.0881729 (7747)\ttotal: 52s\tremaining: 48.6s\n",
      "7800:\tlearn: 0.1599556\ttest: 1.0879268\tbest: 1.0875633 (7777)\ttotal: 52.3s\tremaining: 48.3s\n",
      "7850:\tlearn: 0.1570976\ttest: 1.0872905\tbest: 1.0866266 (7831)\ttotal: 52.6s\tremaining: 47.9s\n",
      "7900:\tlearn: 0.1547196\ttest: 1.0854021\tbest: 1.0854021 (7900)\ttotal: 53s\tremaining: 47.6s\n",
      "7950:\tlearn: 0.1524116\ttest: 1.0841156\tbest: 1.0838906 (7943)\ttotal: 53.3s\tremaining: 47.3s\n",
      "8000:\tlearn: 0.1499376\ttest: 1.0826457\tbest: 1.0826101 (7999)\ttotal: 53.6s\tremaining: 46.9s\n",
      "8050:\tlearn: 0.1475894\ttest: 1.0824518\tbest: 1.0818853 (8042)\ttotal: 54s\tremaining: 46.6s\n",
      "8100:\tlearn: 0.1454193\ttest: 1.0814584\tbest: 1.0813982 (8095)\ttotal: 54.3s\tremaining: 46.3s\n",
      "8150:\tlearn: 0.1434091\ttest: 1.0803642\tbest: 1.0802177 (8142)\ttotal: 54.6s\tremaining: 45.9s\n",
      "8200:\tlearn: 0.1413246\ttest: 1.0801362\tbest: 1.0799075 (8197)\ttotal: 55s\tremaining: 45.6s\n",
      "8250:\tlearn: 0.1390161\ttest: 1.0804938\tbest: 1.0799075 (8197)\ttotal: 55.3s\tremaining: 45.3s\n",
      "8300:\tlearn: 0.1366030\ttest: 1.0792855\tbest: 1.0792855 (8300)\ttotal: 55.7s\tremaining: 44.9s\n",
      "8350:\tlearn: 0.1346422\ttest: 1.0778522\tbest: 1.0776894 (8349)\ttotal: 56s\tremaining: 44.6s\n",
      "8400:\tlearn: 0.1324498\ttest: 1.0770620\tbest: 1.0767908 (8397)\ttotal: 56.3s\tremaining: 44.3s\n",
      "8450:\tlearn: 0.1306136\ttest: 1.0753147\tbest: 1.0750754 (8445)\ttotal: 56.7s\tremaining: 43.9s\n",
      "8500:\tlearn: 0.1286131\ttest: 1.0747839\tbest: 1.0742425 (8496)\ttotal: 57s\tremaining: 43.6s\n",
      "8550:\tlearn: 0.1265303\ttest: 1.0736812\tbest: 1.0736812 (8550)\ttotal: 57.3s\tremaining: 43.3s\n",
      "8600:\tlearn: 0.1244186\ttest: 1.0720992\tbest: 1.0720992 (8600)\ttotal: 57.7s\tremaining: 42.9s\n",
      "8650:\tlearn: 0.1227139\ttest: 1.0708494\tbest: 1.0707453 (8646)\ttotal: 58s\tremaining: 42.6s\n",
      "8700:\tlearn: 0.1207967\ttest: 1.0704190\tbest: 1.0701725 (8680)\ttotal: 58.4s\tremaining: 42.3s\n",
      "8750:\tlearn: 0.1193362\ttest: 1.0699977\tbest: 1.0696487 (8746)\ttotal: 58.7s\tremaining: 41.9s\n",
      "8800:\tlearn: 0.1177997\ttest: 1.0680059\tbest: 1.0680059 (8800)\ttotal: 59.1s\tremaining: 41.6s\n",
      "8850:\tlearn: 0.1161965\ttest: 1.0674493\tbest: 1.0674493 (8850)\ttotal: 59.4s\tremaining: 41.3s\n",
      "8900:\tlearn: 0.1143966\ttest: 1.0669356\tbest: 1.0669356 (8900)\ttotal: 59.7s\tremaining: 40.9s\n",
      "8950:\tlearn: 0.1124919\ttest: 1.0656585\tbest: 1.0656585 (8950)\ttotal: 1m\tremaining: 40.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000:\tlearn: 0.1109780\ttest: 1.0650386\tbest: 1.0648428 (8982)\ttotal: 1m\tremaining: 40.3s\n",
      "9050:\tlearn: 0.1094223\ttest: 1.0645780\tbest: 1.0643152 (9019)\ttotal: 1m\tremaining: 39.9s\n",
      "9100:\tlearn: 0.1078943\ttest: 1.0638266\tbest: 1.0636101 (9074)\ttotal: 1m 1s\tremaining: 39.6s\n",
      "9150:\tlearn: 0.1064772\ttest: 1.0641626\tbest: 1.0633040 (9126)\ttotal: 1m 1s\tremaining: 39.3s\n",
      "9200:\tlearn: 0.1046769\ttest: 1.0637373\tbest: 1.0628799 (9193)\ttotal: 1m 1s\tremaining: 38.9s\n",
      "9250:\tlearn: 0.1032693\ttest: 1.0618259\tbest: 1.0615719 (9245)\ttotal: 1m 2s\tremaining: 38.6s\n",
      "9300:\tlearn: 0.1013992\ttest: 1.0614887\tbest: 1.0613448 (9265)\ttotal: 1m 2s\tremaining: 38.2s\n",
      "9350:\tlearn: 0.0996534\ttest: 1.0609493\tbest: 1.0608235 (9335)\ttotal: 1m 2s\tremaining: 37.9s\n",
      "9400:\tlearn: 0.0982839\ttest: 1.0590293\tbest: 1.0590293 (9400)\ttotal: 1m 3s\tremaining: 37.6s\n",
      "9450:\tlearn: 0.0969941\ttest: 1.0578095\tbest: 1.0578095 (9450)\ttotal: 1m 3s\tremaining: 37.2s\n",
      "9500:\tlearn: 0.0955338\ttest: 1.0561580\tbest: 1.0561030 (9493)\ttotal: 1m 3s\tremaining: 36.9s\n",
      "9550:\tlearn: 0.0937545\ttest: 1.0545147\tbest: 1.0545147 (9550)\ttotal: 1m 4s\tremaining: 36.6s\n",
      "9600:\tlearn: 0.0924892\ttest: 1.0534453\tbest: 1.0534330 (9599)\ttotal: 1m 4s\tremaining: 36.2s\n",
      "9650:\tlearn: 0.0913521\ttest: 1.0517995\tbest: 1.0517995 (9650)\ttotal: 1m 4s\tremaining: 35.9s\n",
      "9700:\tlearn: 0.0899824\ttest: 1.0500277\tbest: 1.0499856 (9689)\ttotal: 1m 5s\tremaining: 35.6s\n",
      "9750:\tlearn: 0.0885256\ttest: 1.0491886\tbest: 1.0489925 (9734)\ttotal: 1m 5s\tremaining: 35.2s\n",
      "9800:\tlearn: 0.0872348\ttest: 1.0481826\tbest: 1.0481826 (9800)\ttotal: 1m 5s\tremaining: 34.9s\n",
      "9850:\tlearn: 0.0860670\ttest: 1.0476063\tbest: 1.0473218 (9831)\ttotal: 1m 6s\tremaining: 34.6s\n",
      "9900:\tlearn: 0.0849265\ttest: 1.0457948\tbest: 1.0457700 (9898)\ttotal: 1m 6s\tremaining: 34.2s\n",
      "9950:\tlearn: 0.0836495\ttest: 1.0444281\tbest: 1.0444124 (9941)\ttotal: 1m 6s\tremaining: 33.9s\n",
      "10000:\tlearn: 0.0825566\ttest: 1.0447190\tbest: 1.0442215 (9984)\ttotal: 1m 7s\tremaining: 33.6s\n",
      "10050:\tlearn: 0.0814286\ttest: 1.0445932\tbest: 1.0442215 (9984)\ttotal: 1m 7s\tremaining: 33.2s\n",
      "10100:\tlearn: 0.0802367\ttest: 1.0454517\tbest: 1.0442215 (9984)\ttotal: 1m 7s\tremaining: 32.9s\n",
      "10150:\tlearn: 0.0789608\ttest: 1.0447214\tbest: 1.0442215 (9984)\ttotal: 1m 8s\tremaining: 32.6s\n",
      "10200:\tlearn: 0.0777740\ttest: 1.0440515\tbest: 1.0440515 (10200)\ttotal: 1m 8s\tremaining: 32.2s\n",
      "10250:\tlearn: 0.0764378\ttest: 1.0436323\tbest: 1.0433535 (10237)\ttotal: 1m 8s\tremaining: 31.9s\n",
      "10300:\tlearn: 0.0753022\ttest: 1.0436253\tbest: 1.0433535 (10237)\ttotal: 1m 9s\tremaining: 31.6s\n",
      "10350:\tlearn: 0.0742713\ttest: 1.0424689\tbest: 1.0424689 (10350)\ttotal: 1m 9s\tremaining: 31.2s\n",
      "10400:\tlearn: 0.0731989\ttest: 1.0429745\tbest: 1.0424689 (10350)\ttotal: 1m 9s\tremaining: 30.9s\n",
      "10450:\tlearn: 0.0722555\ttest: 1.0428384\tbest: 1.0424689 (10350)\ttotal: 1m 10s\tremaining: 30.6s\n",
      "10500:\tlearn: 0.0710787\ttest: 1.0426562\tbest: 1.0421276 (10468)\ttotal: 1m 10s\tremaining: 30.2s\n",
      "10550:\tlearn: 0.0702022\ttest: 1.0417289\tbest: 1.0417289 (10550)\ttotal: 1m 10s\tremaining: 29.9s\n",
      "10600:\tlearn: 0.0692264\ttest: 1.0411241\tbest: 1.0409532 (10581)\ttotal: 1m 11s\tremaining: 29.6s\n",
      "10650:\tlearn: 0.0681917\ttest: 1.0407337\tbest: 1.0407337 (10650)\ttotal: 1m 11s\tremaining: 29.2s\n",
      "10700:\tlearn: 0.0672986\ttest: 1.0399242\tbest: 1.0398752 (10698)\ttotal: 1m 11s\tremaining: 28.9s\n",
      "10750:\tlearn: 0.0663158\ttest: 1.0401442\tbest: 1.0396676 (10718)\ttotal: 1m 12s\tremaining: 28.6s\n",
      "10800:\tlearn: 0.0653537\ttest: 1.0393762\tbest: 1.0393762 (10800)\ttotal: 1m 12s\tremaining: 28.2s\n",
      "10850:\tlearn: 0.0644649\ttest: 1.0391783\tbest: 1.0389190 (10839)\ttotal: 1m 12s\tremaining: 27.9s\n",
      "10900:\tlearn: 0.0636193\ttest: 1.0388546\tbest: 1.0387229 (10899)\ttotal: 1m 13s\tremaining: 27.5s\n",
      "10950:\tlearn: 0.0629278\ttest: 1.0389928\tbest: 1.0387229 (10899)\ttotal: 1m 13s\tremaining: 27.2s\n",
      "11000:\tlearn: 0.0620587\ttest: 1.0377361\tbest: 1.0376262 (10998)\ttotal: 1m 13s\tremaining: 26.9s\n",
      "11050:\tlearn: 0.0612886\ttest: 1.0374137\tbest: 1.0373006 (11043)\ttotal: 1m 14s\tremaining: 26.5s\n",
      "11100:\tlearn: 0.0603682\ttest: 1.0378013\tbest: 1.0372414 (11067)\ttotal: 1m 14s\tremaining: 26.2s\n",
      "11150:\tlearn: 0.0595948\ttest: 1.0374157\tbest: 1.0371223 (11134)\ttotal: 1m 14s\tremaining: 25.9s\n",
      "11200:\tlearn: 0.0585935\ttest: 1.0375687\tbest: 1.0371223 (11134)\ttotal: 1m 15s\tremaining: 25.5s\n",
      "11250:\tlearn: 0.0578219\ttest: 1.0371274\tbest: 1.0367470 (11245)\ttotal: 1m 15s\tremaining: 25.2s\n",
      "11300:\tlearn: 0.0570996\ttest: 1.0365245\tbest: 1.0365245 (11300)\ttotal: 1m 15s\tremaining: 24.9s\n",
      "11350:\tlearn: 0.0563237\ttest: 1.0361838\tbest: 1.0359973 (11345)\ttotal: 1m 16s\tremaining: 24.5s\n",
      "11400:\tlearn: 0.0555053\ttest: 1.0362261\tbest: 1.0358367 (11382)\ttotal: 1m 16s\tremaining: 24.2s\n",
      "11450:\tlearn: 0.0547600\ttest: 1.0365630\tbest: 1.0357840 (11413)\ttotal: 1m 16s\tremaining: 23.9s\n",
      "11500:\tlearn: 0.0539153\ttest: 1.0357586\tbest: 1.0356073 (11486)\ttotal: 1m 17s\tremaining: 23.5s\n",
      "11550:\tlearn: 0.0531934\ttest: 1.0344977\tbest: 1.0344760 (11542)\ttotal: 1m 17s\tremaining: 23.2s\n",
      "11600:\tlearn: 0.0523902\ttest: 1.0332206\tbest: 1.0332206 (11600)\ttotal: 1m 18s\tremaining: 22.9s\n",
      "11650:\tlearn: 0.0515926\ttest: 1.0324645\tbest: 1.0324645 (11650)\ttotal: 1m 18s\tremaining: 22.5s\n",
      "11700:\tlearn: 0.0508827\ttest: 1.0330441\tbest: 1.0324055 (11652)\ttotal: 1m 18s\tremaining: 22.2s\n",
      "11750:\tlearn: 0.0502753\ttest: 1.0326938\tbest: 1.0324055 (11652)\ttotal: 1m 19s\tremaining: 21.8s\n",
      "11800:\tlearn: 0.0495768\ttest: 1.0324578\tbest: 1.0323922 (11772)\ttotal: 1m 19s\tremaining: 21.5s\n",
      "11850:\tlearn: 0.0489511\ttest: 1.0321670\tbest: 1.0321164 (11849)\ttotal: 1m 19s\tremaining: 21.2s\n",
      "11900:\tlearn: 0.0482803\ttest: 1.0319432\tbest: 1.0317427 (11871)\ttotal: 1m 20s\tremaining: 20.8s\n",
      "11950:\tlearn: 0.0477374\ttest: 1.0317489\tbest: 1.0311982 (11933)\ttotal: 1m 20s\tremaining: 20.5s\n",
      "12000:\tlearn: 0.0470561\ttest: 1.0315438\tbest: 1.0311982 (11933)\ttotal: 1m 20s\tremaining: 20.2s\n",
      "12050:\tlearn: 0.0462202\ttest: 1.0309341\tbest: 1.0307825 (12047)\ttotal: 1m 21s\tremaining: 19.8s\n",
      "12100:\tlearn: 0.0456046\ttest: 1.0299259\tbest: 1.0299159 (12099)\ttotal: 1m 21s\tremaining: 19.5s\n",
      "12150:\tlearn: 0.0450007\ttest: 1.0298830\tbest: 1.0297801 (12112)\ttotal: 1m 21s\tremaining: 19.2s\n",
      "12200:\tlearn: 0.0443909\ttest: 1.0296260\tbest: 1.0292597 (12191)\ttotal: 1m 22s\tremaining: 18.8s\n",
      "12250:\tlearn: 0.0437270\ttest: 1.0295375\tbest: 1.0292597 (12191)\ttotal: 1m 22s\tremaining: 18.5s\n",
      "12300:\tlearn: 0.0430554\ttest: 1.0293255\tbest: 1.0292597 (12191)\ttotal: 1m 22s\tremaining: 18.1s\n",
      "12350:\tlearn: 0.0422434\ttest: 1.0293182\tbest: 1.0289674 (12315)\ttotal: 1m 23s\tremaining: 17.8s\n",
      "12400:\tlearn: 0.0416636\ttest: 1.0287295\tbest: 1.0285979 (12385)\ttotal: 1m 23s\tremaining: 17.5s\n",
      "12450:\tlearn: 0.0410825\ttest: 1.0279829\tbest: 1.0279583 (12447)\ttotal: 1m 23s\tremaining: 17.1s\n",
      "12500:\tlearn: 0.0405736\ttest: 1.0275109\tbest: 1.0275109 (12500)\ttotal: 1m 24s\tremaining: 16.8s\n",
      "12550:\tlearn: 0.0400890\ttest: 1.0269955\tbest: 1.0268863 (12542)\ttotal: 1m 24s\tremaining: 16.5s\n",
      "12600:\tlearn: 0.0395387\ttest: 1.0267452\tbest: 1.0267262 (12597)\ttotal: 1m 24s\tremaining: 16.1s\n",
      "12650:\tlearn: 0.0389952\ttest: 1.0271843\tbest: 1.0263523 (12630)\ttotal: 1m 25s\tremaining: 15.8s\n",
      "12700:\tlearn: 0.0384032\ttest: 1.0261584\tbest: 1.0261584 (12700)\ttotal: 1m 25s\tremaining: 15.5s\n",
      "12750:\tlearn: 0.0379137\ttest: 1.0260825\tbest: 1.0259792 (12744)\ttotal: 1m 25s\tremaining: 15.1s\n",
      "12800:\tlearn: 0.0374852\ttest: 1.0253970\tbest: 1.0253941 (12798)\ttotal: 1m 26s\tremaining: 14.8s\n",
      "12850:\tlearn: 0.0369973\ttest: 1.0248917\tbest: 1.0248917 (12850)\ttotal: 1m 26s\tremaining: 14.5s\n",
      "12900:\tlearn: 0.0364754\ttest: 1.0238335\tbest: 1.0238335 (12900)\ttotal: 1m 26s\tremaining: 14.1s\n",
      "12950:\tlearn: 0.0359608\ttest: 1.0230896\tbest: 1.0230896 (12950)\ttotal: 1m 27s\tremaining: 13.8s\n",
      "13000:\tlearn: 0.0353982\ttest: 1.0225394\tbest: 1.0225394 (13000)\ttotal: 1m 27s\tremaining: 13.4s\n",
      "13050:\tlearn: 0.0349220\ttest: 1.0227384\tbest: 1.0225128 (13042)\ttotal: 1m 27s\tremaining: 13.1s\n",
      "13100:\tlearn: 0.0343378\ttest: 1.0224565\tbest: 1.0224565 (13100)\ttotal: 1m 28s\tremaining: 12.8s\n",
      "13150:\tlearn: 0.0338222\ttest: 1.0219943\tbest: 1.0218976 (13123)\ttotal: 1m 28s\tremaining: 12.4s\n",
      "13200:\tlearn: 0.0333166\ttest: 1.0212155\tbest: 1.0212155 (13200)\ttotal: 1m 28s\tremaining: 12.1s\n",
      "13250:\tlearn: 0.0328515\ttest: 1.0212312\tbest: 1.0209711 (13223)\ttotal: 1m 29s\tremaining: 11.8s\n",
      "13300:\tlearn: 0.0323947\ttest: 1.0218252\tbest: 1.0209711 (13223)\ttotal: 1m 29s\tremaining: 11.4s\n",
      "13350:\tlearn: 0.0320168\ttest: 1.0214127\tbest: 1.0209711 (13223)\ttotal: 1m 29s\tremaining: 11.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13400:\tlearn: 0.0316849\ttest: 1.0212488\tbest: 1.0208859 (13369)\ttotal: 1m 30s\tremaining: 10.8s\n",
      "13450:\tlearn: 0.0312916\ttest: 1.0207148\tbest: 1.0206624 (13447)\ttotal: 1m 30s\tremaining: 10.4s\n",
      "13500:\tlearn: 0.0309165\ttest: 1.0211343\tbest: 1.0206624 (13447)\ttotal: 1m 30s\tremaining: 10.1s\n",
      "13550:\tlearn: 0.0304675\ttest: 1.0214905\tbest: 1.0206624 (13447)\ttotal: 1m 31s\tremaining: 9.75s\n",
      "13600:\tlearn: 0.0299929\ttest: 1.0206190\tbest: 1.0206190 (13600)\ttotal: 1m 31s\tremaining: 9.41s\n",
      "13650:\tlearn: 0.0296363\ttest: 1.0203171\tbest: 1.0201686 (13642)\ttotal: 1m 31s\tremaining: 9.08s\n",
      "13700:\tlearn: 0.0292129\ttest: 1.0203410\tbest: 1.0199835 (13691)\ttotal: 1m 32s\tremaining: 8.74s\n",
      "13750:\tlearn: 0.0287524\ttest: 1.0205603\tbest: 1.0199835 (13691)\ttotal: 1m 32s\tremaining: 8.4s\n",
      "13800:\tlearn: 0.0283123\ttest: 1.0199580\tbest: 1.0195159 (13777)\ttotal: 1m 32s\tremaining: 8.07s\n",
      "13850:\tlearn: 0.0278434\ttest: 1.0200454\tbest: 1.0195159 (13777)\ttotal: 1m 33s\tremaining: 7.73s\n",
      "13900:\tlearn: 0.0274692\ttest: 1.0194501\tbest: 1.0193556 (13897)\ttotal: 1m 33s\tremaining: 7.39s\n",
      "13950:\tlearn: 0.0270358\ttest: 1.0193096\tbest: 1.0191462 (13936)\ttotal: 1m 33s\tremaining: 7.06s\n",
      "14000:\tlearn: 0.0266151\ttest: 1.0190408\tbest: 1.0188244 (13983)\ttotal: 1m 34s\tremaining: 6.72s\n",
      "14050:\tlearn: 0.0262413\ttest: 1.0179537\tbest: 1.0179413 (14049)\ttotal: 1m 34s\tremaining: 6.39s\n",
      "14100:\tlearn: 0.0258811\ttest: 1.0173897\tbest: 1.0173897 (14100)\ttotal: 1m 34s\tremaining: 6.05s\n",
      "14150:\tlearn: 0.0255453\ttest: 1.0169978\tbest: 1.0168917 (14143)\ttotal: 1m 35s\tremaining: 5.71s\n",
      "14200:\tlearn: 0.0252230\ttest: 1.0166980\tbest: 1.0165411 (14193)\ttotal: 1m 35s\tremaining: 5.38s\n",
      "14250:\tlearn: 0.0248864\ttest: 1.0164325\tbest: 1.0161626 (14230)\ttotal: 1m 35s\tremaining: 5.04s\n",
      "14300:\tlearn: 0.0245884\ttest: 1.0164519\tbest: 1.0161412 (14272)\ttotal: 1m 36s\tremaining: 4.7s\n",
      "14350:\tlearn: 0.0242295\ttest: 1.0159478\tbest: 1.0158699 (14346)\ttotal: 1m 36s\tremaining: 4.37s\n",
      "14400:\tlearn: 0.0239100\ttest: 1.0153926\tbest: 1.0153657 (14398)\ttotal: 1m 36s\tremaining: 4.03s\n",
      "14450:\tlearn: 0.0235777\ttest: 1.0155051\tbest: 1.0150401 (14424)\ttotal: 1m 37s\tremaining: 3.69s\n",
      "14500:\tlearn: 0.0232165\ttest: 1.0159687\tbest: 1.0150401 (14424)\ttotal: 1m 37s\tremaining: 3.36s\n",
      "14550:\tlearn: 0.0229860\ttest: 1.0162301\tbest: 1.0150401 (14424)\ttotal: 1m 37s\tremaining: 3.02s\n",
      "14600:\tlearn: 0.0227366\ttest: 1.0156876\tbest: 1.0150401 (14424)\ttotal: 1m 38s\tremaining: 2.69s\n",
      "14650:\tlearn: 0.0224322\ttest: 1.0159379\tbest: 1.0150401 (14424)\ttotal: 1m 38s\tremaining: 2.35s\n",
      "14700:\tlearn: 0.0221218\ttest: 1.0156328\tbest: 1.0150401 (14424)\ttotal: 1m 38s\tremaining: 2.01s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.015040111\n",
      "bestIteration = 14424\n",
      "\n",
      "Shrink model to first 14425 iterations.\n",
      "Скор для фолда(14) : 9.0 средний скор на префиксе = 9.0 это заняло = 100 сек.\n",
      "Фолд: 15\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "0:\tlearn: 3.6359650\ttest: 3.0727522\tbest: 3.0727522 (0)\ttotal: 28.2ms\tremaining: 7m 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7560170\ttest: 2.4552958\tbest: 2.4552958 (50)\ttotal: 369ms\tremaining: 1m 48s\n",
      "100:\tlearn: 2.2827029\ttest: 2.2434764\tbest: 2.2434764 (100)\ttotal: 709ms\tremaining: 1m 44s\n",
      "150:\tlearn: 2.0203821\ttest: 2.0580214\tbest: 2.0580214 (150)\ttotal: 1.04s\tremaining: 1m 41s\n",
      "200:\tlearn: 1.8585111\ttest: 1.9490050\tbest: 1.9490050 (200)\ttotal: 1.38s\tremaining: 1m 41s\n",
      "250:\tlearn: 1.7480724\ttest: 1.8780644\tbest: 1.8780644 (250)\ttotal: 1.71s\tremaining: 1m 40s\n",
      "300:\tlearn: 1.6685311\ttest: 1.8372850\tbest: 1.8372850 (300)\ttotal: 2.04s\tremaining: 1m 39s\n",
      "350:\tlearn: 1.6048207\ttest: 1.8010157\tbest: 1.8010157 (350)\ttotal: 2.38s\tremaining: 1m 39s\n",
      "400:\tlearn: 1.5506977\ttest: 1.7676446\tbest: 1.7676446 (400)\ttotal: 2.72s\tremaining: 1m 39s\n",
      "450:\tlearn: 1.5072495\ttest: 1.7309327\tbest: 1.7289198 (449)\ttotal: 3.04s\tremaining: 1m 38s\n",
      "500:\tlearn: 1.4711085\ttest: 1.7083974\tbest: 1.7083974 (500)\ttotal: 3.38s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4374982\ttest: 1.6873930\tbest: 1.6873930 (550)\ttotal: 3.72s\tremaining: 1m 37s\n",
      "600:\tlearn: 1.4102966\ttest: 1.6754300\tbest: 1.6750867 (599)\ttotal: 4.04s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3816110\ttest: 1.6639646\tbest: 1.6619871 (642)\ttotal: 4.38s\tremaining: 1m 36s\n",
      "700:\tlearn: 1.3544026\ttest: 1.6519992\tbest: 1.6519177 (699)\ttotal: 4.72s\tremaining: 1m 36s\n",
      "750:\tlearn: 1.3330208\ttest: 1.6534707\tbest: 1.6488889 (717)\ttotal: 5.04s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.3096620\ttest: 1.6633119\tbest: 1.6488889 (717)\ttotal: 5.38s\tremaining: 1m 35s\n",
      "850:\tlearn: 1.2880209\ttest: 1.6549364\tbest: 1.6488889 (717)\ttotal: 5.72s\tremaining: 1m 35s\n",
      "900:\tlearn: 1.2651056\ttest: 1.6458690\tbest: 1.6458690 (900)\ttotal: 6.04s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2440512\ttest: 1.6377826\tbest: 1.6370088 (946)\ttotal: 6.38s\tremaining: 1m 34s\n",
      "1000:\tlearn: 1.2211323\ttest: 1.6272097\tbest: 1.6271694 (999)\ttotal: 6.71s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.1998757\ttest: 1.6232238\tbest: 1.6229336 (1049)\ttotal: 7.04s\tremaining: 1m 33s\n",
      "1100:\tlearn: 1.1794732\ttest: 1.6215425\tbest: 1.6210594 (1064)\ttotal: 7.38s\tremaining: 1m 33s\n",
      "1150:\tlearn: 1.1608738\ttest: 1.6130020\tbest: 1.6130020 (1150)\ttotal: 7.71s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1437505\ttest: 1.6079424\tbest: 1.6070814 (1194)\ttotal: 8.04s\tremaining: 1m 32s\n",
      "1250:\tlearn: 1.1276460\ttest: 1.6027420\tbest: 1.6027009 (1249)\ttotal: 8.38s\tremaining: 1m 32s\n",
      "1300:\tlearn: 1.1085367\ttest: 1.5936449\tbest: 1.5936449 (1300)\ttotal: 8.71s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.0887449\ttest: 1.5894895\tbest: 1.5893478 (1349)\ttotal: 9.05s\tremaining: 1m 31s\n",
      "1400:\tlearn: 1.0717686\ttest: 1.5870896\tbest: 1.5869213 (1398)\ttotal: 9.39s\tremaining: 1m 31s\n",
      "1450:\tlearn: 1.0581751\ttest: 1.5861316\tbest: 1.5855532 (1442)\ttotal: 9.73s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0421087\ttest: 1.5769093\tbest: 1.5769093 (1500)\ttotal: 10.1s\tremaining: 1m 30s\n",
      "1550:\tlearn: 1.0252970\ttest: 1.5726772\tbest: 1.5726772 (1550)\ttotal: 10.4s\tremaining: 1m 30s\n",
      "1600:\tlearn: 1.0093607\ttest: 1.5640707\tbest: 1.5636252 (1598)\ttotal: 10.7s\tremaining: 1m 29s\n",
      "1650:\tlearn: 0.9950143\ttest: 1.5576719\tbest: 1.5576719 (1650)\ttotal: 11.1s\tremaining: 1m 29s\n",
      "1700:\tlearn: 0.9813328\ttest: 1.5475864\tbest: 1.5475864 (1700)\ttotal: 11.4s\tremaining: 1m 29s\n",
      "1750:\tlearn: 0.9693981\ttest: 1.5405434\tbest: 1.5404580 (1749)\ttotal: 11.7s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9545039\ttest: 1.5330727\tbest: 1.5330727 (1800)\ttotal: 12.1s\tremaining: 1m 28s\n",
      "1850:\tlearn: 0.9412028\ttest: 1.5310678\tbest: 1.5305683 (1838)\ttotal: 12.4s\tremaining: 1m 28s\n",
      "1900:\tlearn: 0.9294598\ttest: 1.5234062\tbest: 1.5231029 (1898)\ttotal: 12.7s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9185973\ttest: 1.5183701\tbest: 1.5183701 (1950)\ttotal: 13.1s\tremaining: 1m 27s\n",
      "2000:\tlearn: 0.9063280\ttest: 1.5138040\tbest: 1.5138040 (2000)\ttotal: 13.4s\tremaining: 1m 27s\n",
      "2050:\tlearn: 0.8950058\ttest: 1.5099847\tbest: 1.5099328 (2049)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.8822498\ttest: 1.5029694\tbest: 1.5027848 (2097)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "2150:\tlearn: 0.8697696\ttest: 1.5016907\tbest: 1.5002389 (2127)\ttotal: 14.4s\tremaining: 1m 26s\n",
      "2200:\tlearn: 0.8578429\ttest: 1.5010516\tbest: 1.5002389 (2127)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8462930\ttest: 1.4981884\tbest: 1.4974196 (2222)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "2300:\tlearn: 0.8340614\ttest: 1.4933666\tbest: 1.4930261 (2286)\ttotal: 15.4s\tremaining: 1m 25s\n",
      "2350:\tlearn: 0.8230813\ttest: 1.4879271\tbest: 1.4879271 (2350)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8121203\ttest: 1.4831333\tbest: 1.4831333 (2400)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "2450:\tlearn: 0.8015091\ttest: 1.4816983\tbest: 1.4816369 (2446)\ttotal: 16.4s\tremaining: 1m 24s\n",
      "2500:\tlearn: 0.7906571\ttest: 1.4784458\tbest: 1.4784315 (2499)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7790845\ttest: 1.4761466\tbest: 1.4757489 (2545)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "2600:\tlearn: 0.7711803\ttest: 1.4734684\tbest: 1.4734684 (2600)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "2650:\tlearn: 0.7621797\ttest: 1.4727282\tbest: 1.4724448 (2640)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7512028\ttest: 1.4687801\tbest: 1.4686013 (2697)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "2750:\tlearn: 0.7395975\ttest: 1.4640105\tbest: 1.4636341 (2747)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "2800:\tlearn: 0.7287653\ttest: 1.4593860\tbest: 1.4593860 (2800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.7181066\ttest: 1.4571714\tbest: 1.4565930 (2847)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "2900:\tlearn: 0.7083689\ttest: 1.4538285\tbest: 1.4537931 (2895)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "2950:\tlearn: 0.6973892\ttest: 1.4519734\tbest: 1.4517021 (2939)\ttotal: 19.8s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.6865730\ttest: 1.4490570\tbest: 1.4490570 (3000)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "3050:\tlearn: 0.6769974\ttest: 1.4466931\tbest: 1.4466236 (3046)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "3100:\tlearn: 0.6678447\ttest: 1.4428203\tbest: 1.4428203 (3100)\ttotal: 20.8s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6602965\ttest: 1.4414658\tbest: 1.4412181 (3128)\ttotal: 21.1s\tremaining: 1m 19s\n",
      "3200:\tlearn: 0.6520190\ttest: 1.4412128\tbest: 1.4403320 (3185)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "3250:\tlearn: 0.6428772\ttest: 1.4384242\tbest: 1.4384242 (3250)\ttotal: 21.8s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6337266\ttest: 1.4360314\tbest: 1.4358158 (3298)\ttotal: 22.1s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.6253262\ttest: 1.4336682\tbest: 1.4330565 (3334)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "3400:\tlearn: 0.6161043\ttest: 1.4310127\tbest: 1.4305489 (3397)\ttotal: 22.8s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.6061152\ttest: 1.4304241\tbest: 1.4291854 (3437)\ttotal: 23.1s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.5974827\ttest: 1.4287208\tbest: 1.4286578 (3497)\ttotal: 23.5s\tremaining: 1m 17s\n",
      "3550:\tlearn: 0.5886972\ttest: 1.4285639\tbest: 1.4271309 (3539)\ttotal: 23.8s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5803139\ttest: 1.4266452\tbest: 1.4257884 (3592)\ttotal: 24.2s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.5715871\ttest: 1.4209105\tbest: 1.4205727 (3648)\ttotal: 24.5s\tremaining: 1m 16s\n",
      "3700:\tlearn: 0.5633235\ttest: 1.4209709\tbest: 1.4205678 (3658)\ttotal: 24.8s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5556923\ttest: 1.4195338\tbest: 1.4194000 (3749)\ttotal: 25.2s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5484994\ttest: 1.4169183\tbest: 1.4167213 (3799)\ttotal: 25.5s\tremaining: 1m 15s\n",
      "3850:\tlearn: 0.5401117\ttest: 1.4160622\tbest: 1.4146450 (3827)\ttotal: 25.8s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5330408\ttest: 1.4143929\tbest: 1.4140801 (3895)\ttotal: 26.2s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.5255575\ttest: 1.4134015\tbest: 1.4131292 (3937)\ttotal: 26.5s\tremaining: 1m 14s\n",
      "4000:\tlearn: 0.5182275\ttest: 1.4086614\tbest: 1.4086614 (4000)\ttotal: 26.8s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.5094188\ttest: 1.4051288\tbest: 1.4051288 (4050)\ttotal: 27.2s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.5017875\ttest: 1.4010326\tbest: 1.4010326 (4100)\ttotal: 27.5s\tremaining: 1m 13s\n",
      "4150:\tlearn: 0.4942344\ttest: 1.3945952\tbest: 1.3945952 (4150)\ttotal: 27.9s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4875564\ttest: 1.3910843\tbest: 1.3908179 (4199)\ttotal: 28.2s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4808894\ttest: 1.3865980\tbest: 1.3865980 (4250)\ttotal: 28.5s\tremaining: 1m 12s\n",
      "4300:\tlearn: 0.4734354\ttest: 1.3832663\tbest: 1.3826806 (4283)\ttotal: 28.9s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4679160\ttest: 1.3813308\tbest: 1.3812511 (4347)\ttotal: 29.2s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4600724\ttest: 1.3758129\tbest: 1.3758129 (4400)\ttotal: 29.5s\tremaining: 1m 11s\n",
      "4450:\tlearn: 0.4526060\ttest: 1.3734796\tbest: 1.3734796 (4450)\ttotal: 29.9s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4460112\ttest: 1.3718359\tbest: 1.3718359 (4500)\ttotal: 30.2s\tremaining: 1m 10s\n",
      "4550:\tlearn: 0.4381977\ttest: 1.3682440\tbest: 1.3682357 (4546)\ttotal: 30.6s\tremaining: 1m 10s\n",
      "4600:\tlearn: 0.4328975\ttest: 1.3664065\tbest: 1.3659964 (4593)\ttotal: 30.9s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4261072\ttest: 1.3639945\tbest: 1.3639945 (4650)\ttotal: 31.2s\tremaining: 1m 9s\n",
      "4700:\tlearn: 0.4196161\ttest: 1.3600019\tbest: 1.3600019 (4700)\ttotal: 31.6s\tremaining: 1m 9s\n",
      "4750:\tlearn: 0.4135377\ttest: 1.3588076\tbest: 1.3586183 (4746)\ttotal: 31.9s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.4082720\ttest: 1.3565336\tbest: 1.3565336 (4800)\ttotal: 32.2s\tremaining: 1m 8s\n",
      "4850:\tlearn: 0.4005793\ttest: 1.3529557\tbest: 1.3521672 (4847)\ttotal: 32.6s\tremaining: 1m 8s\n",
      "4900:\tlearn: 0.3948817\ttest: 1.3503745\tbest: 1.3503745 (4900)\ttotal: 32.9s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3891570\ttest: 1.3486428\tbest: 1.3479982 (4945)\ttotal: 33.3s\tremaining: 1m 7s\n",
      "5000:\tlearn: 0.3837825\ttest: 1.3479544\tbest: 1.3478403 (4999)\ttotal: 33.6s\tremaining: 1m 7s\n",
      "5050:\tlearn: 0.3784769\ttest: 1.3464146\tbest: 1.3464146 (5050)\ttotal: 33.9s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3732203\ttest: 1.3431347\tbest: 1.3430601 (5099)\ttotal: 34.3s\tremaining: 1m 6s\n",
      "5150:\tlearn: 0.3672513\ttest: 1.3411438\tbest: 1.3410237 (5148)\ttotal: 34.6s\tremaining: 1m 6s\n",
      "5200:\tlearn: 0.3622436\ttest: 1.3402607\tbest: 1.3397151 (5187)\ttotal: 34.9s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3561732\ttest: 1.3359527\tbest: 1.3356775 (5245)\ttotal: 35.3s\tremaining: 1m 5s\n",
      "5300:\tlearn: 0.3510144\ttest: 1.3344035\tbest: 1.3344035 (5300)\ttotal: 35.6s\tremaining: 1m 5s\n",
      "5350:\tlearn: 0.3466067\ttest: 1.3316926\tbest: 1.3316926 (5350)\ttotal: 36s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3417784\ttest: 1.3304078\tbest: 1.3295152 (5393)\ttotal: 36.3s\tremaining: 1m 4s\n",
      "5450:\tlearn: 0.3362858\ttest: 1.3306266\tbest: 1.3295152 (5393)\ttotal: 36.6s\tremaining: 1m 4s\n",
      "5500:\tlearn: 0.3317172\ttest: 1.3289422\tbest: 1.3285421 (5484)\ttotal: 37s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3258252\ttest: 1.3264325\tbest: 1.3264325 (5550)\ttotal: 37.3s\tremaining: 1m 3s\n",
      "5600:\tlearn: 0.3207426\ttest: 1.3284995\tbest: 1.3264325 (5550)\ttotal: 37.7s\tremaining: 1m 3s\n",
      "5650:\tlearn: 0.3156427\ttest: 1.3262468\tbest: 1.3255459 (5642)\ttotal: 38s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.3111067\ttest: 1.3262758\tbest: 1.3255459 (5642)\ttotal: 38.3s\tremaining: 1m 2s\n",
      "5750:\tlearn: 0.3062409\ttest: 1.3249401\tbest: 1.3249401 (5750)\ttotal: 38.7s\tremaining: 1m 2s\n",
      "5800:\tlearn: 0.3015936\ttest: 1.3240916\tbest: 1.3233044 (5792)\ttotal: 39s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2971940\ttest: 1.3238252\tbest: 1.3233044 (5792)\ttotal: 39.4s\tremaining: 1m 1s\n",
      "5900:\tlearn: 0.2938476\ttest: 1.3227516\tbest: 1.3222180 (5877)\ttotal: 39.7s\tremaining: 1m 1s\n",
      "5950:\tlearn: 0.2896004\ttest: 1.3216247\tbest: 1.3213793 (5928)\ttotal: 40s\tremaining: 1m\n",
      "6000:\tlearn: 0.2855444\ttest: 1.3202747\tbest: 1.3195483 (5988)\ttotal: 40.4s\tremaining: 1m\n",
      "6050:\tlearn: 0.2812978\ttest: 1.3196048\tbest: 1.3194853 (6048)\ttotal: 40.7s\tremaining: 1m\n",
      "6100:\tlearn: 0.2774102\ttest: 1.3170326\tbest: 1.3170326 (6100)\ttotal: 41s\tremaining: 59.8s\n",
      "6150:\tlearn: 0.2726919\ttest: 1.3161420\tbest: 1.3160754 (6149)\ttotal: 41.4s\tremaining: 59.5s\n",
      "6200:\tlearn: 0.2693792\ttest: 1.3165365\tbest: 1.3155252 (6177)\ttotal: 41.7s\tremaining: 59.2s\n",
      "6250:\tlearn: 0.2653906\ttest: 1.3155503\tbest: 1.3149979 (6230)\ttotal: 42s\tremaining: 58.8s\n",
      "6300:\tlearn: 0.2616677\ttest: 1.3133827\tbest: 1.3133827 (6300)\ttotal: 42.4s\tremaining: 58.5s\n",
      "6350:\tlearn: 0.2579234\ttest: 1.3123596\tbest: 1.3123596 (6350)\ttotal: 42.7s\tremaining: 58.2s\n",
      "6400:\tlearn: 0.2532548\ttest: 1.3121396\tbest: 1.3117143 (6395)\ttotal: 43.1s\tremaining: 57.8s\n",
      "6450:\tlearn: 0.2492929\ttest: 1.3103614\tbest: 1.3097459 (6444)\ttotal: 43.4s\tremaining: 57.5s\n",
      "6500:\tlearn: 0.2457186\ttest: 1.3089396\tbest: 1.3089396 (6500)\ttotal: 43.7s\tremaining: 57.2s\n",
      "6550:\tlearn: 0.2417899\ttest: 1.3067926\tbest: 1.3067926 (6550)\ttotal: 44.1s\tremaining: 56.8s\n",
      "6600:\tlearn: 0.2388844\ttest: 1.3054946\tbest: 1.3054651 (6597)\ttotal: 44.4s\tremaining: 56.5s\n",
      "6650:\tlearn: 0.2352364\ttest: 1.3051456\tbest: 1.3050303 (6628)\ttotal: 44.7s\tremaining: 56.2s\n",
      "6700:\tlearn: 0.2319037\ttest: 1.3030502\tbest: 1.3030502 (6700)\ttotal: 45.1s\tremaining: 55.8s\n",
      "6750:\tlearn: 0.2284915\ttest: 1.3002946\tbest: 1.3001368 (6747)\ttotal: 45.4s\tremaining: 55.5s\n",
      "6800:\tlearn: 0.2248471\ttest: 1.2975294\tbest: 1.2975294 (6800)\ttotal: 45.8s\tremaining: 55.2s\n",
      "6850:\tlearn: 0.2210944\ttest: 1.2954403\tbest: 1.2953251 (6846)\ttotal: 46.1s\tremaining: 54.8s\n",
      "6900:\tlearn: 0.2175351\ttest: 1.2936389\tbest: 1.2936389 (6900)\ttotal: 46.4s\tremaining: 54.5s\n",
      "6950:\tlearn: 0.2143717\ttest: 1.2925567\tbest: 1.2922987 (6948)\ttotal: 46.8s\tremaining: 54.2s\n",
      "7000:\tlearn: 0.2112953\ttest: 1.2902391\tbest: 1.2902175 (6999)\ttotal: 47.1s\tremaining: 53.8s\n",
      "7050:\tlearn: 0.2088224\ttest: 1.2905605\tbest: 1.2900208 (7039)\ttotal: 47.4s\tremaining: 53.5s\n",
      "7100:\tlearn: 0.2055929\ttest: 1.2899242\tbest: 1.2894644 (7096)\ttotal: 47.8s\tremaining: 53.1s\n",
      "7150:\tlearn: 0.2021107\ttest: 1.2886410\tbest: 1.2882881 (7135)\ttotal: 48.1s\tremaining: 52.8s\n",
      "7200:\tlearn: 0.1988666\ttest: 1.2876150\tbest: 1.2875625 (7199)\ttotal: 48.4s\tremaining: 52.5s\n",
      "7250:\tlearn: 0.1960848\ttest: 1.2868363\tbest: 1.2866693 (7231)\ttotal: 48.8s\tremaining: 52.1s\n",
      "7300:\tlearn: 0.1933039\ttest: 1.2847931\tbest: 1.2845769 (7296)\ttotal: 49.1s\tremaining: 51.8s\n",
      "7350:\tlearn: 0.1902327\ttest: 1.2843875\tbest: 1.2838586 (7332)\ttotal: 49.5s\tremaining: 51.5s\n",
      "7400:\tlearn: 0.1873747\ttest: 1.2842454\tbest: 1.2837353 (7371)\ttotal: 49.8s\tremaining: 51.1s\n",
      "7450:\tlearn: 0.1846702\ttest: 1.2830757\tbest: 1.2829673 (7448)\ttotal: 50.1s\tremaining: 50.8s\n",
      "7500:\tlearn: 0.1818693\ttest: 1.2826485\tbest: 1.2815861 (7483)\ttotal: 50.5s\tremaining: 50.5s\n",
      "7550:\tlearn: 0.1787479\ttest: 1.2812844\tbest: 1.2812703 (7546)\ttotal: 50.8s\tremaining: 50.1s\n",
      "7600:\tlearn: 0.1760358\ttest: 1.2805120\tbest: 1.2801293 (7597)\ttotal: 51.2s\tremaining: 49.8s\n",
      "7650:\tlearn: 0.1736858\ttest: 1.2795937\tbest: 1.2791833 (7644)\ttotal: 51.5s\tremaining: 49.5s\n",
      "7700:\tlearn: 0.1712251\ttest: 1.2795836\tbest: 1.2791324 (7692)\ttotal: 51.8s\tremaining: 49.1s\n",
      "7750:\tlearn: 0.1690163\ttest: 1.2779145\tbest: 1.2779145 (7750)\ttotal: 52.2s\tremaining: 48.8s\n",
      "7800:\tlearn: 0.1664941\ttest: 1.2779865\tbest: 1.2773408 (7787)\ttotal: 52.5s\tremaining: 48.5s\n",
      "7850:\tlearn: 0.1645224\ttest: 1.2794678\tbest: 1.2773408 (7787)\ttotal: 52.8s\tremaining: 48.1s\n",
      "7900:\tlearn: 0.1616804\ttest: 1.2775713\tbest: 1.2773408 (7787)\ttotal: 53.2s\tremaining: 47.8s\n",
      "7950:\tlearn: 0.1593224\ttest: 1.2757093\tbest: 1.2756491 (7949)\ttotal: 53.5s\tremaining: 47.4s\n",
      "8000:\tlearn: 0.1572160\ttest: 1.2757425\tbest: 1.2756491 (7949)\ttotal: 53.8s\tremaining: 47.1s\n",
      "8050:\tlearn: 0.1551626\ttest: 1.2745534\tbest: 1.2744952 (8049)\ttotal: 54.2s\tremaining: 46.8s\n",
      "8100:\tlearn: 0.1527378\ttest: 1.2754402\tbest: 1.2742301 (8054)\ttotal: 54.5s\tremaining: 46.4s\n",
      "8150:\tlearn: 0.1507934\ttest: 1.2753790\tbest: 1.2742301 (8054)\ttotal: 54.8s\tremaining: 46.1s\n",
      "8200:\tlearn: 0.1486277\ttest: 1.2746785\tbest: 1.2742301 (8054)\ttotal: 55.2s\tremaining: 45.8s\n",
      "8250:\tlearn: 0.1462720\ttest: 1.2746341\tbest: 1.2739804 (8216)\ttotal: 55.5s\tremaining: 45.4s\n",
      "8300:\tlearn: 0.1441323\ttest: 1.2740793\tbest: 1.2739741 (8270)\ttotal: 55.9s\tremaining: 45.1s\n",
      "8350:\tlearn: 0.1421912\ttest: 1.2752333\tbest: 1.2738739 (8306)\ttotal: 56.2s\tremaining: 44.8s\n",
      "8400:\tlearn: 0.1397663\ttest: 1.2754075\tbest: 1.2738739 (8306)\ttotal: 56.6s\tremaining: 44.4s\n",
      "8450:\tlearn: 0.1373531\ttest: 1.2747028\tbest: 1.2738739 (8306)\ttotal: 56.9s\tremaining: 44.1s\n",
      "8500:\tlearn: 0.1354554\ttest: 1.2740732\tbest: 1.2738739 (8306)\ttotal: 57.2s\tremaining: 43.8s\n",
      "8550:\tlearn: 0.1333009\ttest: 1.2722264\tbest: 1.2721688 (8545)\ttotal: 57.6s\tremaining: 43.4s\n",
      "8600:\tlearn: 0.1310997\ttest: 1.2709702\tbest: 1.2708225 (8597)\ttotal: 57.9s\tremaining: 43.1s\n",
      "8650:\tlearn: 0.1292143\ttest: 1.2714844\tbest: 1.2708177 (8610)\ttotal: 58.3s\tremaining: 42.8s\n",
      "8700:\tlearn: 0.1271963\ttest: 1.2705792\tbest: 1.2703415 (8683)\ttotal: 58.6s\tremaining: 42.4s\n",
      "8750:\tlearn: 0.1253176\ttest: 1.2712408\tbest: 1.2703415 (8683)\ttotal: 58.9s\tremaining: 42.1s\n",
      "8800:\tlearn: 0.1233692\ttest: 1.2709367\tbest: 1.2703415 (8683)\ttotal: 59.3s\tremaining: 41.8s\n",
      "8850:\tlearn: 0.1212640\ttest: 1.2704246\tbest: 1.2701704 (8834)\ttotal: 59.6s\tremaining: 41.4s\n",
      "8900:\tlearn: 0.1193902\ttest: 1.2692399\tbest: 1.2692399 (8900)\ttotal: 60s\tremaining: 41.1s\n",
      "8950:\tlearn: 0.1174739\ttest: 1.2686212\tbest: 1.2685595 (8949)\ttotal: 1m\tremaining: 40.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000:\tlearn: 0.1158517\ttest: 1.2685506\tbest: 1.2682036 (8981)\ttotal: 1m\tremaining: 40.4s\n",
      "9050:\tlearn: 0.1139958\ttest: 1.2679842\tbest: 1.2679842 (9050)\ttotal: 1m\tremaining: 40.1s\n",
      "9100:\tlearn: 0.1123477\ttest: 1.2675162\tbest: 1.2672289 (9092)\ttotal: 1m 1s\tremaining: 39.7s\n",
      "9150:\tlearn: 0.1107568\ttest: 1.2662509\tbest: 1.2662509 (9150)\ttotal: 1m 1s\tremaining: 39.4s\n",
      "9200:\tlearn: 0.1091273\ttest: 1.2655404\tbest: 1.2654917 (9198)\ttotal: 1m 1s\tremaining: 39.1s\n",
      "9250:\tlearn: 0.1077072\ttest: 1.2657176\tbest: 1.2652967 (9203)\ttotal: 1m 2s\tremaining: 38.7s\n",
      "9300:\tlearn: 0.1059598\ttest: 1.2655750\tbest: 1.2652967 (9203)\ttotal: 1m 2s\tremaining: 38.4s\n",
      "9350:\tlearn: 0.1040279\ttest: 1.2644907\tbest: 1.2642220 (9327)\ttotal: 1m 3s\tremaining: 38.1s\n",
      "9400:\tlearn: 0.1026857\ttest: 1.2641270\tbest: 1.2641270 (9400)\ttotal: 1m 3s\tremaining: 37.7s\n",
      "9450:\tlearn: 0.1012172\ttest: 1.2639185\tbest: 1.2635136 (9419)\ttotal: 1m 3s\tremaining: 37.4s\n",
      "9500:\tlearn: 0.0996997\ttest: 1.2631355\tbest: 1.2629161 (9485)\ttotal: 1m 4s\tremaining: 37.1s\n",
      "9550:\tlearn: 0.0983371\ttest: 1.2641220\tbest: 1.2629161 (9485)\ttotal: 1m 4s\tremaining: 36.7s\n",
      "9600:\tlearn: 0.0968763\ttest: 1.2638530\tbest: 1.2629161 (9485)\ttotal: 1m 4s\tremaining: 36.4s\n",
      "9650:\tlearn: 0.0957673\ttest: 1.2623136\tbest: 1.2622916 (9647)\ttotal: 1m 5s\tremaining: 36.1s\n",
      "9700:\tlearn: 0.0945956\ttest: 1.2627132\tbest: 1.2621726 (9652)\ttotal: 1m 5s\tremaining: 35.7s\n",
      "9750:\tlearn: 0.0931538\ttest: 1.2603179\tbest: 1.2602091 (9749)\ttotal: 1m 5s\tremaining: 35.4s\n",
      "9800:\tlearn: 0.0919538\ttest: 1.2603112\tbest: 1.2601873 (9796)\ttotal: 1m 6s\tremaining: 35s\n",
      "9850:\tlearn: 0.0903605\ttest: 1.2601015\tbest: 1.2598114 (9834)\ttotal: 1m 6s\tremaining: 34.7s\n",
      "9900:\tlearn: 0.0889565\ttest: 1.2592186\tbest: 1.2592186 (9900)\ttotal: 1m 6s\tremaining: 34.4s\n",
      "9950:\tlearn: 0.0877204\ttest: 1.2592494\tbest: 1.2589406 (9917)\ttotal: 1m 7s\tremaining: 34s\n",
      "10000:\tlearn: 0.0862910\ttest: 1.2591592\tbest: 1.2589406 (9917)\ttotal: 1m 7s\tremaining: 33.7s\n",
      "10050:\tlearn: 0.0852252\ttest: 1.2580644\tbest: 1.2580644 (10050)\ttotal: 1m 7s\tremaining: 33.4s\n",
      "10100:\tlearn: 0.0838911\ttest: 1.2582464\tbest: 1.2578076 (10086)\ttotal: 1m 8s\tremaining: 33s\n",
      "10150:\tlearn: 0.0826192\ttest: 1.2562568\tbest: 1.2562568 (10150)\ttotal: 1m 8s\tremaining: 32.7s\n",
      "10200:\tlearn: 0.0814331\ttest: 1.2556146\tbest: 1.2555881 (10199)\ttotal: 1m 8s\tremaining: 32.3s\n",
      "10250:\tlearn: 0.0801880\ttest: 1.2543694\tbest: 1.2543694 (10250)\ttotal: 1m 9s\tremaining: 32s\n",
      "10300:\tlearn: 0.0788619\ttest: 1.2543153\tbest: 1.2536959 (10285)\ttotal: 1m 9s\tremaining: 31.7s\n",
      "10350:\tlearn: 0.0777832\ttest: 1.2528958\tbest: 1.2528063 (10339)\ttotal: 1m 9s\tremaining: 31.3s\n",
      "10400:\tlearn: 0.0766287\ttest: 1.2522910\tbest: 1.2521394 (10397)\ttotal: 1m 10s\tremaining: 31s\n",
      "10450:\tlearn: 0.0754696\ttest: 1.2515578\tbest: 1.2515578 (10450)\ttotal: 1m 10s\tremaining: 30.7s\n",
      "10500:\tlearn: 0.0745908\ttest: 1.2517188\tbest: 1.2515528 (10489)\ttotal: 1m 10s\tremaining: 30.3s\n",
      "10550:\tlearn: 0.0733302\ttest: 1.2515571\tbest: 1.2510826 (10524)\ttotal: 1m 11s\tremaining: 30s\n",
      "10600:\tlearn: 0.0723066\ttest: 1.2508258\tbest: 1.2505367 (10589)\ttotal: 1m 11s\tremaining: 29.7s\n",
      "10650:\tlearn: 0.0712969\ttest: 1.2503869\tbest: 1.2502801 (10649)\ttotal: 1m 11s\tremaining: 29.3s\n",
      "10700:\tlearn: 0.0703259\ttest: 1.2506409\tbest: 1.2501512 (10687)\ttotal: 1m 12s\tremaining: 29s\n",
      "10750:\tlearn: 0.0689004\ttest: 1.2510242\tbest: 1.2501512 (10687)\ttotal: 1m 12s\tremaining: 28.6s\n",
      "10800:\tlearn: 0.0677858\ttest: 1.2506230\tbest: 1.2501512 (10687)\ttotal: 1m 12s\tremaining: 28.3s\n",
      "10850:\tlearn: 0.0667158\ttest: 1.2501014\tbest: 1.2499737 (10840)\ttotal: 1m 13s\tremaining: 28s\n",
      "10900:\tlearn: 0.0657977\ttest: 1.2501163\tbest: 1.2494782 (10877)\ttotal: 1m 13s\tremaining: 27.6s\n",
      "10950:\tlearn: 0.0648696\ttest: 1.2496352\tbest: 1.2494782 (10877)\ttotal: 1m 13s\tremaining: 27.3s\n",
      "11000:\tlearn: 0.0638751\ttest: 1.2483095\tbest: 1.2480148 (10987)\ttotal: 1m 14s\tremaining: 27s\n",
      "11050:\tlearn: 0.0629292\ttest: 1.2470650\tbest: 1.2468772 (11044)\ttotal: 1m 14s\tremaining: 26.6s\n",
      "11100:\tlearn: 0.0618594\ttest: 1.2464640\tbest: 1.2463910 (11099)\ttotal: 1m 14s\tremaining: 26.3s\n",
      "11150:\tlearn: 0.0609264\ttest: 1.2461027\tbest: 1.2460018 (11119)\ttotal: 1m 15s\tremaining: 26s\n",
      "11200:\tlearn: 0.0600595\ttest: 1.2462770\tbest: 1.2460018 (11119)\ttotal: 1m 15s\tremaining: 25.6s\n",
      "11250:\tlearn: 0.0590480\ttest: 1.2463624\tbest: 1.2458838 (11230)\ttotal: 1m 15s\tremaining: 25.3s\n",
      "11300:\tlearn: 0.0581799\ttest: 1.2454619\tbest: 1.2448782 (11280)\ttotal: 1m 16s\tremaining: 24.9s\n",
      "11350:\tlearn: 0.0573190\ttest: 1.2446940\tbest: 1.2446779 (11338)\ttotal: 1m 16s\tremaining: 24.6s\n",
      "11400:\tlearn: 0.0564660\ttest: 1.2453240\tbest: 1.2446779 (11338)\ttotal: 1m 16s\tremaining: 24.3s\n",
      "11450:\tlearn: 0.0556710\ttest: 1.2449371\tbest: 1.2442247 (11425)\ttotal: 1m 17s\tremaining: 23.9s\n",
      "11500:\tlearn: 0.0548084\ttest: 1.2443749\tbest: 1.2441168 (11491)\ttotal: 1m 17s\tremaining: 23.6s\n",
      "11550:\tlearn: 0.0538778\ttest: 1.2437687\tbest: 1.2432780 (11531)\ttotal: 1m 17s\tremaining: 23.3s\n",
      "11600:\tlearn: 0.0530551\ttest: 1.2428556\tbest: 1.2428556 (11600)\ttotal: 1m 18s\tremaining: 22.9s\n",
      "11650:\tlearn: 0.0522383\ttest: 1.2426229\tbest: 1.2425656 (11649)\ttotal: 1m 18s\tremaining: 22.6s\n",
      "11700:\tlearn: 0.0514716\ttest: 1.2419578\tbest: 1.2419294 (11698)\ttotal: 1m 18s\tremaining: 22.3s\n",
      "11750:\tlearn: 0.0505774\ttest: 1.2414615\tbest: 1.2414040 (11747)\ttotal: 1m 19s\tremaining: 21.9s\n",
      "11800:\tlearn: 0.0498974\ttest: 1.2409546\tbest: 1.2409546 (11800)\ttotal: 1m 19s\tremaining: 21.6s\n",
      "11850:\tlearn: 0.0489763\ttest: 1.2411652\tbest: 1.2408815 (11839)\ttotal: 1m 19s\tremaining: 21.2s\n",
      "11900:\tlearn: 0.0482162\ttest: 1.2400666\tbest: 1.2400313 (11898)\ttotal: 1m 20s\tremaining: 20.9s\n",
      "11950:\tlearn: 0.0474576\ttest: 1.2402945\tbest: 1.2399076 (11924)\ttotal: 1m 20s\tremaining: 20.6s\n",
      "12000:\tlearn: 0.0467431\ttest: 1.2407280\tbest: 1.2399076 (11924)\ttotal: 1m 20s\tremaining: 20.2s\n",
      "12050:\tlearn: 0.0460320\ttest: 1.2411745\tbest: 1.2399076 (11924)\ttotal: 1m 21s\tremaining: 19.9s\n",
      "12100:\tlearn: 0.0452755\ttest: 1.2412542\tbest: 1.2399076 (11924)\ttotal: 1m 21s\tremaining: 19.6s\n",
      "12150:\tlearn: 0.0447311\ttest: 1.2404131\tbest: 1.2399076 (11924)\ttotal: 1m 21s\tremaining: 19.2s\n",
      "12200:\tlearn: 0.0440339\ttest: 1.2400666\tbest: 1.2399076 (11924)\ttotal: 1m 22s\tremaining: 18.9s\n",
      "12250:\tlearn: 0.0434536\ttest: 1.2397459\tbest: 1.2396819 (12232)\ttotal: 1m 22s\tremaining: 18.5s\n",
      "12300:\tlearn: 0.0428563\ttest: 1.2401753\tbest: 1.2394778 (12272)\ttotal: 1m 23s\tremaining: 18.2s\n",
      "12350:\tlearn: 0.0422868\ttest: 1.2398031\tbest: 1.2394778 (12272)\ttotal: 1m 23s\tremaining: 17.9s\n",
      "12400:\tlearn: 0.0417947\ttest: 1.2388746\tbest: 1.2388746 (12400)\ttotal: 1m 23s\tremaining: 17.5s\n",
      "12450:\tlearn: 0.0412838\ttest: 1.2385862\tbest: 1.2385445 (12437)\ttotal: 1m 24s\tremaining: 17.2s\n",
      "12500:\tlearn: 0.0405586\ttest: 1.2384180\tbest: 1.2384179 (12499)\ttotal: 1m 24s\tremaining: 16.9s\n",
      "12550:\tlearn: 0.0398549\ttest: 1.2388562\tbest: 1.2383394 (12501)\ttotal: 1m 24s\tremaining: 16.5s\n",
      "12600:\tlearn: 0.0392707\ttest: 1.2386240\tbest: 1.2381314 (12583)\ttotal: 1m 25s\tremaining: 16.2s\n",
      "12650:\tlearn: 0.0386934\ttest: 1.2389781\tbest: 1.2381314 (12583)\ttotal: 1m 25s\tremaining: 15.9s\n",
      "12700:\tlearn: 0.0380672\ttest: 1.2387096\tbest: 1.2381314 (12583)\ttotal: 1m 25s\tremaining: 15.5s\n",
      "12750:\tlearn: 0.0375283\ttest: 1.2373001\tbest: 1.2373001 (12750)\ttotal: 1m 26s\tremaining: 15.2s\n",
      "12800:\tlearn: 0.0370123\ttest: 1.2375691\tbest: 1.2371537 (12784)\ttotal: 1m 26s\tremaining: 14.8s\n",
      "12850:\tlearn: 0.0364747\ttest: 1.2369194\tbest: 1.2365426 (12842)\ttotal: 1m 26s\tremaining: 14.5s\n",
      "12900:\tlearn: 0.0359237\ttest: 1.2368658\tbest: 1.2365426 (12842)\ttotal: 1m 27s\tremaining: 14.2s\n",
      "12950:\tlearn: 0.0353470\ttest: 1.2368090\tbest: 1.2365426 (12842)\ttotal: 1m 27s\tremaining: 13.8s\n",
      "13000:\tlearn: 0.0348271\ttest: 1.2367051\tbest: 1.2365426 (12842)\ttotal: 1m 27s\tremaining: 13.5s\n",
      "13050:\tlearn: 0.0344265\ttest: 1.2365423\tbest: 1.2363168 (13038)\ttotal: 1m 28s\tremaining: 13.2s\n",
      "13100:\tlearn: 0.0339076\ttest: 1.2356779\tbest: 1.2356779 (13100)\ttotal: 1m 28s\tremaining: 12.8s\n",
      "13150:\tlearn: 0.0333296\ttest: 1.2353587\tbest: 1.2352534 (13147)\ttotal: 1m 28s\tremaining: 12.5s\n",
      "13200:\tlearn: 0.0329143\ttest: 1.2353206\tbest: 1.2348959 (13186)\ttotal: 1m 29s\tremaining: 12.2s\n",
      "13250:\tlearn: 0.0324113\ttest: 1.2337795\tbest: 1.2337795 (13250)\ttotal: 1m 29s\tremaining: 11.8s\n",
      "13300:\tlearn: 0.0319655\ttest: 1.2338503\tbest: 1.2337597 (13257)\ttotal: 1m 29s\tremaining: 11.5s\n",
      "13350:\tlearn: 0.0315723\ttest: 1.2334880\tbest: 1.2334759 (13347)\ttotal: 1m 30s\tremaining: 11.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13400:\tlearn: 0.0311254\ttest: 1.2335432\tbest: 1.2331895 (13354)\ttotal: 1m 30s\tremaining: 10.8s\n",
      "13450:\tlearn: 0.0307092\ttest: 1.2335519\tbest: 1.2331895 (13354)\ttotal: 1m 30s\tremaining: 10.5s\n",
      "13500:\tlearn: 0.0303014\ttest: 1.2332657\tbest: 1.2331492 (13496)\ttotal: 1m 31s\tremaining: 10.1s\n",
      "13550:\tlearn: 0.0298433\ttest: 1.2335941\tbest: 1.2331040 (13507)\ttotal: 1m 31s\tremaining: 9.79s\n",
      "13600:\tlearn: 0.0293593\ttest: 1.2337464\tbest: 1.2331040 (13507)\ttotal: 1m 31s\tremaining: 9.45s\n",
      "13650:\tlearn: 0.0289054\ttest: 1.2331176\tbest: 1.2330176 (13645)\ttotal: 1m 32s\tremaining: 9.11s\n",
      "13700:\tlearn: 0.0285308\ttest: 1.2325889\tbest: 1.2325889 (13700)\ttotal: 1m 32s\tremaining: 8.78s\n",
      "13750:\tlearn: 0.0281434\ttest: 1.2330153\tbest: 1.2325889 (13700)\ttotal: 1m 32s\tremaining: 8.44s\n",
      "13800:\tlearn: 0.0277330\ttest: 1.2333982\tbest: 1.2325889 (13700)\ttotal: 1m 33s\tremaining: 8.1s\n",
      "13850:\tlearn: 0.0273262\ttest: 1.2326664\tbest: 1.2325889 (13700)\ttotal: 1m 33s\tremaining: 7.76s\n",
      "13900:\tlearn: 0.0270271\ttest: 1.2322284\tbest: 1.2321082 (13865)\ttotal: 1m 33s\tremaining: 7.42s\n",
      "13950:\tlearn: 0.0266483\ttest: 1.2320162\tbest: 1.2316015 (13931)\ttotal: 1m 34s\tremaining: 7.09s\n",
      "14000:\tlearn: 0.0263279\ttest: 1.2320013\tbest: 1.2316015 (13931)\ttotal: 1m 34s\tremaining: 6.75s\n",
      "14050:\tlearn: 0.0259516\ttest: 1.2317839\tbest: 1.2315661 (14031)\ttotal: 1m 34s\tremaining: 6.41s\n",
      "14100:\tlearn: 0.0255960\ttest: 1.2317163\tbest: 1.2315661 (14031)\ttotal: 1m 35s\tremaining: 6.07s\n",
      "14150:\tlearn: 0.0251942\ttest: 1.2309757\tbest: 1.2309437 (14136)\ttotal: 1m 35s\tremaining: 5.74s\n",
      "14200:\tlearn: 0.0248702\ttest: 1.2312987\tbest: 1.2309437 (14136)\ttotal: 1m 35s\tremaining: 5.4s\n",
      "14250:\tlearn: 0.0245338\ttest: 1.2313423\tbest: 1.2309437 (14136)\ttotal: 1m 36s\tremaining: 5.06s\n",
      "14300:\tlearn: 0.0241953\ttest: 1.2309543\tbest: 1.2307014 (14288)\ttotal: 1m 36s\tremaining: 4.72s\n",
      "14350:\tlearn: 0.0238697\ttest: 1.2315491\tbest: 1.2307014 (14288)\ttotal: 1m 36s\tremaining: 4.38s\n",
      "14400:\tlearn: 0.0235483\ttest: 1.2317902\tbest: 1.2307014 (14288)\ttotal: 1m 37s\tremaining: 4.05s\n",
      "14450:\tlearn: 0.0232413\ttest: 1.2307578\tbest: 1.2307014 (14288)\ttotal: 1m 37s\tremaining: 3.71s\n",
      "14500:\tlearn: 0.0229370\ttest: 1.2303087\tbest: 1.2301951 (14498)\ttotal: 1m 37s\tremaining: 3.37s\n",
      "14550:\tlearn: 0.0226566\ttest: 1.2301786\tbest: 1.2298338 (14530)\ttotal: 1m 38s\tremaining: 3.03s\n",
      "14600:\tlearn: 0.0223410\ttest: 1.2310661\tbest: 1.2298338 (14530)\ttotal: 1m 38s\tremaining: 2.69s\n",
      "14650:\tlearn: 0.0220718\ttest: 1.2311067\tbest: 1.2298338 (14530)\ttotal: 1m 38s\tremaining: 2.36s\n",
      "14700:\tlearn: 0.0217667\ttest: 1.2316458\tbest: 1.2298338 (14530)\ttotal: 1m 39s\tremaining: 2.02s\n",
      "14750:\tlearn: 0.0214290\ttest: 1.2310611\tbest: 1.2298338 (14530)\ttotal: 1m 39s\tremaining: 1.68s\n",
      "14800:\tlearn: 0.0211668\ttest: 1.2313999\tbest: 1.2298338 (14530)\ttotal: 1m 39s\tremaining: 1.34s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.229833834\n",
      "bestIteration = 14530\n",
      "\n",
      "Shrink model to first 14531 iterations.\n",
      "Скор для фолда(15) : 9.0 средний скор на префиксе = 9.0 это заняло = 101 сек.\n",
      "Фолд: 16\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "0:\tlearn: 3.5631076\ttest: 3.9645200\tbest: 3.9645200 (0)\ttotal: 44.7ms\tremaining: 11m 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7002268\ttest: 2.9379445\tbest: 2.9379445 (50)\ttotal: 387ms\tremaining: 1m 53s\n",
      "100:\tlearn: 2.2458082\ttest: 2.3506379\tbest: 2.3506379 (100)\ttotal: 717ms\tremaining: 1m 45s\n",
      "150:\tlearn: 1.9950628\ttest: 2.1587799\tbest: 2.1587799 (150)\ttotal: 1.05s\tremaining: 1m 43s\n",
      "200:\tlearn: 1.8346480\ttest: 2.0388441\tbest: 2.0388441 (200)\ttotal: 1.39s\tremaining: 1m 42s\n",
      "250:\tlearn: 1.7347648\ttest: 1.9534378\tbest: 1.9534378 (250)\ttotal: 1.72s\tremaining: 1m 41s\n",
      "300:\tlearn: 1.6536172\ttest: 1.8713347\tbest: 1.8713347 (300)\ttotal: 2.06s\tremaining: 1m 40s\n",
      "350:\tlearn: 1.5875548\ttest: 1.8120197\tbest: 1.8120197 (350)\ttotal: 2.4s\tremaining: 1m 40s\n",
      "400:\tlearn: 1.5333756\ttest: 1.7635013\tbest: 1.7635013 (400)\ttotal: 2.73s\tremaining: 1m 39s\n",
      "450:\tlearn: 1.4887988\ttest: 1.7220519\tbest: 1.7214746 (449)\ttotal: 3.06s\tremaining: 1m 38s\n",
      "500:\tlearn: 1.4507641\ttest: 1.6963314\tbest: 1.6963314 (500)\ttotal: 3.4s\tremaining: 1m 38s\n",
      "550:\tlearn: 1.4172403\ttest: 1.6643744\tbest: 1.6643744 (550)\ttotal: 3.73s\tremaining: 1m 37s\n",
      "600:\tlearn: 1.3902871\ttest: 1.6482281\tbest: 1.6476051 (599)\ttotal: 4.06s\tremaining: 1m 37s\n",
      "650:\tlearn: 1.3633190\ttest: 1.6306075\tbest: 1.6306075 (650)\ttotal: 4.4s\tremaining: 1m 36s\n",
      "700:\tlearn: 1.3395818\ttest: 1.6177432\tbest: 1.6177432 (700)\ttotal: 4.73s\tremaining: 1m 36s\n",
      "750:\tlearn: 1.3148447\ttest: 1.6019104\tbest: 1.6012682 (747)\ttotal: 5.06s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.2897526\ttest: 1.5887816\tbest: 1.5887816 (800)\ttotal: 5.39s\tremaining: 1m 35s\n",
      "850:\tlearn: 1.2687709\ttest: 1.5831150\tbest: 1.5811244 (833)\ttotal: 5.72s\tremaining: 1m 35s\n",
      "900:\tlearn: 1.2480988\ttest: 1.5752238\tbest: 1.5748797 (898)\ttotal: 6.05s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2314346\ttest: 1.5716805\tbest: 1.5715858 (939)\ttotal: 6.38s\tremaining: 1m 34s\n",
      "1000:\tlearn: 1.2118856\ttest: 1.5632080\tbest: 1.5632080 (1000)\ttotal: 6.71s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.1926675\ttest: 1.5525903\tbest: 1.5525903 (1050)\ttotal: 7.04s\tremaining: 1m 33s\n",
      "1100:\tlearn: 1.1728176\ttest: 1.5391655\tbest: 1.5388553 (1099)\ttotal: 7.38s\tremaining: 1m 33s\n",
      "1150:\tlearn: 1.1570432\ttest: 1.5367741\tbest: 1.5363285 (1144)\ttotal: 7.7s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1385150\ttest: 1.5270019\tbest: 1.5269539 (1198)\ttotal: 8.04s\tremaining: 1m 32s\n",
      "1250:\tlearn: 1.1213472\ttest: 1.5216988\tbest: 1.5216665 (1248)\ttotal: 8.38s\tremaining: 1m 32s\n",
      "1300:\tlearn: 1.1057559\ttest: 1.5147526\tbest: 1.5147526 (1300)\ttotal: 8.7s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.0907983\ttest: 1.5066433\tbest: 1.5066164 (1349)\ttotal: 9.04s\tremaining: 1m 31s\n",
      "1400:\tlearn: 1.0739179\ttest: 1.4987435\tbest: 1.4987264 (1399)\ttotal: 9.37s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.0559469\ttest: 1.4927539\tbest: 1.4927539 (1450)\ttotal: 9.71s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0400184\ttest: 1.4834365\tbest: 1.4834365 (1500)\ttotal: 10s\tremaining: 1m 30s\n",
      "1550:\tlearn: 1.0239749\ttest: 1.4746888\tbest: 1.4746888 (1550)\ttotal: 10.4s\tremaining: 1m 30s\n",
      "1600:\tlearn: 1.0095334\ttest: 1.4690209\tbest: 1.4690209 (1600)\ttotal: 10.7s\tremaining: 1m 29s\n",
      "1650:\tlearn: 0.9973906\ttest: 1.4594794\tbest: 1.4588228 (1645)\ttotal: 11s\tremaining: 1m 29s\n",
      "1700:\tlearn: 0.9837937\ttest: 1.4508088\tbest: 1.4508088 (1700)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1750:\tlearn: 0.9683008\ttest: 1.4436944\tbest: 1.4436944 (1750)\ttotal: 11.7s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9516939\ttest: 1.4382485\tbest: 1.4382485 (1800)\ttotal: 12s\tremaining: 1m 28s\n",
      "1850:\tlearn: 0.9368723\ttest: 1.4311062\tbest: 1.4308516 (1848)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9206303\ttest: 1.4264345\tbest: 1.4264345 (1900)\ttotal: 12.7s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9070930\ttest: 1.4206631\tbest: 1.4205194 (1941)\ttotal: 13s\tremaining: 1m 27s\n",
      "2000:\tlearn: 0.8904740\ttest: 1.4169689\tbest: 1.4169689 (2000)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.8766278\ttest: 1.4115626\tbest: 1.4115626 (2050)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.8621547\ttest: 1.4017783\tbest: 1.4016292 (2099)\ttotal: 14s\tremaining: 1m 26s\n",
      "2150:\tlearn: 0.8479186\ttest: 1.3960730\tbest: 1.3960730 (2150)\ttotal: 14.4s\tremaining: 1m 26s\n",
      "2200:\tlearn: 0.8335660\ttest: 1.3952582\tbest: 1.3942185 (2170)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8182238\ttest: 1.3902544\tbest: 1.3902544 (2250)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "2300:\tlearn: 0.8047697\ttest: 1.3863489\tbest: 1.3858190 (2297)\ttotal: 15.4s\tremaining: 1m 25s\n",
      "2350:\tlearn: 0.7917472\ttest: 1.3806841\tbest: 1.3798728 (2345)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.7788391\ttest: 1.3743456\tbest: 1.3743456 (2400)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "2450:\tlearn: 0.7674978\ttest: 1.3715194\tbest: 1.3705417 (2440)\ttotal: 16.4s\tremaining: 1m 24s\n",
      "2500:\tlearn: 0.7551321\ttest: 1.3633437\tbest: 1.3633422 (2499)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7439332\ttest: 1.3625228\tbest: 1.3625228 (2550)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "2600:\tlearn: 0.7311560\ttest: 1.3552703\tbest: 1.3552703 (2600)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "2650:\tlearn: 0.7213412\ttest: 1.3497302\tbest: 1.3497302 (2650)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7103280\ttest: 1.3445821\tbest: 1.3445485 (2699)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "2750:\tlearn: 0.7002655\ttest: 1.3404781\tbest: 1.3400213 (2742)\ttotal: 18.5s\tremaining: 1m 22s\n",
      "2800:\tlearn: 0.6895000\ttest: 1.3372110\tbest: 1.3372110 (2800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.6785615\ttest: 1.3327532\tbest: 1.3327291 (2847)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "2900:\tlearn: 0.6678127\ttest: 1.3289849\tbest: 1.3286878 (2898)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "2950:\tlearn: 0.6575434\ttest: 1.3270132\tbest: 1.3266577 (2946)\ttotal: 19.8s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.6471201\ttest: 1.3225775\tbest: 1.3225775 (3000)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "3050:\tlearn: 0.6364449\ttest: 1.3240295\tbest: 1.3225775 (3000)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "3100:\tlearn: 0.6267750\ttest: 1.3221218\tbest: 1.3220563 (3089)\ttotal: 20.8s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6186577\ttest: 1.3195670\tbest: 1.3192843 (3147)\ttotal: 21.1s\tremaining: 1m 19s\n",
      "3200:\tlearn: 0.6077719\ttest: 1.3184685\tbest: 1.3173370 (3193)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "3250:\tlearn: 0.5964011\ttest: 1.3169811\tbest: 1.3169811 (3250)\ttotal: 21.8s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.5865319\ttest: 1.3167138\tbest: 1.3163120 (3272)\ttotal: 22.2s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.5773268\ttest: 1.3125449\tbest: 1.3124157 (3348)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "3400:\tlearn: 0.5687286\ttest: 1.3099313\tbest: 1.3091974 (3398)\ttotal: 22.8s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.5612542\ttest: 1.3085572\tbest: 1.3085572 (3450)\ttotal: 23.2s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.5520311\ttest: 1.3032053\tbest: 1.3031637 (3498)\ttotal: 23.5s\tremaining: 1m 17s\n",
      "3550:\tlearn: 0.5447161\ttest: 1.3004785\tbest: 1.3002777 (3549)\ttotal: 23.8s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5354187\ttest: 1.3002472\tbest: 1.2999923 (3574)\ttotal: 24.2s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.5281197\ttest: 1.2972608\tbest: 1.2964578 (3647)\ttotal: 24.5s\tremaining: 1m 16s\n",
      "3700:\tlearn: 0.5205613\ttest: 1.2960049\tbest: 1.2955754 (3698)\ttotal: 24.8s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5122990\ttest: 1.2935838\tbest: 1.2935838 (3750)\ttotal: 25.2s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5035988\ttest: 1.2923035\tbest: 1.2921939 (3788)\ttotal: 25.5s\tremaining: 1m 15s\n",
      "3850:\tlearn: 0.4947511\ttest: 1.2917937\tbest: 1.2914384 (3820)\ttotal: 25.8s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.4872720\ttest: 1.2920405\tbest: 1.2912145 (3898)\ttotal: 26.2s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.4798062\ttest: 1.2907738\tbest: 1.2907738 (3950)\ttotal: 26.5s\tremaining: 1m 14s\n",
      "4000:\tlearn: 0.4719290\ttest: 1.2894270\tbest: 1.2890015 (3997)\ttotal: 26.9s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.4646979\ttest: 1.2859177\tbest: 1.2859017 (4049)\ttotal: 27.2s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.4578968\ttest: 1.2829470\tbest: 1.2829456 (4099)\ttotal: 27.5s\tremaining: 1m 13s\n",
      "4150:\tlearn: 0.4511504\ttest: 1.2804469\tbest: 1.2800703 (4147)\ttotal: 27.9s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4440441\ttest: 1.2809939\tbest: 1.2800703 (4147)\ttotal: 28.2s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4374620\ttest: 1.2778188\tbest: 1.2775569 (4249)\ttotal: 28.6s\tremaining: 1m 12s\n",
      "4300:\tlearn: 0.4313129\ttest: 1.2760479\tbest: 1.2758175 (4296)\ttotal: 28.9s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4249848\ttest: 1.2743018\tbest: 1.2743018 (4350)\ttotal: 29.2s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4187260\ttest: 1.2719245\tbest: 1.2719239 (4399)\ttotal: 29.6s\tremaining: 1m 11s\n",
      "4450:\tlearn: 0.4120365\ttest: 1.2686183\tbest: 1.2686183 (4450)\ttotal: 29.9s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4067292\ttest: 1.2671266\tbest: 1.2667636 (4480)\ttotal: 30.2s\tremaining: 1m 10s\n",
      "4550:\tlearn: 0.4000991\ttest: 1.2632292\tbest: 1.2632067 (4545)\ttotal: 30.6s\tremaining: 1m 10s\n",
      "4600:\tlearn: 0.3934914\ttest: 1.2618954\tbest: 1.2617384 (4595)\ttotal: 30.9s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.3869368\ttest: 1.2628801\tbest: 1.2615854 (4606)\ttotal: 31.3s\tremaining: 1m 9s\n",
      "4700:\tlearn: 0.3810447\ttest: 1.2615609\tbest: 1.2613921 (4696)\ttotal: 31.6s\tremaining: 1m 9s\n",
      "4750:\tlearn: 0.3748869\ttest: 1.2610668\tbest: 1.2610668 (4750)\ttotal: 31.9s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.3690519\ttest: 1.2585447\tbest: 1.2585281 (4797)\ttotal: 32.3s\tremaining: 1m 8s\n",
      "4850:\tlearn: 0.3632538\ttest: 1.2581176\tbest: 1.2577613 (4816)\ttotal: 32.6s\tremaining: 1m 8s\n",
      "4900:\tlearn: 0.3568748\ttest: 1.2571598\tbest: 1.2568298 (4879)\ttotal: 32.9s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3515065\ttest: 1.2573208\tbest: 1.2568298 (4879)\ttotal: 33.3s\tremaining: 1m 7s\n",
      "5000:\tlearn: 0.3459407\ttest: 1.2559370\tbest: 1.2556692 (4991)\ttotal: 33.6s\tremaining: 1m 7s\n",
      "5050:\tlearn: 0.3396269\ttest: 1.2547529\tbest: 1.2546812 (5049)\ttotal: 33.9s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3346028\ttest: 1.2527464\tbest: 1.2524256 (5098)\ttotal: 34.3s\tremaining: 1m 6s\n",
      "5150:\tlearn: 0.3297485\ttest: 1.2492189\tbest: 1.2492189 (5150)\ttotal: 34.6s\tremaining: 1m 6s\n",
      "5200:\tlearn: 0.3247208\ttest: 1.2504312\tbest: 1.2490705 (5169)\ttotal: 34.9s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3201907\ttest: 1.2483712\tbest: 1.2482090 (5243)\ttotal: 35.3s\tremaining: 1m 5s\n",
      "5300:\tlearn: 0.3153764\ttest: 1.2487535\tbest: 1.2481478 (5268)\ttotal: 35.6s\tremaining: 1m 5s\n",
      "5350:\tlearn: 0.3101340\ttest: 1.2483039\tbest: 1.2480853 (5335)\ttotal: 36s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3045761\ttest: 1.2469819\tbest: 1.2468098 (5398)\ttotal: 36.3s\tremaining: 1m 4s\n",
      "5450:\tlearn: 0.2994620\ttest: 1.2470340\tbest: 1.2466449 (5411)\ttotal: 36.6s\tremaining: 1m 4s\n",
      "5500:\tlearn: 0.2951524\ttest: 1.2456175\tbest: 1.2455813 (5499)\ttotal: 37s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.2901619\ttest: 1.2473225\tbest: 1.2454753 (5506)\ttotal: 37.3s\tremaining: 1m 3s\n",
      "5600:\tlearn: 0.2858714\ttest: 1.2471053\tbest: 1.2454753 (5506)\ttotal: 37.7s\tremaining: 1m 3s\n",
      "5650:\tlearn: 0.2813960\ttest: 1.2467229\tbest: 1.2454753 (5506)\ttotal: 38s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.2767130\ttest: 1.2451481\tbest: 1.2448409 (5698)\ttotal: 38.3s\tremaining: 1m 2s\n",
      "5750:\tlearn: 0.2722096\ttest: 1.2442520\tbest: 1.2438871 (5744)\ttotal: 38.7s\tremaining: 1m 2s\n",
      "5800:\tlearn: 0.2685126\ttest: 1.2437685\tbest: 1.2434130 (5794)\ttotal: 39s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2645490\ttest: 1.2445136\tbest: 1.2434130 (5794)\ttotal: 39.3s\tremaining: 1m 1s\n",
      "5900:\tlearn: 0.2603718\ttest: 1.2450929\tbest: 1.2434130 (5794)\ttotal: 39.7s\tremaining: 1m 1s\n",
      "5950:\tlearn: 0.2563925\ttest: 1.2440303\tbest: 1.2434130 (5794)\ttotal: 40s\tremaining: 1m\n",
      "6000:\tlearn: 0.2525052\ttest: 1.2435829\tbest: 1.2434130 (5794)\ttotal: 40.3s\tremaining: 1m\n",
      "6050:\tlearn: 0.2482313\ttest: 1.2421998\tbest: 1.2421998 (6050)\ttotal: 40.7s\tremaining: 1m\n",
      "6100:\tlearn: 0.2440990\ttest: 1.2403698\tbest: 1.2403698 (6100)\ttotal: 41s\tremaining: 59.8s\n",
      "6150:\tlearn: 0.2403342\ttest: 1.2397816\tbest: 1.2390385 (6136)\ttotal: 41.4s\tremaining: 59.5s\n",
      "6200:\tlearn: 0.2372430\ttest: 1.2397861\tbest: 1.2390385 (6136)\ttotal: 41.7s\tremaining: 59.2s\n",
      "6250:\tlearn: 0.2331918\ttest: 1.2395164\tbest: 1.2388942 (6243)\ttotal: 42s\tremaining: 58.8s\n",
      "6300:\tlearn: 0.2295447\ttest: 1.2397596\tbest: 1.2388942 (6243)\ttotal: 42.4s\tremaining: 58.5s\n",
      "6350:\tlearn: 0.2256614\ttest: 1.2394028\tbest: 1.2388942 (6243)\ttotal: 42.7s\tremaining: 58.2s\n",
      "6400:\tlearn: 0.2220066\ttest: 1.2387067\tbest: 1.2386525 (6395)\ttotal: 43.1s\tremaining: 57.8s\n",
      "6450:\tlearn: 0.2188671\ttest: 1.2385547\tbest: 1.2380699 (6412)\ttotal: 43.4s\tremaining: 57.5s\n",
      "6500:\tlearn: 0.2151863\ttest: 1.2389850\tbest: 1.2380699 (6412)\ttotal: 43.7s\tremaining: 57.2s\n",
      "6550:\tlearn: 0.2117956\ttest: 1.2381332\tbest: 1.2380692 (6548)\ttotal: 44.1s\tremaining: 56.8s\n",
      "6600:\tlearn: 0.2085142\ttest: 1.2360806\tbest: 1.2360806 (6600)\ttotal: 44.4s\tremaining: 56.5s\n",
      "6650:\tlearn: 0.2047901\ttest: 1.2341641\tbest: 1.2339959 (6645)\ttotal: 44.7s\tremaining: 56.2s\n",
      "6700:\tlearn: 0.2014738\ttest: 1.2330419\tbest: 1.2330419 (6700)\ttotal: 45.1s\tremaining: 55.8s\n",
      "6750:\tlearn: 0.1979183\ttest: 1.2329430\tbest: 1.2324808 (6737)\ttotal: 45.4s\tremaining: 55.5s\n",
      "6800:\tlearn: 0.1946497\ttest: 1.2332406\tbest: 1.2324808 (6737)\ttotal: 45.8s\tremaining: 55.2s\n",
      "6850:\tlearn: 0.1914981\ttest: 1.2329286\tbest: 1.2324808 (6737)\ttotal: 46.1s\tremaining: 54.8s\n",
      "6900:\tlearn: 0.1878034\ttest: 1.2304990\tbest: 1.2304788 (6899)\ttotal: 46.4s\tremaining: 54.5s\n",
      "6950:\tlearn: 0.1845921\ttest: 1.2297684\tbest: 1.2297684 (6950)\ttotal: 46.8s\tremaining: 54.1s\n",
      "7000:\tlearn: 0.1811246\ttest: 1.2286289\tbest: 1.2286289 (7000)\ttotal: 47.1s\tremaining: 53.8s\n",
      "7050:\tlearn: 0.1780748\ttest: 1.2283974\tbest: 1.2279826 (7022)\ttotal: 47.4s\tremaining: 53.5s\n",
      "7100:\tlearn: 0.1752865\ttest: 1.2285041\tbest: 1.2279826 (7022)\ttotal: 47.8s\tremaining: 53.1s\n",
      "7150:\tlearn: 0.1723107\ttest: 1.2288747\tbest: 1.2279826 (7022)\ttotal: 48.1s\tremaining: 52.8s\n",
      "7200:\tlearn: 0.1693002\ttest: 1.2285386\tbest: 1.2279826 (7022)\ttotal: 48.4s\tremaining: 52.5s\n",
      "7250:\tlearn: 0.1664404\ttest: 1.2273992\tbest: 1.2272535 (7245)\ttotal: 48.8s\tremaining: 52.1s\n",
      "7300:\tlearn: 0.1638241\ttest: 1.2265348\tbest: 1.2264348 (7295)\ttotal: 49.1s\tremaining: 51.8s\n",
      "7350:\tlearn: 0.1609862\ttest: 1.2248056\tbest: 1.2247228 (7349)\ttotal: 49.5s\tremaining: 51.5s\n",
      "7400:\tlearn: 0.1585574\ttest: 1.2247904\tbest: 1.2244319 (7384)\ttotal: 49.8s\tremaining: 51.1s\n",
      "7450:\tlearn: 0.1559624\ttest: 1.2245090\tbest: 1.2240251 (7433)\ttotal: 50.1s\tremaining: 50.8s\n",
      "7500:\tlearn: 0.1530650\ttest: 1.2247773\tbest: 1.2240251 (7433)\ttotal: 50.5s\tremaining: 50.5s\n",
      "7550:\tlearn: 0.1504925\ttest: 1.2236042\tbest: 1.2233107 (7547)\ttotal: 50.8s\tremaining: 50.1s\n",
      "7600:\tlearn: 0.1478710\ttest: 1.2219368\tbest: 1.2219115 (7599)\ttotal: 51.1s\tremaining: 49.8s\n",
      "7650:\tlearn: 0.1456467\ttest: 1.2228028\tbest: 1.2219036 (7605)\ttotal: 51.5s\tremaining: 49.4s\n",
      "7700:\tlearn: 0.1429287\ttest: 1.2220787\tbest: 1.2219036 (7605)\ttotal: 51.8s\tremaining: 49.1s\n",
      "7750:\tlearn: 0.1405303\ttest: 1.2222845\tbest: 1.2218516 (7724)\ttotal: 52.2s\tremaining: 48.8s\n",
      "7800:\tlearn: 0.1380920\ttest: 1.2206805\tbest: 1.2206805 (7800)\ttotal: 52.5s\tremaining: 48.4s\n",
      "7850:\tlearn: 0.1354925\ttest: 1.2210765\tbest: 1.2201563 (7823)\ttotal: 52.8s\tremaining: 48.1s\n",
      "7900:\tlearn: 0.1327428\ttest: 1.2214582\tbest: 1.2201563 (7823)\ttotal: 53.2s\tremaining: 47.8s\n",
      "7950:\tlearn: 0.1303296\ttest: 1.2209002\tbest: 1.2201563 (7823)\ttotal: 53.5s\tremaining: 47.4s\n",
      "8000:\tlearn: 0.1279686\ttest: 1.2206831\tbest: 1.2201563 (7823)\ttotal: 53.8s\tremaining: 47.1s\n",
      "8050:\tlearn: 0.1254210\ttest: 1.2210337\tbest: 1.2201563 (7823)\ttotal: 54.2s\tremaining: 46.8s\n",
      "8100:\tlearn: 0.1235105\ttest: 1.2212889\tbest: 1.2201563 (7823)\ttotal: 54.5s\tremaining: 46.4s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.220156302\n",
      "bestIteration = 7823\n",
      "\n",
      "Shrink model to first 7824 iterations.\n",
      "Скор для фолда(16) : 9.0 средний скор на префиксе = 9.0 это заняло = 55 сек.\n",
      "Фолд: 17\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "0:\tlearn: 3.5805699\ttest: 3.5348576\tbest: 3.5348576 (0)\ttotal: 27.6ms\tremaining: 6m 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7332890\ttest: 2.4607367\tbest: 2.4607367 (50)\ttotal: 367ms\tremaining: 1m 47s\n",
      "100:\tlearn: 2.2700291\ttest: 1.9933435\tbest: 1.9933435 (100)\ttotal: 703ms\tremaining: 1m 43s\n",
      "150:\tlearn: 2.0161668\ttest: 1.7218699\tbest: 1.7218699 (150)\ttotal: 1.03s\tremaining: 1m 41s\n",
      "200:\tlearn: 1.8519259\ttest: 1.5769858\tbest: 1.5769858 (200)\ttotal: 1.37s\tremaining: 1m 40s\n",
      "250:\tlearn: 1.7438450\ttest: 1.5155427\tbest: 1.5155427 (250)\ttotal: 1.7s\tremaining: 1m 39s\n",
      "300:\tlearn: 1.6559217\ttest: 1.4493753\tbest: 1.4493753 (300)\ttotal: 2.04s\tremaining: 1m 39s\n",
      "350:\tlearn: 1.5862436\ttest: 1.4024197\tbest: 1.4024197 (350)\ttotal: 2.37s\tremaining: 1m 38s\n",
      "400:\tlearn: 1.5349372\ttest: 1.3768511\tbest: 1.3768511 (400)\ttotal: 2.71s\tremaining: 1m 38s\n",
      "450:\tlearn: 1.4923779\ttest: 1.3553025\tbest: 1.3553025 (450)\ttotal: 3.05s\tremaining: 1m 38s\n",
      "500:\tlearn: 1.4551726\ttest: 1.3318039\tbest: 1.3310508 (498)\ttotal: 3.39s\tremaining: 1m 38s\n",
      "550:\tlearn: 1.4246958\ttest: 1.3160450\tbest: 1.3154401 (548)\ttotal: 3.72s\tremaining: 1m 37s\n",
      "600:\tlearn: 1.3959958\ttest: 1.3085931\tbest: 1.3076175 (594)\ttotal: 4.05s\tremaining: 1m 37s\n",
      "650:\tlearn: 1.3705352\ttest: 1.3081120\tbest: 1.3053541 (633)\ttotal: 4.38s\tremaining: 1m 36s\n",
      "700:\tlearn: 1.3437221\ttest: 1.3035990\tbest: 1.3032359 (699)\ttotal: 4.71s\tremaining: 1m 36s\n",
      "750:\tlearn: 1.3192445\ttest: 1.2920926\tbest: 1.2917628 (746)\ttotal: 5.05s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.2958720\ttest: 1.2903454\tbest: 1.2879135 (796)\ttotal: 5.39s\tremaining: 1m 35s\n",
      "850:\tlearn: 1.2742097\ttest: 1.2873666\tbest: 1.2873666 (850)\ttotal: 5.72s\tremaining: 1m 35s\n",
      "900:\tlearn: 1.2530005\ttest: 1.2838632\tbest: 1.2820011 (896)\ttotal: 6.05s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2340537\ttest: 1.2830816\tbest: 1.2814953 (939)\ttotal: 6.39s\tremaining: 1m 34s\n",
      "1000:\tlearn: 1.2173329\ttest: 1.2790377\tbest: 1.2790377 (1000)\ttotal: 6.72s\tremaining: 1m 34s\n",
      "1050:\tlearn: 1.2003642\ttest: 1.2736155\tbest: 1.2736155 (1050)\ttotal: 7.05s\tremaining: 1m 33s\n",
      "1100:\tlearn: 1.1840281\ttest: 1.2709251\tbest: 1.2708040 (1099)\ttotal: 7.39s\tremaining: 1m 33s\n",
      "1150:\tlearn: 1.1702746\ttest: 1.2648741\tbest: 1.2645743 (1146)\ttotal: 7.72s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1542190\ttest: 1.2623096\tbest: 1.2613748 (1183)\ttotal: 8.05s\tremaining: 1m 32s\n",
      "1250:\tlearn: 1.1400333\ttest: 1.2560800\tbest: 1.2560800 (1250)\ttotal: 8.38s\tremaining: 1m 32s\n",
      "1300:\tlearn: 1.1259340\ttest: 1.2543275\tbest: 1.2540261 (1298)\ttotal: 8.72s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.1119054\ttest: 1.2536310\tbest: 1.2525935 (1333)\ttotal: 9.05s\tremaining: 1m 31s\n",
      "1400:\tlearn: 1.0979022\ttest: 1.2508866\tbest: 1.2504036 (1399)\ttotal: 9.39s\tremaining: 1m 31s\n",
      "1450:\tlearn: 1.0818957\ttest: 1.2444905\tbest: 1.2442760 (1447)\ttotal: 9.73s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0673820\ttest: 1.2373626\tbest: 1.2372236 (1499)\ttotal: 10.1s\tremaining: 1m 30s\n",
      "1550:\tlearn: 1.0531060\ttest: 1.2319937\tbest: 1.2319937 (1550)\ttotal: 10.4s\tremaining: 1m 30s\n",
      "1600:\tlearn: 1.0379223\ttest: 1.2282716\tbest: 1.2274666 (1593)\ttotal: 10.7s\tremaining: 1m 29s\n",
      "1650:\tlearn: 1.0233378\ttest: 1.2224428\tbest: 1.2224252 (1649)\ttotal: 11.1s\tremaining: 1m 29s\n",
      "1700:\tlearn: 1.0086313\ttest: 1.2177855\tbest: 1.2177855 (1700)\ttotal: 11.4s\tremaining: 1m 29s\n",
      "1750:\tlearn: 0.9940754\ttest: 1.2131839\tbest: 1.2128755 (1744)\ttotal: 11.7s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9809578\ttest: 1.2136397\tbest: 1.2110640 (1761)\ttotal: 12.1s\tremaining: 1m 28s\n",
      "1850:\tlearn: 0.9694920\ttest: 1.2122473\tbest: 1.2110640 (1761)\ttotal: 12.4s\tremaining: 1m 28s\n",
      "1900:\tlearn: 0.9571445\ttest: 1.2093002\tbest: 1.2088290 (1894)\ttotal: 12.7s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9443721\ttest: 1.2031081\tbest: 1.2029112 (1949)\ttotal: 13.1s\tremaining: 1m 27s\n",
      "2000:\tlearn: 0.9295281\ttest: 1.2017791\tbest: 1.2017791 (2000)\ttotal: 13.4s\tremaining: 1m 27s\n",
      "2050:\tlearn: 0.9182085\ttest: 1.1965164\tbest: 1.1965164 (2050)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.9073683\ttest: 1.1921892\tbest: 1.1921892 (2100)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "2150:\tlearn: 0.8939603\ttest: 1.1912144\tbest: 1.1898395 (2145)\ttotal: 14.4s\tremaining: 1m 26s\n",
      "2200:\tlearn: 0.8829722\ttest: 1.1884020\tbest: 1.1881549 (2191)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8719237\ttest: 1.1858088\tbest: 1.1856647 (2230)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "2300:\tlearn: 0.8589270\ttest: 1.1798453\tbest: 1.1798453 (2300)\ttotal: 15.4s\tremaining: 1m 25s\n",
      "2350:\tlearn: 0.8464982\ttest: 1.1754458\tbest: 1.1752018 (2347)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8338514\ttest: 1.1718053\tbest: 1.1710939 (2385)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "2450:\tlearn: 0.8194501\ttest: 1.1700158\tbest: 1.1700158 (2450)\ttotal: 16.4s\tremaining: 1m 24s\n",
      "2500:\tlearn: 0.8047318\ttest: 1.1678544\tbest: 1.1674261 (2496)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7933390\ttest: 1.1685376\tbest: 1.1671735 (2507)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "2600:\tlearn: 0.7811350\ttest: 1.1654034\tbest: 1.1654034 (2600)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "2650:\tlearn: 0.7693398\ttest: 1.1641551\tbest: 1.1637869 (2638)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7569118\ttest: 1.1615910\tbest: 1.1615910 (2700)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "2750:\tlearn: 0.7438043\ttest: 1.1573008\tbest: 1.1573008 (2750)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "2800:\tlearn: 0.7326824\ttest: 1.1556710\tbest: 1.1556537 (2785)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.7239752\ttest: 1.1538181\tbest: 1.1538181 (2850)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "2900:\tlearn: 0.7133602\ttest: 1.1537649\tbest: 1.1528403 (2889)\ttotal: 19.4s\tremaining: 1m 21s\n",
      "2950:\tlearn: 0.7007025\ttest: 1.1495066\tbest: 1.1494532 (2942)\ttotal: 19.8s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.6908731\ttest: 1.1455832\tbest: 1.1449451 (2993)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "3050:\tlearn: 0.6802914\ttest: 1.1456667\tbest: 1.1440414 (3012)\ttotal: 20.4s\tremaining: 1m 20s\n",
      "3100:\tlearn: 0.6695029\ttest: 1.1445206\tbest: 1.1436745 (3075)\ttotal: 20.8s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6603400\ttest: 1.1419477\tbest: 1.1419477 (3150)\ttotal: 21.1s\tremaining: 1m 19s\n",
      "3200:\tlearn: 0.6501685\ttest: 1.1420694\tbest: 1.1416017 (3154)\ttotal: 21.4s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6406830\ttest: 1.1415906\tbest: 1.1414411 (3244)\ttotal: 21.8s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6295049\ttest: 1.1411527\tbest: 1.1405917 (3271)\ttotal: 22.1s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.6194747\ttest: 1.1411091\tbest: 1.1405917 (3271)\ttotal: 22.4s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.6097186\ttest: 1.1407225\tbest: 1.1405748 (3391)\ttotal: 22.8s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.5998670\ttest: 1.1401868\tbest: 1.1398154 (3448)\ttotal: 23.1s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.5909480\ttest: 1.1370877\tbest: 1.1370519 (3498)\ttotal: 23.5s\tremaining: 1m 17s\n",
      "3550:\tlearn: 0.5816608\ttest: 1.1360411\tbest: 1.1360411 (3550)\ttotal: 23.8s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5743653\ttest: 1.1341752\tbest: 1.1339750 (3594)\ttotal: 24.1s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.5648186\ttest: 1.1328048\tbest: 1.1326273 (3646)\ttotal: 24.5s\tremaining: 1m 16s\n",
      "3700:\tlearn: 0.5567060\ttest: 1.1309716\tbest: 1.1309583 (3699)\ttotal: 24.8s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5468272\ttest: 1.1291490\tbest: 1.1291244 (3725)\ttotal: 25.1s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5378234\ttest: 1.1271829\tbest: 1.1271829 (3800)\ttotal: 25.5s\tremaining: 1m 15s\n",
      "3850:\tlearn: 0.5284050\ttest: 1.1263289\tbest: 1.1258960 (3840)\ttotal: 25.8s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5198778\ttest: 1.1266470\tbest: 1.1256404 (3861)\ttotal: 26.2s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.5125853\ttest: 1.1248453\tbest: 1.1247381 (3944)\ttotal: 26.5s\tremaining: 1m 14s\n",
      "4000:\tlearn: 0.5037254\ttest: 1.1238135\tbest: 1.1229479 (3987)\ttotal: 26.8s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.4957917\ttest: 1.1228060\tbest: 1.1226782 (4045)\ttotal: 27.2s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.4884719\ttest: 1.1229778\tbest: 1.1217925 (4070)\ttotal: 27.5s\tremaining: 1m 13s\n",
      "4150:\tlearn: 0.4816762\ttest: 1.1194295\tbest: 1.1192783 (4147)\ttotal: 27.8s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4742541\ttest: 1.1167222\tbest: 1.1164348 (4196)\ttotal: 28.2s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4657879\ttest: 1.1175330\tbest: 1.1159657 (4227)\ttotal: 28.5s\tremaining: 1m 12s\n",
      "4300:\tlearn: 0.4580580\ttest: 1.1159435\tbest: 1.1159435 (4300)\ttotal: 28.9s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4520197\ttest: 1.1147969\tbest: 1.1147527 (4339)\ttotal: 29.2s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4457091\ttest: 1.1145268\tbest: 1.1137507 (4385)\ttotal: 29.5s\tremaining: 1m 11s\n",
      "4450:\tlearn: 0.4389672\ttest: 1.1155056\tbest: 1.1137507 (4385)\ttotal: 29.9s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4324084\ttest: 1.1137792\tbest: 1.1132269 (4496)\ttotal: 30.2s\tremaining: 1m 10s\n",
      "4550:\tlearn: 0.4249630\ttest: 1.1151598\tbest: 1.1132269 (4496)\ttotal: 30.5s\tremaining: 1m 10s\n",
      "4600:\tlearn: 0.4170831\ttest: 1.1131715\tbest: 1.1125713 (4569)\ttotal: 30.9s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4119064\ttest: 1.1130783\tbest: 1.1121859 (4622)\ttotal: 31.2s\tremaining: 1m 9s\n",
      "4700:\tlearn: 0.4051824\ttest: 1.1141002\tbest: 1.1121859 (4622)\ttotal: 31.5s\tremaining: 1m 9s\n",
      "4750:\tlearn: 0.3992529\ttest: 1.1126314\tbest: 1.1121859 (4622)\ttotal: 31.9s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.3933733\ttest: 1.1123838\tbest: 1.1121859 (4622)\ttotal: 32.2s\tremaining: 1m 8s\n",
      "4850:\tlearn: 0.3874693\ttest: 1.1127359\tbest: 1.1121859 (4622)\ttotal: 32.5s\tremaining: 1m 8s\n",
      "4900:\tlearn: 0.3805457\ttest: 1.1108686\tbest: 1.1108231 (4899)\ttotal: 32.9s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3746479\ttest: 1.1107483\tbest: 1.1103644 (4918)\ttotal: 33.2s\tremaining: 1m 7s\n",
      "5000:\tlearn: 0.3697010\ttest: 1.1087299\tbest: 1.1086876 (4999)\ttotal: 33.5s\tremaining: 1m 7s\n",
      "5050:\tlearn: 0.3643795\ttest: 1.1073302\tbest: 1.1070043 (5046)\ttotal: 33.9s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3593946\ttest: 1.1054317\tbest: 1.1054317 (5100)\ttotal: 34.2s\tremaining: 1m 6s\n",
      "5150:\tlearn: 0.3537124\ttest: 1.1044336\tbest: 1.1037626 (5125)\ttotal: 34.5s\tremaining: 1m 6s\n",
      "5200:\tlearn: 0.3484490\ttest: 1.1036217\tbest: 1.1034282 (5195)\ttotal: 34.9s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3434109\ttest: 1.1018315\tbest: 1.1016659 (5249)\ttotal: 35.2s\tremaining: 1m 5s\n",
      "5300:\tlearn: 0.3382009\ttest: 1.1006890\tbest: 1.1006465 (5299)\ttotal: 35.6s\tremaining: 1m 5s\n",
      "5350:\tlearn: 0.3322428\ttest: 1.1013521\tbest: 1.0997379 (5311)\ttotal: 35.9s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3272100\ttest: 1.1020189\tbest: 1.0997379 (5311)\ttotal: 36.2s\tremaining: 1m 4s\n",
      "5450:\tlearn: 0.3216613\ttest: 1.1002840\tbest: 1.0997268 (5441)\ttotal: 36.6s\tremaining: 1m 4s\n",
      "5500:\tlearn: 0.3166473\ttest: 1.0983664\tbest: 1.0978956 (5497)\ttotal: 36.9s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3112977\ttest: 1.0977315\tbest: 1.0973433 (5544)\ttotal: 37.2s\tremaining: 1m 3s\n",
      "5600:\tlearn: 0.3067904\ttest: 1.0968009\tbest: 1.0962619 (5586)\ttotal: 37.6s\tremaining: 1m 3s\n",
      "5650:\tlearn: 0.3023373\ttest: 1.0963569\tbest: 1.0962619 (5586)\ttotal: 37.9s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.2977897\ttest: 1.0972450\tbest: 1.0962619 (5586)\ttotal: 38.2s\tremaining: 1m 2s\n",
      "5750:\tlearn: 0.2935128\ttest: 1.0969741\tbest: 1.0962619 (5586)\ttotal: 38.6s\tremaining: 1m 2s\n",
      "5800:\tlearn: 0.2893385\ttest: 1.0949441\tbest: 1.0949441 (5800)\ttotal: 38.9s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2848433\ttest: 1.0943300\tbest: 1.0939309 (5836)\ttotal: 39.2s\tremaining: 1m 1s\n",
      "5900:\tlearn: 0.2796642\ttest: 1.0935676\tbest: 1.0932902 (5893)\ttotal: 39.6s\tremaining: 1m 1s\n",
      "5950:\tlearn: 0.2754656\ttest: 1.0922074\tbest: 1.0922074 (5950)\ttotal: 39.9s\tremaining: 1m\n",
      "6000:\tlearn: 0.2717787\ttest: 1.0919508\tbest: 1.0917186 (5982)\ttotal: 40.3s\tremaining: 1m\n",
      "6050:\tlearn: 0.2671004\ttest: 1.0901075\tbest: 1.0899681 (6049)\ttotal: 40.6s\tremaining: 1m\n",
      "6100:\tlearn: 0.2624944\ttest: 1.0892994\tbest: 1.0884808 (6092)\ttotal: 40.9s\tremaining: 59.7s\n",
      "6150:\tlearn: 0.2586255\ttest: 1.0893148\tbest: 1.0884808 (6092)\ttotal: 41.3s\tremaining: 59.4s\n",
      "6200:\tlearn: 0.2542579\ttest: 1.0881611\tbest: 1.0881611 (6200)\ttotal: 41.6s\tremaining: 59s\n",
      "6250:\tlearn: 0.2501070\ttest: 1.0884024\tbest: 1.0878086 (6236)\ttotal: 41.9s\tremaining: 58.7s\n",
      "6300:\tlearn: 0.2459758\ttest: 1.0876307\tbest: 1.0876307 (6300)\ttotal: 42.3s\tremaining: 58.4s\n",
      "6350:\tlearn: 0.2417245\ttest: 1.0887139\tbest: 1.0874284 (6307)\ttotal: 42.6s\tremaining: 58.1s\n",
      "6400:\tlearn: 0.2378572\ttest: 1.0879142\tbest: 1.0873367 (6385)\ttotal: 43s\tremaining: 57.7s\n",
      "6450:\tlearn: 0.2338700\ttest: 1.0879925\tbest: 1.0873367 (6385)\ttotal: 43.3s\tremaining: 57.4s\n",
      "6500:\tlearn: 0.2305729\ttest: 1.0870750\tbest: 1.0870750 (6500)\ttotal: 43.6s\tremaining: 57s\n",
      "6550:\tlearn: 0.2267693\ttest: 1.0869027\tbest: 1.0867103 (6535)\ttotal: 44s\tremaining: 56.7s\n",
      "6600:\tlearn: 0.2233553\ttest: 1.0873329\tbest: 1.0865364 (6555)\ttotal: 44.3s\tremaining: 56.4s\n",
      "6650:\tlearn: 0.2199508\ttest: 1.0855308\tbest: 1.0853100 (6637)\ttotal: 44.6s\tremaining: 56s\n",
      "6700:\tlearn: 0.2160667\ttest: 1.0844219\tbest: 1.0843490 (6699)\ttotal: 45s\tremaining: 55.7s\n",
      "6750:\tlearn: 0.2130110\ttest: 1.0848720\tbest: 1.0842356 (6708)\ttotal: 45.3s\tremaining: 55.4s\n",
      "6800:\tlearn: 0.2100148\ttest: 1.0854018\tbest: 1.0842356 (6708)\ttotal: 45.6s\tremaining: 55s\n",
      "6850:\tlearn: 0.2062412\ttest: 1.0839867\tbest: 1.0834432 (6841)\ttotal: 46s\tremaining: 54.7s\n",
      "6900:\tlearn: 0.2030084\ttest: 1.0830265\tbest: 1.0829772 (6895)\ttotal: 46.3s\tremaining: 54.4s\n",
      "6950:\tlearn: 0.1998404\ttest: 1.0826602\tbest: 1.0825340 (6914)\ttotal: 46.7s\tremaining: 54s\n",
      "7000:\tlearn: 0.1967418\ttest: 1.0822960\tbest: 1.0822960 (7000)\ttotal: 47s\tremaining: 53.7s\n",
      "7050:\tlearn: 0.1943387\ttest: 1.0819719\tbest: 1.0813805 (7031)\ttotal: 47.3s\tremaining: 53.4s\n",
      "7100:\tlearn: 0.1916773\ttest: 1.0810322\tbest: 1.0810322 (7100)\ttotal: 47.7s\tremaining: 53s\n",
      "7150:\tlearn: 0.1881073\ttest: 1.0806135\tbest: 1.0805470 (7142)\ttotal: 48s\tremaining: 52.7s\n",
      "7200:\tlearn: 0.1850595\ttest: 1.0803021\tbest: 1.0796440 (7165)\ttotal: 48.3s\tremaining: 52.4s\n",
      "7250:\tlearn: 0.1822383\ttest: 1.0791389\tbest: 1.0791389 (7250)\ttotal: 48.7s\tremaining: 52s\n",
      "7300:\tlearn: 0.1792041\ttest: 1.0794624\tbest: 1.0788132 (7268)\ttotal: 49s\tremaining: 51.7s\n",
      "7350:\tlearn: 0.1763561\ttest: 1.0776808\tbest: 1.0775827 (7349)\ttotal: 49.3s\tremaining: 51.3s\n",
      "7400:\tlearn: 0.1733506\ttest: 1.0775295\tbest: 1.0772659 (7357)\ttotal: 49.7s\tremaining: 51s\n",
      "7450:\tlearn: 0.1709135\ttest: 1.0780731\tbest: 1.0772659 (7357)\ttotal: 50s\tremaining: 50.7s\n",
      "7500:\tlearn: 0.1679143\ttest: 1.0772398\tbest: 1.0772212 (7499)\ttotal: 50.3s\tremaining: 50.3s\n",
      "7550:\tlearn: 0.1654177\ttest: 1.0775321\tbest: 1.0770165 (7512)\ttotal: 50.7s\tremaining: 50s\n",
      "7600:\tlearn: 0.1628499\ttest: 1.0767992\tbest: 1.0767229 (7599)\ttotal: 51s\tremaining: 49.7s\n",
      "7650:\tlearn: 0.1602179\ttest: 1.0762408\tbest: 1.0759581 (7648)\ttotal: 51.3s\tremaining: 49.3s\n",
      "7700:\tlearn: 0.1574505\ttest: 1.0762670\tbest: 1.0759581 (7648)\ttotal: 51.7s\tremaining: 49s\n",
      "7750:\tlearn: 0.1552286\ttest: 1.0751734\tbest: 1.0751734 (7750)\ttotal: 52s\tremaining: 48.7s\n",
      "7800:\tlearn: 0.1528339\ttest: 1.0748614\tbest: 1.0745157 (7773)\ttotal: 52.4s\tremaining: 48.3s\n",
      "7850:\tlearn: 0.1505546\ttest: 1.0745591\tbest: 1.0745157 (7773)\ttotal: 52.8s\tremaining: 48.1s\n",
      "7900:\tlearn: 0.1480282\ttest: 1.0739275\tbest: 1.0737004 (7898)\ttotal: 53.1s\tremaining: 47.7s\n",
      "7950:\tlearn: 0.1455222\ttest: 1.0728260\tbest: 1.0724975 (7929)\ttotal: 53.5s\tremaining: 47.4s\n",
      "8000:\tlearn: 0.1429919\ttest: 1.0721536\tbest: 1.0718951 (7990)\ttotal: 53.8s\tremaining: 47.1s\n",
      "8050:\tlearn: 0.1402640\ttest: 1.0732149\tbest: 1.0718951 (7990)\ttotal: 54.2s\tremaining: 46.7s\n",
      "8100:\tlearn: 0.1379160\ttest: 1.0725113\tbest: 1.0718951 (7990)\ttotal: 54.5s\tremaining: 46.4s\n",
      "8150:\tlearn: 0.1356342\ttest: 1.0713673\tbest: 1.0713673 (8150)\ttotal: 54.8s\tremaining: 46.1s\n",
      "8200:\tlearn: 0.1334556\ttest: 1.0707259\tbest: 1.0707248 (8199)\ttotal: 55.2s\tremaining: 45.7s\n",
      "8250:\tlearn: 0.1312704\ttest: 1.0696351\tbest: 1.0696038 (8248)\ttotal: 55.5s\tremaining: 45.4s\n",
      "8300:\tlearn: 0.1291112\ttest: 1.0698262\tbest: 1.0693993 (8256)\ttotal: 55.8s\tremaining: 45.1s\n",
      "8350:\tlearn: 0.1271624\ttest: 1.0693373\tbest: 1.0690638 (8329)\ttotal: 56.2s\tremaining: 44.7s\n",
      "8400:\tlearn: 0.1250090\ttest: 1.0688561\tbest: 1.0686370 (8381)\ttotal: 56.5s\tremaining: 44.4s\n",
      "8450:\tlearn: 0.1229468\ttest: 1.0682287\tbest: 1.0682287 (8450)\ttotal: 56.8s\tremaining: 44s\n",
      "8500:\tlearn: 0.1208903\ttest: 1.0672853\tbest: 1.0670094 (8484)\ttotal: 57.2s\tremaining: 43.7s\n",
      "8550:\tlearn: 0.1188616\ttest: 1.0664993\tbest: 1.0662828 (8549)\ttotal: 57.5s\tremaining: 43.4s\n",
      "8600:\tlearn: 0.1166665\ttest: 1.0651468\tbest: 1.0651468 (8600)\ttotal: 57.9s\tremaining: 43.1s\n",
      "8650:\tlearn: 0.1148472\ttest: 1.0639859\tbest: 1.0639859 (8650)\ttotal: 58.2s\tremaining: 42.7s\n",
      "8700:\tlearn: 0.1130758\ttest: 1.0634827\tbest: 1.0632917 (8678)\ttotal: 58.5s\tremaining: 42.4s\n",
      "8750:\tlearn: 0.1112010\ttest: 1.0630918\tbest: 1.0628401 (8726)\ttotal: 58.9s\tremaining: 42s\n",
      "8800:\tlearn: 0.1093361\ttest: 1.0632682\tbest: 1.0628401 (8726)\ttotal: 59.2s\tremaining: 41.7s\n",
      "8850:\tlearn: 0.1078475\ttest: 1.0628734\tbest: 1.0626689 (8830)\ttotal: 59.6s\tremaining: 41.4s\n",
      "8900:\tlearn: 0.1060188\ttest: 1.0630527\tbest: 1.0622707 (8872)\ttotal: 59.9s\tremaining: 41s\n",
      "8950:\tlearn: 0.1042887\ttest: 1.0631416\tbest: 1.0622707 (8872)\ttotal: 1m\tremaining: 40.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000:\tlearn: 0.1024055\ttest: 1.0617218\tbest: 1.0614961 (8997)\ttotal: 1m\tremaining: 40.4s\n",
      "9050:\tlearn: 0.1009673\ttest: 1.0629847\tbest: 1.0614961 (8997)\ttotal: 1m\tremaining: 40s\n",
      "9100:\tlearn: 0.0994370\ttest: 1.0623666\tbest: 1.0614961 (8997)\ttotal: 1m 1s\tremaining: 39.7s\n",
      "9150:\tlearn: 0.0977721\ttest: 1.0626099\tbest: 1.0614961 (8997)\ttotal: 1m 1s\tremaining: 39.4s\n",
      "9200:\tlearn: 0.0964466\ttest: 1.0628557\tbest: 1.0614961 (8997)\ttotal: 1m 1s\tremaining: 39s\n",
      "9250:\tlearn: 0.0948020\ttest: 1.0625900\tbest: 1.0614961 (8997)\ttotal: 1m 2s\tremaining: 38.7s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.061496099\n",
      "bestIteration = 8997\n",
      "\n",
      "Shrink model to first 8998 iterations.\n",
      "Скор для фолда(17) : 9.0 средний скор на префиксе = 9.0 это заняло = 63 сек.\n",
      "Фолд: 18\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.6226363\ttest: 3.2512653\tbest: 3.2512653 (0)\ttotal: 27.7ms\tremaining: 6m 54s\n",
      "50:\tlearn: 2.7701160\ttest: 2.4071539\tbest: 2.4071539 (50)\ttotal: 373ms\tremaining: 1m 49s\n",
      "100:\tlearn: 2.2987696\ttest: 1.9511365\tbest: 1.9511365 (100)\ttotal: 707ms\tremaining: 1m 44s\n",
      "150:\tlearn: 2.0351416\ttest: 1.7848057\tbest: 1.7848057 (150)\ttotal: 1.03s\tremaining: 1m 41s\n",
      "200:\tlearn: 1.8641011\ttest: 1.7153617\tbest: 1.7153617 (200)\ttotal: 1.37s\tremaining: 1m 40s\n",
      "250:\tlearn: 1.7567307\ttest: 1.6494796\tbest: 1.6494796 (250)\ttotal: 1.71s\tremaining: 1m 40s\n",
      "300:\tlearn: 1.6697135\ttest: 1.5942493\tbest: 1.5942493 (300)\ttotal: 2.04s\tremaining: 1m 39s\n",
      "350:\tlearn: 1.6047347\ttest: 1.5487943\tbest: 1.5487943 (350)\ttotal: 2.38s\tremaining: 1m 39s\n",
      "400:\tlearn: 1.5481952\ttest: 1.5249346\tbest: 1.5245599 (399)\ttotal: 2.71s\tremaining: 1m 38s\n",
      "450:\tlearn: 1.5018355\ttest: 1.5036618\tbest: 1.5036618 (450)\ttotal: 3.04s\tremaining: 1m 37s\n",
      "500:\tlearn: 1.4679591\ttest: 1.4882933\tbest: 1.4880972 (499)\ttotal: 3.37s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4384435\ttest: 1.4721935\tbest: 1.4721935 (550)\ttotal: 3.7s\tremaining: 1m 37s\n",
      "600:\tlearn: 1.4092403\ttest: 1.4557204\tbest: 1.4557204 (600)\ttotal: 4.03s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3827458\ttest: 1.4412220\tbest: 1.4411947 (649)\ttotal: 4.37s\tremaining: 1m 36s\n",
      "700:\tlearn: 1.3613528\ttest: 1.4309344\tbest: 1.4307778 (699)\ttotal: 4.7s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3403931\ttest: 1.4214094\tbest: 1.4214094 (750)\ttotal: 5.02s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.3185442\ttest: 1.4119827\tbest: 1.4115082 (799)\ttotal: 5.36s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.2989737\ttest: 1.4021517\tbest: 1.4021517 (850)\ttotal: 5.69s\tremaining: 1m 34s\n",
      "900:\tlearn: 1.2794871\ttest: 1.3908121\tbest: 1.3908121 (900)\ttotal: 6.01s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2599375\ttest: 1.3807109\tbest: 1.3803907 (942)\ttotal: 6.35s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2406452\ttest: 1.3729054\tbest: 1.3729054 (1000)\ttotal: 6.68s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2251476\ttest: 1.3685288\tbest: 1.3685175 (1049)\ttotal: 7.01s\tremaining: 1m 33s\n",
      "1100:\tlearn: 1.2067724\ttest: 1.3614431\tbest: 1.3614431 (1100)\ttotal: 7.35s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.1899554\ttest: 1.3577110\tbest: 1.3577110 (1150)\ttotal: 7.68s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1704361\ttest: 1.3509038\tbest: 1.3509038 (1200)\ttotal: 8.01s\tremaining: 1m 31s\n",
      "1250:\tlearn: 1.1549165\ttest: 1.3460268\tbest: 1.3447892 (1244)\ttotal: 8.34s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1359298\ttest: 1.3359611\tbest: 1.3359611 (1300)\ttotal: 8.67s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.1191390\ttest: 1.3267579\tbest: 1.3267237 (1349)\ttotal: 9s\tremaining: 1m 30s\n",
      "1400:\tlearn: 1.1016121\ttest: 1.3198998\tbest: 1.3198097 (1399)\ttotal: 9.34s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.0862708\ttest: 1.3123075\tbest: 1.3123014 (1449)\ttotal: 9.69s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0710625\ttest: 1.3070527\tbest: 1.3070527 (1500)\ttotal: 10s\tremaining: 1m 30s\n",
      "1550:\tlearn: 1.0542641\ttest: 1.3035645\tbest: 1.3031807 (1543)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0370700\ttest: 1.2962130\tbest: 1.2962130 (1600)\ttotal: 10.7s\tremaining: 1m 29s\n",
      "1650:\tlearn: 1.0223312\ttest: 1.2968553\tbest: 1.2957483 (1601)\ttotal: 11s\tremaining: 1m 28s\n",
      "1700:\tlearn: 1.0075140\ttest: 1.2906517\tbest: 1.2902396 (1699)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 0.9912638\ttest: 1.2820399\tbest: 1.2820399 (1750)\ttotal: 11.7s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9760088\ttest: 1.2832426\tbest: 1.2815955 (1760)\ttotal: 12s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9622040\ttest: 1.2804930\tbest: 1.2799896 (1819)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9498859\ttest: 1.2775275\tbest: 1.2774159 (1898)\ttotal: 12.7s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9344445\ttest: 1.2721062\tbest: 1.2718312 (1924)\ttotal: 13s\tremaining: 1m 26s\n",
      "2000:\tlearn: 0.9204235\ttest: 1.2682821\tbest: 1.2682821 (2000)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.9080335\ttest: 1.2625468\tbest: 1.2625468 (2050)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.8935360\ttest: 1.2581464\tbest: 1.2580546 (2097)\ttotal: 14s\tremaining: 1m 25s\n",
      "2150:\tlearn: 0.8814632\ttest: 1.2579601\tbest: 1.2577503 (2147)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8685969\ttest: 1.2547572\tbest: 1.2544140 (2196)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8586504\ttest: 1.2508817\tbest: 1.2500166 (2242)\ttotal: 15s\tremaining: 1m 24s\n",
      "2300:\tlearn: 0.8457389\ttest: 1.2469935\tbest: 1.2469935 (2300)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8349435\ttest: 1.2418247\tbest: 1.2418247 (2350)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8222371\ttest: 1.2377737\tbest: 1.2377258 (2398)\ttotal: 16s\tremaining: 1m 23s\n",
      "2450:\tlearn: 0.8090929\ttest: 1.2306075\tbest: 1.2306075 (2450)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.7982188\ttest: 1.2263534\tbest: 1.2257717 (2494)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7876594\ttest: 1.2214752\tbest: 1.2214752 (2550)\ttotal: 17s\tremaining: 1m 23s\n",
      "2600:\tlearn: 0.7750431\ttest: 1.2180447\tbest: 1.2180447 (2600)\ttotal: 17.4s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7627642\ttest: 1.2162625\tbest: 1.2154018 (2638)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7504582\ttest: 1.2101437\tbest: 1.2100148 (2697)\ttotal: 18s\tremaining: 1m 22s\n",
      "2750:\tlearn: 0.7380492\ttest: 1.2046949\tbest: 1.2043654 (2749)\ttotal: 18.4s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7263493\ttest: 1.1997817\tbest: 1.1997817 (2800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.7155988\ttest: 1.1939227\tbest: 1.1939227 (2850)\ttotal: 19s\tremaining: 1m 21s\n",
      "2900:\tlearn: 0.7042144\ttest: 1.1915334\tbest: 1.1915228 (2899)\ttotal: 19.4s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.6944526\ttest: 1.1864221\tbest: 1.1864221 (2950)\ttotal: 19.7s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.6839416\ttest: 1.1813220\tbest: 1.1813220 (3000)\ttotal: 20s\tremaining: 1m 20s\n",
      "3050:\tlearn: 0.6735371\ttest: 1.1768069\tbest: 1.1764264 (3049)\ttotal: 20.4s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6623540\ttest: 1.1735068\tbest: 1.1734729 (3085)\ttotal: 20.7s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6527006\ttest: 1.1708305\tbest: 1.1707076 (3148)\ttotal: 21.1s\tremaining: 1m 19s\n",
      "3200:\tlearn: 0.6424104\ttest: 1.1671582\tbest: 1.1671582 (3200)\ttotal: 21.4s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6327532\ttest: 1.1657812\tbest: 1.1655322 (3248)\ttotal: 21.7s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6219713\ttest: 1.1609994\tbest: 1.1608828 (3296)\ttotal: 22.1s\tremaining: 1m 18s\n",
      "3350:\tlearn: 0.6110507\ttest: 1.1575675\tbest: 1.1575675 (3350)\ttotal: 22.4s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.6021081\ttest: 1.1521961\tbest: 1.1521961 (3400)\ttotal: 22.7s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.5918564\ttest: 1.1506328\tbest: 1.1506293 (3449)\ttotal: 23.1s\tremaining: 1m 17s\n",
      "3500:\tlearn: 0.5830702\ttest: 1.1474491\tbest: 1.1471964 (3499)\ttotal: 23.4s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5733073\ttest: 1.1433376\tbest: 1.1431568 (3540)\ttotal: 23.7s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5657874\ttest: 1.1422309\tbest: 1.1416124 (3593)\ttotal: 24.1s\tremaining: 1m 16s\n",
      "3650:\tlearn: 0.5592514\ttest: 1.1392361\tbest: 1.1390309 (3640)\ttotal: 24.4s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5506649\ttest: 1.1375662\tbest: 1.1372647 (3698)\ttotal: 24.8s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5429500\ttest: 1.1343226\tbest: 1.1343226 (3750)\ttotal: 25.1s\tremaining: 1m 15s\n",
      "3800:\tlearn: 0.5344949\ttest: 1.1314338\tbest: 1.1310540 (3795)\ttotal: 25.4s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5273692\ttest: 1.1302043\tbest: 1.1297963 (3824)\ttotal: 25.8s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5186429\ttest: 1.1276575\tbest: 1.1274938 (3898)\ttotal: 26.1s\tremaining: 1m 14s\n",
      "3950:\tlearn: 0.5104639\ttest: 1.1241226\tbest: 1.1239500 (3949)\ttotal: 26.4s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.5028308\ttest: 1.1213887\tbest: 1.1213567 (3996)\ttotal: 26.8s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.4957295\ttest: 1.1212294\tbest: 1.1210728 (4004)\ttotal: 27.1s\tremaining: 1m 13s\n",
      "4100:\tlearn: 0.4891765\ttest: 1.1206518\tbest: 1.1198665 (4075)\ttotal: 27.4s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4828192\ttest: 1.1187663\tbest: 1.1186813 (4149)\ttotal: 27.8s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4766611\ttest: 1.1180540\tbest: 1.1178171 (4189)\ttotal: 28.1s\tremaining: 1m 12s\n",
      "4250:\tlearn: 0.4697770\ttest: 1.1176499\tbest: 1.1166809 (4239)\ttotal: 28.5s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4613325\ttest: 1.1157133\tbest: 1.1156046 (4299)\ttotal: 28.8s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4552231\ttest: 1.1139552\tbest: 1.1139552 (4350)\ttotal: 29.1s\tremaining: 1m 11s\n",
      "4400:\tlearn: 0.4491859\ttest: 1.1139658\tbest: 1.1129978 (4377)\ttotal: 29.5s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4450:\tlearn: 0.4428876\ttest: 1.1136551\tbest: 1.1129978 (4377)\ttotal: 29.8s\tremaining: 1m 10s\n",
      "4500:\tlearn: 0.4365678\ttest: 1.1134435\tbest: 1.1127145 (4488)\ttotal: 30.1s\tremaining: 1m 10s\n",
      "4550:\tlearn: 0.4287317\ttest: 1.1123707\tbest: 1.1116823 (4539)\ttotal: 30.5s\tremaining: 1m 9s\n",
      "4600:\tlearn: 0.4210880\ttest: 1.1114388\tbest: 1.1114388 (4600)\ttotal: 30.8s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4149891\ttest: 1.1102022\tbest: 1.1098077 (4641)\ttotal: 31.2s\tremaining: 1m 9s\n",
      "4700:\tlearn: 0.4078046\ttest: 1.1076923\tbest: 1.1074898 (4693)\ttotal: 31.5s\tremaining: 1m 8s\n",
      "4750:\tlearn: 0.4004519\ttest: 1.1045332\tbest: 1.1045332 (4750)\ttotal: 31.8s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.3940221\ttest: 1.1028595\tbest: 1.1028595 (4800)\ttotal: 32.2s\tremaining: 1m 8s\n",
      "4850:\tlearn: 0.3885097\ttest: 1.1017832\tbest: 1.1016565 (4823)\ttotal: 32.5s\tremaining: 1m 8s\n",
      "4900:\tlearn: 0.3820128\ttest: 1.0992914\tbest: 1.0992317 (4894)\ttotal: 32.8s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3768590\ttest: 1.0988065\tbest: 1.0987361 (4946)\ttotal: 33.2s\tremaining: 1m 7s\n",
      "5000:\tlearn: 0.3723706\ttest: 1.0987545\tbest: 1.0985579 (4995)\ttotal: 33.5s\tremaining: 1m 7s\n",
      "5050:\tlearn: 0.3666292\ttest: 1.0977537\tbest: 1.0968675 (5034)\ttotal: 33.9s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3608036\ttest: 1.0953381\tbest: 1.0952939 (5097)\ttotal: 34.2s\tremaining: 1m 6s\n",
      "5150:\tlearn: 0.3552622\ttest: 1.0949079\tbest: 1.0946415 (5144)\ttotal: 34.5s\tremaining: 1m 5s\n",
      "5200:\tlearn: 0.3498804\ttest: 1.0942879\tbest: 1.0942879 (5200)\ttotal: 34.9s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3452007\ttest: 1.0926074\tbest: 1.0924686 (5246)\ttotal: 35.2s\tremaining: 1m 5s\n",
      "5300:\tlearn: 0.3393408\ttest: 1.0933318\tbest: 1.0921926 (5273)\ttotal: 35.5s\tremaining: 1m 4s\n",
      "5350:\tlearn: 0.3345010\ttest: 1.0915097\tbest: 1.0914435 (5344)\ttotal: 35.9s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3292378\ttest: 1.0912158\tbest: 1.0904730 (5388)\ttotal: 36.2s\tremaining: 1m 4s\n",
      "5450:\tlearn: 0.3241596\ttest: 1.0904084\tbest: 1.0901467 (5428)\ttotal: 36.5s\tremaining: 1m 3s\n",
      "5500:\tlearn: 0.3188578\ttest: 1.0900696\tbest: 1.0898030 (5483)\ttotal: 36.9s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3139015\ttest: 1.0897340\tbest: 1.0894822 (5547)\ttotal: 37.2s\tremaining: 1m 3s\n",
      "5600:\tlearn: 0.3083675\ttest: 1.0899941\tbest: 1.0894822 (5547)\ttotal: 37.5s\tremaining: 1m 3s\n",
      "5650:\tlearn: 0.3032486\ttest: 1.0896438\tbest: 1.0894735 (5646)\ttotal: 37.9s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.2988117\ttest: 1.0893308\tbest: 1.0887750 (5674)\ttotal: 38.2s\tremaining: 1m 2s\n",
      "5750:\tlearn: 0.2934294\ttest: 1.0892837\tbest: 1.0878984 (5732)\ttotal: 38.5s\tremaining: 1m 2s\n",
      "5800:\tlearn: 0.2890087\ttest: 1.0900127\tbest: 1.0878984 (5732)\ttotal: 38.9s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2842854\ttest: 1.0898413\tbest: 1.0878984 (5732)\ttotal: 39.2s\tremaining: 1m 1s\n",
      "5900:\tlearn: 0.2796952\ttest: 1.0890162\tbest: 1.0878984 (5732)\ttotal: 39.6s\tremaining: 1m 1s\n",
      "5950:\tlearn: 0.2750425\ttest: 1.0894685\tbest: 1.0878984 (5732)\ttotal: 39.9s\tremaining: 1m\n",
      "6000:\tlearn: 0.2706111\ttest: 1.0895999\tbest: 1.0878984 (5732)\ttotal: 40.2s\tremaining: 1m\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 1.087898376\n",
      "bestIteration = 5732\n",
      "\n",
      "Shrink model to first 5733 iterations.\n",
      "Скор для фолда(18) : 9.0 средний скор на префиксе = 9.0 это заняло = 40 сек.\n",
      "Фолд: 19\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "0:\tlearn: 3.6010025\ttest: 3.5506341\tbest: 3.5506341 (0)\ttotal: 46ms\tremaining: 11m 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 2.7352762\ttest: 2.5671417\tbest: 2.5671417 (50)\ttotal: 374ms\tremaining: 1m 49s\n",
      "100:\tlearn: 2.2787922\ttest: 2.1113562\tbest: 2.1113562 (100)\ttotal: 702ms\tremaining: 1m 43s\n",
      "150:\tlearn: 2.0229346\ttest: 1.8864193\tbest: 1.8864193 (150)\ttotal: 1.04s\tremaining: 1m 42s\n",
      "200:\tlearn: 1.8627342\ttest: 1.7428976\tbest: 1.7428976 (200)\ttotal: 1.37s\tremaining: 1m 40s\n",
      "250:\tlearn: 1.7548526\ttest: 1.6149316\tbest: 1.6149316 (250)\ttotal: 1.7s\tremaining: 1m 40s\n",
      "300:\tlearn: 1.6694342\ttest: 1.5477663\tbest: 1.5477663 (300)\ttotal: 2.05s\tremaining: 1m 39s\n",
      "350:\tlearn: 1.6049778\ttest: 1.4972588\tbest: 1.4972588 (350)\ttotal: 2.38s\tremaining: 1m 39s\n",
      "400:\tlearn: 1.5517578\ttest: 1.4530110\tbest: 1.4530110 (400)\ttotal: 2.71s\tremaining: 1m 38s\n",
      "450:\tlearn: 1.5089822\ttest: 1.4264345\tbest: 1.4264345 (450)\ttotal: 3.04s\tremaining: 1m 38s\n",
      "500:\tlearn: 1.4696372\ttest: 1.4025201\tbest: 1.4025201 (500)\ttotal: 3.37s\tremaining: 1m 37s\n",
      "550:\tlearn: 1.4377610\ttest: 1.3797218\tbest: 1.3794091 (549)\ttotal: 3.7s\tremaining: 1m 37s\n",
      "600:\tlearn: 1.4096970\ttest: 1.3638972\tbest: 1.3638972 (600)\ttotal: 4.04s\tremaining: 1m 36s\n",
      "650:\tlearn: 1.3847156\ttest: 1.3451235\tbest: 1.3451235 (650)\ttotal: 4.37s\tremaining: 1m 36s\n",
      "700:\tlearn: 1.3629157\ttest: 1.3320521\tbest: 1.3320521 (700)\ttotal: 4.7s\tremaining: 1m 35s\n",
      "750:\tlearn: 1.3437249\ttest: 1.3268219\tbest: 1.3243135 (747)\ttotal: 5.03s\tremaining: 1m 35s\n",
      "800:\tlearn: 1.3228825\ttest: 1.3098221\tbest: 1.3098221 (800)\ttotal: 5.36s\tremaining: 1m 34s\n",
      "850:\tlearn: 1.3056933\ttest: 1.2981082\tbest: 1.2980800 (847)\ttotal: 5.68s\tremaining: 1m 34s\n",
      "900:\tlearn: 1.2854242\ttest: 1.2899133\tbest: 1.2887837 (894)\ttotal: 6.02s\tremaining: 1m 34s\n",
      "950:\tlearn: 1.2660074\ttest: 1.2797090\tbest: 1.2796704 (949)\ttotal: 6.34s\tremaining: 1m 33s\n",
      "1000:\tlearn: 1.2493991\ttest: 1.2787694\tbest: 1.2770915 (987)\ttotal: 6.67s\tremaining: 1m 33s\n",
      "1050:\tlearn: 1.2338043\ttest: 1.2805364\tbest: 1.2770915 (987)\ttotal: 7.01s\tremaining: 1m 33s\n",
      "1100:\tlearn: 1.2151944\ttest: 1.2784731\tbest: 1.2770915 (987)\ttotal: 7.33s\tremaining: 1m 32s\n",
      "1150:\tlearn: 1.1968737\ttest: 1.2732034\tbest: 1.2732034 (1150)\ttotal: 7.66s\tremaining: 1m 32s\n",
      "1200:\tlearn: 1.1805423\ttest: 1.2730088\tbest: 1.2688332 (1193)\ttotal: 8s\tremaining: 1m 31s\n",
      "1250:\tlearn: 1.1610270\ttest: 1.2584836\tbest: 1.2584836 (1250)\ttotal: 8.32s\tremaining: 1m 31s\n",
      "1300:\tlearn: 1.1462632\ttest: 1.2499863\tbest: 1.2499783 (1299)\ttotal: 8.66s\tremaining: 1m 31s\n",
      "1350:\tlearn: 1.1285399\ttest: 1.2404537\tbest: 1.2401832 (1347)\ttotal: 9s\tremaining: 1m 30s\n",
      "1400:\tlearn: 1.1105471\ttest: 1.2343891\tbest: 1.2343891 (1400)\ttotal: 9.33s\tremaining: 1m 30s\n",
      "1450:\tlearn: 1.0931031\ttest: 1.2328298\tbest: 1.2328298 (1450)\ttotal: 9.66s\tremaining: 1m 30s\n",
      "1500:\tlearn: 1.0765807\ttest: 1.2321980\tbest: 1.2298265 (1499)\ttotal: 9.99s\tremaining: 1m 29s\n",
      "1550:\tlearn: 1.0623171\ttest: 1.2289834\tbest: 1.2272675 (1537)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "1600:\tlearn: 1.0470580\ttest: 1.2260348\tbest: 1.2255574 (1591)\ttotal: 10.6s\tremaining: 1m 29s\n",
      "1650:\tlearn: 1.0336996\ttest: 1.2212712\tbest: 1.2208279 (1646)\ttotal: 11s\tremaining: 1m 28s\n",
      "1700:\tlearn: 1.0190410\ttest: 1.2176279\tbest: 1.2176279 (1700)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1750:\tlearn: 1.0059158\ttest: 1.2121388\tbest: 1.2121388 (1750)\ttotal: 11.6s\tremaining: 1m 28s\n",
      "1800:\tlearn: 0.9888679\ttest: 1.2079027\tbest: 1.2078957 (1799)\ttotal: 12s\tremaining: 1m 27s\n",
      "1850:\tlearn: 0.9747141\ttest: 1.2024987\tbest: 1.2024304 (1848)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1900:\tlearn: 0.9582006\ttest: 1.1949261\tbest: 1.1949261 (1900)\ttotal: 12.6s\tremaining: 1m 27s\n",
      "1950:\tlearn: 0.9439782\ttest: 1.1928411\tbest: 1.1924999 (1936)\ttotal: 13s\tremaining: 1m 26s\n",
      "2000:\tlearn: 0.9309080\ttest: 1.1904644\tbest: 1.1898542 (1997)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "2050:\tlearn: 0.9165686\ttest: 1.1865784\tbest: 1.1855963 (2046)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "2100:\tlearn: 0.9055731\ttest: 1.1858221\tbest: 1.1855963 (2046)\ttotal: 14s\tremaining: 1m 25s\n",
      "2150:\tlearn: 0.8930201\ttest: 1.1799325\tbest: 1.1798055 (2149)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "2200:\tlearn: 0.8806505\ttest: 1.1767568\tbest: 1.1767568 (2200)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "2250:\tlearn: 0.8673968\ttest: 1.1736892\tbest: 1.1736892 (2250)\ttotal: 15s\tremaining: 1m 24s\n",
      "2300:\tlearn: 0.8566227\ttest: 1.1665339\tbest: 1.1660775 (2294)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "2350:\tlearn: 0.8443031\ttest: 1.1642155\tbest: 1.1642155 (2350)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "2400:\tlearn: 0.8314166\ttest: 1.1580164\tbest: 1.1578908 (2399)\ttotal: 16s\tremaining: 1m 23s\n",
      "2450:\tlearn: 0.8210029\ttest: 1.1529755\tbest: 1.1529755 (2450)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "2500:\tlearn: 0.8073343\ttest: 1.1481309\tbest: 1.1481309 (2500)\ttotal: 16.6s\tremaining: 1m 23s\n",
      "2550:\tlearn: 0.7934317\ttest: 1.1409298\tbest: 1.1409298 (2550)\ttotal: 16.9s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.7815301\ttest: 1.1361701\tbest: 1.1361701 (2600)\ttotal: 17.3s\tremaining: 1m 22s\n",
      "2650:\tlearn: 0.7702199\ttest: 1.1304342\tbest: 1.1303253 (2648)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.7597901\ttest: 1.1238304\tbest: 1.1237743 (2696)\ttotal: 18s\tremaining: 1m 21s\n",
      "2750:\tlearn: 0.7482203\ttest: 1.1187109\tbest: 1.1187109 (2750)\ttotal: 18.3s\tremaining: 1m 21s\n",
      "2800:\tlearn: 0.7376004\ttest: 1.1154681\tbest: 1.1153022 (2786)\ttotal: 18.6s\tremaining: 1m 21s\n",
      "2850:\tlearn: 0.7258981\ttest: 1.1157296\tbest: 1.1150041 (2804)\ttotal: 19s\tremaining: 1m 20s\n",
      "2900:\tlearn: 0.7134274\ttest: 1.1133695\tbest: 1.1133695 (2900)\ttotal: 19.3s\tremaining: 1m 20s\n",
      "2950:\tlearn: 0.7040497\ttest: 1.1062448\tbest: 1.1062448 (2950)\ttotal: 19.6s\tremaining: 1m 20s\n",
      "3000:\tlearn: 0.6947771\ttest: 1.1051341\tbest: 1.1044024 (2970)\ttotal: 20s\tremaining: 1m 19s\n",
      "3050:\tlearn: 0.6847351\ttest: 1.1032774\tbest: 1.1021326 (3044)\ttotal: 20.3s\tremaining: 1m 19s\n",
      "3100:\tlearn: 0.6748664\ttest: 1.0993534\tbest: 1.0988173 (3097)\ttotal: 20.6s\tremaining: 1m 19s\n",
      "3150:\tlearn: 0.6638403\ttest: 1.0965327\tbest: 1.0964309 (3149)\ttotal: 21s\tremaining: 1m 18s\n",
      "3200:\tlearn: 0.6530555\ttest: 1.0906645\tbest: 1.0906645 (3200)\ttotal: 21.3s\tremaining: 1m 18s\n",
      "3250:\tlearn: 0.6429739\ttest: 1.0874292\tbest: 1.0866296 (3247)\ttotal: 21.6s\tremaining: 1m 18s\n",
      "3300:\tlearn: 0.6329878\ttest: 1.0840955\tbest: 1.0840955 (3300)\ttotal: 22s\tremaining: 1m 17s\n",
      "3350:\tlearn: 0.6224631\ttest: 1.0791521\tbest: 1.0791521 (3350)\ttotal: 22.3s\tremaining: 1m 17s\n",
      "3400:\tlearn: 0.6127467\ttest: 1.0752865\tbest: 1.0750059 (3394)\ttotal: 22.6s\tremaining: 1m 17s\n",
      "3450:\tlearn: 0.6039479\ttest: 1.0713269\tbest: 1.0703078 (3444)\ttotal: 23s\tremaining: 1m 16s\n",
      "3500:\tlearn: 0.5952796\ttest: 1.0679488\tbest: 1.0679488 (3500)\ttotal: 23.3s\tremaining: 1m 16s\n",
      "3550:\tlearn: 0.5856169\ttest: 1.0634856\tbest: 1.0634856 (3550)\ttotal: 23.6s\tremaining: 1m 16s\n",
      "3600:\tlearn: 0.5760362\ttest: 1.0589226\tbest: 1.0585055 (3590)\ttotal: 24s\tremaining: 1m 15s\n",
      "3650:\tlearn: 0.5667773\ttest: 1.0563016\tbest: 1.0563016 (3650)\ttotal: 24.3s\tremaining: 1m 15s\n",
      "3700:\tlearn: 0.5557429\ttest: 1.0541759\tbest: 1.0540725 (3699)\ttotal: 24.6s\tremaining: 1m 15s\n",
      "3750:\tlearn: 0.5464248\ttest: 1.0509047\tbest: 1.0509047 (3750)\ttotal: 25s\tremaining: 1m 14s\n",
      "3800:\tlearn: 0.5381562\ttest: 1.0469686\tbest: 1.0468001 (3798)\ttotal: 25.3s\tremaining: 1m 14s\n",
      "3850:\tlearn: 0.5296707\ttest: 1.0451989\tbest: 1.0446717 (3846)\ttotal: 25.6s\tremaining: 1m 14s\n",
      "3900:\tlearn: 0.5211294\ttest: 1.0410571\tbest: 1.0407364 (3887)\ttotal: 25.9s\tremaining: 1m 13s\n",
      "3950:\tlearn: 0.5130205\ttest: 1.0397053\tbest: 1.0395291 (3943)\ttotal: 26.3s\tremaining: 1m 13s\n",
      "4000:\tlearn: 0.5048406\ttest: 1.0390243\tbest: 1.0383968 (3985)\ttotal: 26.6s\tremaining: 1m 13s\n",
      "4050:\tlearn: 0.4967994\ttest: 1.0352856\tbest: 1.0347231 (4048)\ttotal: 26.9s\tremaining: 1m 12s\n",
      "4100:\tlearn: 0.4888217\ttest: 1.0322446\tbest: 1.0322421 (4099)\ttotal: 27.3s\tremaining: 1m 12s\n",
      "4150:\tlearn: 0.4813402\ttest: 1.0312484\tbest: 1.0302901 (4122)\ttotal: 27.6s\tremaining: 1m 12s\n",
      "4200:\tlearn: 0.4729408\ttest: 1.0285565\tbest: 1.0285565 (4200)\ttotal: 27.9s\tremaining: 1m 11s\n",
      "4250:\tlearn: 0.4648355\ttest: 1.0258644\tbest: 1.0258155 (4248)\ttotal: 28.3s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.4574863\ttest: 1.0213287\tbest: 1.0212996 (4296)\ttotal: 28.6s\tremaining: 1m 11s\n",
      "4350:\tlearn: 0.4508870\ttest: 1.0213998\tbest: 1.0204837 (4341)\ttotal: 28.9s\tremaining: 1m 10s\n",
      "4400:\tlearn: 0.4437417\ttest: 1.0226143\tbest: 1.0204837 (4341)\ttotal: 29.3s\tremaining: 1m 10s\n",
      "4450:\tlearn: 0.4367430\ttest: 1.0183775\tbest: 1.0182872 (4446)\ttotal: 29.6s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500:\tlearn: 0.4311398\ttest: 1.0178743\tbest: 1.0174173 (4495)\ttotal: 30s\tremaining: 1m 9s\n",
      "4550:\tlearn: 0.4235883\ttest: 1.0170152\tbest: 1.0169787 (4549)\ttotal: 30.3s\tremaining: 1m 9s\n",
      "4600:\tlearn: 0.4171337\ttest: 1.0157339\tbest: 1.0157339 (4600)\ttotal: 30.6s\tremaining: 1m 9s\n",
      "4650:\tlearn: 0.4107953\ttest: 1.0137717\tbest: 1.0137717 (4650)\ttotal: 31s\tremaining: 1m 8s\n",
      "4700:\tlearn: 0.4047021\ttest: 1.0109747\tbest: 1.0109747 (4700)\ttotal: 31.3s\tremaining: 1m 8s\n",
      "4750:\tlearn: 0.3983622\ttest: 1.0084846\tbest: 1.0084846 (4750)\ttotal: 31.6s\tremaining: 1m 8s\n",
      "4800:\tlearn: 0.3921534\ttest: 1.0078243\tbest: 1.0077275 (4797)\ttotal: 31.9s\tremaining: 1m 7s\n",
      "4850:\tlearn: 0.3851365\ttest: 1.0058759\tbest: 1.0058095 (4849)\ttotal: 32.3s\tremaining: 1m 7s\n",
      "4900:\tlearn: 0.3785457\ttest: 1.0035504\tbest: 1.0032622 (4889)\ttotal: 32.6s\tremaining: 1m 7s\n",
      "4950:\tlearn: 0.3728824\ttest: 1.0037866\tbest: 1.0032622 (4889)\ttotal: 32.9s\tremaining: 1m 6s\n",
      "5000:\tlearn: 0.3665324\ttest: 1.0031675\tbest: 1.0024041 (4979)\ttotal: 33.3s\tremaining: 1m 6s\n",
      "5050:\tlearn: 0.3605419\ttest: 1.0019378\tbest: 1.0014934 (5027)\ttotal: 33.6s\tremaining: 1m 6s\n",
      "5100:\tlearn: 0.3551425\ttest: 1.0004062\tbest: 1.0004062 (5100)\ttotal: 33.9s\tremaining: 1m 5s\n",
      "5150:\tlearn: 0.3497508\ttest: 0.9997074\tbest: 0.9994954 (5148)\ttotal: 34.3s\tremaining: 1m 5s\n",
      "5200:\tlearn: 0.3436897\ttest: 0.9993968\tbest: 0.9986717 (5185)\ttotal: 34.6s\tremaining: 1m 5s\n",
      "5250:\tlearn: 0.3381453\ttest: 0.9970476\tbest: 0.9968188 (5248)\ttotal: 35s\tremaining: 1m 4s\n",
      "5300:\tlearn: 0.3324224\ttest: 0.9936190\tbest: 0.9936190 (5300)\ttotal: 35.3s\tremaining: 1m 4s\n",
      "5350:\tlearn: 0.3276044\ttest: 0.9917325\tbest: 0.9916567 (5349)\ttotal: 35.6s\tremaining: 1m 4s\n",
      "5400:\tlearn: 0.3219959\ttest: 0.9859852\tbest: 0.9859852 (5400)\ttotal: 36s\tremaining: 1m 3s\n",
      "5450:\tlearn: 0.3178010\ttest: 0.9845284\tbest: 0.9845248 (5449)\ttotal: 36.3s\tremaining: 1m 3s\n",
      "5500:\tlearn: 0.3128555\ttest: 0.9826352\tbest: 0.9823339 (5484)\ttotal: 36.6s\tremaining: 1m 3s\n",
      "5550:\tlearn: 0.3075211\ttest: 0.9798885\tbest: 0.9798885 (5550)\ttotal: 37s\tremaining: 1m 2s\n",
      "5600:\tlearn: 0.3024026\ttest: 0.9786474\tbest: 0.9786474 (5600)\ttotal: 37.3s\tremaining: 1m 2s\n",
      "5650:\tlearn: 0.2982278\ttest: 0.9757309\tbest: 0.9757099 (5648)\ttotal: 37.6s\tremaining: 1m 2s\n",
      "5700:\tlearn: 0.2940121\ttest: 0.9719132\tbest: 0.9719132 (5700)\ttotal: 38s\tremaining: 1m 1s\n",
      "5750:\tlearn: 0.2896297\ttest: 0.9701637\tbest: 0.9699311 (5747)\ttotal: 38.3s\tremaining: 1m 1s\n",
      "5800:\tlearn: 0.2853709\ttest: 0.9691650\tbest: 0.9681831 (5777)\ttotal: 38.7s\tremaining: 1m 1s\n",
      "5850:\tlearn: 0.2809995\ttest: 0.9662561\tbest: 0.9658494 (5844)\ttotal: 39s\tremaining: 1m\n",
      "5900:\tlearn: 0.2769285\ttest: 0.9653168\tbest: 0.9652732 (5899)\ttotal: 39.3s\tremaining: 1m\n",
      "5950:\tlearn: 0.2723432\ttest: 0.9647391\tbest: 0.9647266 (5938)\ttotal: 39.7s\tremaining: 1m\n",
      "6000:\tlearn: 0.2683138\ttest: 0.9623751\tbest: 0.9622705 (5993)\ttotal: 40s\tremaining: 60s\n",
      "6050:\tlearn: 0.2637270\ttest: 0.9606772\tbest: 0.9606772 (6050)\ttotal: 40.3s\tremaining: 59.7s\n",
      "6100:\tlearn: 0.2591963\ttest: 0.9594317\tbest: 0.9592890 (6095)\ttotal: 40.7s\tremaining: 59.3s\n",
      "6150:\tlearn: 0.2546919\ttest: 0.9563204\tbest: 0.9562974 (6149)\ttotal: 41s\tremaining: 59s\n",
      "6200:\tlearn: 0.2505268\ttest: 0.9544581\tbest: 0.9544458 (6199)\ttotal: 41.4s\tremaining: 58.7s\n",
      "6250:\tlearn: 0.2458677\ttest: 0.9540987\tbest: 0.9537516 (6241)\ttotal: 41.7s\tremaining: 58.3s\n",
      "6300:\tlearn: 0.2420330\ttest: 0.9528842\tbest: 0.9528842 (6300)\ttotal: 42s\tremaining: 58s\n",
      "6350:\tlearn: 0.2385711\ttest: 0.9521578\tbest: 0.9514460 (6331)\ttotal: 42.4s\tremaining: 57.7s\n",
      "6400:\tlearn: 0.2345072\ttest: 0.9525779\tbest: 0.9514460 (6331)\ttotal: 42.7s\tremaining: 57.3s\n",
      "6450:\tlearn: 0.2303438\ttest: 0.9497493\tbest: 0.9496797 (6449)\ttotal: 43s\tremaining: 57s\n",
      "6500:\tlearn: 0.2264639\ttest: 0.9475219\tbest: 0.9475219 (6500)\ttotal: 43.4s\tremaining: 56.7s\n",
      "6550:\tlearn: 0.2227670\ttest: 0.9460914\tbest: 0.9460914 (6550)\ttotal: 43.7s\tremaining: 56.3s\n",
      "6600:\tlearn: 0.2192801\ttest: 0.9463363\tbest: 0.9459681 (6590)\ttotal: 44s\tremaining: 56s\n",
      "6650:\tlearn: 0.2158724\ttest: 0.9456701\tbest: 0.9450754 (6643)\ttotal: 44.4s\tremaining: 55.7s\n",
      "6700:\tlearn: 0.2123980\ttest: 0.9446677\tbest: 0.9446383 (6699)\ttotal: 44.7s\tremaining: 55.4s\n",
      "6750:\tlearn: 0.2087182\ttest: 0.9428490\tbest: 0.9427732 (6747)\ttotal: 45s\tremaining: 55s\n",
      "6800:\tlearn: 0.2054269\ttest: 0.9420310\tbest: 0.9420310 (6800)\ttotal: 45.4s\tremaining: 54.7s\n",
      "6850:\tlearn: 0.2026329\ttest: 0.9410757\tbest: 0.9410200 (6833)\ttotal: 45.7s\tremaining: 54.4s\n",
      "6900:\tlearn: 0.1993099\ttest: 0.9392952\tbest: 0.9392330 (6891)\ttotal: 46s\tremaining: 54s\n",
      "6950:\tlearn: 0.1960854\ttest: 0.9388691\tbest: 0.9385359 (6912)\ttotal: 46.4s\tremaining: 53.7s\n",
      "7000:\tlearn: 0.1932000\ttest: 0.9381062\tbest: 0.9381033 (6999)\ttotal: 46.7s\tremaining: 53.4s\n",
      "7050:\tlearn: 0.1902765\ttest: 0.9379964\tbest: 0.9379964 (7050)\ttotal: 47s\tremaining: 53s\n",
      "7100:\tlearn: 0.1872533\ttest: 0.9370516\tbest: 0.9369376 (7097)\ttotal: 47.4s\tremaining: 52.7s\n",
      "7150:\tlearn: 0.1844231\ttest: 0.9350578\tbest: 0.9350542 (7149)\ttotal: 47.7s\tremaining: 52.4s\n",
      "7200:\tlearn: 0.1815296\ttest: 0.9350451\tbest: 0.9347946 (7183)\ttotal: 48.1s\tremaining: 52s\n",
      "7250:\tlearn: 0.1788450\ttest: 0.9341288\tbest: 0.9341288 (7250)\ttotal: 48.4s\tremaining: 51.7s\n",
      "7300:\tlearn: 0.1760944\ttest: 0.9332996\tbest: 0.9331040 (7279)\ttotal: 48.7s\tremaining: 51.4s\n",
      "7350:\tlearn: 0.1734791\ttest: 0.9333736\tbest: 0.9328121 (7308)\ttotal: 49.1s\tremaining: 51.1s\n",
      "7400:\tlearn: 0.1706302\ttest: 0.9320985\tbest: 0.9320474 (7397)\ttotal: 49.4s\tremaining: 50.7s\n",
      "7450:\tlearn: 0.1679144\ttest: 0.9309738\tbest: 0.9303961 (7432)\ttotal: 49.7s\tremaining: 50.4s\n",
      "7500:\tlearn: 0.1653123\ttest: 0.9313492\tbest: 0.9303961 (7432)\ttotal: 50.1s\tremaining: 50.1s\n",
      "7550:\tlearn: 0.1625243\ttest: 0.9309791\tbest: 0.9303961 (7432)\ttotal: 50.4s\tremaining: 49.7s\n",
      "7600:\tlearn: 0.1597230\ttest: 0.9294917\tbest: 0.9294917 (7600)\ttotal: 50.8s\tremaining: 49.4s\n",
      "7650:\tlearn: 0.1567283\ttest: 0.9274278\tbest: 0.9272883 (7629)\ttotal: 51.1s\tremaining: 49.1s\n",
      "7700:\tlearn: 0.1540938\ttest: 0.9270381\tbest: 0.9270381 (7700)\ttotal: 51.4s\tremaining: 48.7s\n",
      "7750:\tlearn: 0.1518181\ttest: 0.9259862\tbest: 0.9256059 (7728)\ttotal: 51.8s\tremaining: 48.4s\n",
      "7800:\tlearn: 0.1492294\ttest: 0.9252928\tbest: 0.9252928 (7800)\ttotal: 52.1s\tremaining: 48.1s\n",
      "7850:\tlearn: 0.1469563\ttest: 0.9245204\tbest: 0.9245204 (7850)\ttotal: 52.5s\tremaining: 47.8s\n",
      "7900:\tlearn: 0.1447252\ttest: 0.9237328\tbest: 0.9233182 (7889)\ttotal: 52.8s\tremaining: 47.4s\n",
      "7950:\tlearn: 0.1424090\ttest: 0.9234684\tbest: 0.9232703 (7948)\ttotal: 53.1s\tremaining: 47.1s\n",
      "8000:\tlearn: 0.1399263\ttest: 0.9232642\tbest: 0.9229195 (7992)\ttotal: 53.5s\tremaining: 46.8s\n",
      "8050:\tlearn: 0.1377603\ttest: 0.9225169\tbest: 0.9222545 (8047)\ttotal: 53.8s\tremaining: 46.5s\n",
      "8100:\tlearn: 0.1355966\ttest: 0.9214770\tbest: 0.9214624 (8099)\ttotal: 54.2s\tremaining: 46.1s\n",
      "8150:\tlearn: 0.1333371\ttest: 0.9210951\tbest: 0.9206259 (8141)\ttotal: 54.5s\tremaining: 45.8s\n",
      "8200:\tlearn: 0.1310378\ttest: 0.9202604\tbest: 0.9199968 (8196)\ttotal: 54.8s\tremaining: 45.5s\n",
      "8250:\tlearn: 0.1286719\ttest: 0.9190566\tbest: 0.9190356 (8249)\ttotal: 55.2s\tremaining: 45.1s\n",
      "8300:\tlearn: 0.1268433\ttest: 0.9185450\tbest: 0.9178912 (8271)\ttotal: 55.5s\tremaining: 44.8s\n",
      "8350:\tlearn: 0.1249832\ttest: 0.9181998\tbest: 0.9178464 (8328)\ttotal: 55.8s\tremaining: 44.5s\n",
      "8400:\tlearn: 0.1228728\ttest: 0.9174753\tbest: 0.9170307 (8388)\ttotal: 56.2s\tremaining: 44.1s\n",
      "8450:\tlearn: 0.1210279\ttest: 0.9177445\tbest: 0.9170307 (8388)\ttotal: 56.5s\tremaining: 43.8s\n",
      "8500:\tlearn: 0.1191260\ttest: 0.9177165\tbest: 0.9170307 (8388)\ttotal: 56.8s\tremaining: 43.5s\n",
      "8550:\tlearn: 0.1173770\ttest: 0.9163804\tbest: 0.9163804 (8550)\ttotal: 57.2s\tremaining: 43.1s\n",
      "8600:\tlearn: 0.1155114\ttest: 0.9164082\tbest: 0.9160325 (8571)\ttotal: 57.5s\tremaining: 42.8s\n",
      "8650:\tlearn: 0.1136707\ttest: 0.9162794\tbest: 0.9160325 (8571)\ttotal: 57.9s\tremaining: 42.5s\n",
      "8700:\tlearn: 0.1121876\ttest: 0.9160247\tbest: 0.9159966 (8697)\ttotal: 58.2s\tremaining: 42.1s\n",
      "8750:\tlearn: 0.1105241\ttest: 0.9148712\tbest: 0.9148712 (8750)\ttotal: 58.5s\tremaining: 41.8s\n",
      "8800:\tlearn: 0.1089127\ttest: 0.9149997\tbest: 0.9142180 (8761)\ttotal: 58.9s\tremaining: 41.5s\n",
      "8850:\tlearn: 0.1072726\ttest: 0.9139150\tbest: 0.9135831 (8843)\ttotal: 59.2s\tremaining: 41.1s\n",
      "8900:\tlearn: 0.1055055\ttest: 0.9132034\tbest: 0.9130781 (8890)\ttotal: 59.5s\tremaining: 40.8s\n",
      "8950:\tlearn: 0.1037354\ttest: 0.9131707\tbest: 0.9130781 (8890)\ttotal: 59.9s\tremaining: 40.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000:\tlearn: 0.1022891\ttest: 0.9126410\tbest: 0.9126188 (8992)\ttotal: 1m\tremaining: 40.1s\n",
      "9050:\tlearn: 0.1006868\ttest: 0.9131400\tbest: 0.9118745 (9022)\ttotal: 1m\tremaining: 39.8s\n",
      "9100:\tlearn: 0.0990179\ttest: 0.9127250\tbest: 0.9118745 (9022)\ttotal: 1m\tremaining: 39.5s\n",
      "9150:\tlearn: 0.0973472\ttest: 0.9122094\tbest: 0.9118745 (9022)\ttotal: 1m 1s\tremaining: 39.1s\n",
      "9200:\tlearn: 0.0957610\ttest: 0.9108152\tbest: 0.9108152 (9200)\ttotal: 1m 1s\tremaining: 38.8s\n",
      "9250:\tlearn: 0.0943379\ttest: 0.9114388\tbest: 0.9105874 (9214)\ttotal: 1m 1s\tremaining: 38.5s\n",
      "9300:\tlearn: 0.0930154\ttest: 0.9107344\tbest: 0.9105725 (9295)\ttotal: 1m 2s\tremaining: 38.1s\n",
      "9350:\tlearn: 0.0912766\ttest: 0.9103224\tbest: 0.9102588 (9347)\ttotal: 1m 2s\tremaining: 37.8s\n",
      "9400:\tlearn: 0.0897928\ttest: 0.9098641\tbest: 0.9096248 (9394)\ttotal: 1m 2s\tremaining: 37.5s\n",
      "9450:\tlearn: 0.0880381\ttest: 0.9092286\tbest: 0.9090008 (9443)\ttotal: 1m 3s\tremaining: 37.1s\n",
      "9500:\tlearn: 0.0864351\ttest: 0.9080325\tbest: 0.9079264 (9492)\ttotal: 1m 3s\tremaining: 36.8s\n",
      "9550:\tlearn: 0.0850740\ttest: 0.9072998\tbest: 0.9072998 (9550)\ttotal: 1m 3s\tremaining: 36.5s\n",
      "9600:\tlearn: 0.0834791\ttest: 0.9069582\tbest: 0.9068079 (9592)\ttotal: 1m 4s\tremaining: 36.1s\n",
      "9650:\tlearn: 0.0819567\ttest: 0.9073757\tbest: 0.9067494 (9629)\ttotal: 1m 4s\tremaining: 35.8s\n",
      "9700:\tlearn: 0.0807688\ttest: 0.9065613\tbest: 0.9062066 (9685)\ttotal: 1m 4s\tremaining: 35.5s\n",
      "9750:\tlearn: 0.0793308\ttest: 0.9069421\tbest: 0.9062066 (9685)\ttotal: 1m 5s\tremaining: 35.1s\n",
      "9800:\tlearn: 0.0779755\ttest: 0.9075587\tbest: 0.9062066 (9685)\ttotal: 1m 5s\tremaining: 34.8s\n",
      "9850:\tlearn: 0.0767361\ttest: 0.9068840\tbest: 0.9062066 (9685)\ttotal: 1m 5s\tremaining: 34.5s\n",
      "9900:\tlearn: 0.0755501\ttest: 0.9063672\tbest: 0.9062066 (9685)\ttotal: 1m 6s\tremaining: 34.1s\n",
      "9950:\tlearn: 0.0741958\ttest: 0.9064256\tbest: 0.9058648 (9911)\ttotal: 1m 6s\tremaining: 33.8s\n",
      "10000:\tlearn: 0.0731283\ttest: 0.9062754\tbest: 0.9058648 (9911)\ttotal: 1m 6s\tremaining: 33.5s\n",
      "10050:\tlearn: 0.0718587\ttest: 0.9066373\tbest: 0.9058648 (9911)\ttotal: 1m 7s\tremaining: 33.1s\n",
      "10100:\tlearn: 0.0706995\ttest: 0.9060459\tbest: 0.9058648 (9911)\ttotal: 1m 7s\tremaining: 32.8s\n",
      "10150:\tlearn: 0.0695469\ttest: 0.9064768\tbest: 0.9057737 (10123)\ttotal: 1m 7s\tremaining: 32.4s\n",
      "10200:\tlearn: 0.0685167\ttest: 0.9063590\tbest: 0.9057737 (10123)\ttotal: 1m 8s\tremaining: 32.1s\n",
      "10250:\tlearn: 0.0676066\ttest: 0.9068259\tbest: 0.9057737 (10123)\ttotal: 1m 8s\tremaining: 31.8s\n",
      "10300:\tlearn: 0.0666787\ttest: 0.9067478\tbest: 0.9057737 (10123)\ttotal: 1m 8s\tremaining: 31.5s\n",
      "10350:\tlearn: 0.0657732\ttest: 0.9063245\tbest: 0.9057737 (10123)\ttotal: 1m 9s\tremaining: 31.1s\n",
      "10400:\tlearn: 0.0647484\ttest: 0.9060939\tbest: 0.9057737 (10123)\ttotal: 1m 9s\tremaining: 30.8s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.9057737318\n",
      "bestIteration = 10123\n",
      "\n",
      "Shrink model to first 10124 iterations.\n",
      "Скор для фолда(19) : 9.0 средний скор на префиксе = 9.0 это заняло = 70 сек.\n",
      "Процесс обучения модели занял = 1127 секунд\n"
     ]
    }
   ],
   "source": [
    "class CatBoostEvalMetricPearson(object):\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        preds = np.array(approxes[0])\n",
    "        target = np.array(target)\n",
    "        err = deviation_metric(np.exp(target), np.exp(preds))\n",
    "        return err, 0\n",
    "\n",
    "\n",
    "def train_cat(train, valid, num_features, categorical_features, target_train, target_valid, EPOCHS):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    test_data = Pool(data=test[num_features + categorical_features],\n",
    "                  cat_features=categorical_features)\n",
    "\n",
    "\n",
    "    train_data = Pool(data=train[num_features + categorical_features],\n",
    "                      cat_features=categorical_features,\n",
    "                      label=np.log(target_train))\n",
    "\n",
    "    val_data = Pool(data=valid[num_features + categorical_features],\n",
    "                cat_features=categorical_features,\n",
    "                  label=np.log(target_valid))\n",
    "    \n",
    "\n",
    "    cat_model = CatBoostRegressor(\n",
    "        learning_rate=0.012,\n",
    "        iterations=15000,\n",
    "        metric_period=50,\n",
    "        eval_metric=CatBoostEvalMetricPearson(),\n",
    "    )\n",
    "    cat_model.fit(train_data, eval_set=val_data, use_best_model=True, early_stopping_rounds=300)\n",
    "  \n",
    "    y_valid = cat_model.predict(test_data)\n",
    "\n",
    "    return cat_model, y_valid\n",
    "\n",
    "\n",
    "start_train_model_time = time.time()\n",
    "\n",
    "scores = []\n",
    "cat_predicts = np.zeros(len(train))\n",
    "\n",
    "cat_models = []\n",
    "for fold_num, (train_indexes, valid_indexes) in enumerate(split_list):\n",
    "    start_time = time.time()\n",
    "    print(f\"Фолд: {fold_num}\")\n",
    "\n",
    "    train_sub_df = train[features_columns_order].loc[train_indexes].reset_index(drop=True)\n",
    "    valid_sub_df = train[features_columns_order].loc[valid_indexes].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Размер трейна = {train_sub_df.shape} Размер валидации = {valid_sub_df.shape}\")\n",
    "    model, predict_validation = train_cat(\n",
    "        train_sub_df,\n",
    "        valid_sub_df,\n",
    "        NUM_FEATURES_COLUMNS,\n",
    "        CATEGORICAL_FEATURES_COLUMNS,\n",
    "        train_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        valid_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        EPOCHS\n",
    "        )\n",
    "\n",
    "    cat_models += [model]\n",
    "    predict_on_validation = model.predict(valid_sub_df[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS])\n",
    "    cat_predicts[valid_indexes] = np.exp(predict_on_validation)\n",
    "    targets_for_validation = valid_sub_df[TARGET_COLUMNS].values[:, 0]\n",
    "    current_score = deviation_metric(targets_for_validation, predict_on_validation)\n",
    "    scores += [current_score]\n",
    "    print(\n",
    "        f\"Скор для фолда({fold_num}) : {np.round(current_score, 4)} средний скор на префиксе = {np.round(np.mean(scores), 4)} это заняло = {int(time.time() - start_time)} сек.\")\n",
    "print(f\"Процесс обучения модели занял = {int(time.time() - start_train_model_time)} секунд\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "443ee697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17326.68044258941, 1274188.5949374526, 61582.147919846844)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Предикт xgb на test\n",
    "def get_cat_predict(models, test):\n",
    "    result = np.zeros(len(test))\n",
    "    for model in cat_models:\n",
    "        predict = model.predict(test[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS])\n",
    "        result += np.exp(predict) / len(models)\n",
    "    return result\n",
    "\n",
    "\n",
    "test_cat_predict = get_cat_predict(xgb_models, test)\n",
    "\n",
    "test_cat_predict.min(), test_cat_predict.max(), test_cat_predict.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7398d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2476c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e514dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.070112\n",
      "         Iterations: 14\n",
      "         Function evaluations: 100\n",
      "         Gradient evaluations: 20\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d8f6d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00820521, -0.30958003,  0.99053633,  0.22868203])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_spb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95af4932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.001246\n",
      "         Iterations: 12\n",
      "         Function evaluations: 80\n",
      "         Gradient evaluations: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.07274949, 0.06529732, 0.48726262, 0.28138078])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minimize_arit(W):\n",
    "    ypred = W[0] * nn_predicts + W[1] * lgb_predicts + W[2] * xgb_predicts + W[3] * cat_predicts\n",
    "    return deviation_metric(train_targets, ypred)\n",
    "\n",
    "\n",
    "W = minimize(minimize_arit, [1.0 / 4] * 4, options={'gtol': 1e-6, 'disp': True}).x\n",
    "# 1.018536\n",
    "W "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94f4f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_submission = pd.read_csv('dataset/test_submission.csv')\n",
    "test_submission['per_square_meter_price'] = test_nn_predict * W[0] + test_lgb_predict * W[1] + test_xgb_predict * W[2] + test_cat_predict * W[3]\n",
    "test_submission['per_square_meter_price'] = test_submission['per_square_meter_price'].apply(lambda x: max(1000.0, x))\n",
    "test_submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94f261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f19682",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predicts_spb = xgb_predicts[train.city == 0]\n",
    "cat_predicts_spb = cat_predicts[train.city == 0]\n",
    "nn_predicts_spb = nn_predicts[train.city == 0]\n",
    "lgb_predicts_spb = lgb_predicts[train.city == 0]\n",
    "train_targets_spb = train_targets[train.city == 0]\n",
    "\n",
    "test_nn_predict_spb = test_nn_predict[test.city == 0]\n",
    "test_lgb_predict_spb = test_lgb_predict[test.city == 0]\n",
    "test_xgb_predict_spb = test_xgb_predict[test.city == 0]\n",
    "test_cat_predict_spb = test_cat_predict[test.city == 0]\n",
    "\n",
    "def minimize_arit_spb(W):\n",
    "    ypred = W[0] * nn_predicts_spb + W[1] * lgb_predicts_spb + W[2] * xgb_predicts_spb + W[3] * cat_predicts_spb\n",
    "    return deviation_metric(train_targets_spb, ypred)\n",
    "\n",
    "\n",
    "W_spb = minimize(minimize_arit_spb, [1.0 / 4] * 4, options={'gtol': 1e-6, 'disp': True}).x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83dc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission.loc[test.city == 0, 'per_square_meter_price'] = test_nn_predict_spb * W[0] + test_lgb_predict_spb * W[1] + test_xgb_predict_spb * W[2] + test_cat_predict_spb * W[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec16e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission.to_csv('submission_cities.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
