{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a140480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_GPU = False\n",
    "# Импорт нужных библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from neighbors import Neighborhoods\n",
    "\n",
    "from indices import MainDataset\n",
    "from dnn_utils import preprocess_floor\n",
    "from metric import metrics_stat, deviation_metric\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import Pool\n",
    "\n",
    "def reset_tensorflow_session():\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(41)\n",
    "    np.random.seed(41)\n",
    "\n",
    "\n",
    "THRESHOLD = 0.15\n",
    "NEGATIVE_WEIGHT = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73007644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Категориальные данные\n",
    "CATEGORICAL_FEATURES_COLUMNS = ['region', 'city', 'realty_type', 'floor', 'osm_city_nearest_name', 'street']\n",
    "# Численные данные\n",
    "NUM_FEATURES_COLUMNS = ['lat', 'lng', 'osm_amenity_points_in_0.001',\n",
    "                        'osm_amenity_points_in_0.005', 'osm_amenity_points_in_0.0075',\n",
    "                        'osm_amenity_points_in_0.01', 'osm_building_points_in_0.001',\n",
    "                        'osm_building_points_in_0.005', 'osm_building_points_in_0.0075',\n",
    "                        'osm_building_points_in_0.01', 'osm_catering_points_in_0.001',\n",
    "                        'osm_catering_points_in_0.005', 'osm_catering_points_in_0.0075',\n",
    "                        'osm_catering_points_in_0.01', 'osm_city_closest_dist',\n",
    "                        'osm_city_nearest_population',\n",
    "                        'osm_crossing_closest_dist', 'osm_crossing_points_in_0.001',\n",
    "                        'osm_crossing_points_in_0.005', 'osm_crossing_points_in_0.0075',\n",
    "                        'osm_crossing_points_in_0.01', 'osm_culture_points_in_0.001',\n",
    "                        'osm_culture_points_in_0.005', 'osm_culture_points_in_0.0075',\n",
    "                        'osm_culture_points_in_0.01', 'osm_finance_points_in_0.001',\n",
    "                        'osm_finance_points_in_0.005', 'osm_finance_points_in_0.0075',\n",
    "                        'osm_finance_points_in_0.01', 'osm_healthcare_points_in_0.005',\n",
    "                        'osm_healthcare_points_in_0.0075', 'osm_healthcare_points_in_0.01',\n",
    "                        'osm_historic_points_in_0.005', 'osm_historic_points_in_0.0075',\n",
    "                        'osm_historic_points_in_0.01', 'osm_hotels_points_in_0.005',\n",
    "                        'osm_hotels_points_in_0.0075', 'osm_hotels_points_in_0.01',\n",
    "                        'osm_leisure_points_in_0.005', 'osm_leisure_points_in_0.0075',\n",
    "                        'osm_leisure_points_in_0.01', 'osm_offices_points_in_0.001',\n",
    "                        'osm_offices_points_in_0.005', 'osm_offices_points_in_0.0075',\n",
    "                        'osm_offices_points_in_0.01', 'osm_shops_points_in_0.001',\n",
    "                        'osm_shops_points_in_0.005', 'osm_shops_points_in_0.0075',\n",
    "                        'osm_shops_points_in_0.01', 'osm_subway_closest_dist',\n",
    "                        'osm_train_stop_closest_dist', 'osm_train_stop_points_in_0.005',\n",
    "                        'osm_train_stop_points_in_0.0075', 'osm_train_stop_points_in_0.01',\n",
    "                        'osm_transport_stop_closest_dist', 'osm_transport_stop_points_in_0.005',\n",
    "                        'osm_transport_stop_points_in_0.0075',\n",
    "                        'osm_transport_stop_points_in_0.01',\n",
    "                        'reform_count_of_houses_1000', 'reform_count_of_houses_500',\n",
    "                        'reform_house_population_1000', 'reform_house_population_500',\n",
    "                        'reform_mean_floor_count_1000', 'reform_mean_floor_count_500',\n",
    "                        'reform_mean_year_building_1000', 'reform_mean_year_building_500', 'total_square',\n",
    "                        \"neighbor_dist\", \"neighbor_total_price\", \"neighbor_square_price\", \"neighbor10_dist\",\n",
    "                        \"has_basement\", \"floor_count\"\n",
    "\n",
    "                        ]\n",
    "# Таргет\n",
    "TARGET_COLUMNS = ['per_square_meter_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a970f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "train = train[train.price_type == 1].reset_index(drop=True)\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "dataset = pd.concat([train, test]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d49f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_index = MainDataset(\"dataset/train.csv\")\n",
    "test_dataset_index = MainDataset(\"dataset/test.csv\", need_index=False)\n",
    "neighborhoods = Neighborhoods(train_dataset_index.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a61ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"neighbor_dist\"] = -999\n",
    "dataset[\"neighbor_total_price\"] = -999\n",
    "dataset[\"neighbor_square_price\"] = -999\n",
    "dataset[\"neighbor10_dist\"] = -999\n",
    "for d in [test_dataset_index, train_dataset_index]:\n",
    "    for i, o in enumerate(d.all_objects):\n",
    "        if o.row[\"price_type\"] != 1:\n",
    "            continue\n",
    "        neighbor = neighborhoods.get_haversine_closest(o, 12)\n",
    "        neighbor1 = neighborhoods.get_haversine_closest(o, 2)\n",
    "        n = neighbor[0]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor_dist\"] = n[1]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor_total_price\"] = n[0].row[\"per_square_meter_price\"] * \\\n",
    "                                                                            n[0].row[\"total_square\"]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor_square_price\"] = n[0].row[\"per_square_meter_price\"]\n",
    "        dataset.loc[dataset[\"id\"] == o.row[\"id\"], \"neighbor10_dist\"] = neighbor[10][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b660cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset=preprocess_floor.preprocess(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58922f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        dict_encoding = {key: val for val, key in enumerate(df[column].unique())}\n",
    "        df[column] = df[column].map(dict_encoding)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d58f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = encode_categorical_features(dataset, CATEGORICAL_FEATURES_COLUMNS)\n",
    "data = data.fillna(data.mean())\n",
    "train = data[data.is_train == 1].reset_index(drop=True)\n",
    "test = data[data.is_train == 0].reset_index(drop=True)\n",
    "train = train.drop(columns=['is_train'])\n",
    "test = test.drop(columns=['is_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e665cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standart_split(data, n_splits=5, seed=41):\n",
    "    kf = KFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
    "    split_list = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        split_list += [(train_index, test_index)]\n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f22ad8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_order(columns):\n",
    "    columns_order = sorted([x for x in columns if not x in (CATEGORICAL_FEATURES_COLUMNS + TARGET_COLUMNS)])\n",
    "    return columns_order + CATEGORICAL_FEATURES_COLUMNS + TARGET_COLUMNS\n",
    "\n",
    "features_columns_order = get_columns_order(train.columns.values.tolist())\n",
    "\n",
    "split_list = get_standart_split(train, n_splits=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa189b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фолд: 0\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.28829\n",
      "[500]\tvalid-deviation_error:1.19579\n",
      "[750]\tvalid-deviation_error:1.12317\n",
      "[1000]\tvalid-deviation_error:1.07731\n",
      "[1250]\tvalid-deviation_error:1.06419\n",
      "[1500]\tvalid-deviation_error:1.04849\n",
      "[1750]\tvalid-deviation_error:1.04006\n",
      "[2000]\tvalid-deviation_error:1.03421\n",
      "[2250]\tvalid-deviation_error:1.03343\n",
      "[2500]\tvalid-deviation_error:1.02683\n",
      "[2750]\tvalid-deviation_error:1.02551\n",
      "[3000]\tvalid-deviation_error:1.02438\n",
      "[3250]\tvalid-deviation_error:1.02447\n",
      "[3500]\tvalid-deviation_error:1.02396\n",
      "[3585]\tvalid-deviation_error:1.02439\n",
      "Скор для фолда(0) : 9.0 средний скор на префиксе = 9.0 это заняло = 26 сек.\n",
      "Фолд: 1\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.41481\n",
      "[500]\tvalid-deviation_error:1.05535\n",
      "[750]\tvalid-deviation_error:1.02482\n",
      "[1000]\tvalid-deviation_error:1.01718\n",
      "[1250]\tvalid-deviation_error:1.00933\n",
      "[1500]\tvalid-deviation_error:1.00255\n",
      "[1750]\tvalid-deviation_error:1.00591\n",
      "[1975]\tvalid-deviation_error:1.00672\n",
      "Скор для фолда(1) : 9.0 средний скор на префиксе = 9.0 это заняло = 16 сек.\n",
      "Фолд: 2\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.36425\n",
      "[500]\tvalid-deviation_error:0.88875\n",
      "[750]\tvalid-deviation_error:0.88950\n",
      "[1000]\tvalid-deviation_error:0.89475\n",
      "[1056]\tvalid-deviation_error:0.88989\n",
      "Скор для фолда(2) : 9.0 средний скор на префиксе = 9.0 это заняло = 8 сек.\n",
      "Фолд: 3\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.23607\n",
      "[500]\tvalid-deviation_error:1.04250\n",
      "[750]\tvalid-deviation_error:1.01849\n",
      "[1000]\tvalid-deviation_error:1.01107\n",
      "[1250]\tvalid-deviation_error:1.01185\n",
      "[1405]\tvalid-deviation_error:1.01564\n",
      "Скор для фолда(3) : 9.0 средний скор на префиксе = 9.0 это заняло = 11 сек.\n",
      "Фолд: 4\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.26386\n",
      "[500]\tvalid-deviation_error:1.06613\n",
      "[750]\tvalid-deviation_error:1.04096\n",
      "[1000]\tvalid-deviation_error:1.04149\n",
      "[1250]\tvalid-deviation_error:1.04171\n",
      "[1276]\tvalid-deviation_error:1.04154\n",
      "Скор для фолда(4) : 9.0 средний скор на префиксе = 9.0 это заняло = 9 сек.\n",
      "Фолд: 5\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.51457\n",
      "[500]\tvalid-deviation_error:1.34478\n",
      "[750]\tvalid-deviation_error:1.29223\n",
      "[1000]\tvalid-deviation_error:1.27548\n",
      "[1250]\tvalid-deviation_error:1.26920\n",
      "[1500]\tvalid-deviation_error:1.26581\n",
      "[1750]\tvalid-deviation_error:1.26466\n",
      "[2000]\tvalid-deviation_error:1.26524\n",
      "[2250]\tvalid-deviation_error:1.26427\n",
      "[2500]\tvalid-deviation_error:1.26719\n",
      "[2716]\tvalid-deviation_error:1.26690\n",
      "Скор для фолда(5) : 9.0 средний скор на префиксе = 9.0 это заняло = 23 сек.\n",
      "Фолд: 6\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.25718\n",
      "[500]\tvalid-deviation_error:1.07972\n",
      "[750]\tvalid-deviation_error:1.03424\n",
      "[1000]\tvalid-deviation_error:1.00824\n",
      "[1250]\tvalid-deviation_error:1.01266\n",
      "[1500]\tvalid-deviation_error:1.01774\n",
      "[1617]\tvalid-deviation_error:1.02202\n",
      "Скор для фолда(6) : 9.0 средний скор на префиксе = 9.0 это заняло = 13 сек.\n",
      "Фолд: 7\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.04266\n",
      "[500]\tvalid-deviation_error:1.06064\n",
      "[750]\tvalid-deviation_error:1.01302\n",
      "[1000]\tvalid-deviation_error:0.99735\n",
      "[1250]\tvalid-deviation_error:0.98857\n",
      "[1500]\tvalid-deviation_error:0.98941\n",
      "[1750]\tvalid-deviation_error:0.99239\n",
      "[1938]\tvalid-deviation_error:0.98856\n",
      "Скор для фолда(7) : 9.0 средний скор на префиксе = 9.0 это заняло = 14 сек.\n",
      "Фолд: 8\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.10622\n",
      "[500]\tvalid-deviation_error:0.84713\n",
      "[750]\tvalid-deviation_error:0.84028\n",
      "[1000]\tvalid-deviation_error:0.83726\n",
      "[1250]\tvalid-deviation_error:0.84501\n",
      "[1500]\tvalid-deviation_error:0.84667\n",
      "[1555]\tvalid-deviation_error:0.84806\n",
      "Скор для фолда(8) : 9.0 средний скор на префиксе = 9.0 это заняло = 10 сек.\n",
      "Фолд: 9\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.35295\n",
      "[500]\tvalid-deviation_error:1.09388\n",
      "[750]\tvalid-deviation_error:1.07121\n",
      "[1000]\tvalid-deviation_error:1.07974\n",
      "[1250]\tvalid-deviation_error:1.07575\n",
      "[1313]\tvalid-deviation_error:1.07692\n",
      "Скор для фолда(9) : 9.0 средний скор на префиксе = 9.0 это заняло = 9 сек.\n",
      "Фолд: 10\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.13668\n",
      "[500]\tvalid-deviation_error:0.97795\n",
      "[750]\tvalid-deviation_error:0.97648\n",
      "[1000]\tvalid-deviation_error:0.97805\n",
      "[1250]\tvalid-deviation_error:0.96593\n",
      "[1500]\tvalid-deviation_error:0.95787\n",
      "[1750]\tvalid-deviation_error:0.96612\n",
      "[1880]\tvalid-deviation_error:0.96309\n",
      "Скор для фолда(10) : 9.0 средний скор на префиксе = 9.0 это заняло = 14 сек.\n",
      "Фолд: 11\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.07016\n",
      "[500]\tvalid-deviation_error:1.28944\n",
      "[750]\tvalid-deviation_error:1.24713\n",
      "[1000]\tvalid-deviation_error:1.22631\n",
      "[1250]\tvalid-deviation_error:1.21333\n",
      "[1500]\tvalid-deviation_error:1.20897\n",
      "[1750]\tvalid-deviation_error:1.21233\n",
      "[1976]\tvalid-deviation_error:1.21084\n",
      "Скор для фолда(11) : 9.0 средний скор на префиксе = 9.0 это заняло = 13 сек.\n",
      "Фолд: 12\n",
      "Размер трейна = (4268, 83) Размер валидации = (225, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.18505\n",
      "[500]\tvalid-deviation_error:1.13062\n",
      "[750]\tvalid-deviation_error:1.09563\n",
      "[1000]\tvalid-deviation_error:1.07920\n",
      "[1250]\tvalid-deviation_error:1.07336\n",
      "[1500]\tvalid-deviation_error:1.06999\n",
      "[1750]\tvalid-deviation_error:1.07461\n",
      "[1992]\tvalid-deviation_error:1.07778\n",
      "Скор для фолда(12) : 9.0 средний скор на префиксе = 9.0 это заняло = 13 сек.\n",
      "Фолд: 13\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.37783\n",
      "[500]\tvalid-deviation_error:1.14885\n",
      "[750]\tvalid-deviation_error:1.09966\n",
      "[1000]\tvalid-deviation_error:1.07614\n",
      "[1250]\tvalid-deviation_error:1.06497\n",
      "[1500]\tvalid-deviation_error:1.06388\n",
      "[1750]\tvalid-deviation_error:1.05682\n",
      "[2000]\tvalid-deviation_error:1.05830\n",
      "[2250]\tvalid-deviation_error:1.05492\n",
      "[2500]\tvalid-deviation_error:1.06073\n",
      "[2709]\tvalid-deviation_error:1.06201\n",
      "Скор для фолда(13) : 9.0 средний скор на префиксе = 9.0 это заняло = 18 сек.\n",
      "Фолд: 14\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.25962\n",
      "[500]\tvalid-deviation_error:0.96898\n",
      "[750]\tvalid-deviation_error:0.95005\n",
      "[1000]\tvalid-deviation_error:0.92848\n",
      "[1250]\tvalid-deviation_error:0.91144\n",
      "[1500]\tvalid-deviation_error:0.89971\n",
      "[1750]\tvalid-deviation_error:0.89209\n",
      "[2000]\tvalid-deviation_error:0.88905\n",
      "[2250]\tvalid-deviation_error:0.88743\n",
      "[2500]\tvalid-deviation_error:0.88283\n",
      "[2750]\tvalid-deviation_error:0.88301\n",
      "[3000]\tvalid-deviation_error:0.88170\n",
      "[3250]\tvalid-deviation_error:0.88051\n",
      "[3500]\tvalid-deviation_error:0.87992\n",
      "[3750]\tvalid-deviation_error:0.88028\n",
      "[3901]\tvalid-deviation_error:0.88085\n",
      "Скор для фолда(14) : 9.0 средний скор на префиксе = 9.0 это заняло = 29 сек.\n",
      "Фолд: 15\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.30173\n",
      "[500]\tvalid-deviation_error:1.29690\n",
      "[750]\tvalid-deviation_error:1.19325\n",
      "[1000]\tvalid-deviation_error:1.14227\n",
      "[1250]\tvalid-deviation_error:1.11699\n",
      "[1500]\tvalid-deviation_error:1.10276\n",
      "[1750]\tvalid-deviation_error:1.10068\n",
      "[2000]\tvalid-deviation_error:1.10300\n",
      "[2250]\tvalid-deviation_error:1.10004\n",
      "[2500]\tvalid-deviation_error:1.10361\n",
      "[2713]\tvalid-deviation_error:1.10216\n",
      "Скор для фолда(15) : 9.0 средний скор на префиксе = 9.0 это заняло = 20 сек.\n",
      "Фолд: 16\n",
      "Размер трейна = (4269, 83) Размер валидации = (224, 83)\n",
      "[0]\tvalid-deviation_error:9.00000\n",
      "[250]\tvalid-deviation_error:4.56543\n",
      "[500]\tvalid-deviation_error:1.27255\n",
      "[750]\tvalid-deviation_error:1.22632\n",
      "[1000]\tvalid-deviation_error:1.21671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1250]\tvalid-deviation_error:1.21239\n"
     ]
    }
   ],
   "source": [
    "def xbg_error(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    err = deviation_metric(np.exp(labels), np.exp(preds)/1.1)\n",
    "    return 'deviation_error', err\n",
    "\n",
    "\n",
    "def train_xgb(train, valid, num_features, categorical_features, target_train, target_valid, EPOCHS, params):\n",
    "    dtest = xgb.DMatrix(test[num_features + categorical_features])\n",
    "    y_valid = np.zeros(len(valid))\n",
    "\n",
    "    dtrain = xgb.DMatrix(train[num_features + categorical_features], np.log(target_train), \n",
    "                        )\n",
    "    dvalid = xgb.DMatrix(valid[num_features + categorical_features], np.log(target_valid), \n",
    "                        )\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        EPOCHS,\n",
    "        [(dvalid, \"valid\")],\n",
    "        verbose_eval=250,\n",
    "        early_stopping_rounds=500,\n",
    "        feval=xbg_error,\n",
    "    )\n",
    "    y_valid = model.predict(dvalid)\n",
    "\n",
    "    return model, y_valid\n",
    "\n",
    "\n",
    "start_train_model_time = time.time()\n",
    "\n",
    "xgboost_seed = 41\n",
    "xgboost_params = {\n",
    "    \"subsample\": 0.70,\n",
    "    \"colsample_bytree\": 0.50,\n",
    "    \"max_depth\": 7,\n",
    "    \"learning_rate\": 0.012,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'disable_default_eval_metric': 1,\n",
    "    \"nthread\": -1,\n",
    "    \"max_bin\": 128,\n",
    "    'min_child_weight': 0.0,\n",
    "    'reg_lambda': 0.0,\n",
    "    'reg_alpha': 0.0,\n",
    "    'seed': xgboost_seed,\n",
    "}\n",
    "\n",
    "\n",
    "EPOCHS = 10000\n",
    "scores = []\n",
    "xgb_predicts = np.zeros(len(train))\n",
    "\n",
    "xgb_models = []\n",
    "for fold_num, (train_indexes, valid_indexes) in enumerate(split_list):\n",
    "    start_time = time.time()\n",
    "    print(f\"Фолд: {fold_num}\")\n",
    "\n",
    "    train_sub_df = train[features_columns_order].loc[train_indexes].reset_index(drop=True)\n",
    "    valid_sub_df = train[features_columns_order].loc[valid_indexes].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Размер трейна = {train_sub_df.shape} Размер валидации = {valid_sub_df.shape}\")\n",
    "    # Обучаем Xgboost и делаем предикт на валидационной выборке\n",
    "    model, predict_validation = train_xgb(\n",
    "        train_sub_df,\n",
    "        valid_sub_df,\n",
    "        NUM_FEATURES_COLUMNS,\n",
    "        CATEGORICAL_FEATURES_COLUMNS,\n",
    "        train_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        valid_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        EPOCHS,\n",
    "        xgboost_params)\n",
    "\n",
    "    xgb_models += [model]\n",
    "    predict_on_validation = model.predict(\n",
    "        xgb.DMatrix(valid_sub_df[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS]))\n",
    "    xgb_predicts[valid_indexes] = np.exp(predict_on_validation)\n",
    "    targets_for_validation = valid_sub_df[TARGET_COLUMNS].values[:, 0]\n",
    "    current_score = deviation_metric(targets_for_validation, predict_on_validation)\n",
    "    scores += [current_score]\n",
    "    print(\n",
    "        f\"Скор для фолда({fold_num}) : {np.round(current_score, 4)} средний скор на префиксе = {np.round(np.mean(scores), 4)} это заняло = {int(time.time() - start_time)} сек.\")\n",
    "print(f\"Процесс обучения модели занял = {int(time.time() - start_train_model_time)} секунд\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b0cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предикт xgb на test\n",
    "def get_xgb_predict(models, test):\n",
    "    result = np.zeros(len(test))\n",
    "    for model in models:\n",
    "        predict = model.predict(xgb.DMatrix(test[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS]))\n",
    "        result += predict / len(models)\n",
    "    return result\n",
    "\n",
    "test_xgb_predict = get_xgb_predict(xgb_models, test)\n",
    "\n",
    "test_xgb_predict=np.exp(test_xgb_predict)\n",
    "\n",
    "test_xgb_predict.min(), test_xgb_predict.max(), test_xgb_predict.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ba129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ca116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBoostEvalMetricPearson(object):\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        preds = np.array(approxes[0])\n",
    "        target = np.array(target)\n",
    "        err = deviation_metric(np.exp(target), np.exp(preds)/1.1)\n",
    "        return err, 0\n",
    "\n",
    "\n",
    "def train_cat(train, valid, num_features, categorical_features, target_train, target_valid, EPOCHS):\n",
    "\n",
    "    test_data = Pool(data=test[num_features + categorical_features],\n",
    "                  cat_features=categorical_features)\n",
    "\n",
    "\n",
    "    train_data = Pool(data=train[num_features + categorical_features],\n",
    "                      cat_features=categorical_features,\n",
    "                      label=np.log(target_train))\n",
    "\n",
    "    val_data = Pool(data=valid[num_features + categorical_features],\n",
    "                cat_features=categorical_features,\n",
    "                  label=np.log(target_valid))\n",
    "\n",
    "    cat_model = CatBoostRegressor(\n",
    "        l2_leaf_reg=5,\n",
    "        bagging_temperature=1.2,\n",
    "        random_strength=1.1,\n",
    "        learning_rate=0.012,\n",
    "        iterations=10000,\n",
    "        metric_period=50,\n",
    "        eval_metric=CatBoostEvalMetricPearson(),\n",
    "    )\n",
    "    cat_model.fit(train_data, eval_set=val_data, use_best_model=True, early_stopping_rounds=300)\n",
    "  \n",
    "    y_valid = cat_model.predict(test_data)\n",
    "\n",
    "    return cat_model, y_valid\n",
    "\n",
    "\n",
    "start_train_model_time = time.time()\n",
    "\n",
    "scores = []\n",
    "cat_predicts = np.zeros(len(train))\n",
    "\n",
    "cat_models = []\n",
    "for fold_num, (train_indexes, valid_indexes) in enumerate(split_list):\n",
    "    start_time = time.time()\n",
    "    print(f\"Фолд: {fold_num}\")\n",
    "\n",
    "    train_sub_df = train[features_columns_order].loc[train_indexes].reset_index(drop=True)\n",
    "    valid_sub_df = train[features_columns_order].loc[valid_indexes].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Размер трейна = {train_sub_df.shape} Размер валидации = {valid_sub_df.shape}\")\n",
    "    model, predict_validation = train_cat(\n",
    "        train_sub_df,\n",
    "        valid_sub_df,\n",
    "        NUM_FEATURES_COLUMNS,\n",
    "        CATEGORICAL_FEATURES_COLUMNS,\n",
    "        train_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        valid_sub_df[TARGET_COLUMNS[0]].values,\n",
    "        EPOCHS\n",
    "        )\n",
    "\n",
    "    cat_models += [model]\n",
    "    predict_on_validation = model.predict(valid_sub_df[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS])\n",
    "    cat_predicts[valid_indexes] = np.exp(predict_on_validation)\n",
    "    targets_for_validation = valid_sub_df[TARGET_COLUMNS].values[:, 0]\n",
    "    current_score = deviation_metric(targets_for_validation, predict_on_validation)\n",
    "    scores += [current_score]\n",
    "    print(\n",
    "        f\"Скор для фолда({fold_num}) : {np.round(current_score, 4)} средний скор на префиксе = {np.round(np.mean(scores), 4)} это заняло = {int(time.time() - start_time)} сек.\")\n",
    "print(f\"Процесс обучения модели занял = {int(time.time() - start_train_model_time)} секунд\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_cat_predict(models, test):\n",
    "    result = np.zeros(len(test))\n",
    "    for model in cat_models:\n",
    "        predict = model.predict(test[NUM_FEATURES_COLUMNS + CATEGORICAL_FEATURES_COLUMNS])\n",
    "        result += np.exp(predict) / len(models)\n",
    "    return result\n",
    "\n",
    "\n",
    "test_cat_predict = get_cat_predict(xgb_models, test)\n",
    "\n",
    "test_cat_predict.min(), test_cat_predict.max(), test_cat_predict.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0b0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a0516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4016a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = train[TARGET_COLUMNS[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82315547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_arit(W):\n",
    "    ypred =  W[0] * xgb_predicts + W[1] * cat_predicts\n",
    "    return deviation_metric(train_targets, ypred)\n",
    "\n",
    "\n",
    "W = minimize(minimize_arit, [1.0 / 2] * 2, options={'gtol': 1e-6, 'disp': True}).x\n",
    "W\n",
    "# 1.006250\n",
    "# array([0.55692824, 0.34630855])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_submission = pd.read_csv('dataset/test_submission.csv')\n",
    "test_submission['per_square_meter_price'] = test_xgb_predict * W[0] + test_cat_predict * W[1]\n",
    "test_submission['per_square_meter_price'] = test_submission['per_square_meter_price'].apply(lambda x: max(1000.0, x))\n",
    "test_submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4e599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "344c167b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.990203\n",
      "         Iterations: 10\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 12\n",
      "[ 0.9809335  -0.07784708]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.675573\n",
      "         Iterations: 9\n",
      "         Function evaluations: 33\n",
      "         Gradient evaluations: 11\n",
      "[0.7116518  0.16042453]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.561361\n",
      "         Iterations: 8\n",
      "         Function evaluations: 30\n",
      "         Gradient evaluations: 10\n",
      "[0.53635383 0.35041296]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.857445\n",
      "         Iterations: 10\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 12\n",
      "[ 0.97625562 -0.04545534]\n"
     ]
    }
   ],
   "source": [
    "for city_id in [0,4,2,22]:\n",
    "    xgb_predicts_spb = xgb_predicts[train.city == city_id]\n",
    "    cat_predicts_spb = cat_predicts[train.city == city_id]\n",
    "    train_targets_spb = train_targets[train.city == city_id]\n",
    "\n",
    "    test_xgb_predict_spb = test_xgb_predict[test.city == city_id]\n",
    "    test_cat_predict_spb = test_cat_predict[test.city == city_id]\n",
    "\n",
    "    def minimize_arit_spb(W):\n",
    "        ypred = W[0] * xgb_predicts_spb + W[1] * cat_predicts_spb\n",
    "        return deviation_metric(train_targets_spb, ypred)\n",
    "\n",
    "\n",
    "    W_spb = minimize(minimize_arit_spb, [1.0 / 2] * 2, options={'gtol': 1e-6, 'disp': True}).x\n",
    "    print(W_spb)\n",
    "    new_score = test_xgb_predict_spb * W_spb[0] + test_cat_predict_spb * W_spb[1]\n",
    "    old_score = test_submission.loc[test.city == city_id, 'per_square_meter_price'].values\n",
    "    test_submission.loc[test.city == city_id, 'per_square_meter_price'] =  (new_score+old_score)/2\n",
    "test_submission.to_csv('submission_city.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e0da565",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission['per_square_meter_price'] = test_xgb_predict * W[0] + test_cat_predict * W[1]\n",
    "test_submission['per_square_meter_price'] = test_submission['per_square_meter_price'].apply(lambda x: max(1000.0, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ea29a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.049092\n",
      "         Iterations: 10\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 12\n",
      "[0.71474959 0.20057966]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.104496\n",
      "         Iterations: 8\n",
      "         Function evaluations: 30\n",
      "         Gradient evaluations: 10\n",
      "[0.60046668 0.29104654]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.828466\n",
      "         Iterations: 9\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 12\n",
      "[0.62227654 0.27797815]\n"
     ]
    }
   ],
   "source": [
    "for realty_id in [0,1,2]:\n",
    "    xgb_predicts_spb = xgb_predicts[train.realty_type == realty_id]\n",
    "    cat_predicts_spb = cat_predicts[train.realty_type == realty_id]\n",
    "    train_targets_spb = train_targets[train.realty_type == realty_id]\n",
    "\n",
    "    test_xgb_predict_spb = test_xgb_predict[test.realty_type == realty_id]\n",
    "    test_cat_predict_spb = test_cat_predict[test.realty_type == realty_id]\n",
    "\n",
    "    def minimize_arit_spb(W):\n",
    "        ypred = W[0] * xgb_predicts_spb + W[1] * cat_predicts_spb\n",
    "        return deviation_metric(train_targets_spb, ypred)\n",
    "\n",
    "\n",
    "    W_spb = minimize(minimize_arit_spb, [1.0 / 2] * 2, options={'gtol': 1e-6, 'disp': True}).x\n",
    "    print(W_spb)\n",
    "    new_score = test_xgb_predict_spb * W_spb[0] + test_cat_predict_spb * W_spb[1]\n",
    "    old_score = test_submission.loc[test.realty_type == realty_id, 'per_square_meter_price'].values\n",
    "    test_submission.loc[test.realty_type == realty_id, 'per_square_meter_price'] =  (new_score+old_score)/2\n",
    "\n",
    "test_submission.to_csv('submission_realty.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a4995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6efc1611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e5435d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
